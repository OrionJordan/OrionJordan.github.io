[
  {
    "objectID": "qmd/integral/intro.html",
    "href": "qmd/integral/intro.html",
    "title": "Integration",
    "section": "",
    "text": "This section of notes is all about integration. I am currently studying for the 2024 UNT Integration bee. On the left you’ll see detailed strategies for solving different types of integrals.\nThe scope of this section is limited to integrals whos contents may appear in the UNT integration bee. As such no methods for definite integrals will be shown."
  },
  {
    "objectID": "qmd/graph/GraphTheory.html",
    "href": "qmd/graph/GraphTheory.html",
    "title": "Graph Theory",
    "section": "",
    "text": "Graph Theory is the study of Graphs (Shocking) and their applications. The subject doesn’t require any real prerequisites, except some basic knowledge of naive set theory. Many problems in math and computer science can be modeled with graphs, despite seeming on the surface entirely unrelated. In fact, even chemist have begun to use graphs as a way to model molecules!\n\nTable of Contents\n0 - Graph Theory\n  0.1 - Preface\n  0.2 - Table of Contents\n1 - Introduction\n  1.1 - Graphs\n    1.1.1 - Definition\n    1.1.2 - Common Families of Graphs\n  1.2 - Vertex Degrees\n  1.3 - Paths, Cycles, Trails\n2 - Structure and Representation\n3 - Matching\n4 - Subgraphs\n5 - Trees\n6 - Connectivity\n7 - Planarity\n8 - Coloring\n9 - Flows\n10 - Hamilton Cycles"
  },
  {
    "objectID": "qmd/integral/simple/trivial.html",
    "href": "qmd/integral/simple/trivial.html",
    "title": "Basics",
    "section": "",
    "text": "Integration is the inverse of the differentiation. If \\frac{x}{dx}f(x) = g(x), then\n\n\\int g(x)dx = f(x) + C"
  },
  {
    "objectID": "qmd/basics/sets.html",
    "href": "qmd/basics/sets.html",
    "title": "Sets",
    "section": "",
    "text": "A set is a collection of elements, usually denoted with a capital letter A,B,\\cdots,Z. Important groups of numbers are denoted in Blackboard bold font; for example the set \\mathbb{N}, which refers to the natural numbers. Sets are given the following notation\nA set S containing the numbers 1,2 and 3 as elements is wrote S = \\{1,2,3\\}. The order in which the elements are listed is irrelevant, S = \\{1,2,3\\} = \\{3,2,1\\}. This notation becomes tedious however when attempting to write a set with a large amount of elements. This is where set builder notation comes in. Set builder notation defines a set in the form\nS = \\{\\text{A function of}\\: x \\:|\\: \\text{A predicate of}\\: x\\}\nFor example, the set of all square numbers would be\nS = \\{ x^2 \\:|\\: x \\in \\mathbb{N}\\} = \\{1,4,9,\\ldots\\}\nThere are very commonly used sets we assume the existence of, and denote with special characters to save time\nDefinition: Given any set A, the of A, denoted \\mathcal{P}(\\mathbb{A}) is the set of all subsets of A; i.e.\n\\mathcal{P}(A) = \\{B | B \\subseteq A\\}\nFor example, if A = \\{a,b\\}, then \\mathcal{P}(A) = \\{\\{\\},\\{a\\},\\{b\\},\\{a,b\\}\\} Notice that \\varnothing and A are always elements of \\mathcal{P}(A). Also note a \\not\\in \\mathcal{P}(A), but \\{a\\} \\in \\mathcal{P}(A)."
  },
  {
    "objectID": "qmd/basics/sets.html#footnotes",
    "href": "qmd/basics/sets.html#footnotes",
    "title": "Sets",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe notation \\mathbb{Z} for integers comes from the German word Zahlen, which means integer.↩︎"
  },
  {
    "objectID": "qmd/basics/sets1.html",
    "href": "qmd/basics/sets1.html",
    "title": "Sets",
    "section": "",
    "text": "A set is a collection of elements, usually denoted with a capital letter A,B,\\cdots,Z. Important groups of numbers are denoted in Blackboard bold font; for example the set \\mathbb{N}, which refers to the natural numbers. Sets are given the following notation\nA set S containing the numbers 1,2 and 3 as elements is wrote S = \\{1,2,3\\}. The order in which the elements are listed is irrelevant, S = \\{1,2,3\\} = \\{3,2,1\\}. This notation becomes tedious however when attempting to write a set with a large amount of elements. This is where set builder notation comes in. Set builder notation defines a set in the form\nS = \\{\\text{A function of}\\: x \\:|\\: \\text{A predicate of}\\: x\\}\nFor example, the set of all square numbers would be\nS = \\{ x^2 \\:|\\: x \\in \\mathbb{N}\\} = \\{1,4,9,\\ldots\\}\nThere are very commonly used sets we assume the existence of, and denote with special characters to save time\nDefinition: Given any set A, the of A, denoted \\mathcal{P}(\\mathbb{A}) is the set of all subsets of A; i.e.\n\\mathcal{P}(A) = \\{B | B \\subseteq A\\}\nFor example, if A = \\{a,b\\}, then \\mathcal{P}(A) = \\{\\{\\},\\{a\\},\\{b\\},\\{a,b\\}\\} Notice that \\varnothing and A are always elements of \\mathcal{P}(A). Also note a \\not\\in \\mathcal{P}(A), but \\{a\\} \\in \\mathcal{P}(A)."
  },
  {
    "objectID": "qmd/basics/sets1.html#footnotes",
    "href": "qmd/basics/sets1.html#footnotes",
    "title": "Sets",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe notation \\mathbb{Z} for integers comes from the German word Zahlen, which means integer.↩︎"
  },
  {
    "objectID": "qmd/basics/sets2.html",
    "href": "qmd/basics/sets2.html",
    "title": "Sets",
    "section": "",
    "text": "A set is a collection of elements, usually denoted with a capital letter A,B,\\cdots,Z. Important groups of numbers are denoted in Blackboard bold font; for example the set \\mathbb{N}, which refers to the natural numbers. Sets are given the following notation\nA set S containing the numbers 1,2 and 3 as elements is wrote S = \\{1,2,3\\}. The order in which the elements are listed is irrelevant, S = \\{1,2,3\\} = \\{3,2,1\\}. This notation becomes tedious however when attempting to write a set with a large amount of elements. This is where set builder notation comes in. Set builder notation defines a set in the form\nS = \\{\\text{A function of}\\: x \\:|\\: \\text{A predicate of}\\: x\\}\nFor example, the set of all square numbers would be\nS = \\{ x^2 \\:|\\: x \\in \\mathbb{N}\\} = \\{1,4,9,\\ldots\\}\nThere are very commonly used sets we assume the existence of, and denote with special characters to save time\nDefinition: Given any set A, the of A, denoted \\mathcal{P}(\\mathbb{A}) is the set of all subsets of A; i.e.\n\\mathcal{P}(A) = \\{B | B \\subseteq A\\}\nFor example, if A = \\{a,b\\}, then \\mathcal{P}(A) = \\{\\{\\},\\{a\\},\\{b\\},\\{a,b\\}\\} Notice that \\varnothing and A are always elements of \\mathcal{P}(A). Also note a \\not\\in \\mathcal{P}(A), but \\{a\\} \\in \\mathcal{P}(A)."
  },
  {
    "objectID": "qmd/basics/sets2.html#footnotes",
    "href": "qmd/basics/sets2.html#footnotes",
    "title": "Sets",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe notation \\mathbb{Z} for integers comes from the German word Zahlen, which means integer.↩︎"
  },
  {
    "objectID": "qmd/graph/intro/graphs.html",
    "href": "qmd/graph/intro/graphs.html",
    "title": "Graphs",
    "section": "",
    "text": "This section covers the definition of a graph, and common families of graphs."
  },
  {
    "objectID": "qmd/graph/intro/graphs.html#alternate-definition",
    "href": "qmd/graph/intro/graphs.html#alternate-definition",
    "title": "Graphs",
    "section": "Alternate definition",
    "text": "Alternate definition\nA more rigourous definition of a graph G will include an incidence function \\psi_G that connects vertices to edges.\n\n\n\n\n\n\nDefinition\n\n\n\nA graph G is an ordered pair (V(G),E(G)) where V(G) is a set of vertices and E(G) is a set, disjoint from V(G), of edges, along with an incidence function \\psi_G that associates each edge in E(G) an unordered pair of vertices in V(G).\n\n\nAn edge e is said to join its endpoints u,v if \\psi_G(e) = \\{u,v\\}.\n\n\n\n\n\n\nExample (Rigourous Graph)\n\n\n\n\n\nAn example of a rigourous graph G is\n\nG = (V(G),E(G))\n\nwhere\n\nV(G) = \\{a,b,c,d,e\\}\\\\\nE(G) = \\{e_1,e_2,e_3,e_4,e_5,e_6,e_7,e_8\\}\n\nand \\psi_G conncects\n\n\\psi_G(e_1) = \\{a,b\\}, \\psi_G(e_2) = \\{a,a\\}, \\psi_G(e_3) = \\{a,c\\}, \\psi_G(e_4) = \\{b,e\\}\\\\\n\\psi_G(e_5) = \\{b,a\\}, \\psi_G(e_6) = \\{c,b\\}, \\psi_G(e_7) = \\{d,d\\}, \\psi_G(e_8) = \\{c,e\\}"
  },
  {
    "objectID": "qmd/graph/intro/graphs.html#complete-graphs",
    "href": "qmd/graph/intro/graphs.html#complete-graphs",
    "title": "Graphs",
    "section": "Complete Graphs",
    "text": "Complete Graphs\n\n\n\n\n\n\nDefinition\n\n\n\nA complete graph is a simple graph where there exist an edge between every pair of distinct vertices. A complete graph with n vertices is notated K_n.\n\n\n(Insert picture of graphs K1 through K5)\n\n\n\n\n\n\nTheorem\n\n\n\nA complete graph K_n contains \\binom{n}{2} edges.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nThe graph K_n has an edge between every pair of distinct vertices. Because order doesn’t affect edges (e = uv is equivalent to e = vu), the number of edges is analougous to n choose 2, \\binom{n}{2}."
  },
  {
    "objectID": "qmd/graph/intro/graphs.html#bipartite-graphs",
    "href": "qmd/graph/intro/graphs.html#bipartite-graphs",
    "title": "Graphs",
    "section": "Bipartite Graphs",
    "text": "Bipartite Graphs\n\n\n\n\n\n\nDefinition\n\n\n\nA bipartite graph G is a simple graph whose vertex set can be partitioned into two subsets U and V, such that every edge in G has one endpoint in U, and one edpoint in V.\n\n\n(Insert picture of a few bipartite graphs)\n\n\n\n\n\n\nProposition\n\n\n\nA bipartite graph cannot contain any loops.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nIf an edge was loop, it would connect the same vertex to both endpoints, which contradicts our definition of a bipartite graph.\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA complete bipartite graph G is a simple bipartite graph such that every vertex in one of the bipartition subsets is joined to every other vertex in the other bipartite subset. A complete bipartite graph is notated K_{m,n} where m is the number of vertices in one of the graphs bipartite set, and n is the number of vertices in the other.\n\n\n(Example of a complete bipartite graph)"
  },
  {
    "objectID": "qmd/graph/intro/graphs.html#regular-graphs",
    "href": "qmd/graph/intro/graphs.html#regular-graphs",
    "title": "Graphs",
    "section": "Regular Graphs",
    "text": "Regular Graphs\nTo look at regular graphs, we first have to establish the degree of a vertex.\n\n\n\n\n\n\nDefinition\n\n\n\nThe degree of a vertex v is a positive integer equal to the number of vertices in the neighborhood of v.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA k-regular graph is a graph where each vertex has k other vertices in it’s neighborhood.\n\n\n\n\n\n\n\n\nExample\n\n\n\n\n\n\n\n\n\n\n\n\nFor example, the Petersen graph is 3-regular, as each vertex in the graph has three other vertices in it’s neighborhood."
  },
  {
    "objectID": "qmd/graph/trees/Matchings.html",
    "href": "qmd/graph/trees/Matchings.html",
    "title": "Matchings",
    "section": "",
    "text": "A Matching is a name given to a collection of edges in a graph G with no common vertex.\n\n\n\n\n\n\nDefinition\n\n\n\nGiven a graph G and a matching M\nAn alternating path is a path that alternates between edges in M and edges outside of M.\nAn augmented Path is an alternating path that starts and ends on vertices not included in the matching.\n\n\nNote that is (G,M) has an augmented path, than M is not a maximum matching, as flipping each edge to be in M if it wasn’t before, or out of M if it was produces a matching with more edges.\n\n\n\n\n\n\nDefinition\n\n\n\nA perfect matching is a matching where every vertex is in the matching.\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nA matching M in a graph G is maximum if and only if there are no augementing paths in G\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe already know that if G,M has an augmented path, then M is not maximum. All we need to prove is thay if there are no augmented paths, than M is maximum. If we assume M is not maximum, there exist a matching M^\\prime such that |M^\\prime| &gt; |M|.\nConsider the graph with a vertex set of V(G) and an edge set M \\Delta M^\\prime. Every vertex in this graph has a degree less than or equal to 2. Any connected componet of this new graph will be either a path or a cycle."
  },
  {
    "objectID": "qmd/about.html",
    "href": "qmd/about.html",
    "title": "Orions Online Math Notes",
    "section": "",
    "text": "A work in progress website documenting my varius math and lecture notes."
  },
  {
    "objectID": "qmd/random/discrete.html",
    "href": "qmd/random/discrete.html",
    "title": "Discrete Calculus",
    "section": "",
    "text": "Discrete calculus, sometimes called Finite calculus, is the study of incremental change, as opposed to regular calculus, the study of continuous change. Discrete calculus most regularly deals with solving summations and functions defined on the natural numbers."
  },
  {
    "objectID": "qmd/random/discrete.html#discrete-derivative",
    "href": "qmd/random/discrete.html#discrete-derivative",
    "title": "Discrete Calculus",
    "section": "Discrete Derivative",
    "text": "Discrete Derivative\nIn continuous calculus, the derivative is the ‘instantaneous rate of change’ of a function. That concept can’t exist with incremental change. The smallest rate of change in a discrete function is the change between integers. Therefore we define our discrete derivative\n\n\n\n\n\n\nDefinition\n\n\n\nThe discrete derivative is the smallest change in a discrete function, defined $$ f(x) = f(x+1) - f(x)\n\n\nWe can now prove may properties about the discrete derivative\n\n\n\n\n\n\nTheorem\n\n\n\nThe discrete derivative has the following properties\nConstant rule\n\\Delta c = 0 for all c \\in \\mathbb{N}\nLinearity\n\\Delta af(x) = a \\Delta f(x)\nProduct rule\n\\Delta f(x)g(x) = f(x) \\Delta g(x) + g(x) \\Delta f(x) + \\Delta f(x) \\Delta g(x)\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nTo-do\n\n\n\n\nFunctions\nNow that we’ve defined the discrete derivative, we can start finding the discrete derivative of functions.\nTake for example, the function"
  },
  {
    "objectID": "qmd/integral/simple/basics.html",
    "href": "qmd/integral/simple/basics.html",
    "title": "Basics",
    "section": "",
    "text": "Integration is the inverse of the differentiation. If f^\\prime(x) = g(x), then\n\\int g(x)\\,dx = f(x) + C.\nIntegrals have a property called linearity. This means they are closed under linear transformations of functions, as shown below.\n\\int \\alpha f(x) + \\beta g(x) \\,dx = \\alpha \\int f(x) \\,dx+ \\beta \\int g(x) \\,dx"
  },
  {
    "objectID": "qmd/integral/simple/basics.html#inverse-power-rule",
    "href": "qmd/integral/simple/basics.html#inverse-power-rule",
    "title": "Basics",
    "section": "Inverse power rule",
    "text": "Inverse power rule\nOne of the basic rules of differentiation is that of power rule.\n\n\\frac{d}{dx} x^m = mx^{m-1}\n\nSuspecting this will be a useful property, we can derive an expression for the inverse power rule from the definition of an integral.\n\n\\int mx^{m-1} dx = x^m\n\nApply linearity and the substituion n = m-1\n\n\\int x^{n} dx = \\frac{x^{n+1}}{n+1}\n\n\n\n\n\n\n\nExample\n\n\n\n\n\nFind the solution to the following integral\n\n\\int 2x^2 - 3x - 1 \\, dx\n\nWe first begin by applying linearity\n\n= 2 \\int x^2 \\,dx - 3\\int x \\, dx - \\int 1x^0 \\, dx\n\nThen inverse power rule\n\n= \\frac{2x^3}{3} - \\frac{3x^2}{2} - x + C\n\nGiving us a solution to the polynomial. This process can be done for any standard polynomial.\n\n\n\n\n\n\n\n\n\nTheorem (Integration of a polynomial)\n\n\n\nLet f(x) be a polynomial in the form\n\nf(x) = a_nx^n + a_{n-1}x^{n-1} + \\cdots + a_1x + c\n\nThen\n\n\\int f(x)\\,dx = \\frac{a_nx^{n+1}}{n+1} + \\frac{a_{n-1}x^{n}}{n} +  \\cdots + \\frac{a_1x^2}{2} + cx + C\n\n\n\n\nEdge case\nOne may notice that when n=-1, inverse power rules gives us an undefined result\n\n\\int x^{-1}\\,dx = \\frac{1}{0} + C.\n\nFor this particular value of n, we get the expression\n\n\\int x^{-1}\\,dx = \\ln|x| + C.\n\nNote the absolute value bars. This is because the function \\ln is not defined for negative values of x, where our integrand is."
  },
  {
    "objectID": "qmd/integral/simple/basics.html#common-identities",
    "href": "qmd/integral/simple/basics.html#common-identities",
    "title": "Basics",
    "section": "Common identities",
    "text": "Common identities\nThis section will cover many commonly used integration identities without much explanation.\n\nTrig identities\nTrigonometry is a huge part of the integration bee, and will repeatedly appear in almost every section of this guide. As such it is crucial to have a complete understanding of these functions and how they interact.\nThe integrals below are the direct inverse of differentiating the six primary trig functions.\n\\begin{array}{ll}\n\\displaystyle\\int{{\\cos x\\,dx}} = \\sin x + C \\hspace{0.5in} & \\displaystyle\\int{{\\sin x\\,dx}} =  - \\cos x + C\\\\\n\n\\displaystyle\\int{{{{\\sec }^2}x\\,dx}} = \\tan x + C \\hspace{0.5in} & \\displaystyle\\int{{{{\\csc }^2}x\\,dx}} =  - \\cot x + C\\\\\n\n\\displaystyle\\int{{\\sec x\\tan x\\,dx}} = \\sec x + C \\hspace{0.5in} & \\displaystyle\\int{{\\csc x\\cot x\\,dx}} =  - \\csc x + C\n\\end{array}\nIt is helpful (for me at least) to memorize the left column of the table, and then derive the right side by replacing each function with its ‘compliment’, and then negating the result.\n\n\nInverse Trig identities\nWe can use special formulas to differentiate inverse functions. By differentiating \\arcsin(x) and \\arctan(x), we get\n\n\\int \\frac{1}{x^2 + 1} \\, dx = \\arctan(x) + C \\hspace{0.5in} \\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = \\arcsin(x) + C\n\nIt is worth noting that\n\n\\frac{d}{dx}\\arccos(x) = -\\frac{1}{1-x^2}.\n\nSo the second integral can also be solved\n\n\\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = -\\arccos(x) + C.\n\nThis is because \\arcsin and -\\arccos differ by a constant (\\frac{\\pi}{2}).\n\n\nExponential and logarithmic functions\nBy once again inverting common derivative rules, we get the following identities.\n\n\\int e^x \\, dx = e^x + C \\hspace{0.5in} \\int a^x \\,dx = \\frac{a^x}{\\ln{x}} + C"
  },
  {
    "objectID": "qmd/integral/simple/substitution.html",
    "href": "qmd/integral/simple/substitution.html",
    "title": "Substitution",
    "section": "",
    "text": "The motivating example for this section will be the integral shown below.\n\\int \\sec^2(x)e^{1 + \\tan{x}} \\, dx\nThe techniques shown in the last section don’t work here. Linearity does not allow for separation of products, and we don’t have an identity which gets us a solution. In order to solve these types of integrals, we’ll need a new rule.\nSubstitution for integrals is often in the form\n\\int f(g(x))g^\\prime(x)\\, dx = \\int f(u)\\, du, \\text{where } u = g(x)."
  },
  {
    "objectID": "qmd/integral/simple/substitution.html#inverse-power-rule",
    "href": "qmd/integral/simple/substitution.html#inverse-power-rule",
    "title": "Substitution",
    "section": "Inverse power rule",
    "text": "Inverse power rule\nOne of the basic rules of differentiation is that of power rule.\n\n\\frac{d}{dx} x^m = mx^{m-1}\n\nSuspecting this will be a useful property, we can derive an expression for the inverse power rule from the definition of an integral.\n\n\\int mx^{m-1} dx = x^m\n\nApply linearity and the substituion n = m-1\n\n\\int x^{n} dx = \\frac{x^{n+1}}{n+1}\n\n\n\n\n\n\n\nExample\n\n\n\n\n\nFind the solution to the following integral\n\n\\int 2x^2 - 3x - 1 \\, dx\n\nWe first begin by applying linearity\n\n= 2 \\int x^2 \\,dx - 3\\int x \\, dx - \\int 1x^0 \\, dx\n\nThen inverse power rule\n\n= \\frac{2x^3}{3} - \\frac{3x^2}{2} - x + C\n\nGiving us a solution to the polynomial. This process can be done for any standard polynomial.\n\n\n\n\n\n\n\n\n\nTheorem (Integration of a polynomial)\n\n\n\nLet f(x) be a polynomial in the form\n\nf(x) = a_nx^n + a_{n-1}x^{n-1} + \\cdots + a_1x + c\n\nThen\n\n\\int f(x)\\,dx = \\frac{a_nx^{n+1}}{n+1} + \\frac{a_{n-1}x^{n}}{n} +  \\cdots + \\frac{a_1x^2}{2} + cx + C\n\n\n\n\nEdge case\nOne may notice that when n=-1, inverse power rules gives us an undefined result\n\n\\int x^{-1}\\,dx = \\frac{1}{0} + C.\n\nFor this particular value of n, we get the expression\n\n\\int x^{-1}\\,dx = \\ln|x| + C.\n\nNote the absolute value bars. This is because the function \\ln is not defined for negative values of x, where our integrand is."
  },
  {
    "objectID": "qmd/integral/simple/substitution.html#common-identities",
    "href": "qmd/integral/simple/substitution.html#common-identities",
    "title": "Substitution",
    "section": "Common identities",
    "text": "Common identities\nThis section will cover many commonly used integration identities without much explanation.\n\nTrig identities\nTrigonometry is a huge part of the integration bee, and will repeatedly appear in almost every section of this guide. As such it is crucial to have a complete understanding of these functions and how they interact.\nThe integrals below are the direct inverse of differentiating the six primary trig functions.\n\\begin{array}{ll}\n\\displaystyle\\int{{\\cos x\\,dx}} = \\sin x + C \\hspace{0.5in} & \\displaystyle\\int{{\\sin x\\,dx}} =  - \\cos x + C\\\\\n\n\\displaystyle\\int{{{{\\sec }^2}x\\,dx}} = \\tan x + C \\hspace{0.5in} & \\displaystyle\\int{{{{\\csc }^2}x\\,dx}} =  - \\cot x + C\\\\\n\n\\displaystyle\\int{{\\sec x\\tan x\\,dx}} = \\sec x + C \\hspace{0.5in} & \\displaystyle\\int{{\\csc x\\cot x\\,dx}} =  - \\csc x + C\n\\end{array}\nIt is helpful (for me at least) to memorize the left column of the table, and then derive the right side by replacing each function with its ‘compliment’, and then negating the result.\n\n\nInverse Trig identities\nWe can use special formulas to differentiate inverse functions. By differentiating \\arcsin(x) and \\arctan(x), we get\n\n\\int \\frac{1}{x^2 + 1} \\, dx = \\arctan(x) + C \\hspace{0.5in} \\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = \\arcsin(x) + C\n\nIt is worth noting that\n\n\\frac{d}{dx}\\arccos(x) = -\\frac{1}{1-x^2}.\n\nSo the second integral can also be solved\n\n\\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = -\\arccos(x) + C.\n\nThis is because \\arcsin and -\\arccos differ by a constant (\\frac{\\pi}{2}).\n\n\nExponential and logorithmic functions\nBy once again inversing common derivaitve rules, we get the following identites.\n\n\\int e^x \\, dx = e^x + C \\hspace{0.5in} \\int a^x \\,dx = \\frac{a^x}{\\ln{x}} + C"
  },
  {
    "objectID": "qmd/integral/simple/intpart.html",
    "href": "qmd/integral/simple/intpart.html",
    "title": "Integration by parts",
    "section": "",
    "text": "There will often be integrals where substitution cannot simplify the integrand into one term. We can use the following as our motivating example\n\\int x e^{6x} dx\nAttempting to use a substitution, such as u = 6x gives us\n\\int ue^u\\,du\nwhich while technically simpler gets us nowhere. We need a new technique to be able to properly separate functions where substitution fails. This is where integration by parts comes in.\nLets try to use the formula to solve our example. We can choose u to be either term in our example.\nAnd voila, our integral is solved."
  },
  {
    "objectID": "qmd/integral/simple/intpart.html#tabular-method",
    "href": "qmd/integral/simple/intpart.html#tabular-method",
    "title": "Integration by parts",
    "section": "Tabular method",
    "text": "Tabular method\nAn easier (faster) way to do integration by parts is known as the Tabular method. The tabular method can quickly calculate repeated integration by parts.\n\n\n\n\n\n\nExample (Stop 1)\n\n\n\n\n\nThe following example will show the first ‘stop’ used in tabular integration.\nFind the solution to the following integral\n\n\\int x^2 \\sin(3x) \\, dx\n\nThis could be solved using our formula for integration by parts, but this results in a messy calculation using repeated integration by parts. In order to solve these problems faster, we will use the Tabular method.\nFirst, choose two terms to work with in the integral. We will choose x^2 and \\sin(3x). We want to choose a term that will eventually default to 0 after repeated differention. Place this term under the D in your table, and the other term under the I. Draw a plus to the left of your terms.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} x^2 \\hspace{0.25in} & \\sin(3x)\n\\end{array}\nTo begin, we will differentiate the term under our D, and integrate the term under our I, then flip the sign.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} x^2 \\hspace{0.25in} & \\sin(3x)\\\\\n- & \\hspace{0.25in} 2x \\hspace{0.25in} & \\frac{1}{3}\\cos(3x)\n\\end{array}\nRepeating this process eventually gives us a 0 in our D column. This is our first stop, meaning we don’t need any more steps.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} x^2 \\hspace{0.25in} & \\sin(3x)\\\\\n- & \\hspace{0.25in} 2x \\hspace{0.25in} & -(1/3)\\cos(3x)\\\\\n+ & \\hspace{0.25in} 2 \\hspace{0.25in} & -(1/9)\\sin(3x)\\\\\n- & \\hspace{0.25in} 0 \\hspace{0.25in} & (1/27)\\cos(3x)\\\\\n\\end{array}\nMultiply the n^{th} under the D by the (n+1)^{th} term under the I. Then add or subtract the product by the sign the the left of the D column. This is the answer to our integral.\n\n\\int x^2 \\sin (3x) \\,dx = -\\frac{1}{3}x^2\\cos(3x) + \\frac{2}{9}x\\sin(3x) - \\frac{2}{27}\\cos(3x) + C\n\nAnd we’re done!\n\n\n\n\n\n\n\n\n\nExample (Stop 2)\n\n\n\n\n\nThe following example will show the second ‘stop’ used in tabular integration.\n\n\\int x^4 \\ln x \\,dx\n\nAlthough it seems obvious we should put x^4 under the D column, we quickly realize that we cannot integrate \\ln x without integration by parts. Because of this, we have no choice but to but \\ln x under the D column. Carrying on with our calculations\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} \\ln x \\hspace{0.25in} & x^4\\\\\n- & \\hspace{0.25in} x^{-1} \\hspace{0.25in} & (1/5)x^5\n\\end{array}\nWe can quickly notice that 0 will never appear under the D column. This is where our second stop comes in. If we can easily calculate the integral of a rows product (That is, the product of terms under the D and I columns for a singular row) than we stop, and add the integral of that row to our diagonal solution.\n\n\\int x^4 \\ln x \\,dx = \\frac{1}{5}x^5\\ln x  - \\frac{1}{5} \\int x^{-1}x^5\n\nThis is formula for regular integration by parts, so unfortunately this didn’t save us any time, but we still got the right answer!\n\n\\int x^4 \\ln x \\,dx = \\frac{1}{5}x^5\\ln x  - \\frac{1}{25} x^5\n\n\n\n\n\n\n\n\n\n\nExample (Stop 3)\n\n\n\n\n\nThe following example will show the third ‘stop’ used in tabular integration.\n\n\\int e^x \\sin x \\,dx\n\nIntegrating e^x and \\sin x are both easy. I’ll choose to integrate e^x for simplicity sake.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} \\sin x \\hspace{0.25in} & e^x\\\\\n- & \\hspace{0.25in} \\cos x \\hspace{0.25in} & e^x\\\\\n+ & \\hspace{0.25in} -\\sin x \\hspace{0.25in} & e^x\\\\\n- & \\hspace{0.25in} -\\cos x \\hspace{0.25in} & e^x\n\\end{array}\nClearly this will go on forever without a 0 under our D column, or an easily integrable row. This introduces our third stop. Notice that our first and third rows only differ by a constant coefficient. When this happens, we write our diagonalization and our integral, stopping at the repeated row.\n\n\\int e^x \\sin x \\,dx = e^x \\sin x - e^x \\cos(x) - \\int e^x \\sin x \\, dx\n\nNotice how this is the same integral on the left and right hand of the equation. Moving the integral over gives us\n\n2\\int e^x \\sin x \\,dx = e^x \\sin x - e^x \\cos(x)\n\nDiving by 2\n\n\\int e^x \\sin x \\,dx = \\frac{e^x \\sin x - e^x \\cos(x)}{2}\n\nAnd we have our answer.\n\n\n\nClearly the tabular method is a huge time saver for repeated integration by parts."
  },
  {
    "objectID": "qmd/integral/simple/basics.html#examples",
    "href": "qmd/integral/simple/basics.html#examples",
    "title": "Basics",
    "section": "Examples",
    "text": "Examples\nSome example problems from various websites\n\nInverse power rule\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.1.1)\n\n\n\nEvaluate the following integral\n\n\\int 6x^5 - 18x^2 + 7 \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the formula for evaluating polynomials\n\n\\int 6x^5 - 18x^2 + 7 \\, dx = x^6 - 6x^3 + 7x + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.1.1)\n\n\n\nEvaluate the following integral\n\n\\int 6x^5\\, dx - 18x^2 + 7\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNotice the integral ends at the dx, meaning the solution is\n\n\\int 6x^5 - 18x^2 + 7 \\, dx = x^6 - 18x^2 + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.1.3)\n\n\n\nEvaluate the following integral\n\n\\int 12t^7 - t^2 - t + 3 \\, dt\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nClassic polynomial, the only difference is the use of t instead of x\n\n\\int 12t^7 - t^2 - t + 3 \\, dt = \\frac{3}{2}t^8 - \\frac{1}{3}t^3 - \\frac{1}{2}t^2 + 3t + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.6)\n\n\n\nEvaluate the following integral\n\n\\int \\sqrt[3]{w} + 10\\sqrt[5]{w^3}\\, dw\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nConvert the radicals to fractional exponets\n\n\\int \\sqrt[3]{w} + 10\\sqrt[5]{w^3}\\, dw = \\int w^\\frac{1}{3} + 10w^\\frac{3}{5} \\, dw\n\nAnd then apply inverse power rule\n\n\\int \\sqrt[3]{w} + 10\\sqrt[5]{w^3}\\, dw = \\frac{3}{4}w^\\frac{4}{3} + \\frac{25}{4}w^\\frac{8}{5} + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.9)\n\n\n\nEvaluate the following integral\n\n\\int \\frac{7}{3y^6} + \\frac{1}{y^{10}} - \\frac{2}{\\sqrt[3]{y^4}} \\, dy\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nConvert the radicals to fractional exponents\n\n\\int \\frac{7}{3y^6} + \\frac{1}{y^{10}} - \\frac{2}{\\sqrt[3]{y^4}} \\, dy = \\int \\frac{7}{3}y^{-6} + y^{-10} - 2y^{\\frac{4}{3}} \\, dy\n\nAnd then apply inverse power rule\n\n\\int \\frac{7}{3y^6} + \\frac{1}{y^{10}} - \\frac{2}{\\sqrt[3]{y^4}} \\, dy = -\\frac{7}{15}y^{-5} - \\frac{1}{9} y^{-9} + 6y^{-\\frac{1}{3}} + C\n\nBe careful to make sure you have the right answer.\n\n\n\n\n\nCommon identites\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.14)\n\n\n\nEvaluate the following integral\n\n\\int \\sin x + 10 \\csc^2 x \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSimply use linearity to break up the integral, and then apply identities\n\n\\int \\sin x + 10 \\csc^2 x \\, dx = -\\cos x - 10 \\cot x + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.15)\n\n\n\nEvaluate the following integral\n\n\\int 2\\cos x - \\sec x\\tan x \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSimply use linearity to break up the integral, and then apply identities\n\n\\int 2\\cos x - \\sec x\\tan x \\, dx = 2 \\sin x - \\sec x + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.16)\n\n\n\nEvaluate the following integral\n\n\\int 12 + \\csc \\theta \\left( {\\sin  \\theta  + \\csc  \\theta } \\right)\\,d\\theta\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nMultiply out and simplify the equation. \n\\int 12 + \\csc \\theta \\left( {\\sin  \\theta  + \\csc  \\theta } \\right)\\,d\\theta = \\int 12 + 1 + \\csc^2 \\theta \\, d\\theta\n\nBecause\n\n\\csc x= \\frac{1}{\\sin x}\n\nSo we get the answer\n\n\\int 12 + \\csc \\theta \\left( {\\sin  \\theta  + \\csc  \\theta } \\right)\\,d\\theta = 13 \\theta + \\cot \\theta + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.20)\n\n\n\nEvaluate the following integral\n\n\\int{{\\frac{1}{{1 + {x^2}}} + \\frac{{12}}{{\\sqrt {1 - {x^2}} }}\\,dx}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the inverse trig identities\n\n\\int{{\\frac{1}{{1 + {x^2}}} + \\frac{{12}}{{\\sqrt {1 - {x^2}} }}\\,dx}} = \\arctan x + 12 \\arcsin x + C"
  },
  {
    "objectID": "qmd/integral/simple/substitution.html#examples",
    "href": "qmd/integral/simple/substitution.html#examples",
    "title": "Substitution",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.3.1)\n\n\n\nEvaluate the following integral\n\n\\int   {{\\left( {8x - 12} \\right){{\\left( {4{x^2} - 12x} \\right)}^4}\\,dx}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the substitution\n\nu = 4x^2 - 12x\n\nWe get \n\\int   {{\\left( {8x - 12} \\right){{\\left( {4{x^2} - 12x} \\right)}^4}\\,dx}} = \\frac{1}{5}(4x^2 - 12x)^5 + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.3.2)\n\n\n\nEvaluate the following integral\n\n\\int{{3{t^{ - 4}}{{\\left( {2 + 4{t^{ - 3}}} \\right)}^{ - 7}}\\,dt}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the substitution\n\nu = 2 - 4t^{-3}\n\nWe get \n\\int{{3{t^{ - 4}}{{\\left( {2 + 4{t^{ - 3}}} \\right)}^{ - 7}}\\,dt}} = \\frac{1}{24}(2+4t^{-3})^{-6} + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.3.14)\n\n\n\nEvaluate the following integral\n\n\\int \\frac{\\csc x \\cot c}{2- \\csc x} \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFirst notice how \\csc x \\cot x is clearly the derivative of -\\csc x. This leads us to try some form of \\csc x for u. I use\n\nu = \\csc x\n\nLeading too \n\\int \\frac{\\csc x \\cot c}{2- \\csc x} \\, dx = - \\int \\frac{1}{2 - u} \\, du\n\nWhich is clearly\n\n\\int \\frac{\\csc x \\cot c}{2- \\csc x} \\, dx = \\ln |2 - u| + C = \\ln |2 - \\csc x| + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.3.13)\n\n\n\nEvaluate the following integral\n\n\\int{{10\\sin \\left( {2x} \\right)\\cos \\left( {2x} \\right)\\sqrt {{{\\cos }^2}\\left( {2x} \\right) - 5} \\,dx}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWhile the integral looks incredibly complex, if we substitute the term inside the radical (the usual choice) we can start to break it down.\n\nu = \\cos^2(2x) - 5\n\nThus \n\\int{{10\\sin \\left( {2x} \\right)\\cos \\left( {2x} \\right)\\sqrt {{{\\cos }^2}\\left( {2x} \\right) - 5} \\,dx}} = -\\frac{5}{2} \\int \\sqrt{u} \\, du\n\nWhich leads too\n\n\\int{{10\\sin \\left( {2x} \\right)\\cos \\left( {2x} \\right)\\sqrt {{{\\cos }^2}\\left( {2x} \\right) - 5} \\,dx}} = -\\frac{5}{3}(\\cos^2(2x) - 5)^\\frac{3}{2} + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.3.15)\n\n\n\nEvaluate the following integral\n\n\\int \\frac{6}{7 + y^2} \\,dy\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis does not follow our usual f(g(x))g^\\prime(x) example. For this case, we’ll try to convert into an identity we know. It is clear we can’t have y^2 be a term in u, as this would only make the integral more complicated (as thers no y to be consumed in the du). The integrand sorta resembles the derivative of \\arctan y, so we can try to rewrite it\n\n\\int \\frac{6}{7 + y^2} \\,dy = \\frac{6}{7} \\int \\frac{1}{1 + \\frac{y^2}{7}} \\, dy\n\nNotice that if we make the substitution \nu = \\frac{y}{\\sqrt{7}}\n\nWe get\n\n\\int \\frac{6}{7 + y^2} \\,dy = \\frac{6\\sqrt{7}}{7} \\int \\frac{1}{1 + u^2} \\, du\n\nWhich gives us\n\n\\int \\frac{6}{7 + y^2} \\,dy = \\frac{6\\sqrt{7}}{7} \\arctan \\left(\\frac{y}{\\sqrt{7}}\\right) + C\n\n\n\n\n\n\n\n\n\n\nProblem - Arctan generalization\n\n\n\nEvaluate the previous integral in it’s general form\n\n\\int \\frac{1}{a^2 + x^2} \\,dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLike last time, we’ll factor out a^2 from the bottom and then use a substitution.\n\n\\int \\frac{1}{a^2 + x^2} \\,dx = \\frac{1}{a^2} \\int \\frac{1}{1 + (x^2/a^2)} \\, dy\n\nMakeing the substitution \nu = \\frac{x}{a}\n\nWe get\n\n\\int \\frac{1}{a^2 + x^2} \\,dx = \\frac{1}{a} \\int \\frac{1}{1 + u^2} \\, dx\n\nWhich gives us\n\n\\int \\frac{1}{a^2 + x^2} \\,dx = \\frac{1}{a} \\arctan \\left(\\frac{x}{a}\\right) + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.4.6)\n\n\n\nEvaluate the following integral\n\n\\int{{20{{e}^{2 - 8w}}\\sqrt {1 + {{e}}^{2 - 8w}}} \\, + 7{w^3} - 6\\,\\,\\sqrt[3]{w}\\,dw}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing linearity on the integral allows us to do different substitutions. Seeing as the last two terms can be integrated with the inverse power rule, we only need to a substitution on the first term. Luckily this is an easy case.\n\nu = 1 + e^{2-8w}\n\nGives\n\n\\int{{20{{e}^{2 - 8w}}\\sqrt {1 + {{e}}^{2 - 8w}}} \\,dw} = -\\frac{5}{2}\\int \\sqrt{u}\\, du\n\nWhich is\n\n\\int{{20{{e}^{2 - 8w}}\\sqrt {1 + {{e}}^{2 - 8w}}} \\,dw} = -\\frac{5}{3}(1 + e^{2-8w})^\\frac{3}{2} + C\n\nThen solving the other terms gives us our solution.\n\n= -\\frac{5}{3}(1 + e^{2-8w})^\\frac{3}{2} + \\frac{7}{4}w^4 - \\frac{9}{2}w^\\frac{4}{3} + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus II - A7.1.18)\n\n\n\nEvaluate the following integral\n\n\\int{{\\frac{{{x^7}}}{{\\sqrt {{x^4} + 1} }}\\,dx}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the substitution\n\nu = x^4 + 1\n\nWe get\n\n\\int{{\\frac{{{x^7}}}{{\\sqrt {{x^4} + 1} }}\\,dx}} = \\frac{1}{4}\\int \\frac{u - 1}{\\sqrt{u}}\n\nWhich we can then apply linearity and inverse power rule to, giving us\n\n\\int{{\\frac{{{x^7}}}{{\\sqrt {{x^4} + 1} }}\\,dx}} = \\frac{1}{4}\\left( \\frac{2}{3}(x^4 + 1)^\\frac{3}{2} + 2(x^4 + 1)^\\frac{1}{2}\\right) + C"
  },
  {
    "objectID": "qmd/integral/simple/intpart.html#examples",
    "href": "qmd/integral/simple/intpart.html#examples",
    "title": "Integration by parts",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\n\nProblem\n\n\n\nEvaluate the following integral\n\n\\int \\ln x \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSolving this is a little counter intuitive seeing as it only has one term. If we let 1 be the second term however, we can evaluate with the tabular method. We pretty cleary have the integrate 1, as we can’t integrate \\ln x.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} \\ln x \\hspace{0.25in} & 1\\\\\n- & \\hspace{0.25in} \\frac{1}{x} \\hspace{0.25in} & x\n\\end{array}\nBecause the product of the second row is easy to integrate, we stop using the tabular method and compute.\n\n\\int \\ln x \\, dx = x \\ln x - \\int 1 \\, dx = x \\ln x - x + C\n\nWhich solves our integral.\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus II - 7.1.1)\n\n\n\nEvaluate the following integral\n\n\\int 4x \\cos \\left( {2 - 3x} \\right)\\,dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe have two terms, 4x and \\cos (2-3x). Its clear that differentiaing 4x will give us 0 quickly, so we begin with the tabular method.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} 4x \\hspace{0.25in} & \\cos (2-3x)\\\\\n- & \\hspace{0.25in} 4 \\hspace{0.25in} & -(1/3)\\sin (2-3x)\\\\\n+ & \\hspace{0.25in} 0 \\hspace{0.25in} & -(1/9)\\cos (2-3x)\\\\\n\\end{array}\nWe use the first stop, and get the following solution to the integral\n\n\\int 4x \\cos \\left( {2 - 3x} \\right)\\,dx = -\\frac{4x}{3}\\sin (2-3x) - \\frac{4}{9} \\cos (2-3x) + C\n\nWhich solves our integral.\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus II - 7.1.5)\n\n\n\nEvaluate the following integral\n\n\\int{{e}^{2x}}\\cos \\left( {\\frac{1}{4}x} \\right)\\,dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWithout any leads on which term to integrate, I choose to integrate cos(\\frac{1}{4}x) on a whim. You may integrate either term however, and the answer will be the same.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} e^{2x} \\hspace{0.25in} & \\cos ((1/4)x)\\\\\n- & \\hspace{0.25in} 2e^{2x} \\hspace{0.25in} & 4\\sin ((1/4)x)\\\\\n+ & \\hspace{0.25in} 4e^{2x} \\hspace{0.25in} & -16\\cos ((1/4)x)\\\\\n\\end{array}\nNotice how the product of row three is a multiple of our initial integral. This is the third stop, so we evaluate our table to get.\n\n\\int{{e}^{2x}}\\cos \\left( {\\frac{1}{4}x} \\right)\\,dx = 4e^{2x}\\sin(\\frac{1}{4}x) + 32e^{2x}\\cos(\\frac{1}{4}x) - 64\\int{{e}^{2x}}\\cos \\left( {\\frac{1}{4}x} \\right)\\,dx\n\n\n65 \\int{{e}^{2x}}\\cos \\left( {\\frac{1}{4}x} \\right)\\,dx = 4e^{2x}\\sin(\\frac{1}{4}x) + 32e^{2x}\\cos(\\frac{1}{4}x)\n\n\n\\int{{e}^{2x}}\\cos \\left( {\\frac{1}{4}x} \\right)\\,dx = \\frac{4e^{2x}\\sin(\\frac{1}{4}x) + 32e^{2x}\\cos(\\frac{1}{4}x)}{65}\n\nWhich solves our integral.\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus II - A7.1.12)\n\n\n\nEvaluate the following integral\n\n\\int 8\\arctan\\left( 2x \\right)\\,dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nBecause integrating \\arctan is the question, we will derive it instead, and integrate the 8.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} \\arctan(2x) \\hspace{0.25in} & 8\\\\\n- & \\hspace{0.25in} 2/(1+4x^2) \\hspace{0.25in} & 8x\\\\\n\\end{array}\nUsing our third stop and integrating the second row, we get\n\n\\int 8\\arctan\\left(2x\\right)\\,dx = 8x\\arctan(2x) - \\int \\frac{8x}{1+4x^2}\n\nApplying a substitution \nu = 4x^2\n\nWe get \n\\int 8\\arctan\\left(2x \\right)\\,dx = 8x\\arctan(2x) - \\ln |1+4x^2| + C\n\nSolving our integral."
  },
  {
    "objectID": "qmd/integral/simple/decomp.html",
    "href": "qmd/integral/simple/decomp.html",
    "title": "Partial fraction decomposition",
    "section": "",
    "text": "Consider the integral shown below.\n\\int{{\\frac{{3x + 11}}{{{x^2} - x - 6}}\\,dx}}\nOur current methods will not work to evaluate the integral. There is no simple way to apply a substitution or the tabular method. However, if we break up the fraction\n\\frac{{3x + 11}}{{{x^2} - x - 6}} = \\frac{4}{x - 3} - \\frac{1}{x + 2}\nThe solution becomes trivial\n\\int{{\\frac{{3x + 11}}{{{x^2} - x - 6}}\\,dx}} = 4\\ln |x - 3| - \\ln |x + 2| + C.\nFinding ways to break up the fractions is known as partial fraction decomposition."
  },
  {
    "objectID": "qmd/integral/simple/decomp.html#examples",
    "href": "qmd/integral/simple/decomp.html#examples",
    "title": "Partial fraction decomposition",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\n\nJoe Foster (Integration by parts - C3)\n\n\n\nEvaluate the following integral\n\n\\int \\frac{x^3 + x^2 + 2x + 1}{(x^2 + 1)(x^2 + 2)} \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can break up the integral as it contains distinct quadratic factors.\n\n\\frac{x^3 + x^2 + 2x + 1}{(x^2 + 1)(x^2 + 2)} =  \\frac{Ax + B}{x^2 + 1} + \\frac{Cx + D}{x^2 + 2}\n\nCross multiplying \nx^3 + x^2 + 2x + 1 = (Ax + B)(x^2 + 2) + (Cx + D)(x^2 + 1)\n\nGives us the following system of equations\n\\begin{array}{ll}\nx^3  & = (A + C)x^3\\\\\nx^2 & = (B + D)x^2\\\\\n2x & = (2A + C)x \\\\\n1 & = (2B + D)\n\\end{array}\nSolving the system yields\n\\begin{array}{ll}\nA = 1  & B = 0\\\\\nC = 0 & D = 1\n\\end{array}\nThis solves our decomposition. We now have to integrate\n\n\\int \\frac{x}{x^2 + 1} + \\frac{1}{x^2 + 2} \\, dx\n\nThe first term can be solved by the substitution u = x^2, and the second term can be evaluated with an \\arctan x. This gives us\n\n\\int \\frac{x^3 + x^2 + 2x + 1}{(x^2 + 1)(x^2 + 2)} \\, dx = \\frac{1}{2}\\ln |x^2 + 1| + \\frac{1}{\\sqrt{2}} \\arctan \\left( \\frac{x}{\\sqrt{2}} \\right) + C"
  },
  {
    "objectID": "qmd/integral/simple/decomp.html#method",
    "href": "qmd/integral/simple/decomp.html#method",
    "title": "Partial fraction decomposition",
    "section": "Method",
    "text": "Method\nWhen given an integral in the form\n\n\\int \\frac{P(X)}{Q(X)} \\, dx\n\nWhere P(x) and Q(x) are polynomials such that the degree of Q(x) is higher than the degree of P(x). We can decompose the fraction based on the factors of Q(x). There are four cases for the factors of Q(x).\n\n\n\n\n\n\nDecomposition cases\n\n\n\n\n\nCase I: Distinct linear factors\nWhen Q(x) has distinct linear factors, i.e.\n\nQ(x) = (a_1 x + b_1)(a_2 x + b_2)\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A}{a_1x + b_1} + \\frac{B}{a_2x + b_2}\n\nCase 2: Repeated linear factors\nWhen Q(x) has repeated linear factors, i.e.\n\nQ(x) = (a x + b)^k\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A_1}{ax + b} + \\frac{A_2}{(ax + b)^2} + \\cdots + \\frac{A_k}{(a x + b)^k}\n\nCase 3: Distinct quadratic factors\nWhen Q(x) has distinct quadratic factors, i.e.\n\nQ(x) = (a_1 x^2 + b_1x + c_1)(a_2 x^2 + b_2x + c_2)\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A_1 + B_1}{a_1 x^2 + b_1x + c_1} + \\frac{A_2 + B_2}{a_2 x^2 + b_2x + c_2}\n\nCase 4: Repeated quadratic factors\nWhen Q(x) has repeated quadratic factors, i.e.\n\nQ(x) = (a x^2 + bx + c)^k\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A_1x + B_1}{a x^2 + bx + c} + \\cdots + \\frac{A_kx + B_k}{(a x^2 + bx + c)^k}\n\n\n\n\nNote that Q(x) does not have one case of factors exculsivly. For example\n\nQ(x) = (a_1x+b_1)(a_2x^2 + b_2x + c_2)^2\n\nWill decompose into\n\n\\frac{P(x)}{Q(x)} = \\frac{A}{a_1x + b_1} + \\frac{Bx + C}{a_2 x^2 + b_2x + c_2} + \\frac{Dx + E}{(a_2 x^2 + b_2x + c_2)^2}\n\nNext we need a method for finding the value of the constants in the numerator.\n\n\n\n\n\n\nEvaluating constants\n\n\n\n\n\nConsider the integral from the beginning\n\n\\int \\frac{3x + 11}{x^2 - x - 6} \\,dx\n\nWe can now decompose the integrand to obtain\n\n\\frac{3x + 11}{x^2 - x - 6} = \\frac{A}{x - 3} + \\frac{B}{x + 2}\n\nThe problem is now finding values for the constants A,B which make the relation true. By cross multiplying the right side of the equation we get\n\n\\frac{3x + 11}{x^2 - x - 6} = \\frac{A(x + 2) + B(x - 3)}{(x - 3)(x + 2)}\n\nWhich simplifies to\n\n3x + 11 = A(x + 2) + B(x - 3).\n\nWe can then create a system of equations such that the above expression is always true. This method is long but will always work. The faster method (that isn’t always possible) is to find values of x such that the equation reduces. Using the faster method, we obtain\n\nx = 3 \\: : \\: 3(3) + 11 = A(3 + 2) + B(3 - 3) \\implies A = 4\\\\\nx = -2 \\: : \\: 3(-2) + 11 = A(-2 + 2) + B(-2 - 3) \\implies B = -1\n\nWhich gives us our final expression\n\n\\frac{3x + 11}{x^2 - x - 6} = \\frac{4}{x - 3} - \\frac{1}{x + 2}\n\nWhich as shown above, makes the integral trivial to solve.\n\n\\int{{\\frac{{3x + 11}}{{{x^2} - x - 6}}\\,dx}} = 4\\ln |x - 3| - \\ln |x + 2| + C."
  },
  {
    "objectID": "qmd/integral/tricky/hyperbolic.html",
    "href": "qmd/integral/tricky/hyperbolic.html",
    "title": "Hyperbolic trigonometry",
    "section": "",
    "text": "Integration is the inverse of the differentiation. If f^\\prime(x) = g(x), then\n\\int g(x)\\,dx = f(x) + C.\nIntegrals have a property called linearity. This means they are closed under linear transformations of functions, as shown below.\n\\int \\alpha f(x) + \\beta g(x) \\,dx = \\alpha \\int f(x) \\,dx+ \\beta \\int g(x) \\,dx"
  },
  {
    "objectID": "qmd/integral/tricky/hyperbolic.html#inverse-power-rule",
    "href": "qmd/integral/tricky/hyperbolic.html#inverse-power-rule",
    "title": "Hyperbolic trigonometry",
    "section": "Inverse power rule",
    "text": "Inverse power rule\nOne of the basic rules of differentiation is that of power rule.\n\n\\frac{d}{dx} x^m = mx^{m-1}\n\nSuspecting this will be a useful property, we can derive an expression for the inverse power rule from the definition of an integral.\n\n\\int mx^{m-1} dx = x^m\n\nApply linearity and the substituion n = m-1\n\n\\int x^{n} dx = \\frac{x^{n+1}}{n+1}\n\n\n\n\n\n\n\nExample\n\n\n\n\n\nFind the solution to the following integral\n\n\\int 2x^2 - 3x - 1 \\, dx\n\nWe first begin by applying linearity\n\n= 2 \\int x^2 \\,dx - 3\\int x \\, dx - \\int 1x^0 \\, dx\n\nThen inverse power rule\n\n= \\frac{2x^3}{3} - \\frac{3x^2}{2} - x + C\n\nGiving us a solution to the polynomial. This process can be done for any standard polynomial.\n\n\n\n\n\n\n\n\n\nTheorem (Integration of a polynomial)\n\n\n\nLet f(x) be a polynomial in the form\n\nf(x) = a_nx^n + a_{n-1}x^{n-1} + \\cdots + a_1x + c\n\nThen\n\n\\int f(x)\\,dx = \\frac{a_nx^{n+1}}{n+1} + \\frac{a_{n-1}x^{n}}{n} +  \\cdots + \\frac{a_1x^2}{2} + cx + C\n\n\n\n\nEdge case\nOne may notice that when n=-1, inverse power rules gives us an undefined result\n\n\\int x^{-1}\\,dx = \\frac{1}{0} + C.\n\nFor this particular value of n, we get the expression\n\n\\int x^{-1}\\,dx = \\ln|x| + C.\n\nNote the absolute value bars. This is because the function \\ln is not defined for negative values of x, where our integrand is."
  },
  {
    "objectID": "qmd/integral/tricky/hyperbolic.html#common-identities",
    "href": "qmd/integral/tricky/hyperbolic.html#common-identities",
    "title": "Hyperbolic trigonometry",
    "section": "Common identities",
    "text": "Common identities\nThis section will cover many commonly used integration identities without much explanation.\n\nTrig identities\nTrigonometry is a huge part of the integration bee, and will repeatedly appear in almost every section of this guide. As such it is crucial to have a complete understanding of these functions and how they interact.\nThe integrals below are the direct inverse of differentiating the six primary trig functions.\n\\begin{array}{ll}\n\\displaystyle\\int{{\\cos x\\,dx}} = \\sin x + C \\hspace{0.5in} & \\displaystyle\\int{{\\sin x\\,dx}} =  - \\cos x + C\\\\\n\n\\displaystyle\\int{{{{\\sec }^2}x\\,dx}} = \\tan x + C \\hspace{0.5in} & \\displaystyle\\int{{{{\\csc }^2}x\\,dx}} =  - \\cot x + C\\\\\n\n\\displaystyle\\int{{\\sec x\\tan x\\,dx}} = \\sec x + C \\hspace{0.5in} & \\displaystyle\\int{{\\csc x\\cot x\\,dx}} =  - \\csc x + C\n\\end{array}\nIt is helpful (for me at least) to memorize the left column of the table, and then derive the right side by replacing each function with its ‘compliment’, and then negating the result.\n\n\nInverse Trig identities\nWe can use special formulas to differentiate inverse functions. By differentiating \\arcsin(x) and \\arctan(x), we get\n\n\\int \\frac{1}{x^2 + 1} \\, dx = \\arctan(x) + C \\hspace{0.5in} \\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = \\arcsin(x) + C\n\nIt is worth noting that\n\n\\frac{d}{dx}\\arccos(x) = -\\frac{1}{1-x^2}.\n\nSo the second integral can also be solved\n\n\\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = -\\arccos(x) + C.\n\nThis is because \\arcsin and -\\arccos differ by a constant (\\frac{\\pi}{2}).\n\n\nExponential and logarithmic functions\nBy once again inverting common derivative rules, we get the following identities.\n\n\\int e^x \\, dx = e^x + C \\hspace{0.5in} \\int a^x \\,dx = \\frac{a^x}{\\ln{x}} + C"
  },
  {
    "objectID": "qmd/integral/tricky/hyperbolic.html#examples",
    "href": "qmd/integral/tricky/hyperbolic.html#examples",
    "title": "Hyperbolic trigonometry",
    "section": "Examples",
    "text": "Examples\nSome example problems from various websites\n\nInverse power rule\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.1.1)\n\n\n\nEvaluate the following integral\n\n\\int 6x^5 - 18x^2 + 7 \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the formula for evaluating polynomials\n\n\\int 6x^5 - 18x^2 + 7 \\, dx = x^6 - 6x^3 + 7x + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.1.1)\n\n\n\nEvaluate the following integral\n\n\\int 6x^5\\, dx - 18x^2 + 7\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNotice the integral ends at the dx, meaning the solution is\n\n\\int 6x^5 - 18x^2 + 7 \\, dx = x^6 - 18x^2 + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.1.3)\n\n\n\nEvaluate the following integral\n\n\\int 12t^7 - t^2 - t + 3 \\, dt\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nClassic polynomial, the only difference is the use of t instead of x\n\n\\int 12t^7 - t^2 - t + 3 \\, dt = \\frac{3}{2}t^8 - \\frac{1}{3}t^3 - \\frac{1}{2}t^2 + 3t + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.6)\n\n\n\nEvaluate the following integral\n\n\\int \\sqrt[3]{w} + 10\\sqrt[5]{w^3}\\, dw\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nConvert the radicals to fractional exponets\n\n\\int \\sqrt[3]{w} + 10\\sqrt[5]{w^3}\\, dw = \\int w^\\frac{1}{3} + 10w^\\frac{3}{5} \\, dw\n\nAnd then apply inverse power rule\n\n\\int \\sqrt[3]{w} + 10\\sqrt[5]{w^3}\\, dw = \\frac{3}{4}w^\\frac{4}{3} + \\frac{25}{4}w^\\frac{8}{5} + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.9)\n\n\n\nEvaluate the following integral\n\n\\int \\frac{7}{3y^6} + \\frac{1}{y^{10}} - \\frac{2}{\\sqrt[3]{y^4}} \\, dy\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nConvert the radicals to fractional exponents\n\n\\int \\frac{7}{3y^6} + \\frac{1}{y^{10}} - \\frac{2}{\\sqrt[3]{y^4}} \\, dy = \\int \\frac{7}{3}y^{-6} + y^{-10} - 2y^{\\frac{4}{3}} \\, dy\n\nAnd then apply inverse power rule\n\n\\int \\frac{7}{3y^6} + \\frac{1}{y^{10}} - \\frac{2}{\\sqrt[3]{y^4}} \\, dy = -\\frac{7}{15}y^{-5} - \\frac{1}{9} y^{-9} + 6y^{-\\frac{1}{3}} + C\n\nBe careful to make sure you have the right answer.\n\n\n\n\n\nCommon identites\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.14)\n\n\n\nEvaluate the following integral\n\n\\int \\sin x + 10 \\csc^2 x \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSimply use linearity to break up the integral, and then apply identities\n\n\\int \\sin x + 10 \\csc^2 x \\, dx = -\\cos x - 10 \\cot x + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.15)\n\n\n\nEvaluate the following integral\n\n\\int 2\\cos x - \\sec x\\tan x \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSimply use linearity to break up the integral, and then apply identities\n\n\\int 2\\cos x - \\sec x\\tan x \\, dx = 2 \\sin x - \\sec x + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.16)\n\n\n\nEvaluate the following integral\n\n\\int 12 + \\csc \\theta \\left( {\\sin  \\theta  + \\csc  \\theta } \\right)\\,d\\theta\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nMultiply out and simplify the equation. \n\\int 12 + \\csc \\theta \\left( {\\sin  \\theta  + \\csc  \\theta } \\right)\\,d\\theta = \\int 12 + 1 + \\csc^2 \\theta \\, d\\theta\n\nBecause\n\n\\csc x= \\frac{1}{\\sin x}\n\nSo we get the answer\n\n\\int 12 + \\csc \\theta \\left( {\\sin  \\theta  + \\csc  \\theta } \\right)\\,d\\theta = 13 \\theta + \\cot \\theta + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.20)\n\n\n\nEvaluate the following integral\n\n\\int{{\\frac{1}{{1 + {x^2}}} + \\frac{{12}}{{\\sqrt {1 - {x^2}} }}\\,dx}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the inverse trig identities\n\n\\int{{\\frac{1}{{1 + {x^2}}} + \\frac{{12}}{{\\sqrt {1 - {x^2}} }}\\,dx}} = \\arctan x + 12 \\arcsin x + C"
  },
  {
    "objectID": "qmd/integral/simple/trigsub.html",
    "href": "qmd/integral/simple/trigsub.html",
    "title": "Trig substitutions",
    "section": "",
    "text": "Our motivation for this section is the following integral\n\\int \\frac{\\sqrt{25x^2 - 4}}{x} \\, dx\nThis integral is very difficult to solve with the previous techniques. The trick comes from the substitution\nx = \\frac{2}{5}\\sec \\theta\nWhich after a fair amount of algebra and calculus gives us\n\\int \\frac{\\sqrt{25x^2 - 4}}{x} \\, dx = \\sqrt{25x^2 - 4} + 2\\arccos \\left(\\frac{2}{5x}\\right) + C\nSolving these integrals relies on a method known as trigonometric substitutions."
  },
  {
    "objectID": "qmd/integral/simple/trigsub.html#inverse-power-rule",
    "href": "qmd/integral/simple/trigsub.html#inverse-power-rule",
    "title": "Trig substitutions",
    "section": "Inverse power rule",
    "text": "Inverse power rule\nOne of the basic rules of differentiation is that of power rule.\n\n\\frac{d}{dx} x^m = mx^{m-1}\n\nSuspecting this will be a useful property, we can derive an expression for the inverse power rule from the definition of an integral.\n\n\\int mx^{m-1} dx = x^m\n\nApply linearity and the substituion n = m-1\n\n\\int x^{n} dx = \\frac{x^{n+1}}{n+1}\n\n\n\n\n\n\n\nExample\n\n\n\n\n\nFind the solution to the following integral\n\n\\int 2x^2 - 3x - 1 \\, dx\n\nWe first begin by applying linearity\n\n= 2 \\int x^2 \\,dx - 3\\int x \\, dx - \\int 1x^0 \\, dx\n\nThen inverse power rule\n\n= \\frac{2x^3}{3} - \\frac{3x^2}{2} - x + C\n\nGiving us a solution to the polynomial. This process can be done for any standard polynomial.\n\n\n\n\n\n\n\n\n\nTheorem (Integration of a polynomial)\n\n\n\nLet f(x) be a polynomial in the form\n\nf(x) = a_nx^n + a_{n-1}x^{n-1} + \\cdots + a_1x + c\n\nThen\n\n\\int f(x)\\,dx = \\frac{a_nx^{n+1}}{n+1} + \\frac{a_{n-1}x^{n}}{n} +  \\cdots + \\frac{a_1x^2}{2} + cx + C\n\n\n\n\nEdge case\nOne may notice that when n=-1, inverse power rules gives us an undefined result\n\n\\int x^{-1}\\,dx = \\frac{1}{0} + C.\n\nFor this particular value of n, we get the expression\n\n\\int x^{-1}\\,dx = \\ln|x| + C.\n\nNote the absolute value bars. This is because the function \\ln is not defined for negative values of x, where our integrand is."
  },
  {
    "objectID": "qmd/integral/simple/trigsub.html#common-identities",
    "href": "qmd/integral/simple/trigsub.html#common-identities",
    "title": "Trig substitutions",
    "section": "Common identities",
    "text": "Common identities\nThis section will cover many commonly used integration identities without much explanation.\n\nTrig identities\nTrigonometry is a huge part of the integration bee, and will repeatedly appear in almost every section of this guide. As such it is crucial to have a complete understanding of these functions and how they interact.\nThe integrals below are the direct inverse of differentiating the six primary trig functions.\n\\begin{array}{ll}\n\\displaystyle\\int{{\\cos x\\,dx}} = \\sin x + C \\hspace{0.5in} & \\displaystyle\\int{{\\sin x\\,dx}} =  - \\cos x + C\\\\\n\n\\displaystyle\\int{{{{\\sec }^2}x\\,dx}} = \\tan x + C \\hspace{0.5in} & \\displaystyle\\int{{{{\\csc }^2}x\\,dx}} =  - \\cot x + C\\\\\n\n\\displaystyle\\int{{\\sec x\\tan x\\,dx}} = \\sec x + C \\hspace{0.5in} & \\displaystyle\\int{{\\csc x\\cot x\\,dx}} =  - \\csc x + C\n\\end{array}\nIt is helpful (for me at least) to memorize the left column of the table, and then derive the right side by replacing each function with its ‘compliment’, and then negating the result.\n\n\nInverse Trig identities\nWe can use special formulas to differentiate inverse functions. By differentiating \\arcsin(x) and \\arctan(x), we get\n\n\\int \\frac{1}{x^2 + 1} \\, dx = \\arctan(x) + C \\hspace{0.5in} \\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = \\arcsin(x) + C\n\nIt is worth noting that\n\n\\frac{d}{dx}\\arccos(x) = -\\frac{1}{1-x^2}.\n\nSo the second integral can also be solved\n\n\\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = -\\arccos(x) + C.\n\nThis is because \\arcsin and -\\arccos differ by a constant (\\frac{\\pi}{2}).\n\n\nExponential and logarithmic functions\nBy once again inverting common derivative rules, we get the following identities.\n\n\\int e^x \\, dx = e^x + C \\hspace{0.5in} \\int a^x \\,dx = \\frac{a^x}{\\ln{x}} + C"
  },
  {
    "objectID": "qmd/integral/simple/trigsub.html#examples",
    "href": "qmd/integral/simple/trigsub.html#examples",
    "title": "Trig substitutions",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\n\nProblem\n\n\n\nEvaluate the following integral\n\n\\int \\frac{\\sqrt{9 - x^2}}{x^2}\\,dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNotice that the radicle expression resembles the third row of our table. If we make the substitution\n\nx = 3\\sin \\theta\\\\\ndx = 3\\cos\\theta\\,d\\theta\n\nWe get\n\n\\int \\frac{\\sqrt{9 - x^2}}{x^2}\\,dx = \\int\\frac{3\\sqrt{1-\\sin^2\\theta}}{9\\sin^2\\theta}(3\\cos\\theta)\\,d\\theta = \\int\\frac{\\cos^2\\theta}{\\sin^2\\theta} d\\theta\n\nWhich evaulates to \n\\int\\frac{\\cos^2\\theta}{\\sin^2\\theta} d\\theta = -\\cot\\theta - \\theta + C\n\nThis however, is only half the problem. We still need to convert the equation back to its orginal variable. Once again, the method of drawing a triangle will help to simplify the final expression.\nNote that \\sin \\theta = \\displaystyle\\frac{\\text{opp}}{\\text{hyp}} = \\displaystyle\\frac{x}{3}\n\n\nCode\n\\usetikzlibrary{graphs,graphs.standard,angles,quotes}\n\n\\begin{tikzpicture}\n\n\\draw[fill=black] (0,0);\n\\draw[fill=black] (3,0);\n\\draw[fill=black] (3,2);\n\\draw[line width=1pt] (0,0) -- (3,0) -- (3,2) -- (0,0);\n\\node at (1.75,-.3) {$\\sqrt{9 -x^2}$};\n\\node at (1.2,1.25) {$3$};\n\\node at (3.2,1) {$x$};\n\n\\coordinate (origo) at (0,0);\n\\coordinate (pivot) at (3,2);\n\\coordinate (mary) at (3,0);\n\n\\pic[draw, -, \"$\\theta$\", angle eccentricity=1.5]{angle = mary--origo--pivot};\n\\end{tikzpicture}\n\n\n\n\n\n\n\n\n\nSo\n\n\\cot \\theta = \\frac{\\text{adj}}{\\text{opp}} = \\frac{\\sqrt{9 -x^2}}{x}\n\nGiving us a final answer of\n\n\\int \\frac{\\sqrt{9 - x^2}}{x^2}\\,dx = \\frac{-\\sqrt{9-x^2}}{x} - \\arcsin\\left(\\frac{x}{3}\\right) + C"
  },
  {
    "objectID": "qmd/integral/simple/trigsub.html#method",
    "href": "qmd/integral/simple/trigsub.html#method",
    "title": "Trig substitutions",
    "section": "Method",
    "text": "Method\nFirst, lets explain how we solved the previous integral.\n\n\n\n\n\n\nExample\n\n\n\n\n\nWe have the following integral, which is difficult to solve using previous techniques.\n\n\\int \\frac{\\sqrt{25x^2 - 4}}{x} \\, dx\n\nUsing the substitution\n\nx = \\frac{2}{5}\\sec \\theta\n\nWe can reduce the integral and get a solution in terms of \\theta.\n\\begin{array}{ll}\n\n& = \\displaystyle \\int \\frac{\\sqrt{25(\\frac{2}{5}\\sec \\theta)^2 - 4}}{\\frac{2}{5}\\sec \\theta} \\, (\\frac{2}{5}\\tan \\theta \\sec \\theta \\, d\\theta)\\\\\n& =  \\displaystyle\\int \\sqrt{4\\sec^2 \\theta - 4} \\, \\tan \\theta \\, d\\theta\\\\\n& = \\displaystyle2\\int \\sqrt{\\sec^2 \\theta - 1} \\, \\tan \\theta \\, d\\theta = 2\\int\\tan^2\\theta \\, d\\theta\\\\\n& = 2\\left(\\tan \\theta + \\theta\\right) + C\n\\end{array}\nNow we only need to undo our substitution. Notice that\n\n\\sec \\theta = \\frac{\\text{hyp}}{\\text{adj}} = \\frac{5x}{2}\n\nThis can be visualized in the triangle.\n\n\nCode\n\\usetikzlibrary{graphs,graphs.standard,angles,quotes}\n\n\\begin{tikzpicture}\n\n\\draw[fill=black] (0,0);\n\\draw[fill=black] (3,0);\n\\draw[fill=black] (3,2);\n\\draw[line width=1pt] (0,0) -- (3,0) -- (3,2) -- (0,0);\n\\node at (1.75,-.25) {$2$};\n\\node at (1.2,1.25) {$5x$};\n\\node at (3.9,1) {$\\sqrt{25x^2 - 4}$};\n\n\\coordinate (origo) at (0,0);\n\\coordinate (pivot) at (3,2);\n\\coordinate (mary) at (3,0);\n\n\\pic[draw, -, \"$\\theta$\", angle eccentricity=1.5]{angle = mary--origo--pivot};\n\\end{tikzpicture}\n\n\n\n\n\n\n\n\n\nFrom here can see that \n\\tan \\theta = \\frac{\\sqrt{25x^2-4}}{2}\n\n\n\\theta = \\arccos \\left(\\frac{2}{5x}\\right)\n\nGiving us our final answer\n\n\\int \\frac{\\sqrt{25x^2 - 4}}{x} \\, dx = \\sqrt{25x^2-4} + 2\\arccos \\left(\\frac{2}{5x}\\right) + C\n\n\n\n\nWhen faced with an integral containing a radical expression in the form \\sqrt{\\pm(bx + c)^2 \\pm a}, we can usually find some subtitution for x which simplifies the expression into a singular trigonometric identity. This is achievable due to the following three identities.\n\\begin{array}{ll}\n1 - \\sin^2x &=& \\cos^2 x\\\\\n\\tan^2x + 1 &=& \\sec^2 x\\\\\n\\sec^2x - 1 &=& \\tan^2 x\n\\end{array}\nLets see how these identites allow us to reduce certain radicals.\n\n\n\n\n\n\nTrig substitutions\n\n\n\n\n\nLets examine the three cases where trig identities allow us to simplify a radical expression.\nCase I: \\sqrt{a - (bx + c)^2}\nNotice how this case is a constant, subtracted by a squared variable term. This resembles our first expression, 1 - \\sin^2x = \\cos^2 x. We want to get the expression in these terms so we can reduce the radicle. Notice by making the substitution\n\n(bx + c) = \\sqrt{a}\\sin \\theta\n\nWe get the equation\n\n\\sqrt{a - (\\sqrt{a}\\sin\\theta)^2} = \\sqrt{a}\\sqrt{1-\\sin^2\\theta} = \\sqrt{a}\\cos\\theta\n\nWe have now elimated the variable from the radical.\nCase II: \\sqrt{(bx + c)^2 + a}\nThis case resembles our identity \\tan^2x + 1 = \\sec^2 x. So lets try the substitution\n\n(bx + c) = \\sqrt{a}\\tan \\theta\n\nWhich gives us\n\n\\sqrt{(\\sqrt{a}\\tan \\theta)^2 + a} = \\sqrt{a}\\sqrt{\\tan^2 \\theta + 1} = \\sqrt{a}\\sec\\theta\n\nWe have now elimated the variable from the radical.\nCase III: \\sqrt{(bx + c)^2 - a}\nThis case resembles \\sec^2x - 1. Using the substitution\n\n(bx + c) = \\sqrt{a}\\sec \\theta\n\nWe get the equation\n\n\\sqrt{(\\sqrt{a}\\sec \\theta)^2 - a} = \\sqrt{a}\\sqrt{\\sec^2\\theta - 1} = \\sqrt{a}\\tan\\theta\n\nWe have now elimated the variable from the radical.\n\n\n\nFor ease of use, the following table shows what substitution to make depending on the case.\n\\begin{array}{ll}\n\\text{Radical expression} \\hspace{0.25in} & \\text{Substitution}\\\\\n&\\\\\n\\sqrt{a - (bx + c)^2} \\hspace{0.25in} & (bx + c) = \\sqrt{a}\\sin\\theta\\\\\n&\\\\\n\\sqrt{(bx + c)^2 + a} \\hspace{0.25in} & (bx + c) = \\sqrt{a}\\tan\\theta\\\\\n&\\\\\n\\sqrt{(bx + c)^2 - a} \\hspace{0.25in} & (bx + c) = \\sqrt{a}\\sec\\theta\n\\end{array}"
  },
  {
    "objectID": "qmd/todo/todo.html",
    "href": "qmd/todo/todo.html",
    "title": "Todo",
    "section": "",
    "text": "Todo list for the website"
  },
  {
    "objectID": "qmd/todo/todo.html#discrete-derivative",
    "href": "qmd/todo/todo.html#discrete-derivative",
    "title": "Discrete Calculus",
    "section": "Discrete Derivative",
    "text": "Discrete Derivative\nIn continuous calculus, the derivative is the ‘instantaneous rate of change’ of a function. That concept can’t exist with incremental change. The smallest rate of change in a discrete function is the change between integers. Therefore we define our discrete derivative\n\n\n\n\n\n\nDefinition\n\n\n\nThe discrete derivative is the smallest change in a discrete function, defined $$ f(x) = f(x+1) - f(x)\n\n\nWe can now prove may properties about the discrete derivative\n\n\n\n\n\n\nTheorem\n\n\n\nThe discrete derivative has the following properties\nConstant rule\n\\Delta c = 0 for all c \\in \\mathbb{N}\nLinearity\n\\Delta af(x) = a \\Delta f(x)\nProduct rule\n\\Delta f(x)g(x) = f(x) \\Delta g(x) + g(x) \\Delta f(x) + \\Delta f(x) \\Delta g(x)\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nTo-do\n\n\n\n\nFunctions\nNow that we’ve defined the discrete derivative, we can start finding the discrete derivative of functions.\nTake for example, the function"
  },
  {
    "objectID": "qmd/todo/todo.html#website",
    "href": "qmd/todo/todo.html#website",
    "title": "Todo",
    "section": "Website",
    "text": "Website\n\nMakeover\nAdd about page, change math notes to one section\nCopy castles notes"
  },
  {
    "objectID": "qmd/todo/todo.html#integrals",
    "href": "qmd/todo/todo.html#integrals",
    "title": "Todo",
    "section": "Integrals",
    "text": "Integrals\n\nMake everything less plagarized\nmake the equations fit on mobile"
  },
  {
    "objectID": "qmd/bookrev/concrete/recprob.html",
    "href": "qmd/bookrev/concrete/recprob.html",
    "title": "Recurrent Problems",
    "section": "",
    "text": "This chapter of ‘Concrete Mathematics’ explores recurrence problems."
  },
  {
    "objectID": "qmd/bookrev/concrete/recprob.html#the-tower-of-hanoi",
    "href": "qmd/bookrev/concrete/recprob.html#the-tower-of-hanoi",
    "title": "Recurrent Problems",
    "section": "The Tower of Hanoi",
    "text": "The Tower of Hanoi\nThe Tower of Hanoi is a problem proposed by Edouard Lucas in 1883. We are given a tower of eight disks stacked in decreasing size on one of three pegs. The objective is to transfer the disks from one peg to another, only moving one disk at a time, and never moving a larger disk onto a smaller one.\nThe authors present the solution throught the use of two techniques. The authors first look at small cases of the problem, and then create a variable T_n to analyze.\nSay that T_n is the minimum number of moves to transfer a tower of size n to another peg. It is clear T_1 = 1, and that T_2 = 3. Additionally, one could say T_0 = 0.\nWhen given a tower of size n, it takes T_{n-1} moves to move the n-1 smaller tower onto another peg, one move to move the largest disk onto the desired peg, and then another T_{n-1} moves to move the tower of size n onto the largest disk. This gives us a general formula\n\nT_0 = 0;\\\\\nT_n = 2T_{n-1} + 1\n\\tag{1}\nA set of inequalities like the one shown in Equation 1 is called a recurrence. Defined as giving an intial value (T_0 = 0) and then a general value in terms of an earlier one T_{n} = 2T_{n-1} + 1.\nThough finding a numerical value becomes tedious when n is large enough. What would reduce computation time is a ‘closed form’ for T_n, one that can be evaluated without knowing T_n for all smaller values of n.\nThrough less than rigourous means, one can determine that the equation\n\nT_n = 2^n - 1 \\quad \\text{for } n \\geq 0\n\\tag{2}\nBut this is not a proof. We can manually confirm it to be true for many values of n, but in order to prove it for all values of n, we will use a tool called Mathematical induction.\nThis works by first proving the equation true for one value of n, know as n_0 called the basis. Then proving it for all $ n &gt; n_0$. We assume the statement is true for all values n_0 to n - 1 inclusive.\nWe can use n = 0 as our basis, as clearly T_0 = 2^0 - 1 = 0. The induction follows for n &gt; 0 if we use the induction hypothesis to say (2) holds for n - 1\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\nThus (2) holds for n. We have now found and proved our closed formula for T_n holds.\nIn order to solve this problem, we first found a mathematical expression that allowed us to solve the problem for any number of disks, and then found a closed form for our mathematical expression. The book will focus primarily on finding these closed forms of mathematical expression, and without using a lucky guess to find the closed form.\nIntrestingly enough, our recurrence from (1) can be simplified by adding 1 to both sides of the equation:\n\nT_0 + 1 = 1\\\\\nT_n + 1 = 2T_{n-1} + 2\n\nNow if we let U_n = T_n + 1, we get\n\nU_0 = 1\\\\\nU_n = 2U_{n-1}\n\\tag{3}\nIt is pretty clear that our closed formula is U_n = 2^n; thus T_n = 2^n - 1."
  },
  {
    "objectID": "qmd/bookrev/concrete/recprob.html#lines-in-the-plane",
    "href": "qmd/bookrev/concrete/recprob.html#lines-in-the-plane",
    "title": "Recurrent Problems",
    "section": "Lines in the Plane",
    "text": "Lines in the Plane\nOur next problem is on the plane. What is the maximum number L_n of regions defined by n lines on a plane. This problem was first solved by Jacob Steiner in 1826. If we take a similar approach to the last section, starting with smaller cases:\n\nL_0 = 1\\\\\nL_1 = 2\\\\\nL_2 = 4\n\nWe might come to the natural conclusion that L_n = 2^n. And this would be true if each line cut each region in half; but adding a third line makes it clear that we can only split as most 3 regions, giving us L_3 = 7. We realize that a new line on the plane adds k extra regions if and only if it intersects k old regions, and the line intersects k regions if and only if it hits the previous lines in k-1 places. Two lines can intersect in at most one point. So the new line can intersect the n - 1 lines at n-1 places. Thus the upper bound for this problem is\n\nL_n \\leq L_{n-1} + n \\quad \\text{for} n &gt; 0.\n\nFurthermore it’s easy to change this into equality by adding the restriction that none of the n lines are parrall, and that three lines do not intersect at the same point. This ensures that each new line n intersects every other line at some new point splitting the region. Our recurrence relation is then\n\nL_0 = 1;\\\\\nL_n = L_{n-1} + n,\\quad \\text{for } n &gt; 0.\n\\tag{4}\nOne can verify there are no silly mistakes by checking our established values of L_0,L_1 and L_2. All checks out, so we buy the recurrence relation. Now we need a general formula.\nThrough some trial and error, we can unfold L_n into\n\nL_n = L_0 + 1 + 2 + \\cdots + n\n\nLetting\n\nS_n = 1 + 2 + \\cdots + n\n\nWe get the ‘closed form’\n\nL_n = 1 + S_n\n\nBut this just replaces one recurrence for another. It is said that in 1786, when Guass was nine years old, he had found a closed form of S_n using the following trick\n\\begin{array}{ll}\n&S_n &=  &1  &+ &2 &+ \\cdots + &(n - 1) &+ &n\\\\\n+&S_n &=  &n  &+ &(n-1) &+ \\cdots + &2 &+ &1\\\\\n\\hline\n2&S_n &= &(n+1) &+ &(n+1) &+ \\cdots + &(n+1) &+ &(n+1)\n\\end{array}\\\\\nNotice how 2S_n is now just equal to n copies of (n + 1), therefore\n\nS_n = \\frac{n(n+1)}{2}, \\quad \\text{for } n \\geq 0\n\\tag{5}\nGiving us our closed form\n\nL_n = \\frac{n(n+1)}{2} + 1, \\quad \\text{for } n \\geq 0.\n\\tag{6}\nOne might consider this a proof, despite the handwavy techniques used in its derivation. A proof by induction is simple, so we might as well give ourselves some stricter standards. The induction is proved with\n\nL_n = \\frac{(n-1)n}{2} + 1 + n = \\frac{n(n+1)}{2} + 1\n\nThus we have no doubt (6) is correct.\nWe can now look at a vairation of the line problem. Suppose instead of straight lines each line has a zig in it. What is the maximum number Z_n of regions determined by n. One can see Z_1 = 2 and Z_2 = 7.\nFrom some thought and small cases, one notices that a line with a zig is simply two lines who don’t extend past their intersection point. We can arrange these zigged lines such that the intersection point is far enough from the other lines that we only lose two regions per line. Thus\n\nZ_n = L_2n - 2n = 2n(2n - 1)/2 + 1 - 2n\\\\\nZ_n = 2n^2 - n + 1 \\quad \\text{for } n \\geq 0.\n\\tag{7}"
  },
  {
    "objectID": "qmd/bookrev/concrete/recprob.html#the-josephus-problem",
    "href": "qmd/bookrev/concrete/recprob.html#the-josephus-problem",
    "title": "Recurrent Problems",
    "section": "The Josephus Problem",
    "text": "The Josephus Problem\nThe Josephus problem is actually an ancient problem dating back to the first century. The problem has n people standing in a circle. Each person kills the person directly to their left, until there is only one left. We want to find the position of the surviving player.\nWe can easily see J(1) = 1. When there is an even number 2n of players, note that all the even numbers die the first round. Our circle would then resemble a circle of size n, where each players number has been doubled and then had 1 subtracted from it. That is\n\nJ(2n) = 2J(n) - 1\n\nNow if we do a similar thing with an odd number of survivors, we see\n\nJ(2n + 1) = 2J(n) + 1\n\nThis can be used to define a recurrence relation\n\nJ(1) = 1\\\\\nJ(2n) = 2J(n) - 1\\\\\nJ(2n + 1) = 2J(n) + 1\n\\tag{8}\nThis recurrence is much more effienct than our previous ones. As if we wanted to calculate a large n, we would need far fewer than n steps to get our solution (Around \\log_2n steps).\nThrough some trial and error, we can arrive at the following equation\n\nJ(2^m + l) = 2l + 1\n\\tag{9}\nWhich can be solved by induction.\n\nBinary Representation\nBecause powers of 2 played such an important role in finding our solution, one might want to look at n in it’s base 2 reprensentation. Suppose\n\nn = (b_mb_{m-1}\\ldots b_1b_0)_2\n\nNote that b_m is always 1. Letting n = 2^m + l, we have\n\nn = (1b_{m-1}\\ldots b_1b_0)_2\\\\\nl = (0b_{m-1}\\ldots b_1b_0)_2\\\\\n2l = (b_{m-1}\\ldots b_1b_00)_2\\\\\n2l + 1 = (b_{m-1}\\ldots b_1b_01)_2\\\\\nJ(n) = (b_{m-1}\\ldots b_1b_0b_m)_2\n\nThus\n\nJ((1b_{m-1}\\ldots b_1b_0)_2) = (b_{m-1}\\ldots b_1b_0b_m)_2\n\\tag{10}\nThis means we can find J(n) by doing a one-bit cyclic shift left on n. Which is insanely simple given the amount of work it was to find a solution in base 10! For example, if n = 1101_2 then J(n) = 1011_2. Note this breaks when J(1011_2) = 111_2\nIf we repeatedly apply J to a number n, we will eventually produce a number consisting of bits which are exclusivly 1, whos value is 2^{v(n)} - 1 where v(n) is the number of bits of value 1 in the binary representation of n. Because v(13) = 3,\n\nJ(J(\\cdots J(13)\\cdots)) = 2^3 - 1 = 7.\n\nHow many iterations of J does it take to get this fixed value? No idea.\n\n\nGenerilized Josephus Problem\nWhat would happen if we generilized (8) with different constants? How would that change our closed form solutions. Lets investiagte this with a more general recurrence\n\\begin{array}{ll}\nf(1) &=& \\alpha;\\\\\nf(2n) &=& 2f(n) + \\beta;\\\\\nf(2n + 1) &=& 2f(n) + \\gamma;\n\\end{array}\n\n\\tag{11}\nOur recurrence J(n) had constants \\alpha = 1, \\beta = -1 and \\gamma = 1."
  },
  {
    "objectID": "qmd/bookrev/towerhanoi.html",
    "href": "qmd/bookrev/towerhanoi.html",
    "title": "The Tower of Hanoi",
    "section": "",
    "text": "The Tower of Hanoi is a problem proposed by Edouard Lucas in 1883. We are given a tower of eight disks stacked in decreasing size on one of three pegs. The objective is to transfer the disks from one peg to another, only moving one disk at a time, and never moving a larger disk onto a smaller one.\nSay that T_n is the minimum number of moves to transfer a tower of size n to another peg. It is clear T_1 = 1, and that T_2 = 3. Additionally, one could say T_0 = 0.\nWhen given a tower of size n, it takes T_{n-1} moves to move the n-1 smaller tower onto another peg, one move to move the largest disk onto the desired peg, and then another T_{n-1} moves to move the tower of size n onto the largest disk. This gives us a general formula\n\nT_0 = 0;\\\\\nT_n = 2T_{n-1} + 1\n\\tag{1}\nA set of inequalities like the one shown in \\left(1\\right) is called a recurrence. Defined by an intial value (T_0 = 0) and then a general value in terms of an earlier one T_{n} = 2T_{n-1} + 1.\nThough finding a numerical value becomes tedious when n is large enough. What would reduce computation time is a ‘closed form’ for T_n, one that can be evaluated without knowing T_n for all smaller values of n.\nCalculating the first few values of T, we get T_1 = 1, T_2 = 3, T_3 = 7, T_4 = 15, ect. It would appear that \nT_n = 2^n - 1 \\quad \\text{for } n \\geq 0\n\\tag{2}\nBut this is not a proof. We can manually confirm it to be true for many values of n, but in order to prove it for all values of n, we will have to use induction.\n\n\n\n\n\n\nProof\n\n\n\nWe want to show\n\nT_n = 2^n - 1.\n\nWe use n = 0 for our basis, which works as 2^0 - 1 = 0.\nBy the induction hypothesis\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\n\n\nWe can use n = 0 as our basis, as clearly T_0 = 2^0 - 1 = 0. The induction follows for n &gt; 0 if we use the induction hypothesis to say (2) holds for n - 1\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\nThus (2) holds for n. We have now found and proved our closed formula for T_n holds.\nIn order to solve this problem, we first found a mathematical expression that allowed us to solve the problem for any number of disks, and then found a closed form for our mathematical expression. The book will focus primarily on finding these closed forms of mathematical expression, and without using a lucky guess to find the closed form.\nIntrestingly enough, our recurrence from (1) can be simplified by adding 1 to both sides of the equation:\n\nT_0 + 1 = 1\\\\\nT_n + 1 = 2T_{n-1} + 2\n\nNow if we let U_n = T_n + 1, we get\n\nU_0 = 1\\\\\nU_n = 2U_{n-1}\n\\tag{3}\nIt is pretty clear that our closed formula is U_n = 2^n; thus T_n = 2^n - 1."
  },
  {
    "objectID": "qmd/bookrev/towerhanoi.html#the-tower-of-hanoi",
    "href": "qmd/bookrev/towerhanoi.html#the-tower-of-hanoi",
    "title": "Recurrent Problems",
    "section": "The Tower of Hanoi",
    "text": "The Tower of Hanoi\nThe Tower of Hanoi is a problem proposed by Edouard Lucas in 1883. We are given a tower of eight disks stacked in decreasing size on one of three pegs. The objective is to transfer the disks from one peg to another, only moving one disk at a time, and never moving a larger disk onto a smaller one.\nThe authors present the solution throught the use of two techniques. The authors first look at small cases of the problem, and then create a variable T_n to analyze.\nSay that T_n is the minimum number of moves to transfer a tower of size n to another peg. It is clear T_1 = 1, and that T_2 = 3. Additionally, one could say T_0 = 0.\nWhen given a tower of size n, it takes T_{n-1} moves to move the n-1 smaller tower onto another peg, one move to move the largest disk onto the desired peg, and then another T_{n-1} moves to move the tower of size n onto the largest disk. This gives us a general formula\n\nT_0 = 0;\\\\\nT_n = 2T_{n-1} + 1\n\\tag{1}\nA set of inequalities like the one shown in Equation 1 is called a recurrence. Defined as giving an intial value (T_0 = 0) and then a general value in terms of an earlier one T_{n} = 2T_{n-1} + 1.\nThough finding a numerical value becomes tedious when n is large enough. What would reduce computation time is a ‘closed form’ for T_n, one that can be evaluated without knowing T_n for all smaller values of n.\nThrough less than rigourous means, one can determine that the equation\n\nT_n = 2^n - 1 \\quad \\text{for } n \\geq 0\n\\tag{2}\nBut this is not a proof. We can manually confirm it to be true for many values of n, but in order to prove it for all values of n, we will use a tool called Mathematical induction.\nThis works by first proving the equation true for one value of n, know as n_0 called the basis. Then proving it for all $ n &gt; n_0$. We assume the statement is true for all values n_0 to n - 1 inclusive.\nWe can use n = 0 as our basis, as clearly T_0 = 2^0 - 1 = 0. The induction follows for n &gt; 0 if we use the induction hypothesis to say (2) holds for n - 1\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\nThus (2) holds for n. We have now found and proved our closed formula for T_n holds.\nIn order to solve this problem, we first found a mathematical expression that allowed us to solve the problem for any number of disks, and then found a closed form for our mathematical expression. The book will focus primarily on finding these closed forms of mathematical expression, and without using a lucky guess to find the closed form.\nIntrestingly enough, our recurrence from (1) can be simplified by adding 1 to both sides of the equation:\n\nT_0 + 1 = 1\\\\\nT_n + 1 = 2T_{n-1} + 2\n\nNow if we let U_n = T_n + 1, we get\n\nU_0 = 1\\\\\nU_n = 2U_{n-1}\n\\tag{3}\nIt is pretty clear that our closed formula is U_n = 2^n; thus T_n = 2^n - 1."
  },
  {
    "objectID": "qmd/bookrev/towerhanoi.html#lines-in-the-plane",
    "href": "qmd/bookrev/towerhanoi.html#lines-in-the-plane",
    "title": "The Tower of Hanoi",
    "section": "Lines in the Plane",
    "text": "Lines in the Plane\nOur next problem is on the plane. What is the maximum number L_n of regions defined by n lines on a plane. This problem was first solved by Jacob Steiner in 1826. If we take a similar approach to the last section, starting with smaller cases:\n\nL_0 = 1\\\\\nL_1 = 2\\\\\nL_2 = 4\n\nWe might come to the natural conclusion that L_n = 2^n. And this would be true if each line cut each region in half; but adding a third line makes it clear that we can only split as most 3 regions, giving us L_3 = 7. We realize that a new line on the plane adds k extra regions if and only if it intersects k old regions, and the line intersects k regions if and only if it hits the previous lines in k-1 places. Two lines can intersect in at most one point. So the new line can intersect the n - 1 lines at n-1 places. Thus the upper bound for this problem is\n\nL_n \\leq L_{n-1} + n \\quad \\text{for} n &gt; 0.\n\nFurthermore it’s easy to change this into equality by adding the restriction that none of the n lines are parrall, and that three lines do not intersect at the same point. This ensures that each new line n intersects every other line at some new point splitting the region. Our recurrence relation is then\n\nL_0 = 1;\\\\\nL_n = L_{n-1} + n,\\quad \\text{for } n &gt; 0.\n\\tag{4}\nOne can verify there are no silly mistakes by checking our established values of L_0,L_1 and L_2. All checks out, so we buy the recurrence relation. Now we need a general formula.\nThrough some trial and error, we can unfold L_n into\n\nL_n = L_0 + 1 + 2 + \\cdots + n\n\nLetting\n\nS_n = 1 + 2 + \\cdots + n\n\nWe get the ‘closed form’\n\nL_n = 1 + S_n\n\nBut this just replaces one recurrence for another. It is said that in 1786, when Guass was nine years old, he had found a closed form of S_n using the following trick\n\\begin{array}{ll}\n&S_n &=  &1  &+ &2 &+ \\cdots + &(n - 1) &+ &n\\\\\n+&S_n &=  &n  &+ &(n-1) &+ \\cdots + &2 &+ &1\\\\\n\\hline\n2&S_n &= &(n+1) &+ &(n+1) &+ \\cdots + &(n+1) &+ &(n+1)\n\\end{array}\\\\\nNotice how 2S_n is now just equal to n copies of (n + 1), therefore\n\nS_n = \\frac{n(n+1)}{2}, \\quad \\text{for } n \\geq 0\n\\tag{5}\nGiving us our closed form\n\nL_n = \\frac{n(n+1)}{2} + 1, \\quad \\text{for } n \\geq 0.\n\\tag{6}\nOne might consider this a proof, despite the handwavy techniques used in its derivation. A proof by induction is simple, so we might as well give ourselves some stricter standards. The induction is proved with\n\nL_n = \\frac{(n-1)n}{2} + 1 + n = \\frac{n(n+1)}{2} + 1\n\nThus we have no doubt (6) is correct.\nWe can now look at a vairation of the line problem. Suppose instead of straight lines each line has a zig in it. What is the maximum number Z_n of regions determined by n. One can see Z_1 = 2 and Z_2 = 7.\nFrom some thought and small cases, one notices that a line with a zig is simply two lines who don’t extend past their intersection point. We can arrange these zigged lines such that the intersection point is far enough from the other lines that we only lose two regions per line. Thus\n\nZ_n = L_2n - 2n = 2n(2n - 1)/2 + 1 - 2n\\\\\nZ_n = 2n^2 - n + 1 \\quad \\text{for } n \\geq 0.\n\\tag{7}"
  },
  {
    "objectID": "qmd/bookrev/towerhanoi.html#the-josephus-problem",
    "href": "qmd/bookrev/towerhanoi.html#the-josephus-problem",
    "title": "The Tower of Hanoi",
    "section": "The Josephus Problem",
    "text": "The Josephus Problem\nThe Josephus problem is actually an ancient problem dating back to the first century. The problem has n people standing in a circle. Each person kills the person directly to their left, until there is only one left. We want to find the position of the surviving player.\nWe can easily see J(1) = 1. When there is an even number 2n of players, note that all the even numbers die the first round. Our circle would then resemble a circle of size n, where each players number has been doubled and then had 1 subtracted from it. That is\n\nJ(2n) = 2J(n) - 1\n\nNow if we do a similar thing with an odd number of survivors, we see\n\nJ(2n + 1) = 2J(n) + 1\n\nThis can be used to define a recurrence relation\n\nJ(1) = 1\\\\\nJ(2n) = 2J(n) - 1\\\\\nJ(2n + 1) = 2J(n) + 1\n\\tag{8}\nThis recurrence is much more effienct than our previous ones. As if we wanted to calculate a large n, we would need far fewer than n steps to get our solution (Around \\log_2n steps).\nThrough some trial and error, we can arrive at the following equation\n\nJ(2^m + l) = 2l + 1\n\\tag{9}\nWhich can be solved by induction.\n\nBinary Representation\nBecause powers of 2 played such an important role in finding our solution, one might want to look at n in it’s base 2 reprensentation. Suppose\n\nn = (b_mb_{m-1}\\ldots b_1b_0)_2\n\nNote that b_m is always 1. Letting n = 2^m + l, we have\n\nn = (1b_{m-1}\\ldots b_1b_0)_2\\\\\nl = (0b_{m-1}\\ldots b_1b_0)_2\\\\\n2l = (b_{m-1}\\ldots b_1b_00)_2\\\\\n2l + 1 = (b_{m-1}\\ldots b_1b_01)_2\\\\\nJ(n) = (b_{m-1}\\ldots b_1b_0b_m)_2\n\nThus\n\nJ((1b_{m-1}\\ldots b_1b_0)_2) = (b_{m-1}\\ldots b_1b_0b_m)_2\n\\tag{10}\nThis means we can find J(n) by doing a one-bit cyclic shift left on n. Which is insanely simple given the amount of work it was to find a solution in base 10! For example, if n = 1101_2 then J(n) = 1011_2. Note this breaks when J(1011_2) = 111_2\nIf we repeatedly apply J to a number n, we will eventually produce a number consisting of bits which are exclusivly 1, whos value is 2^{v(n)} - 1 where v(n) is the number of bits of value 1 in the binary representation of n. Because v(13) = 3,\n\nJ(J(\\cdots J(13)\\cdots)) = 2^3 - 1 = 7.\n\nHow many iterations of J does it take to get this fixed value? No idea.\n\n\nGenerilized Josephus Problem\nWhat would happen if we generilized (8) with different constants? How would that change our closed form solutions. Lets investiagte this with a more general recurrence\n\\begin{array}{ll}\nf(1) &=& \\alpha;\\\\\nf(2n) &=& 2f(n) + \\beta;\\\\\nf(2n + 1) &=& 2f(n) + \\gamma;\n\\end{array}\n\n\\tag{11}\nOur recurrence J(n) had constants \\alpha = 1, \\beta = -1 and \\gamma = 1."
  },
  {
    "objectID": "qmd/bookrev/towerhanoi.html#the-problem",
    "href": "qmd/bookrev/towerhanoi.html#the-problem",
    "title": "The Tower of Hanoi",
    "section": "",
    "text": "The Tower of Hanoi is a problem proposed by Edouard Lucas in 1883. We are given a tower of eight disks stacked in decreasing size on one of three pegs. The objective is to transfer the disks from one peg to another, only moving one disk at a time, and never moving a larger disk onto a smaller one.\nSay that T_n is the minimum number of moves to transfer a tower of size n to another peg. It is clear T_1 = 1, and that T_2 = 3. Additionally, one could say T_0 = 0.\nWhen given a tower of size n, it takes T_{n-1} moves to move the n-1 smaller tower onto another peg, one move to move the largest disk onto the desired peg, and then another T_{n-1} moves to move the tower of size n onto the largest disk. This gives us a general formula\n\nT_0 = 0;\\\\\nT_n = 2T_{n-1} + 1\n\\tag{1}\nA set of inequalities like the one shown in \\left(1\\right) is called a recurrence. Defined by an intial value (T_0 = 0) and then a general value in terms of an earlier one T_{n} = 2T_{n-1} + 1.\nThough finding a numerical value becomes tedious when n is large enough. What would reduce computation time is a ‘closed form’ for T_n, one that can be evaluated without knowing T_n for all smaller values of n.\nCalculating the first few values of T, we get T_1 = 1, T_2 = 3, T_3 = 7, T_4 = 15, ect. It would appear that \nT_n = 2^n - 1 \\quad \\text{for } n \\geq 0\n\\tag{2}\nBut this is not a proof. We can manually confirm it to be true for many values of n, but in order to prove it for all values of n, we will have to use induction.\n\n\n\n\n\n\nProof\n\n\n\nWe want to show\n\nT_n = 2^n - 1.\n\nWe use n = 0 for our basis, which works as 2^0 - 1 = 0.\nBy the induction hypothesis\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\n\n\nWe can use n = 0 as our basis, as clearly T_0 = 2^0 - 1 = 0. The induction follows for n &gt; 0 if we use the induction hypothesis to say (2) holds for n - 1\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\nThus (2) holds for n. We have now found and proved our closed formula for T_n holds.\nIn order to solve this problem, we first found a mathematical expression that allowed us to solve the problem for any number of disks, and then found a closed form for our mathematical expression. The book will focus primarily on finding these closed forms of mathematical expression, and without using a lucky guess to find the closed form.\nIntrestingly enough, our recurrence from (1) can be simplified by adding 1 to both sides of the equation:\n\nT_0 + 1 = 1\\\\\nT_n + 1 = 2T_{n-1} + 2\n\nNow if we let U_n = T_n + 1, we get\n\nU_0 = 1\\\\\nU_n = 2U_{n-1}\n\\tag{3}\nIt is pretty clear that our closed formula is U_n = 2^n; thus T_n = 2^n - 1."
  },
  {
    "objectID": "qmd/concrete/recurrent/towerhanoi.html",
    "href": "qmd/concrete/recurrent/towerhanoi.html",
    "title": "The Tower of Hanoi",
    "section": "",
    "text": "The Tower of Hanoi is a problem proposed by Edouard Lucas in 1883. We are given a tower of eight disks stacked in decreasing size on one of three pegs. The objective is to transfer the disks from one peg to another, only moving one disk at a time, and never moving a larger disk onto a smaller one.\nSay that T_n is the minimum number of moves to transfer a tower of size n to another peg. It is clear T_1 = 1, and that T_2 = 3. Additionally, one could say T_0 = 0.\nWhen given a tower of size n, it takes T_{n-1} moves to move the n-1 smaller tower onto another peg, one move to move the largest disk onto the desired peg, and then another T_{n-1} moves to move the tower of size n onto the largest disk. This gives us a general formula\n\nT_0 = 0;\\\\\nT_n = 2T_{n-1} + 1\n\\tag{1}\nA set of inequalities like the one shown in \\left(1\\right) is called a recurrence. Defined by an intial value (T_0 = 0) and then a general value in terms of an earlier one T_{n} = 2T_{n-1} + 1.\nThough finding a numerical value becomes tedious when n is large enough. What would reduce computation time is a ‘closed form’ for T_n, one that can be evaluated without knowing T_n for all smaller values of n.\nCalculating the first few values of T, we get T_1 = 1, T_2 = 3, T_3 = 7, T_4 = 15, ect. It would appear that \nT_n = 2^n - 1 \\quad \\text{for } n \\geq 0\n\\tag{2}\nBut this is not a proof. We can manually confirm it to be true for many values of n, but in order to prove it for all values of n, we will have to use induction.\n\n\n\n\n\n\nProof\n\n\n\nWe want to show\n\nT_n = 2^n - 1.\n\nWe use n = 0 for our basis, which works as 2^0 - 1 = 0.\nBy the induction hypothesis\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\nAnd thus T_n = 2^n - 1 for all n.\n\n\nSo we get\nIn order to solve this problem, we first found a mathematical expression that allowed us to solve the problem for any number of disks, and then found a closed form for our mathematical expression. The book will focus primarily on finding these closed forms of mathematical expression, and without using a lucky guess to find the closed form.\nIntrestingly enough, our recurrence from (1) can be simplified by adding 1 to both sides of the equation:\n\nT_0 + 1 = 1\\\\\nT_n + 1 = 2T_{n-1} + 2\n\nNow if we let U_n = T_n + 1, we get\n\nU_0 = 1\\\\\nU_n = 2U_{n-1}\n\\tag{3}\nIt is pretty clear that our closed formula is U_n = 2^n; thus T_n = 2^n - 1."
  },
  {
    "objectID": "qmd/concrete/recurrent/towerhanoi.html#the-problem",
    "href": "qmd/concrete/recurrent/towerhanoi.html#the-problem",
    "title": "The Tower of Hanoi",
    "section": "",
    "text": "The Tower of Hanoi is a problem proposed by Edouard Lucas in 1883. We are given a tower of eight disks stacked in decreasing size on one of three pegs. The objective is to transfer the disks from one peg to another, only moving one disk at a time, and never moving a larger disk onto a smaller one.\nSay that T_n is the minimum number of moves to transfer a tower of size n to another peg. It is clear T_1 = 1, and that T_2 = 3. Additionally, one could say T_0 = 0.\nWhen given a tower of size n, it takes T_{n-1} moves to move the n-1 smaller tower onto another peg, one move to move the largest disk onto the desired peg, and then another T_{n-1} moves to move the tower of size n onto the largest disk. This gives us a general formula\n\nT_0 = 0;\\\\\nT_n = 2T_{n-1} + 1\n\\tag{1}\nA set of inequalities like the one shown in \\left(1\\right) is called a recurrence. Defined by an intial value (T_0 = 0) and then a general value in terms of an earlier one T_{n} = 2T_{n-1} + 1.\nThough finding a numerical value becomes tedious when n is large enough. What would reduce computation time is a ‘closed form’ for T_n, one that can be evaluated without knowing T_n for all smaller values of n.\nCalculating the first few values of T, we get T_1 = 1, T_2 = 3, T_3 = 7, T_4 = 15, ect. It would appear that \nT_n = 2^n - 1 \\quad \\text{for } n \\geq 0\n\\tag{2}\nBut this is not a proof. We can manually confirm it to be true for many values of n, but in order to prove it for all values of n, we will have to use induction.\n\n\n\n\n\n\nProof\n\n\n\nWe want to show\n\nT_n = 2^n - 1.\n\nWe use n = 0 for our basis, which works as 2^0 - 1 = 0.\nBy the induction hypothesis\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\nAnd thus T_n = 2^n - 1 for all n.\n\n\nSo we get\nIn order to solve this problem, we first found a mathematical expression that allowed us to solve the problem for any number of disks, and then found a closed form for our mathematical expression. The book will focus primarily on finding these closed forms of mathematical expression, and without using a lucky guess to find the closed form.\nIntrestingly enough, our recurrence from (1) can be simplified by adding 1 to both sides of the equation:\n\nT_0 + 1 = 1\\\\\nT_n + 1 = 2T_{n-1} + 2\n\nNow if we let U_n = T_n + 1, we get\n\nU_0 = 1\\\\\nU_n = 2U_{n-1}\n\\tag{3}\nIt is pretty clear that our closed formula is U_n = 2^n; thus T_n = 2^n - 1."
  },
  {
    "objectID": "qmd/concrete/recurrent/towerhanoi.html#linear-problem",
    "href": "qmd/concrete/recurrent/towerhanoi.html#linear-problem",
    "title": "The Tower of Hanoi",
    "section": "Linear Problem",
    "text": "Linear Problem\nNow that we have an understanding for the general problem, we can begin making some alterations. In the linear problem, we label the pegs A,B and C. A disk can only be moved from peg A to peg B, and peg B to peg C.\nWe are tasked with finding the shortest number of moves to get a tower of size n from peg A to peg C. Let this minimum be given by L(n).\nThe only way to move the bottom disk n is to have the entire tower of n-1 disks on peg C. Then we can move disk n onto peg B. The only way to move the disk forward again is if the n-1 tower is on peg A now. We can now move disk n to peg C, and the tower back onto peg C. This gives us the following recurrence\n\nL(0) = 0\\\\\nL(n) = 3L(n-1) + 2\n\nUsing our previous simplification trick, let U(n) = L(n) + 1.\n\nU(n) = L(n) + 1 = 3L(n-1) + 3 = 3(L(n-1) + 1) = 3U(n-1)\\\\\n\nThus we get the closed formula\n\nL(n) = 3^n - 1"
  },
  {
    "objectID": "qmd/concrete/intro.html",
    "href": "qmd/concrete/intro.html",
    "title": "Concrete Mathematics",
    "section": "",
    "text": "Concrete mathematics is basically just discrete mathematics with a cooler name. These are my notes on the book.\n\nTable of Contents\n1 - Recurrent Problems\n  1.1 - The Tower of Hanoi\n  1.2 - Lines in the Plane\n  1.3 - The Josephus Problem\n2 - Structure and Representation\n3 - Matching\n4 - Subgraphs\n5 - Trees\n6 - Connectivity\n7 - Planarity\n8 - Coloring\n9 - Flows\n10 - Hamilton Cycles"
  },
  {
    "objectID": "qmd/concrete/recurrent/recprob.html",
    "href": "qmd/concrete/recurrent/recprob.html",
    "title": "Recurrent Problems",
    "section": "",
    "text": "This chapter of ‘Concrete Mathematics’ explores recurrence problems."
  },
  {
    "objectID": "qmd/concrete/recurrent/recprob.html#the-tower-of-hanoi",
    "href": "qmd/concrete/recurrent/recprob.html#the-tower-of-hanoi",
    "title": "Recurrent Problems",
    "section": "The Tower of Hanoi",
    "text": "The Tower of Hanoi\nThe Tower of Hanoi is a problem proposed by Edouard Lucas in 1883. We are given a tower of eight disks stacked in decreasing size on one of three pegs. The objective is to transfer the disks from one peg to another, only moving one disk at a time, and never moving a larger disk onto a smaller one.\nThe authors present the solution throught the use of two techniques. The authors first look at small cases of the problem, and then create a variable T_n to analyze.\nSay that T_n is the minimum number of moves to transfer a tower of size n to another peg. It is clear T_1 = 1, and that T_2 = 3. Additionally, one could say T_0 = 0.\nWhen given a tower of size n, it takes T_{n-1} moves to move the n-1 smaller tower onto another peg, one move to move the largest disk onto the desired peg, and then another T_{n-1} moves to move the tower of size n onto the largest disk. This gives us a general formula\n\nT_0 = 0;\\\\\nT_n = 2T_{n-1} + 1\n\\tag{1}\nA set of inequalities like the one shown in Equation 1 is called a recurrence. Defined as giving an intial value (T_0 = 0) and then a general value in terms of an earlier one T_{n} = 2T_{n-1} + 1.\nThough finding a numerical value becomes tedious when n is large enough. What would reduce computation time is a ‘closed form’ for T_n, one that can be evaluated without knowing T_n for all smaller values of n.\nThrough less than rigourous means, one can determine that the equation\n\nT_n = 2^n - 1 \\quad \\text{for } n \\geq 0\n\\tag{2}\nBut this is not a proof. We can manually confirm it to be true for many values of n, but in order to prove it for all values of n, we will use a tool called Mathematical induction.\nThis works by first proving the equation true for one value of n, know as n_0 called the basis. Then proving it for all $ n &gt; n_0$. We assume the statement is true for all values n_0 to n - 1 inclusive.\nWe can use n = 0 as our basis, as clearly T_0 = 2^0 - 1 = 0. The induction follows for n &gt; 0 if we use the induction hypothesis to say (2) holds for n - 1\n\nT_n = 2T_{n-1} + 1 = 2(2^{n-1} - 1) + 1 = 2^n - 1\n\nThus (2) holds for n. We have now found and proved our closed formula for T_n holds.\nIn order to solve this problem, we first found a mathematical expression that allowed us to solve the problem for any number of disks, and then found a closed form for our mathematical expression. The book will focus primarily on finding these closed forms of mathematical expression, and without using a lucky guess to find the closed form.\nIntrestingly enough, our recurrence from (1) can be simplified by adding 1 to both sides of the equation:\n\nT_0 + 1 = 1\\\\\nT_n + 1 = 2T_{n-1} + 2\n\nNow if we let U_n = T_n + 1, we get\n\nU_0 = 1\\\\\nU_n = 2U_{n-1}\n\\tag{3}\nIt is pretty clear that our closed formula is U_n = 2^n; thus T_n = 2^n - 1."
  },
  {
    "objectID": "qmd/concrete/recurrent/recprob.html#lines-in-the-plane",
    "href": "qmd/concrete/recurrent/recprob.html#lines-in-the-plane",
    "title": "Recurrent Problems",
    "section": "Lines in the Plane",
    "text": "Lines in the Plane\nOur next problem is on the plane. What is the maximum number L_n of regions defined by n lines on a plane. This problem was first solved by Jacob Steiner in 1826. If we take a similar approach to the last section, starting with smaller cases:\n\nL_0 = 1\\\\\nL_1 = 2\\\\\nL_2 = 4\n\nWe might come to the natural conclusion that L_n = 2^n. And this would be true if each line cut each region in half; but adding a third line makes it clear that we can only split as most 3 regions, giving us L_3 = 7. We realize that a new line on the plane adds k extra regions if and only if it intersects k old regions, and the line intersects k regions if and only if it hits the previous lines in k-1 places. Two lines can intersect in at most one point. So the new line can intersect the n - 1 lines at n-1 places. Thus the upper bound for this problem is\n\nL_n \\leq L_{n-1} + n \\quad \\text{for} n &gt; 0.\n\nFurthermore it’s easy to change this into equality by adding the restriction that none of the n lines are parrall, and that three lines do not intersect at the same point. This ensures that each new line n intersects every other line at some new point splitting the region. Our recurrence relation is then\n\nL_0 = 1;\\\\\nL_n = L_{n-1} + n,\\quad \\text{for } n &gt; 0.\n\\tag{4}\nOne can verify there are no silly mistakes by checking our established values of L_0,L_1 and L_2. All checks out, so we buy the recurrence relation. Now we need a general formula.\nThrough some trial and error, we can unfold L_n into\n\nL_n = L_0 + 1 + 2 + \\cdots + n\n\nLetting\n\nS_n = 1 + 2 + \\cdots + n\n\nWe get the ‘closed form’\n\nL_n = 1 + S_n\n\nBut this just replaces one recurrence for another. It is said that in 1786, when Guass was nine years old, he had found a closed form of S_n using the following trick\n\\begin{array}{ll}\n&S_n &=  &1  &+ &2 &+ \\cdots + &(n - 1) &+ &n\\\\\n+&S_n &=  &n  &+ &(n-1) &+ \\cdots + &2 &+ &1\\\\\n\\hline\n2&S_n &= &(n+1) &+ &(n+1) &+ \\cdots + &(n+1) &+ &(n+1)\n\\end{array}\\\\\nNotice how 2S_n is now just equal to n copies of (n + 1), therefore\n\nS_n = \\frac{n(n+1)}{2}, \\quad \\text{for } n \\geq 0\n\\tag{5}\nGiving us our closed form\n\nL_n = \\frac{n(n+1)}{2} + 1, \\quad \\text{for } n \\geq 0.\n\\tag{6}\nOne might consider this a proof, despite the handwavy techniques used in its derivation. A proof by induction is simple, so we might as well give ourselves some stricter standards. The induction is proved with\n\nL_n = \\frac{(n-1)n}{2} + 1 + n = \\frac{n(n+1)}{2} + 1\n\nThus we have no doubt (6) is correct.\nWe can now look at a vairation of the line problem. Suppose instead of straight lines each line has a zig in it. What is the maximum number Z_n of regions determined by n. One can see Z_1 = 2 and Z_2 = 7.\nFrom some thought and small cases, one notices that a line with a zig is simply two lines who don’t extend past their intersection point. We can arrange these zigged lines such that the intersection point is far enough from the other lines that we only lose two regions per line. Thus\n\nZ_n = L_2n - 2n = 2n(2n - 1)/2 + 1 - 2n\\\\\nZ_n = 2n^2 - n + 1 \\quad \\text{for } n \\geq 0.\n\\tag{7}"
  },
  {
    "objectID": "qmd/concrete/recurrent/recprob.html#the-josephus-problem",
    "href": "qmd/concrete/recurrent/recprob.html#the-josephus-problem",
    "title": "Recurrent Problems",
    "section": "The Josephus Problem",
    "text": "The Josephus Problem\nThe Josephus problem is actually an ancient problem dating back to the first century. The problem has n people standing in a circle. Each person kills the person directly to their left, until there is only one left. We want to find the position of the surviving player.\nWe can easily see J(1) = 1. When there is an even number 2n of players, note that all the even numbers die the first round. Our circle would then resemble a circle of size n, where each players number has been doubled and then had 1 subtracted from it. That is\n\nJ(2n) = 2J(n) - 1\n\nNow if we do a similar thing with an odd number of survivors, we see\n\nJ(2n + 1) = 2J(n) + 1\n\nThis can be used to define a recurrence relation\n\nJ(1) = 1\\\\\nJ(2n) = 2J(n) - 1\\\\\nJ(2n + 1) = 2J(n) + 1\n\\tag{8}\nThis recurrence is much more effienct than our previous ones. As if we wanted to calculate a large n, we would need far fewer than n steps to get our solution (Around \\log_2n steps).\nThrough some trial and error, we can arrive at the following equation\n\nJ(2^m + l) = 2l + 1\n\\tag{9}\nWhich can be solved by induction.\n\nBinary Representation\nBecause powers of 2 played such an important role in finding our solution, one might want to look at n in it’s base 2 reprensentation. Suppose\n\nn = (b_mb_{m-1}\\ldots b_1b_0)_2\n\nNote that b_m is always 1. Letting n = 2^m + l, we have\n\nn = (1b_{m-1}\\ldots b_1b_0)_2\\\\\nl = (0b_{m-1}\\ldots b_1b_0)_2\\\\\n2l = (b_{m-1}\\ldots b_1b_00)_2\\\\\n2l + 1 = (b_{m-1}\\ldots b_1b_01)_2\\\\\nJ(n) = (b_{m-1}\\ldots b_1b_0b_m)_2\n\nThus\n\nJ((1b_{m-1}\\ldots b_1b_0)_2) = (b_{m-1}\\ldots b_1b_0b_m)_2\n\\tag{10}\nThis means we can find J(n) by doing a one-bit cyclic shift left on n. Which is insanely simple given the amount of work it was to find a solution in base 10! For example, if n = 1101_2 then J(n) = 1011_2. Note this breaks when J(1011_2) = 111_2\nIf we repeatedly apply J to a number n, we will eventually produce a number consisting of bits which are exclusivly 1, whos value is 2^{v(n)} - 1 where v(n) is the number of bits of value 1 in the binary representation of n. Because v(13) = 3,\n\nJ(J(\\cdots J(13)\\cdots)) = 2^3 - 1 = 7.\n\nHow many iterations of J does it take to get this fixed value? No idea.\n\n\nGenerilized Josephus Problem\nWhat would happen if we generilized (8) with different constants? How would that change our closed form solutions. Lets investiagte this with a more general recurrence\n\\begin{array}{ll}\nf(1) &=& \\alpha;\\\\\nf(2n) &=& 2f(n) + \\beta;\\\\\nf(2n + 1) &=& 2f(n) + \\gamma;\n\\end{array}\n\n\\tag{11}\nOur recurrence J(n) had constants \\alpha = 1, \\beta = -1 and \\gamma = 1."
  },
  {
    "objectID": "qmd/concrete/recurrent/towerhanoi.html#cyclic-problem",
    "href": "qmd/concrete/recurrent/towerhanoi.html#cyclic-problem",
    "title": "The Tower of Hanoi",
    "section": "Cyclic Problem",
    "text": "Cyclic Problem\nImagine that you could only make clockwise moves. That is, A to B, B to C, and C to A. We let Q(n) be the minimum number of moves to get a tower of size n from peg A to peg B, and R(n) to reverse Q(n), that is get a tower from peg B to A.\nFor this problem, we will define Q and R in terms of each other, and solve the recurrence in a later chapter. Starting with Q(n), one can notice by moving the top n-1 disks back, the largest disk forward, and then the top n-1 disks back, we get\n\nQ(0) = 0\\\\\nQ(n) = 2R(n-1) + 1\n\nSimilary for R(n), we can move the top n-1 back a peg, the bottom disk forward a peg, the top n-1 back to their starting peg, move the bottom peg once more, and then move the top n-1 back. This gets us\n\nR(n) = R(n-1) + 1 + Q(n-1) + 1 + R(n-1)\\\\\nR(n) = 2R(n-1) + Q(n-1) + 2\\\\\nR(n) = Q(n) + Q(n-1) + 1"
  },
  {
    "objectID": "qmd/concrete/recurrent/towerhanoi.html#multiple-disks",
    "href": "qmd/concrete/recurrent/towerhanoi.html#multiple-disks",
    "title": "The Tower of Hanoi",
    "section": "Multiple disks",
    "text": "Multiple disks\nWhat if we have a tower of 2n disks of n sizes. That is we have two disks of each size, which are indistinguishable. After a little tinkering it’s clear that it is never beneficial to split the disks up, therefore the optimal solution is just doubling our initial solution. Letting D(n) be the optimal number of moves to move a stack,\n\nD(n) = 2T(n).\n\nThis problem becomes interesting if we let the two disks be distinguishable, and we wish to create the original tower. Let the minimum number of moves for this tower be DD(n). One may think this could be easily by moving the top n-1 towers in this fashion, move the bottom two disks, move n-1 back, move the bottom two, and then the top n-1 back on top. This gives us\n\nDD(n) = 3DD(n-1) + 4\n\nUnfortunetly induction immeditly fails, as DD(1) is 3. Notice that if we move all the disks of any size k an even number of times, they’ll be oriented right. We can minimize DD(n) by moving the bottom disks 3 times into the right orientation, and all the others an even number of times. Try it out, and notice how we get the following\n\nDD(n) = 4D(n-1) + 3\n\nThis works with induction, and can be simplified to give us\n\\begin{array}{ll}\nDD(n) &= 4D(n-1) + 3 = 8T(n-1) + 3 = 8(2^{n-1} - 1) + 3\\\\\n&=  2^{n+2} - 5 = 2^n - 1\n\\end{array}"
  },
  {
    "objectID": "qmd/logic/formalsystem.html",
    "href": "qmd/logic/formalsystem.html",
    "title": "Formal Systems",
    "section": "",
    "text": "A formal system consists of a formal language, with strict rules on what symbols are allowed and how to connect them, combined with a deductive system, containing axioms and rules for deducing true statements.\nOf course, without knowledge of what a language or deductive system is, this definition is useless."
  },
  {
    "objectID": "qmd/logic/formalsystem.html#formal-languages",
    "href": "qmd/logic/formalsystem.html#formal-languages",
    "title": "Formal Systems",
    "section": "Formal Languages",
    "text": "Formal Languages\nA formal language is defined by its symbols, such as quantifiers or connectives, and its syntax, rules for combining symbols. The most important class of formal language is known as first-order language, denoted \\mathcal{L}_1.\nThe symbols in a first-order language can be grouped into seven categories. Some authors may however chose to group the symbols into more or less categories, but the disctintion is arbitrary. These categories are\n\nConnectives - \\land, \\lor, \\implies, \\iff, \\lnot\nQuantifiers - \\forall, \\exists\nVariables - v_1,v_2,v_3 ect. A first-order language may consist of any countable amount of variables.\nConstants - c_0, c_1, c_2 ect. A first-order language may consist of any countable amount of constants.\nOperations - A first-order language can consist of any amount of countable operations (functions) f of any order.\nRelations - A first-order language can consist of any amount of countable relations p of any order.\nParentheses - Right ) and left (.\n\nMost of the time \\to will be used instead of \\implies, and \\leftrightarrow instead of \\iff, as the symbols are smaller are easier to read. For readibility sake, parenthesis occur in different sizes, or occansionally as brackets. Commas are also inserted to make formulas easier to read, but are not a formal symbol.\nNow we can begin constructing the syntax for first-order languages.\n\n\n\n\n\n\nDefinition\n\n\n\nEvery variable or constant is a term. Additionally, if f is an operator of degree n, and t_1,t_2,\\dots,t_n are terms, then f(t_1,t_2,\\dots,t_n) is a term.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf p is a relation of degree n, and t_1,t_2,\\dots,t_n are terms, then p(t_1,t_2,\\dots,t_n) is a formula.\nAdditionally, if P and Q are formulas, and x is a variable, then the expressions\n\nP \\iff Q, P \\implies Q, P \\land Q, P \\lor Q\\\\\n\\lnot P, \\forall x P, \\exists x P\n\nare also formulas.\n\n\nNote that mathematicians almost never write in unabbreviated notation. For example, the equation x + y would be wrote +(x,y), which looks silly.\nWe now can construct formulas from our symbols. Deciding truth values for these formulas is the role of a deductive system."
  },
  {
    "objectID": "qmd/logic/formalsystem.html#deduction-apparatus",
    "href": "qmd/logic/formalsystem.html#deduction-apparatus",
    "title": "Formal Systems",
    "section": "Deduction apparatus",
    "text": "Deduction apparatus"
  },
  {
    "objectID": "qmd/logic/formalsystem.html#deductive-apparatus",
    "href": "qmd/logic/formalsystem.html#deductive-apparatus",
    "title": "Formal Systems",
    "section": "Deductive apparatus",
    "text": "Deductive apparatus\nA deductive apparatus is a set of axioms and rules of inference which are used to deduce one true statement from another. The standard deductive apparatus is shown below. I don’t quite understand these so i’ll mostly brush over them.\n\n\n\n\n\n\nStandard deductive apparatus\n\n\n\nThe axioms and inferences listed are the standard for first-order logic.\nLogical Axioms\n\nAll tautologies\nUniversal specification\n\\forall x (P \\implies Q) \\implies (\\forall x P \\implies \\forall x Q)\nP \\implies \\forall x P\nDefinition of \\exists\nx = x\nSubstitution of equals\n\nRules of inference\nRules of inference are used to deduce a true statement from a previous. There is typically only one rule of inference.\n\nModus ponens"
  },
  {
    "objectID": "qmd/logic/theorem.html",
    "href": "qmd/logic/theorem.html",
    "title": "Formal Theories",
    "section": "",
    "text": "A theory is a set of formulas T in a formal language. We can take these theories as axioms, and combine them with a formal system belonging to first-order logic to create a first-order theory.\nWe’re long overdue for an example, so lets examine the two most popular first-order theories, Zermelo-Fraenkel set theory, and Peano arithmetic."
  },
  {
    "objectID": "qmd/logic/formalsystem.html#deductive-systems",
    "href": "qmd/logic/formalsystem.html#deductive-systems",
    "title": "Formal Systems",
    "section": "Deductive systems",
    "text": "Deductive systems\nA deductive system (deductive apparatus) is (usually) a set of axioms and rules of inference which are used to deduce one true statement from another. It is very common in math to use a Hilbert System, which consist of a large number of axioms, and few to no rules of inferences.\nBelow is an example of a Hilbert System which describes first-order logic.\n\n\n\n\n\n\nFOL Deductive system example1\n\n\n\nLogical Axioms\nThe first four axioms describe propositional logic, which is logic without quantifiers like \\land or \\lor.\nP1. \\phi \\rightarrow \\phi\nP2. \\phi \\rightarrow (\\psi \\rightarrow \\phi)\nP3. (\\phi \\rightarrow (\\psi \\rightarrow \\zeta)) \\rightarrow ((\\phi \\rightarrow \\psi) \\rightarrow (\\phi \\rightarrow \\zeta))\nP4. (\\lnot \\phi \\rightarrow \\lnot \\psi) \\rightarrow (\\psi \\rightarrow \\phi)\nHere, \\phi,\\psi and \\zeta refer to formulas, as constructed from our language. Thus, P1 could represent p \\rightarrow p or (p \\land q) \\rightarrow (p \\land q). This axiomitization is in no way unique, and in fact axiom P1 can be proven from P2 and P3.\nThe next three axioms allow us to manipulate quantifiers.\nQ5. \\forall x\\,(\\phi) \\rightarrow \\phi[x:=t] (Meaning t may be substituded for x in \\phi)\nQ6. \\forall x\\,(\\phi \\rightarrow \\psi) \\rightarrow (\\forall x\\,(\\phi) \\rightarrow \\forall x\\, (\\psi))\nQ7. \\phi \\rightarrow \\forall x \\,(\\phi) (where x is not free in \\phi)\nThese three axioms allow us to use the \\forall quantifier.\nFor formal systems where equality is not defined as a relation, the following two axioms are necessary.\nI8. x = x for every variable x.\nI9. (x = y) \\rightarrow (\\phi(x) = \\phi(y))\nRules of inference\nRules of inference are used to deduce a true statement from a previous. Modus ponens is typically the only used rule of inference.\nR1. Modus ponens\nModus ponens states that if p and p \\rightarrow q are true, then q is true.\n\n\nNote any connective can be formed using only \\lnot and \\rightarrow, and the exists quantifier can be defined using connectives and the for all quantifier.\nNow that we’ve defined a formal language to produce formulas, and a deduction system to define truth, we can construct a formal system."
  },
  {
    "objectID": "qmd/logic/formalsystem.html#footnotes",
    "href": "qmd/logic/formalsystem.html#footnotes",
    "title": "Formal Systems",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis section is copied from Wikipedia almost verbatim.↩︎"
  },
  {
    "objectID": "qmd/logic/formalsystem.html#formal-systems",
    "href": "qmd/logic/formalsystem.html#formal-systems",
    "title": "Formal Systems",
    "section": "Formal systems",
    "text": "Formal systems\nThe first formal system we"
  },
  {
    "objectID": "qmd/logic/formalsystem.html#first-order-logic",
    "href": "qmd/logic/formalsystem.html#first-order-logic",
    "title": "Formal Systems",
    "section": "First-order logic",
    "text": "First-order logic\nAlthough we can construct many formal systems by combining different languages with different deductive systems, the most popular formal systems belong to first-order logic, sometimes called predicate logic.\n\n\n\n\n\n\nDefinition\n\n\n\nFirst-order logic refers to a collection of formal systems composed of\n\nA first-order language\nA deductive system equivalent to the example shown above\n\n\n\nAs a concrete example, both ZF (Zermelo-Fraenkel set theory) and PA (Peano arithmetic) are theories in first-order logic. They both use a unique first-order language, and the same deductive system. So they both can be said to use first-order logic.\nWhat exactly ZF and PA are, and what a theory is, are explained in the next part."
  },
  {
    "objectID": "qmd/logic/theorem.html#example",
    "href": "qmd/logic/theorem.html#example",
    "title": "Formal Theories",
    "section": "Example",
    "text": "Example\nBelow is an example of a formal proof done in PA. Note the immense amount of pain that went into crafting it.\n\n\n\n\n\n\nLemma (Conjunction introduction)\n\n\n\n\\begin{alignat*}{2}\n&\\vdash A          &\\quad &\\textbf{}\\\\\n&\\vdash B          &\\quad &\\textbf{}\\\\\n&\\vdash A \\land B          &\\quad &\\textbf{Conjunction introduction}\\\\\n\\end{alignat*}\nThis will be assumed true.\n\n\n\n\n\n\n\n\nLemma (Symmetry of equality)\n\n\n\n\\begin{alignat*}{2}\n&\\vdash \\forall x \\forall y (x = y \\rightarrow y = x)          &\\quad &\\textbf{Symmetry of equality}\\\\\n\\end{alignat*}\nThis will be assumed true.\n\n\n\n\n\n\n\n\nLemma (Transitivity of equality)\n\n\n\n\\begin{alignat*}{2}\n&\\vdash \\forall x \\forall y \\forall z (x = y \\rightarrow (y = z \\rightarrow x = z))          &\\quad &\\textbf{Transitivity of equality}\\\\\n\\end{alignat*}\nThis will be assumed true.\n\n\n\n\n\n\n\n\nLemma (Conjunction introduction)\n\n\n\n\\begin{alignat*}{2}\n&\\vdash A          &\\quad &\\textbf{}\\\\\n&\\vdash B          &\\quad &\\textbf{}\\\\\n&\\vdash A \\land B          &\\quad &\\textbf{Conjunction introduction}\\\\\n\\end{alignat*}\nThis will be assumed true.\n\n\n\n\n\n\n\n\nTheorem (Commutative property of addition)\n\n\n\nPA \\vdash \\forall x \\forall y\\,(x + y = y + x)\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe’ll prove the theorem through induction on x. By axiom A7 we want to show\n(1)\\quad PA \\vdash \\forall y\\,(\\overline{0} + y = y + \\overline{0})\n(2)\\quad PA \\vdash \\forall y\\,(x + y = y + x) \\rightarrow \\forall y\\,(S(x) + y = y + S(x))\nWe start by proving (1). We’ll first prove the statement\nPA \\vdash \\forall y\\,(\\overline{0} + y = y).\nBy axiom A7 we want to show\n(1.1) \\quad PA \\vdash (\\overline{0} + \\overline{0} = \\overline{0})\n(1.2) \\quad PA \\vdash (\\overline{0} + y = y) \\rightarrow (\\overline{0} + S(y) = S(y))\nWe can prove (1.1)\n\\begin{alignat*}{2}\nPA &\\vdash \\forall x(x + \\overline{0} = x)          &\\quad &\\textbf{A3}\\\\\nPA &\\vdash \\forall x(x + \\overline{0} = x) \\rightarrow (\\overline{0} + \\overline{0} = \\overline{0})          &\\quad &\\textbf{Q5}\\\\\nPA &\\vdash (\\overline{0} + \\overline{0} = \\overline{0})          &\\quad &\\textbf{Modus ponens}\\\\\n\\end{alignat*}\nTo prove (1.2), let \\phi be the formula (\\overline{0} + y = y)\n\\begin{alignat*}{2}\nPA \\cup \\phi &\\vdash (\\overline{0} + y = y)          &\\quad &\\text{}\\\\\nPA \\cup \\phi &\\vdash \\forall x \\forall y (x + S(y) = S(x + y))          &\\quad &\\textbf{A4}\\\\\nPA \\cup \\phi &\\vdash \\forall x \\forall y (x + S(y) = S(x + y)) \\rightarrow \\overline{0} + S(y) = S(\\overline{0} + y)         &\\quad &\\textbf{Q5}\\\\\nPA \\cup \\phi &\\vdash \\overline{0} + S(y) = S(\\overline{0} + y)         &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\phi &\\vdash \\overline{0} + y = y \\rightarrow S(\\overline{0} + y) = S(y)          &\\quad &\\textbf{I9}\\\\\nPA \\cup \\phi &\\vdash S(\\overline{0} + y) = S(y)          &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\phi &\\vdash \\overline{0} + S(y) = S(y)          &\\quad &\\textbf{Transitivity of equality}\\\\\nPA &\\vdash (\\overline{0} + y = y) \\rightarrow (\\overline{0} + S(y) = S(y))&\\quad &\\textbf{Deductive theorem}\\\\\n\\end{alignat*}\nLet \\phi_{1.1} be (\\overline{0} + \\overline{0} = \\overline{0}) and \\phi_{1.2} be (\\overline{0} + y = y) \\rightarrow (\\overline{0} + S(y) = S(y))\n\\begin{alignat*}{2}\nPA &\\vdash (\\overline{0} + \\overline{0} = \\overline{0})          &\\quad &\\textbf{1.1}\\\\\nPA &\\vdash (\\overline{0} + y = y) \\rightarrow (\\overline{0} + S(y) = S(y))          &\\quad &\\textbf{1.2}\\\\\nPA &\\vdash \\phi_{1.1} \\land \\phi_{1.2}          &\\quad &\\textbf{Conjunction introduction}\\\\\nPA &\\vdash (\\phi_{1.1} \\land \\phi_{1.2}) \\rightarrow \\forall y (\\overline{0} + y = y)&\\quad &\\textbf{A7}\\\\\nPA &\\vdash \\forall y (\\overline{0} + y = y)&\\quad &\\textbf{Modus ponens}\\\\\n\\end{alignat*}\nNow we prove the equivalence to (1).\n\\begin{alignat*}{2}\nPA &\\vdash \\forall x (x + \\overline{0} = x)    &\\quad &\\textbf{A3}\\\\\nPA &\\vdash \\forall x (x + \\overline{0} = x) \\rightarrow y + \\overline{0} = y   &\\quad &\\textbf{Q5}\\\\\nPA &\\vdash y + \\overline{0} = y   &\\quad &\\textbf{Modus ponens}\\\\\nPA &\\vdash y = y + \\overline{0}   &\\quad &\\textbf{Symmetry of equality}\\\\\nPA &\\vdash \\forall y (\\overline{0} + y = y) \\rightarrow \\overline{0} + y = y &\\quad &\\textbf{Q5}\\\\\nPA &\\vdash \\overline{0} + y = y   &\\quad &\\textbf{Modus ponens}\\\\\nPA &\\vdash \\overline{0} + y = y + \\overline{0}   &\\quad &\\textbf{Transitivity of equality}\\\\\nPA &\\vdash \\overline{0} + y = y + \\overline{0} \\rightarrow \\forall y \\, (\\overline{0} + y = y + \\overline{0})   &\\quad &\\textbf{Q7}\\\\\nPA &\\vdash \\forall y\\,(\\overline{0} + y = y + \\overline{0})   &\\quad &\\textbf{Modus ponens}\\\\\n\\end{alignat*}\nNow we can prove (2). We’ll start by proving a prerequisite\nPA \\vdash \\forall y \\,(S(x) + y = S(x + y))\nBy A7 we want to show\n(2.1) \\quad PA \\vdash S(x) + \\overline{0} = S(x + \\overline{0})\n(2.2) \\quad PA \\vdash S(x) + y = S(x + y) \\rightarrow S(x) + S(y) = S(x + S(y))\nWe can first prove (2.1)\n\\begin{alignat*}{2}\nPA &\\vdash \\forall x(x + \\overline{0} = x)          &\\quad &\\textbf{A3}\\\\\nPA &\\vdash \\forall x(x + \\overline{0} = x) \\rightarrow S(x) + \\overline{0} = S(x)        &\\quad &\\textbf{Q5}\\\\\nPA &\\vdash S(x) + \\overline{0} = S(x)        &\\quad &\\textbf{Modus ponens}\\\\\nPA &\\vdash \\forall x(x + \\overline{0} = x)          &\\quad &\\textbf{A3}\\\\\nPA &\\vdash \\forall x(x + \\overline{0} = x) \\rightarrow x + \\overline{0} = x        &\\quad &\\textbf{Q5}\\\\\nPA &\\vdash x + \\overline{0} = x        &\\quad &\\textbf{Modus ponens}\\\\\nPA &\\vdash x + \\overline{0} = x \\rightarrow S(x + \\overline{0}) = S(x)      &\\quad &\\textbf{I9}\\\\\nPA &\\vdash S(x + \\overline{0}) = S(x)        &\\quad &\\textbf{Modus ponens}\\\\\nPA &\\vdash S(x) = S(x + \\overline{0})        &\\quad &\\textbf{Symmetry of equality}\\\\\nPA &\\vdash S(x) + \\overline{0} = S(x + \\overline{0})        &\\quad &\\textbf{Transitivity of equality}\\\\\n\\end{alignat*}\nThen (2.2). Let \\psi be the formula (S(x) + y = S(x + y))\n\\begin{alignat*}{2}\nPA \\cup \\psi &\\vdash S(x) + y = S(x + y)          &\\quad &\\text{}\\\\\nPA \\cup \\psi &\\vdash \\forall x \\forall y(x + S(y) = S(x + y))          &\\quad &\\textbf{A4}\\\\\nPA \\cup \\psi &\\vdash \\forall x \\forall y(x + S(y) = S(x + y)) \\rightarrow   S(x) + S(y) = S(S(x) + y)    &\\quad &\\textbf{Q5}\\\\\nPA \\cup \\psi &\\vdash S(x) + S(y) = S(S(x) + y)    &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\psi &\\vdash \\forall x \\forall y(x + S(y) = S(x + y))          &\\quad &\\textbf{A4}\\\\\nPA \\cup \\psi &\\vdash \\forall x \\forall y(x + S(y) = S(x + y)) \\rightarrow   x + S(y) = S(x + y)    &\\quad &\\textbf{Q5}\\\\\nPA \\cup \\psi &\\vdash x + S(y) = S(x + y)    &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\psi &\\vdash S(x + y) = x + S(y)    &\\quad &\\textbf{Symmetry of equality}\\\\\nPA \\cup \\psi &\\vdash S(x) + y = x + S(y)     &\\quad &\\textbf{Transitivity of equality}\\\\\nPA \\cup \\psi &\\vdash S(x) + y = x + S(y) \\rightarrow S(S(x) + y) = S(x + S(y))     &\\quad &\\textbf{I9}\\\\\nPA \\cup \\psi &\\vdash S(S(x) + y) = S(x + S(y))     &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\psi &\\vdash S(x) + S(y) = S(x + S(y))     &\\quad &\\textbf{Transitivity of equality}\\\\\nPA &\\vdash S(x) + y = S(x + y) \\rightarrow S(x) + S(y) = S(x + S(y))     &\\quad &\\textbf{Deductive theorem}\\\\\n\\end{alignat*}\nLet (2.1) and (2.2) be \\psi_{2.1} and \\psi_{2.2} respectively.\n\\begin{alignat*}{2}\nPA &\\vdash S(x) + \\overline{0} = S(x + \\overline{0})        &\\quad &\\textbf{2.1}\\\\\nPA &\\vdash S(x) + y = S(x + y) \\rightarrow S(x) + S(y) = S(x + S(y))     &\\quad &\\textbf{2.2}\\\\\nPA &\\vdash   \\psi_{2.1} \\land \\psi_{2.2}      &\\quad &\\textbf{Conjunction introduction}\\\\\nPA &\\vdash (\\psi_{2.1} \\land \\phi_{2.2}) \\rightarrow \\forall y (S(x) + y = S(x + y))&\\quad &\\textbf{A7}\\\\\nPA &\\vdash \\forall y (S(x) + y = S(x + y))&\\quad &\\textbf{Modus ponens}\\\\\n\\end{alignat*}\nLet this formula be denoted \\pi\nNow we can prove (2). Let \\zeta be the formula \\forall y(x + y = y + x)\n\\begin{alignat*}{2}\nPA \\cup \\zeta &\\vdash \\forall y(x + y = y + x)          &\\quad &\\text{}\\\\\nPA \\cup \\zeta &\\vdash \\forall y (S(x) + y = S(x + y))         &\\quad &\\pmb\\pi\\\\\nPA \\cup \\zeta &\\vdash \\forall y (S(x) + y = S(x + y)) \\rightarrow S(x) + y = S(x + y)         &\\quad &\\textbf{Q5}\\\\\nPA \\cup \\zeta &\\vdash  S(x) + y = S(x + y)         &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\zeta &\\vdash \\forall y(x + y = y + x) \\rightarrow x + y = y + x         &\\quad &\\textbf{Q5}\\\\\nPA \\cup \\zeta &\\vdash x + y = y + x         &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\zeta &\\vdash x + y = y + x \\rightarrow S(x + y) = S(y + x)        &\\quad &\\textbf{I9}\\\\\nPA \\cup \\zeta &\\vdash S(x + y) = S(y + x)        &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\zeta &\\vdash S(x) + y = S(y + x)        &\\quad &\\textbf{Transitivity of equality}\\\\\nPA \\cup \\zeta &\\vdash \\forall x \\forall y(x + S(y) = S(x + y))          &\\quad &\\textbf{A4}\\\\\nPA \\cup \\zeta &\\vdash \\forall x \\forall y(x + S(y) = S(x + y)) \\rightarrow   y + S(x) = S(y + x)    &\\quad &\\textbf{Q5}\\\\\nPA \\cup \\zeta &\\vdash y + S(x) = S(y + x)    &\\quad &\\textbf{Modus ponens}\\\\\nPA \\cup \\zeta &\\vdash S(y + x) = y + S(x)   &\\quad &\\textbf{Symmetry of equality}\\\\\nPA \\cup \\zeta &\\vdash S(x) + y = y + S(x)   &\\quad &\\textbf{Transitivity of equality}\\\\\nPA \\cup \\zeta &\\vdash S(x) + y = y + S(x) \\rightarrow \\forall y (S(x) + y = y + S(x))   &\\quad &\\textbf{Q7}\\\\\nPA \\cup \\zeta &\\vdash \\forall y (S(x) + y = y + S(x))   &\\quad &\\textbf{Modus ponens}\\\\\nPA &\\vdash \\forall y(x + y = y + x) \\rightarrow \\forall y (S(x) + y = y + S(x))   &\\quad &\\textbf{Deductive theorem}\\\\\n\\end{alignat*}\nAnd finally, let \\gamma_1 and \\gamma_2 be (1) and (2) respectively.\n\\begin{alignat*}{2}\nPA &\\vdash \\forall y\\,(\\overline{0} + y = y + \\overline{0})          &\\quad &\\pmb\\gamma_1\\\\\nPA &\\vdash \\forall y\\,(x + y = y + x) \\rightarrow \\forall y\\,(S(x) + y = y + S(x))          &\\quad &\\pmb\\gamma_2\\\\\nPA &\\vdash \\gamma_1 \\land \\gamma_2          &\\quad &\\textbf{Conjunction introduction}\\\\\nPA &\\vdash (\\gamma_1 \\land \\gamma_2) \\rightarrow \\forall y \\forall x(x + y = y + x)  &\\quad &\\textbf{A7}\\\\\nPA &\\vdash \\forall y \\forall x(x + y = y + x) &\\quad &\\textbf{Modus ponens}\\\\\n\\end{alignat*}"
  },
  {
    "objectID": "qmd/logic/theorem.html#proof",
    "href": "qmd/logic/theorem.html#proof",
    "title": "Formal theories",
    "section": "Proof",
    "text": "Proof\nNow that we have knowledge of what a first-order theory is, lets look at how to prove statements with them. We first need to give the definition of what proof even means.\n\n\n\n\n\n\nDefinition\n\n\n\nLet T be a set of first-order formulas. A proof from T is a finite sequence of formulas such that every step is either a logical axiom, a member of T, or a result of one of our rules of inference. A proof a formula P from T is given when P is the last step of a proof from T.\n\n\nIf we can prove P from a theory T, we say T proves P, denoted T \\vdash P\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varnothing \\vdash P, then P is derivable from only our deductive apparatus, and we call P a law of logic.\nTwo formulas P and Q are called logically equivalent if \\vdash (P \\leftrightarrow Q)\n\n\nWe denote the set of theorems (statements provable from T) in T as Thm(T).\n\n\n\n\n\n\nDefinition\n\n\n\nIf Thm(T_1) \\subseteq Thm(T_2), which is the same as T_2 \\vdash T_1, we say that T_1 is a subtheory of T_2, and T_2 is an extension of T_1. If Thm(T_1) = Thm(T_2) then T_1 and T_2 are equivalent.\n\n\nLots of boring and tedious notation, but such is life. The great thing about proofs is that they are computable, meaning there exist a machine, i.e. computer program, that can verify the validity of any proof. This does not mean that a computer can create a proof however, just that given one, they can check its accuracy.\nOne of the great things about first-order logic is that provability and truth are equivalent. That is, if there exist a formula P, we can construct it from T with a proof, if and only if P and all statements in T are true!"
  },
  {
    "objectID": "qmd/logic/theorem.html#formal-proofs",
    "href": "qmd/logic/theorem.html#formal-proofs",
    "title": "Formal Theories",
    "section": "Formal proofs",
    "text": "Formal proofs\nNow that we have knowledge of what a first-order theory is, lets look at how to prove statements with them. We first need to give the definition of what a proof.\n\n\n\n\n\n\nDefinition\n\n\n\nLet T be a set of first-order formulas. A proof from T is a finite sequence of formulas such that every step is either a logical axiom, a member of T, or a result of one of our rules of inference. A proof a formula P from T is given when P is the last step of a proof from T.\n\n\nIf we can prove P from a theory T, we say T proves P, denoted T \\vdash P\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varnothing \\vdash P, then P is derivable from only our deductive apparatus, and we call P a law of logic.\nTwo formulas P and Q are called logically equivalent if \\vdash (P \\leftrightarrow Q)\n\n\nWe denote the set of theorems (statements provable from T) in T as Thm(T).\n\n\n\n\n\n\nDefinition\n\n\n\nIf Thm(T_1) \\subseteq Thm(T_2), which is the same as T_2 \\vdash T_1, we say that T_1 is a subtheory of T_2, and T_2 is an extension of T_1. If Thm(T_1) = Thm(T_2) then T_1 and T_2 are equivalent.\n\n\nLots of boring and tedious notation, but such is life. The great thing about proofs is that they are computable, meaning there exist a machine, i.e. computer program, that can verify the validity of any proof. This does not mean that a computer can create a proof however, just that given one, they can check its accuracy.\nOne of the great things about first-order logic is that provability and truth are equivalent. That is, if there exist a formula P, we can construct it from T with a proof, if and only if P and all statements in T are true!\n\n\n\n\n\n\nDefinition\n\n\n\nWe say a theory T is consistent if no contradiction can be derived from it. A formula P is said to be independent of T if neither P nor \\lnot P can be proved from T. We call T complete if no sentence (formula with no free variables) of its language is independent of T."
  },
  {
    "objectID": "qmd/logic/theorem.html#meta",
    "href": "qmd/logic/theorem.html#meta",
    "title": "Formal Theories",
    "section": "Meta",
    "text": "Meta"
  },
  {
    "objectID": "qmd/logic/theorem.html#metatheorems",
    "href": "qmd/logic/theorem.html#metatheorems",
    "title": "Formal Theories",
    "section": "Metatheorems",
    "text": "Metatheorems\nMetatheorems are theorems about first-order logic. The following two metatheorems are the most notable.\n\n\n\n\n\n\nTheorem (Deduction Theorem)\n\n\n\nIf T \\cup \\{P\\} \\vdash Q then T \\vdash (P \\rightarrow Q)\n\n\nWhich means, if T and P prove Q, then T proves that P implies Q.\n\n\n\n\n\n\nTheorem (Universal generalization)\n\n\n\nIf T \\vdash P(x), and x is not a free variable, then T \\vdash \\forall x \\,P(x)"
  },
  {
    "objectID": "qmd/logic/theorem.html#first-order-theories",
    "href": "qmd/logic/theorem.html#first-order-theories",
    "title": "Formal Theories",
    "section": "First-order theories",
    "text": "First-order theories\nZF and PA are two examples of first-order theories. They use different symbols, so they require different languages.\n\n\n\n\n\n\n\n\nFirst-order language\n\\mathcal{L}_\\text{ZF}\n\\mathcal{L}_\\text{PA}\n\n\n\n\nConnectives\n\\land, \\lor, \\implies, \\iff, \\lnot\n\\land, \\lor, \\implies, \\iff, \\lnot\n\n\nQuantifiers\n\\forall, \\exists\n\\forall, \\exists\n\n\nVariables\nv_1,v_2,v_3 ect.\nv_1,v_2,v_3 ect.\n\n\nConstants\n\\varnothing (the empty set)\n\\overline{0} (zero)\n\n\nOperations -\nNone\nS (successor, degree 1) + (addition, degree 2), \\cdot (multiplication, degree 2)\n\n\nRelations -\n\\in (belongs to, degree 2)\n= (equality, degree 2)\n\n\nParentheses -\n), (\n), (\n\n\n\nBoth languages have the same syntax for combining symbols into formulas. They also use the same deductive system (any system equivalent to the example shown in the last section). We’ll delve deeper into Zermelo-Fraenkel set theory later, so we’ll examine Peano arithmetic as the example for the rest of the section.\nPeano arithmetic is a first-order theory, so it combines our formal system with a theory, consisting of formulas we define to be true.\n\n\n\n\n\n\nAxioms in Peano arithmetic\n\n\n\nThe first six axioms listed are rather simple. Note that \\overline{0} \\not = 0, as \\overline{0} is a formal symbol, not a number.\nA1. \\forall x \\,(\\overline{0} \\not = S(x))\nA2. \\forall x,y \\,(S(x) = S(y) \\rightarrow x = y)\nA3. \\forall x \\,(x + \\overline{0} = x)\nA4. \\forall x \\forall y \\,(x + S(y) = S(x + y))\nA5. \\forall x \\,(x \\cdot \\overline{0} = \\overline{0})\nA6. \\forall x,y \\,(x \\cdot S(y) = x \\cdot y + x)\nHowever, the seventh axiom poses a problem for first-order logic. We want an axiom allowing us to use induction. For this we’ll have to use something called an axiom schema, an infinite list of axioms, one for each formula \\phi which can be constructed in PA.\nA7. [\\phi(\\overline{0}) \\land \\forall n (\\phi(n) \\rightarrow \\phi(S(n)))] \\rightarrow \\forall n \\phi(n)\n\n\nThis has two drawbacks. The first of which being PA is not finite axiomatizable, meaning we need an infinite amount of axioms to define PA. This is annoying, but such is life. The second and more serious drawback is as follows. Each formula \\phi can be thought of a set of numbers n such that \\phi(n) is true. There exist an uncountable amount of sets n, but only a countable amount of formulas \\phi can be constructed. Therefore, our induction may prove inadequate for some theorems. This can rectified with second-order logic, which will be discussed later."
  },
  {
    "objectID": "qmd/matrix/unitone.html",
    "href": "qmd/matrix/unitone.html",
    "title": "Fundementals",
    "section": "",
    "text": "Let \\mathbb{R}^m be the space of column vectors with real entries, symbollically read\n\n\\mathbb{R}^m = \\{vector : x_i \\in \\mathbb{R}\\}\n\nWe use this to define a Linear combination\n\n\n\n\n\n\nDefinition\n\n\n\nIf v,w are both in \\mathbb{R}^m, and a,b in \\mathbb{R}, then av + bw is a linear combination.\n\n\nThere are two ways of looking at a matrix. Suppose we have a m by n matrix A.\n\\begin{align*}\nA =\n\\begin{pmatrix}\nA_{1,1} & \\cdots & A_{m,1}\\\\\n\\vdots &  & \\vdots\\\\\nA_{1,n} & \\cdots & A_{m,n}\n\\end{pmatrix}\n\\end{align*}\nWe have the column view of A, and the row view of A. Write\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be an m by n matrix. We define the Transpose of A, denoted A^T, as\n\n\nWe immeditally get the following properties\n\nA_{m\\times n} = A^T_{n\\times m}\n(A^T)^T = A\n\nWe can define a matrix\n\n\n\n\n\n\nDefinition\n\n\n\nA matrix (m \\times n) is a function f \\colon \\mathbb{R} \\rightarrow \\mathbb{R}\nIf A_{m \\times n},\\, x \\in \\mathbb{R}^n, then\nA_x = A vector x = a linear combination of A col$ = col of row vecs\n\n\nMatrix multiplication\nWe denote the standard basis of \\mathbb{R}^m as\n\\begin{align*}\ne_1 =\n\\begin{pmatrix}\n1\\\\\n0\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_2 =\n\\begin{pmatrix}\n0\\\\\n1\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_m =\n\\begin{pmatrix}\n0\\\\\n0\\\\\n\\vdots\\\\\n1\n\\end{pmatrix}\n\\end{align*}\nAny vector in \\mathbb{R}^m is a linear combination of these e_i’s, in a unique way. For example\n\\begin{align*}\nx =\n\\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix} =\nx_1 e_1 + \\cdots + x_m e_m\n\\end{align*}\nWe define the identity matrix\n\\begin{align*}\nCol_j I = e_j, I = \\begin{pmatrix}\n1 & & 0\\\\\n& \\ddots & \\\\\n0 & & 1\n\\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "qmd/matrix/unitone.html#subsection-1",
    "href": "qmd/matrix/unitone.html#subsection-1",
    "title": "Unit one",
    "section": "",
    "text": "Let \\mathbb{R}^m be the space of column vectors with real entries, symbollically read\n\n\\mathbb{R}^m = \\{vector : x_i \\in \\mathbb{R}\\}\n\nWe use this to define a Linear combination\n\n\n\n\n\n\nDefinition\n\n\n\nIf v,w are both in \\mathbb{R}^m, and a,b in \\mathbb{R}, then av + bw is a linear combination.\n\n\nThere are two ways of looking at a matrix. Suppose we have a m by n matrix A.\n\\begin{align*}\nA =\n\\begin{pmatrix}\nA_{1,1} & \\cdots & A_{m,1}\\\\\n\\vdots &  & \\vdots\\\\\nA_{1,n} & \\cdots & A_{m,n}\n\\end{pmatrix}\n\\end{align*}\nWe have the column view of A, and the row view of A. Write\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be an m by n matrix. We define the Transpose of A, denoted A^T, as\n\n\nWe immeditally get the following properties\n\nA_{m\\times n} = A^T_{n\\times m}\n(A^T)^T = A\n\nWe can define a matrix\n\n\n\n\n\n\nDefinition\n\n\n\nA matrix (m \\times n) is a function f \\colon \\mathbb{R} \\rightarrow \\mathbb{R}\nIf A_{m \\times n},\\, x \\in \\mathbb{R}^n, then\nA_x = A vector x = a linear combination of A col$ = col of row vecs\n\n\nMatrix multiplication\nWe denote the standard basis of \\mathbb{R}^m as\n\\begin{align*}\ne_1 =\n\\begin{pmatrix}\n1\\\\\n0\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_2 =\n\\begin{pmatrix}\n0\\\\\n1\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_m =\n\\begin{pmatrix}\n0\\\\\n0\\\\\n\\vdots\\\\\n1\n\\end{pmatrix}\n\\end{align*}\nAny vector in \\mathbb{R}^m is a linear combination of these e_i’s, in a unique way. For example\n\\begin{align*}\nx =\n\\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix} =\nx_1 e_1 + \\cdots + x_m e_m\n\\end{align*}\nWe define the identity matrix\n\\begin{align*}\nCol_j I = e_j, I = \\begin{pmatrix}\n1 & & 0\\\\\n& \\ddots & \\\\\n0 & & 1\n\\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "qmd/matrix/unitone.html#subsection-2",
    "href": "qmd/matrix/unitone.html#subsection-2",
    "title": "Unit one",
    "section": "Subsection 2",
    "text": "Subsection 2\nIf x,y \\in \\mathbb{R}^m, then\n\\begin{align*}\nx^T y = \\begin{pmatrix}\nx_1 & \\cdots & x_m\n\\end{pmatrix}\n\\begin{pmatrix}\ny_1\\\\\n\\vdots\\\\\ny_n\n\\end{pmatrix} = x \\cdot y =\n\\sum^m_{i = 1}x_iy_i\n\\end{align*}\n\n\n\n\n\n\nDefinition\n\n\n\nWe define the unit vector in the direction of x (if x \\not = 0)\n\n\\hat{x} = \\frac{x}{|x|}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nWe say x is perpendicular to y, denoted x \\perp y, if x \\cdot y = 0\n\n\n\n\n\n\n\n\nFact (Law of cosines)\n\n\n\nLet \\alpha be the angle between our vectors x and y. Then\n\n\\cos\\alpha = \\frac{x \\cdot y}{|x||y|}"
  },
  {
    "objectID": "qmd/matrix/unitone.html#dot-product",
    "href": "qmd/matrix/unitone.html#dot-product",
    "title": "Fundementals",
    "section": "Dot product",
    "text": "Dot product\nIf x,y \\in \\mathbb{R}^m, then\n\\begin{align*}\nx^T y = \\begin{pmatrix}\nx_1 & \\cdots & x_m\n\\end{pmatrix}\n\\begin{pmatrix}\ny_1\\\\\n\\vdots\\\\\ny_n\n\\end{pmatrix} = x \\cdot y =\n\\sum^m_{i = 1}x_iy_i\n\\end{align*}\n\n\n\n\n\n\nDefinition\n\n\n\nWe define the unit vector in the direction of x (if x \\not = 0)\n\n\\hat{x} = \\frac{x}{|x|}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nWe say x is perpendicular to y, denoted x \\perp y, if x \\cdot y = 0\n\n\n\n\n\n\n\n\nFact (Law of cosines)\n\n\n\nLet \\alpha be the angle between our vectors x and y. Then\n\n\\cos\\alpha = \\frac{x \\cdot y}{|x||y|}\n\n\n\n\n\n\n\n\n\nTheorem (Schwarz inequality)\n\n\n\nFor all x,y \\in \\mathbb{R}^T\n\n|x \\cdot y| \\leq |x||y|\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nWe define the orthagonal component of a column vector x\n\\begin{align*}\nx^\\perp = \\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix}^\\perp\n\n=\n\n\\{\\text{All $y$ in $\\mathbb{R}^m$ perpendicular to $x$}\\}\n\\end{align*}\nsymbollically\n\\begin{align*}\nx^\\perp = \\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix}^\\perp\n\n=\n\n\\left\\{y =\n\n\\begin{pmatrix}\ny_1\\\\\n\\vdots\\\\\ny_m\n\\end{pmatrix}\n\n\\colon\n\nx_1 y_1 + \\cdots + x_m y_m = 0\n\\right\\}\n\\end{align*}"
  },
  {
    "objectID": "qmd/matrix/unitone.html#basics",
    "href": "qmd/matrix/unitone.html#basics",
    "title": "Fundementals",
    "section": "",
    "text": "Let \\mathbb{R}^m be the space of column vectors with real entries, symbollically read\n\n\\mathbb{R}^m = \\{vector : x_i \\in \\mathbb{R}\\}\n\nWe use this to define a Linear combination\n\n\n\n\n\n\nDefinition\n\n\n\nIf v,w are both in \\mathbb{R}^m, and a,b in \\mathbb{R}, then av + bw is a linear combination.\n\n\nThere are two ways of looking at a matrix. Suppose we have a m by n matrix A.\n\\begin{align*}\nA =\n\\begin{pmatrix}\nA_{1,1} & \\cdots & A_{m,1}\\\\\n\\vdots &  & \\vdots\\\\\nA_{1,n} & \\cdots & A_{m,n}\n\\end{pmatrix}\n\\end{align*}\nWe have the column view of A, and the row view of A. Write\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be an m by n matrix. We define the Transpose of A, denoted A^T, as\n\n\nWe immeditally get the following properties\n\nA_{m\\times n} = A^T_{n\\times m}\n(A^T)^T = A\n\nWe can define a matrix\n\n\n\n\n\n\nDefinition\n\n\n\nA matrix (m \\times n) is a function f \\colon \\mathbb{R} \\rightarrow \\mathbb{R}\nIf A_{m \\times n},\\, x \\in \\mathbb{R}^n, then\nA_x = A vector x = a linear combination of A col$ = col of row vecs\n\n\nMatrix multiplication\nWe denote the standard basis of \\mathbb{R}^m as\n\\begin{align*}\ne_1 =\n\\begin{pmatrix}\n1\\\\\n0\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_2 =\n\\begin{pmatrix}\n0\\\\\n1\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_m =\n\\begin{pmatrix}\n0\\\\\n0\\\\\n\\vdots\\\\\n1\n\\end{pmatrix}\n\\end{align*}\nAny vector in \\mathbb{R}^m is a linear combination of these e_i’s, in a unique way. For example\n\\begin{align*}\nx =\n\\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix} =\nx_1 e_1 + \\cdots + x_m e_m\n\\end{align*}\nWe define the identity matrix\n\\begin{align*}\nCol_j I = e_j, I = \\begin{pmatrix}\n1 & & 0\\\\\n& \\ddots & \\\\\n0 & & 1\n\\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "qmd/diffeq/unitone.html",
    "href": "qmd/diffeq/unitone.html",
    "title": "Unit one",
    "section": "",
    "text": "Let \\mathbb{R}^m be the space of column vectors with real entries, symbollically read\n\n\\mathbb{R}^m = \\{vector : x_i \\in \\mathbb{R}\\}\n\nWe use this to define a Linear combination\n\n\n\n\n\n\nDefinition\n\n\n\nIf v,w are both in \\mathbb{R}^m, and a,b in \\mathbb{R}, then av + bw is a linear combination.\n\n\nThere are two ways of looking at a matrix. Suppose we have a m by n matrix A.\n\\begin{align*}\nA =\n\\begin{pmatrix}\nA_{1,1} & \\cdots & A_{m,1}\\\\\n\\vdots &  & \\vdots\\\\\nA_{1,n} & \\cdots & A_{m,n}\n\\end{pmatrix}\n\\end{align*}\nWe have the column view of A, and the row view of A. Write\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be an m by n matrix. We define the Transpose of A, denoted A^T, as\n\n\nWe immeditally get the following properties\n\nA_{m\\times n} = A^T_{n\\times m}\n(A^T)^T = A\n\nWe can define a matrix\n\n\n\n\n\n\nDefinition\n\n\n\nA matrix (m \\times n) is a function f \\colon \\mathbb{R} \\rightarrow \\mathbb{R}\nIf A_{m \\times n},\\, x \\in \\mathbb{R}^n, then\nA_x = A vector x = a linear combination of A col$ = col of row vecs\n\n\nMatrix multiplication\nWe denote the standard basis of \\mathbb{R}^m as\n\\begin{align*}\ne_1 =\n\\begin{pmatrix}\n1\\\\\n0\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_2 =\n\\begin{pmatrix}\n0\\\\\n1\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_m =\n\\begin{pmatrix}\n0\\\\\n0\\\\\n\\vdots\\\\\n1\n\\end{pmatrix}\n\\end{align*}\nAny vector in \\mathbb{R}^m is a linear combination of these e_i’s, in a unique way. For example\n\\begin{align*}\nx =\n\\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix} =\nx_1 e_1 + \\cdots + x_m e_m\n\\end{align*}\nWe define the identity matrix\n\\begin{align*}\nCol_j I = e_j, I = \\begin{pmatrix}\n1 & & 0\\\\\n& \\ddots & \\\\\n0 & & 1\n\\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "qmd/diffeq/unitone.html#basics",
    "href": "qmd/diffeq/unitone.html#basics",
    "title": "Unit one",
    "section": "",
    "text": "Let \\mathbb{R}^m be the space of column vectors with real entries, symbollically read\n\n\\mathbb{R}^m = \\{vector : x_i \\in \\mathbb{R}\\}\n\nWe use this to define a Linear combination\n\n\n\n\n\n\nDefinition\n\n\n\nIf v,w are both in \\mathbb{R}^m, and a,b in \\mathbb{R}, then av + bw is a linear combination.\n\n\nThere are two ways of looking at a matrix. Suppose we have a m by n matrix A.\n\\begin{align*}\nA =\n\\begin{pmatrix}\nA_{1,1} & \\cdots & A_{m,1}\\\\\n\\vdots &  & \\vdots\\\\\nA_{1,n} & \\cdots & A_{m,n}\n\\end{pmatrix}\n\\end{align*}\nWe have the column view of A, and the row view of A. Write\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be an m by n matrix. We define the Transpose of A, denoted A^T, as\n\n\nWe immeditally get the following properties\n\nA_{m\\times n} = A^T_{n\\times m}\n(A^T)^T = A\n\nWe can define a matrix\n\n\n\n\n\n\nDefinition\n\n\n\nA matrix (m \\times n) is a function f \\colon \\mathbb{R} \\rightarrow \\mathbb{R}\nIf A_{m \\times n},\\, x \\in \\mathbb{R}^n, then\nA_x = A vector x = a linear combination of A col$ = col of row vecs\n\n\nMatrix multiplication\nWe denote the standard basis of \\mathbb{R}^m as\n\\begin{align*}\ne_1 =\n\\begin{pmatrix}\n1\\\\\n0\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_2 =\n\\begin{pmatrix}\n0\\\\\n1\\\\\n\\vdots\\\\\n0\n\\end{pmatrix}, e_m =\n\\begin{pmatrix}\n0\\\\\n0\\\\\n\\vdots\\\\\n1\n\\end{pmatrix}\n\\end{align*}\nAny vector in \\mathbb{R}^m is a linear combination of these e_i’s, in a unique way. For example\n\\begin{align*}\nx =\n\\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix} =\nx_1 e_1 + \\cdots + x_m e_m\n\\end{align*}\nWe define the identity matrix\n\\begin{align*}\nCol_j I = e_j, I = \\begin{pmatrix}\n1 & & 0\\\\\n& \\ddots & \\\\\n0 & & 1\n\\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "qmd/diffeq/unitone.html#dot-product",
    "href": "qmd/diffeq/unitone.html#dot-product",
    "title": "Unit one",
    "section": "Dot product",
    "text": "Dot product\nIf x,y \\in \\mathbb{R}^m, then\n\\begin{align*}\nx^T y = \\begin{pmatrix}\nx_1 & \\cdots & x_m\n\\end{pmatrix}\n\\begin{pmatrix}\ny_1\\\\\n\\vdots\\\\\ny_n\n\\end{pmatrix} = x \\cdot y =\n\\sum^m_{i = 1}x_iy_i\n\\end{align*}\n\n\n\n\n\n\nDefinition\n\n\n\nWe define the unit vector in the direction of x (if x \\not = 0)\n\n\\hat{x} = \\frac{x}{|x|}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nWe say x is perpendicular to y, denoted x \\perp y, if x \\cdot y = 0\n\n\n\n\n\n\n\n\nFact (Law of cosines)\n\n\n\nLet \\alpha be the angle between our vectors x and y. Then\n\n\\cos\\alpha = \\frac{x \\cdot y}{|x||y|}\n\n\n\n\n\n\n\n\n\nTheorem (Schwarz inequality)\n\n\n\nFor all x,y \\in \\mathbb{R}^T\n\n|x \\cdot y| \\leq |x||y|\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nWe define the orthagonal component of a column vector x\n\\begin{align*}\nx^\\perp = \\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix}^\\perp\n\n=\n\n\\{\\text{All $y$ in $\\mathbb{R}^m$ perpendicular to $x$}\\}\n\\end{align*}\nsymbollically\n\\begin{align*}\nx^\\perp = \\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_m\n\\end{pmatrix}^\\perp\n\n=\n\n\\left\\{y =\n\n\\begin{pmatrix}\ny_1\\\\\n\\vdots\\\\\ny_m\n\\end{pmatrix}\n\n\\colon\n\nx_1 y_1 + \\cdots + x_m y_m = 0\n\\right\\}\n\\end{align*}\n\nSubspaces"
  },
  {
    "objectID": "qmd/diffeq/unitone.html#subspaces",
    "href": "qmd/diffeq/unitone.html#subspaces",
    "title": "Unit one",
    "section": "Subspaces",
    "text": "Subspaces"
  },
  {
    "objectID": "qmd/matrix/unitone.html#subspaces",
    "href": "qmd/matrix/unitone.html#subspaces",
    "title": "Fundementals",
    "section": "Subspaces",
    "text": "Subspaces\n\n\n\n\n\n\nDefinition\n\n\n\nA subspace V of \\mathbb{R}^m is a subset closed under addition and scalar multiplication.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nThe column space of a matrix A_{(m \\times n)} is \\text{Range}(A \\colon \\mathbb{R}^n \\rightarrow \\mathbb{R}^m)\n\n\nWe can use these definitions to prove some facts about subspaces.\n\n\n\n\n\n\nClaim\n\n\n\nThe function A \\colon \\mathbb{R}^n \\to \\mathbb{R}^m has linearity.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nWrite later\n\n\n\n\n\n\n\n\n\nClaim\n\n\n\n\\text{ColSp}(A) is a subspace of \\mathbb{R}^m\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nSuppose we have to vertices in the column space\n\nAv, Av^\\prime\n\nNote we then have\nAv + Av^\\prime = A(v + v^\\prime) \\in \\text{Range}(A) = \\text{ColSp}(A)\nand\n\\lambda(Av) = A(\\lambda v)\nFufilling the requirements for a subspace.\n\n\n\nIt might help to look at some examples\n\n\n\n\n\n\nExample\n\n\n\nDo column space examples\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nSuppose v_1,\\ldots,v_n are all vectors in \\mathbb{R}^m. Then\n\n\\text{Span} \\{ v_1,\\ldots,v_n \\} = \\{ \\text{All linear combinations of } v_i \\}\n\n\n\n\n\n\n\n\n\nClaim\n\n\n\nThe \\text{Span}\\{v_1,\\ldots,v_n\\} is a subspace of \\mathbb{R}^m\n\n\n\n\n\n\n\n\nClaim\n\n\n\nThe \\text{ColSp}(A) = \\text{Span}\\{\\text{Columns of }A\\}\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA set \\{v_1,\\ldots,v_n\\} in \\mathbb{R}^m is linearly dependent if for some k, v_k \\in \\text{Span}\\{v_1,\\ldots,v_{k-1}\\}. Otherwise we say the set is linearly independent\n\n\nSuppose we have a matrix A with a rank of 1. This means that our \\text{ColSp}(A) is 1 dimensional.\n\n\n\n\n\n\nDefinition\n\n\n\nThe \\text{RowSp}(A) = \\text{Span}\\{\\text{Transposes of Rows}\\} = \\text{ColSp}(A^T)\n\n\nIf the \\text{ColSp}(A) is one dimensional, than so is \\text{RowSp}(A). This is because\n\nA = vc^T = expand this later"
  },
  {
    "objectID": "qmd/pde/introduction.html",
    "href": "qmd/pde/introduction.html",
    "title": "Partial differential equations",
    "section": "",
    "text": "Partial differential equations is the study of functions with partial derivatives, and two or more independent variables. PDE’s are incredibly useful models, and appear in almost every natural science.\nThe way that heat is transferred through material is given by a PDE, known as the Heat transfer equation\n\\frac{\\partial u}{\\partial t} = a \\frac{\\partial^2u}{\\partial x^2}\nThe equation of the displacment in a wave over time can be given by a PDE,\n\\frac{\\partial^2 u}{\\partial t^2} = c^2 \\frac{\\partial^2u}{\\partial x^2}\nAnd the Poisson equation, used in a wide variety of fields in physics.\n\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2u}{\\partial y^2} = P(x,y)"
  },
  {
    "objectID": "qmd/pde/introduction.html#table-of-contents",
    "href": "qmd/pde/introduction.html#table-of-contents",
    "title": "Partial differential equations",
    "section": "Table of contents",
    "text": "Table of contents"
  },
  {
    "objectID": "qmd/numanal/formalsystem.html",
    "href": "qmd/numanal/formalsystem.html",
    "title": "Numerical Analysis",
    "section": "",
    "text": "A formal system consists of a formal language, with strict rules on what symbols are allowed and how to connect them, combined with a deductive system, containing axioms and rules for deducing true statements.\n\n\n\n\n\n\nDefinition\n\n\n\nA formal system is a mathematical structure consisting of\n\nA formal language\nA deductive system"
  },
  {
    "objectID": "qmd/pde/unitone.html",
    "href": "qmd/pde/unitone.html",
    "title": "Heat equation",
    "section": "",
    "text": "We start with a review of ordinary differential equations."
  },
  {
    "objectID": "qmd/pde/unitone.html#subsection-1",
    "href": "qmd/pde/unitone.html#subsection-1",
    "title": "Heat equation",
    "section": "Subsection 1",
    "text": "Subsection 1"
  },
  {
    "objectID": "qmd/numanal/floatingpoint.html",
    "href": "qmd/numanal/floatingpoint.html",
    "title": "Fundementals",
    "section": "",
    "text": "Computers don’t use exact numbers when preforming calculations, but instead use a floating point system.\n\n\n\n\n\n\nDefinition\n\n\n\nA floating point number x is expressed as\n\nx = S \\times 2^E \\times 1.b_1b_2\\ldots b_{52}\n\nSuch that S represents the sign of the number, + or -. E is an exponent, and b_1 through b_52 are binary digits.\n\n\n\n\n\n\n\n\nExample\n\n\n\nSuppose we have a variable x = 6 and we wish to express it as a floating point number. We first convert the number to binary\n\n6_{10} = 110_{2}\n\nWe now specify where the decimal is, by adding an exponent\n\n6_{10} = 110_{2} = 2^2\\times1.10_2\n\nAnd finally adding the sign\n\n6_{10} = 110_{2} = 1\\times2^2\\times1.10_2\n\n\n\nWe can also express fractions, particular ones without a terminating digit. For example,\n\n0.3 = 1 \\times 2^{-2} \\times 1.00110011001\\ldots\n\nTerminating after 52 digits.\n\n\nComputers themselves store numbers as a collection of 64 bits\n\nx = s_1e_1\\ldots e_{11}m_1\\ldots m_{52}\n\nOne bit for the sign of a number, 11 bits for the exponent, and 52 bits for the mantissa (digits after the decimal place).\nClearly this means that only a finite amount of numbers can be expressed in floating point, and numbers are rounded to their nearest corresponding floating point. This leads to a loss of signifigance, and means functions with extremly large or small inputs will be catastrophically wrong, as the difference between two numbers is completly outside of the range floating point can represent.\nTake the identical functions f(x) and g(x)\n\nf(x) = \\frac{1 - \\cos(x)}{\\sin^2(x)}\n\n\ng(x) = \\frac{1}{1 + \\cos(x)}\n\nf(x) suffers from an egregious loss of signifigance error as x decreases towards 0, But g(x) won’t.\n\n\n\nThe number 101.101 rounds up to 110, because the digits after the decimal are above .1. If they aren’t the number terminates at the decimal. If 101.1\\overline{0} then we get 110, but if we have 110.1\\overline{0}, we drop the number. This is based on the digit in the units place. If it is a 1, we round up, if it is not, we drop it."
  },
  {
    "objectID": "qmd/numanal/floatingpoint.html#floating-point",
    "href": "qmd/numanal/floatingpoint.html#floating-point",
    "title": "Fundementals",
    "section": "",
    "text": "Computers don’t use exact numbers when preforming calculations, but instead use a floating point system.\n\n\n\n\n\n\nDefinition\n\n\n\nA floating point number x is expressed as\n\nx = S \\times 2^E \\times 1.b_1b_2\\ldots b_{52}\n\nSuch that S represents the sign of the number, + or -. E is an exponent, and b_1 through b_52 are binary digits.\n\n\n\n\n\n\n\n\nExample\n\n\n\nSuppose we have a variable x = 6 and we wish to express it as a floating point number. We first convert the number to binary\n\n6_{10} = 110_{2}\n\nWe now specify where the decimal is, by adding an exponent\n\n6_{10} = 110_{2} = 2^2\\times1.10_2\n\nAnd finally adding the sign\n\n6_{10} = 110_{2} = 1\\times2^2\\times1.10_2\n\n\n\nWe can also express fractions, particular ones without a terminating digit. For example,\n\n0.3 = 1 \\times 2^{-2} \\times 1.00110011001\\ldots\n\nTerminating after 52 digits.\n\n\nComputers themselves store numbers as a collection of 64 bits\n\nx = s_1e_1\\ldots e_{11}m_1\\ldots m_{52}\n\nOne bit for the sign of a number, 11 bits for the exponent, and 52 bits for the mantissa (digits after the decimal place).\nClearly this means that only a finite amount of numbers can be expressed in floating point, and numbers are rounded to their nearest corresponding floating point. This leads to a loss of signifigance, and means functions with extremly large or small inputs will be catastrophically wrong, as the difference between two numbers is completly outside of the range floating point can represent.\nTake the identical functions f(x) and g(x)\n\nf(x) = \\frac{1 - \\cos(x)}{\\sin^2(x)}\n\n\ng(x) = \\frac{1}{1 + \\cos(x)}\n\nf(x) suffers from an egregious loss of signifigance error as x decreases towards 0, But g(x) won’t.\n\n\n\nThe number 101.101 rounds up to 110, because the digits after the decimal are above .1. If they aren’t the number terminates at the decimal. If 101.1\\overline{0} then we get 110, but if we have 110.1\\overline{0}, we drop the number. This is based on the digit in the units place. If it is a 1, we round up, if it is not, we drop it."
  },
  {
    "objectID": "qmd/matrix/unitone.html#matrix-multiplication",
    "href": "qmd/matrix/unitone.html#matrix-multiplication",
    "title": "Fundementals",
    "section": "Matrix multiplication",
    "text": "Matrix multiplication\nSuppose we have two matricies A_{(m\\times n)} and Z_{(l\\times m)}. Recall the function definition of a matrix. Then\n\nZ \\circ A \\colon \\mathbb{R}^n \\to \\mathbb{R}^l\n\n\n\n\n\n\n\nClaim\n\n\n\nZ \\circ A is linear\n\n\n\n\n\n\n\n\nProof\n\n\n\n(Z \\circ A)(v_1 + v_2) = Later\n\n\nSo Z \\circ A is some (l \\times n) matrix, which can be computed as follows.\n\\begin{align*}\nZ \\circ A\n\n\\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_n\n\\end{pmatrix}\n\n&=\n\nZ\\left(A \\begin{pmatrix}\nx_1\\\\\n\\vdots\\\\\nx_n\n\\end{pmatrix}\\right)\\\\\n\n&=\n\nZ\\left( x_1 \\text{Col}_1 A + \\cdots + x_n \\text{Col}_n A \\right)\\\\\n\n&=\n\n\\begin{pmatrix}\nZ\\text{Col}_1 A & \\cdots & Z \\text{Col}_n A\n\\end{pmatrix}\n\n\\end{align*}\nThus we have a fomula to compose two matrices. Matrix multiplication is associative because it’s function composition. There are three ways that we multiply matrices, each giving the same result.\n\n\\text{Column view:} \\quad  ZA = (Z\\text{Col}_1 A  \\cdots  Z \\text{Col}_n A)\\\\\n\\text{Row-Column view:} \\quad (ZA)_{ij} = (\\text{Row}_{i}Z) \\cdot (\\text{Col}_j A)\\\\\n\\text{Row view:} \\quad  ZA = \\text{Row}_1(Z)A\\\\\n\\text{Column-Row view:} \\quad (ZA)_{ij} = (\\text{Col}_1 Z)(\\text{Row}_1 A) + \\cdots + (\\text{Col}_m Z)(\\text{Row}_m A)\n\n\nRow-column decomposition\nLet A = CR. Construct C as follows.\n\\begin{align*}\n\\text{Col}_1 C &= \\text{First non-$0$ column of $A$}\\\\\n\\text{Col}_2 C &= \\text{First column of $A$ not parallel to } \\text{Col}_1 A\\\\\n&\\vdots\\\\\n\\text{Col}_r C &= \\text{First column of $A$ not in Span}\\{\\text{Col}_1C, \\cdots, \\text{Col}_{r-1} C\\}\\\\\n\\end{align*}\nThus C is an (m \\times r) matrix, whose column space is identitcal to that of A."
  },
  {
    "objectID": "qmd/pde/heatEquation.html",
    "href": "qmd/pde/heatEquation.html",
    "title": "Heat equation",
    "section": "",
    "text": "We start with a review of ordinary differential equations."
  },
  {
    "objectID": "qmd/pde/heatEquation.html#subsection-1",
    "href": "qmd/pde/heatEquation.html#subsection-1",
    "title": "Heat equation",
    "section": "Subsection 1",
    "text": "Subsection 1"
  },
  {
    "objectID": "qmd/diffeq/fode.html",
    "href": "qmd/diffeq/fode.html",
    "title": "First order differential equations",
    "section": "",
    "text": "A first order differential equation is an equation in the form\ny^\\prime = f(x,y).\nThere is no general solution to a first order differential equation, so we’ll have to examine special cases ."
  },
  {
    "objectID": "qmd/diffeq/fode.html#linear-equations",
    "href": "qmd/diffeq/fode.html#linear-equations",
    "title": "First order differential equations",
    "section": "Linear Equations",
    "text": "Linear Equations\nConsider the general first order linear equation,\n\ny^\\prime + p(x)y = g(x),\n\nwhere p(x) and g(x) are continous functions on some interval. Lucky for us, a general solution exists!\n\n\n\n\n\n\nTheorem\n\n\n\nThe general solution for a first order linear differential equation is\n\ny = \\frac{1}{\\mu(x)}\\left(\\int \\mu(x) g(x) dx + C\\right)\n\nwhere\n\n\\mu(x) = \\exp \\left(\\int p(x) dx\\right)\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe first need to consider a function \\mu(x) such that\n\n\\mu(x) p(x) = \\mu^\\prime (x)\n\nOn the assumption that \\mu(x) exists,\n\n\\mu(x)y^\\prime + \\mu^\\prime(x)y = \\mu(x)g(x).\n\nNotice that the LHS of the equation looks suspiciously like the product rule, so\n\n(\\mu(x)y(x))^\\prime = \\mu(x)g(x).\n\nIntegrating and swapping some terms around allows us to isolate y(x)\n\n\\mu(x)y(x) + C = \\int \\mu(x)g(x) dx\\\\\ny(x) = \\frac{1}{\\mu(x)}\\left(\\int \\mu(x)g(x) dx + C\\right)\n\nWhich gives us our general solution! We just need to find an explicit function \\mu(x).\n\n\\mu(x)p(x) = \\mu^\\prime(x)\\\\\np(x) = \\frac{\\mu^\\prime(x)}{\\mu(x)}\n\nNotice the RHS is the general solution of the derivative \\ln f(x)\n\np(x) = \\left( \\ln \\mu(x) \\right)^\\prime\\\\\n\\int p(x) = \\ln \\mu(x)\\\\\n\\mu(x) = \\exp \\left( \\int p(x) dx \\right)\n\nThus we have proved out general solution\n\n\nAn Initial value problem is a first order differential equation together with an initial condition, for example\n\\begin{cases}\n      y^\\prime + ay = 0\\\\\n      y(0) = 2\n\\end{cases}\nUsing the formula we just proved, the solution to the first equation is simply\n\ny = Ce^{-ax}.\n\nBut when given an initial condition, we have to pick a value of C such that y(0) = 2\n\ny(0) = Ce^{-a0} = C \\implies C = 2  \n\nSo we get the answer to our IVP\n\ny = 2e^{-ax}"
  },
  {
    "objectID": "qmd/diffeq/fode.html#seperable-equations",
    "href": "qmd/diffeq/fode.html#seperable-equations",
    "title": "First order differential equations",
    "section": "Seperable Equations",
    "text": "Seperable Equations\nConsider the equation\n\nM(x) + N(y)y^\\prime = 0\n\nWhere M(x) and N(y) are continous functions. Not every first order differential equation can be wrote like this, but if it can, we call the equation seperable.\n\n\n\n\n\n\nTheorem\n\n\n\nThe implicit solution for a first order seperable differential equation is given by\n\n\\int M(x) dx = \\int -N(y) dy\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe can seperate our equation such that all the x terms are on one side\n\nM(x) = -N(y)y^\\prime \\implies M(x) = -N(y)\\frac{dy}{dx}\n\nIntegrate both sides by x \n\\int M(x) dx = \\int -N(y)\\frac{dy}{dx} dx\n\nUse a dummy substitution u = y(x), giving\n\ndu = y^\\prime(x) dx = \\frac{dy}{dx} dx \\\\\n\\int M(x) dx = \\int -N(u) du\n\nThen for ease of notation, simply let u = y\n\n\\int M(x) dx = \\int -N(y) dy\n\n\n\nFor example\n\n\n\n\n\n\nExample\n\n\n\nThe equation\n\ny^\\prime =  6y^2x\n\ncan be seperated into\n\n\\frac{y^\\prime}{y^2} - 6x =  0.\n\nThus, M(x) = 6x and N(y) = \\frac{1}{y^2}, and we get our implicit solution\n\n\\int -6x dx = \\int -\\frac{1}{y^2} dy\\\\\n \n-3x^2 + C = \\frac{1}{y}\\\\\n\nWhich can easily be converted into our explicit solution\n\ny = \\frac{1}{C - 3x^2}"
  },
  {
    "objectID": "qmd/numanal/fundementals.html",
    "href": "qmd/numanal/fundementals.html",
    "title": "Fundementals",
    "section": "",
    "text": "Computers don’t use exact numbers when preforming calculations, but instead use a floating point system.\n\n\n\n\n\n\nDefinition\n\n\n\nA floating point number x is expressed as\n\nx = S \\times 2^E \\times 1.b_1b_2\\ldots b_{52}\n\nSuch that S represents the sign of the number, + or -. E is an exponent, and b_1 through b_52 are binary digits.\n\n\n\n\n\n\n\n\nExample\n\n\n\nSuppose we have a variable x = 6 and we wish to express it as a floating point number. We first convert the number to binary\n\n6_{10} = 110_{2}\n\nWe now specify where the decimal is, by adding an exponent\n\n6_{10} = 110_{2} = 2^2\\times1.10_2\n\nAnd finally adding the sign\n\n6_{10} = 110_{2} = 1\\times2^2\\times1.10_2\n\n\n\nWe can also express fractions, particular ones without a terminating digit. For example,\n\n0.3 = 1 \\times 2^{-2} \\times 1.00110011001\\ldots\n\nTerminating after 52 digits.\n\n\nComputers themselves store numbers as a collection of 64 bits\n\nx = s_1e_1\\ldots e_{11}m_1\\ldots m_{52}\n\nOne bit for the sign of a number, 11 bits for the exponent, and 52 bits for the mantissa (digits after the decimal place).\nClearly this means that only a finite amount of numbers can be expressed in floating point, and numbers are rounded to their nearest corresponding floating point. This leads to a loss of signifigance, and means functions with extremly large or small inputs will be catastrophically wrong, as the difference between two numbers is completly outside of the range floating point can represent.\nTake the identical functions f(x) and g(x)\n\nf(x) = \\frac{1 - \\cos(x)}{\\sin^2(x)}\n\n\ng(x) = \\frac{1}{1 + \\cos(x)}\n\nf(x) suffers from an egregious loss of signifigance error as x decreases towards 0, But g(x) won’t.\n\n\n\nThe number 101.101 rounds up to 110, because the digits after the decimal are above .1. If they aren’t the number terminates at the decimal. If 101.1\\overline{0} then we get 110, but if we have 110.1\\overline{0}, we drop the number. This is based on the digit in the units place. If it is a 1, we round up, if it is not, we drop it."
  },
  {
    "objectID": "qmd/numanal/fundementals.html#floating-point",
    "href": "qmd/numanal/fundementals.html#floating-point",
    "title": "Fundementals",
    "section": "",
    "text": "Computers don’t use exact numbers when preforming calculations, but instead use a floating point system.\n\n\n\n\n\n\nDefinition\n\n\n\nA floating point number x is expressed as\n\nx = S \\times 2^E \\times 1.b_1b_2\\ldots b_{52}\n\nSuch that S represents the sign of the number, + or -. E is an exponent, and b_1 through b_52 are binary digits.\n\n\n\n\n\n\n\n\nExample\n\n\n\nSuppose we have a variable x = 6 and we wish to express it as a floating point number. We first convert the number to binary\n\n6_{10} = 110_{2}\n\nWe now specify where the decimal is, by adding an exponent\n\n6_{10} = 110_{2} = 2^2\\times1.10_2\n\nAnd finally adding the sign\n\n6_{10} = 110_{2} = 1\\times2^2\\times1.10_2\n\n\n\nWe can also express fractions, particular ones without a terminating digit. For example,\n\n0.3 = 1 \\times 2^{-2} \\times 1.00110011001\\ldots\n\nTerminating after 52 digits.\n\n\nComputers themselves store numbers as a collection of 64 bits\n\nx = s_1e_1\\ldots e_{11}m_1\\ldots m_{52}\n\nOne bit for the sign of a number, 11 bits for the exponent, and 52 bits for the mantissa (digits after the decimal place).\nClearly this means that only a finite amount of numbers can be expressed in floating point, and numbers are rounded to their nearest corresponding floating point. This leads to a loss of signifigance, and means functions with extremly large or small inputs will be catastrophically wrong, as the difference between two numbers is completly outside of the range floating point can represent.\nTake the identical functions f(x) and g(x)\n\nf(x) = \\frac{1 - \\cos(x)}{\\sin^2(x)}\n\n\ng(x) = \\frac{1}{1 + \\cos(x)}\n\nf(x) suffers from an egregious loss of signifigance error as x decreases towards 0, But g(x) won’t.\n\n\n\nThe number 101.101 rounds up to 110, because the digits after the decimal are above .1. If they aren’t the number terminates at the decimal. If 101.1\\overline{0} then we get 110, but if we have 110.1\\overline{0}, we drop the number. This is based on the digit in the units place. If it is a 1, we round up, if it is not, we drop it."
  },
  {
    "objectID": "qmd/numanal/fundementals.html#taylor-series",
    "href": "qmd/numanal/fundementals.html#taylor-series",
    "title": "Fundementals",
    "section": "Taylor series",
    "text": "Taylor series\nThe taylor expansion of a function f(x) is given by\n\nf(x) = \\sum^m_{k=0} \\frac{f^{(k)}(x)(x-x_0)^k}{k!} + \\frac{f^{(m + 1)}(c)(x-x_0)^{m+1}}{(m+1)!}\n\n\n\n\n\n\n\nExample\n\n\n\nTake the function f(x) = e^x We can taylor expand it to get\n\nf(x) = e^x = 1 + \\frac{x}{1!} + \\frac{x^2}{2!} + \\cdots + \\frac{x^k}{k!} + \\frac{e^cx^{k+1}}{k+1!}\n\n\n\nWe can also write the Taylor series\n\nf(x + h) = \\sum^m_{k=0} \\frac{h^kf^{(k)}(x)}{k!}\n\n\n\n\n\n\n\nExample\n\n\n\nFind the error\n\\begin{align*}\ny^\\prime(x) &= ay(x) + by(x + h) + \\varepsilon\\\\\ny^\\prime(x) &= ay(x) + b\\left(y(x) - hy^\\prime(x) + \\frac{h^2}{2}y^{\\prime\\prime}(c_1)\\right) + \\varepsilon\\\\\ny^\\prime(x) &= (a+b)y(x) - bhy^\\prime(x) + \\frac{bh^2}{2}y^{\\prime\\prime}(c_1) + \\varepsilon\\\\\n\\end{align*}\nSo\n\na = -b\\quad b = -\\frac{1}{h}\\quad\n\nThus we get\n\ny^\\prime(x) = \\frac{y(x+h) - y(x)}{h} + \\varepsilon\n\nwith an error \n\\varepsilon = -\\frac{h}{2}y^{\\prime\\prime}(c_1).\n\n\n\nWhen we plug these numbers into the computer however, we are going to have an error as we have only 52 digits of precision. This gives us the machine error \\epsilon. So if we wanted to numerically approximate the derivative\n\ny^\\prime(x) = \\frac{y(x+h) - y(x) + 2\\epsilon y}{h} + \\varepsilon\n\nThis gives us the total error, the sum of the machine error, and the taylor error.\n\n\\varepsilon_T = \\epsilon + \\varepsilon\n\n\n\\varepsilon_T = \\frac{2\\epsilon |y|}{2h} + \\frac{2h^2}{12}|y^{\\prime\\prime\\prime}(x)|\n\nBy computing the derivative, we can find the smallest total error.\n\n\\frac{d\\varepsilon_T}{dh} = -\\frac{1}{h^2}\\epsilon |y| + \\frac{h}{3}|y^{\\prime\\prime\\prime}| = 0\n\nSolving for h\n\nh_{opt} =\\left(\\frac{3\\epsilon |y|}{|y^{\\prime\\prime\\prime}|}\\right)^\\frac{1}{3}\n\nFor example, lets try the function y = e^x. This gives us an optimal error\n\nh_{opt} = \\left( 3 \\times 2^{-52} \\frac{e^x}{e^x} \\right)^\\frac{1}{3}\n\n\n\n\n\n\n\nExample\n\n\n\nLets find the optimal value of h using a different error.\n\n\\varepsilon = -\\frac{h}{2}y^{\\prime\\prime}(c_1)\n\nWe can rewrite our equation\n\ny^\\prime(x) = \\frac{y(x+h) - y(x) + 2\\epsilon y}{h} + -\\frac{h}{2}y^{\\prime\\prime}(c_1)\n\nThen\n\n\\varepsilon_T = \\frac{2\\epsilon |y|}{h} + \\frac{h}{2}y^{\\prime\\prime}\n\nTaking the derivative\n\n\\frac{d \\varepsilon_T}{dh} = -\\frac{2\\epsilon |y|}{h^2} + \\frac{1}{2}y^{\\prime\\prime} = 0\n\nWe get\n\n\\frac{2\\epsilon |y|}{h^2} = \\frac{1}{2}y^{\\prime\\prime}\n\nThus\n\nh_{opt} = \\left(\\frac{4\\epsilon |y|}{|y^{\\prime\\prime}|}\\right)^\\frac{1}{2}\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLets find the error of the following expression\n\ny^{\\prime\\prime} = ay(x-h) + by(x) + cy(x+h) + \\varepsilon\\\\\n\n\\begin{align*}\ny^{\\prime\\prime} &= a\\left(y(x)-hy^\\prime(x) + \\frac{h^2}{2}y^{\\prime\\prime}(x) - \\frac{h^3}{6}y^{\\prime\\prime\\prime}(x) + \\frac{h^4}{4!}y^{(4)}(x) \\right)\\\\\n&+ by(x) \\\\\n&+ c\\left(y(x)+hy^\\prime(x) + \\frac{h^2}{2}y^{\\prime\\prime}(x) + \\frac{h^3}{6}y^{\\prime\\prime\\prime}(x) + \\frac{h^4}{4!}y^{(4)}(x) \\right)\n\\end{align*}\nThus\n\\begin{align*}\n(a + b + c) = 0\\\\\nh(c-a) = 0\\\\\n\\frac{h^2}{2}(a-c) = 1\n\\end{align*}\nThus we have constants\n\nc = a\\quad a = \\frac{1}{h^2} \\quad b = -\\frac{2}{h^2}\n\nAnd we’re left with the error\n\\begin{align*}\n\\varepsilon = -\\frac{h^2}{2y}\\left(y^{(4)}(c_1)+y^{(4)}(c_2)\\right)\n\\end{align*}\nThus we have\n\ny^{\\prime\\prime}(x) = \\frac{y(x-h)-2y(x)+y(x+h)}{h^2} + \\varepsilon\n\nLets find the optimal error. First we include the machine error\n\n\\epsilon_m = \\frac{4\\epsilon |y|}{h^2}\n\nCombine with our function error \n\\varepsilon_{T} = \\frac{4\\epsilon |y|}{h^2} +  \\frac{h^2}{2y}\\left(y^{(4)}\\right)\n\nContinue rest later.\n\n\nExample again\n\n\n\n\n\n\nExample\n\n\n\nTaylor expand f(x) = (1+x)^{1/2}\nWe get clearly\n\nf^{(k)}(x) = \\frac{(-1)^{k+1}}{2^k}(3\\cdot 5\\cdots (2k-3))(1+x)^{\\frac{-2k-1}{2}}\n\nSo our taylor expansion\n\nf(x) = (1+x)^{1/2} = 1 + \\frac{x}{2} - \\frac{1}{2^2}\\frac{x^2}{2!} + \\frac{3}{2^3}\\frac{x^3}{3!} \\cdots + \\frac{-1^{k+1}}{2^k}(1\\cdot 3\\cdot 5\\cdots (2k-3))\\frac{x^k}{k!}"
  },
  {
    "objectID": "qmd/diffeq/fode.html#exact-equations",
    "href": "qmd/diffeq/fode.html#exact-equations",
    "title": "First order differential equations",
    "section": "Exact Equations",
    "text": "Exact Equations"
  },
  {
    "objectID": "qmd/logic/intro.html",
    "href": "qmd/logic/intro.html",
    "title": "Introduction to Mathematical Logic",
    "section": "",
    "text": "Mathematical logic is the study of formal reasoning and logic within mathematical systems. The study of logic typically consists of the construction of a formal system, and then investigating what statements can be made true or false in that system."
  },
  {
    "objectID": "qmd/logic/intro.html#table-of-contents",
    "href": "qmd/logic/intro.html#table-of-contents",
    "title": "Introduction to Mathematical Logic",
    "section": "Table of contents",
    "text": "Table of contents\n\nFormal Systems"
  },
  {
    "objectID": "qmd/logic/formal-systems/formal-language.html",
    "href": "qmd/logic/formal-systems/formal-language.html",
    "title": "Formal languages",
    "section": "",
    "text": "To begin with constructing a formal system, we need to first need to know what symbols our logic will be using, and how to connect them. These properties are given by a formal language.\nSymbols, are individual elements used in a language. These symbols concatenate to form formulas (sometimes called words or sentences). The collection of all symbols and formulas in a language, is called an alphabet.\nA formal language is often given a syntax, rules for how symbols can be combined. If a formula can be constructed using the syntax attributed to the language, it is called a well-formed formula, often abbreviated wff.\nWith these definitions, we define a"
  },
  {
    "objectID": "qmd/logic/formal-systems/formal-language.html#formal-languages",
    "href": "qmd/logic/formal-systems/formal-language.html#formal-languages",
    "title": "Formal language",
    "section": "Formal Languages",
    "text": "Formal Languages\nA formal language is defined by its symbols, such as quantifiers or connectives, and its syntax, rules for combining symbols. The most important class of formal language is known as first-order language, denoted \\mathcal{L}_1.\nThe symbols in a first-order language can be grouped into seven categories. Some authors may however chose to group the symbols into more or less categories, but the distinction is arbitrary. These categories are\n\nConnectives - \\land, \\lor, \\implies, \\iff, \\lnot\nQuantifiers - \\forall, \\exists\nVariables - v_1,v_2,v_3 ect. A first-order language may consist of any countable amount of variables.\nConstants - c_0, c_1, c_2 ect. A first-order language may consist of any countable amount of constants.\nOperations - A first-order language can consist of any amount of countable operations (functions) f of any order.\nRelations - A first-order language can consist of any amount of countable relations p of any order.\nParentheses - Right ) and left (.\n\nMost of the time \\to will be used instead of \\implies, and \\leftrightarrow instead of \\iff, as the symbols are smaller are easier to read. For readibility sake, parenthesis occur in different sizes, or occansionally as brackets. Commas are also inserted to make formulas easier to read, but are not a formal symbol.\nNow we can begin constructing the syntax for first-order languages.\n\n\n\n\n\n\nDefinition\n\n\n\nEvery variable or constant is a term. Additionally, if f is an operator of degree n, and t_1,t_2,\\dots,t_n are terms, then f(t_1,t_2,\\dots,t_n) is a term.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf p is a relation of degree n, and t_1,t_2,\\dots,t_n are terms, then p(t_1,t_2,\\dots,t_n) is a formula.\nAdditionally, if P and Q are formulas, and x is a variable, then the expressions\n\nP \\iff Q, P \\implies Q, P \\land Q, P \\lor Q\\\\\n\\lnot P, \\forall x P, \\exists x P\n\nare also formulas.\n\n\nNote that mathematicians almost never write in unabbreviated notation. For example, the equation x + y would be wrote +(x,y), which looks silly.\nWe now can construct formulas from our symbols. Deciding truth values for these formulas is the role of a deductive system."
  },
  {
    "objectID": "qmd/logic/formal-systems/formal-language.html#deductive-systems",
    "href": "qmd/logic/formal-systems/formal-language.html#deductive-systems",
    "title": "Formal language",
    "section": "Deductive systems",
    "text": "Deductive systems\nA deductive system (deductive apparatus) is (usually) a set of axioms and rules of inference which are used to deduce one true statement from another. It is very common in math to use a Hilbert System, which consist of a large number of axioms, and few to no rules of inferences.\nBelow is an example of a Hilbert System which describes first-order logic.\n\n\n\n\n\n\nFOL Deductive system example2\n\n\n\nLogical Axioms\nThe first four axioms describe propositional logic, which is logic without quantifiers like \\land or \\lor.\nP1. \\phi \\rightarrow \\phi\nP2. \\phi \\rightarrow (\\psi \\rightarrow \\phi)\nP3. (\\phi \\rightarrow (\\psi \\rightarrow \\zeta)) \\rightarrow ((\\phi \\rightarrow \\psi) \\rightarrow (\\phi \\rightarrow \\zeta))\nP4. (\\lnot \\phi \\rightarrow \\lnot \\psi) \\rightarrow (\\psi \\rightarrow \\phi)\nHere, \\phi,\\psi and \\zeta refer to formulas, as constructed from our language. Thus, P1 could represent p \\rightarrow p or (p \\land q) \\rightarrow (p \\land q). This axiomitization is in no way unique, and in fact axiom P1 can be proven from P2 and P3.\nThe next three axioms allow us to manipulate quantifiers.\nQ5. \\forall x\\,(\\phi) \\rightarrow \\phi[x:=t] (Meaning t may be substituded for x in \\phi)\nQ6. \\forall x\\,(\\phi \\rightarrow \\psi) \\rightarrow (\\forall x\\,(\\phi) \\rightarrow \\forall x\\, (\\psi))\nQ7. \\phi \\rightarrow \\forall x \\,(\\phi) (where x is not free in \\phi)\nThese three axioms allow us to use the \\forall quantifier.\nFor formal systems where equality is not defined as a relation, the following two axioms are necessary.\nI8. x = x for every variable x.\nI9. (x = y) \\rightarrow (\\phi(x) = \\phi(y))\nRules of inference\nRules of inference are used to deduce a true statement from a previous. Modus ponens is typically the only used rule of inference.\nR1. Modus ponens\nModus ponens states that if p and p \\rightarrow q are true, then q is true.\n\n\nNote any connective can be formed using only \\lnot and \\rightarrow, and the exists quantifier can be defined using connectives and the for all quantifier.\nNow that we’ve defined a formal language to produce formulas, and a deduction system to define truth, we can construct a formal system."
  },
  {
    "objectID": "qmd/logic/formal-systems/formal-language.html#first-order-logic",
    "href": "qmd/logic/formal-systems/formal-language.html#first-order-logic",
    "title": "Formal language",
    "section": "First-order logic",
    "text": "First-order logic\nAlthough we can construct many formal systems by combining different languages with different deductive systems, the most popular formal systems belong to first-order logic, sometimes called predicate logic.\n\n\n\n\n\n\nDefinition\n\n\n\nFirst-order logic refers to a collection of formal systems composed of\n\nA first-order language\nA deductive system equivalent to the example shown above\n\n\n\nAs a concrete example, both ZF (Zermelo-Fraenkel set theory) and PA (Peano arithmetic) are theories in first-order logic. They both use a unique first-order language, and the same deductive system. So they both can be said to use first-order logic.\nWhat exactly ZF and PA are, and what a theory is, are explained in the next part."
  },
  {
    "objectID": "qmd/logic/formal-systems/formal-language.html#footnotes",
    "href": "qmd/logic/formal-systems/formal-language.html#footnotes",
    "title": "Formal languages",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis example was given by Noam Chomsky in his thesis The logical structure of linguistic theory↩︎"
  },
  {
    "objectID": "qmd/logic/formal-systems/formal-language.html#first-order-languages",
    "href": "qmd/logic/formal-systems/formal-language.html#first-order-languages",
    "title": "Formal languages",
    "section": "First order languages",
    "text": "First order languages\nFor a more in-depth look at a formal language, lets take a dive into first-order language. I’ll use the slightly obscure notation used in [Ebbinghaus, Flum, Thomas], as I personally feel they take a very formal approach to developing a formal language.\nThe alphabet of a first-order language has the following symbols\n\nConnectives - \\land, \\lor, \\rightarrow, \\leftrightarrow, \\lnot\nQuantifiers - \\forall, \\exists\nVariables - v_1,v_2,v_3, \\cdots, v_n\nEquality - The equal sign ‘=’\nParentheses - Right ) and left (.\nOperations - A first-order language can consist of any amount of countable operations (functions) f of any order.\nRelations - A first-order language can consist of any amount of countable relations p of any order.\nConstants - c_0, c_1, c_2 ect. A first-order language may consist of any countable amount of constants.\n\nFor readability sake, parenthesis occur in different sizes, or occasionally as brackets. Commas are also inserted to make formulas easier to read, but are not a formal symbol.\nThe first five groups listed are denoted \\mathbb{A}, and S denotes the unique operations, relations, and constants in the language. The set S determines the unique first-order language. We denote the shared alphabet \\mathbb{A}_S = \\mathbb{A} \\cup S.\nNow we can begin constructing the syntax for first-order languages. We start by defining terms\n\n\n\n\n\n\nDefinition\n\n\n\nS-terms are strings in \\mathbb{A}_S which can be formed by the finite application of the following rules\n(T1) Every variable is an S-term.\n(T2) Every constant is an S-term.\n(T3) If f is an operator of degree n in S, and t_1,t_2,\\dots,t_n are S-terms, then ft_1,t_2,\\dots,t_n is an S-term.\n\n\nThe set of all S-terms is denoted T^S. Through repeated applications of the three rules above, we can create larger terms. For example\n\\begin{alignat*}{2}\n& c_1 & \\quad &(T2)\\\\\n& v_1    &\\quad &(T1)\\\\\n& gc_1v_1   &\\quad &(T3) \\text{ with $c_1$ and $v_1$ applied to $g$}\n\\end{alignat*}\nSo gc_1v_1 is an S-term. Most of the time this is wrote g(c_1,v_1), but to keep things formal we’ll use the objectively worse notation for now. We will however introduce shorthand later. Now that we have S-terms, we can start creating formulas.\n\n\n\n\n\n\nDefinition\n\n\n\nS-formulas are strings in \\mathbb{A}_S which can be formed by the finite application of the following rules\n(F1) If t_1 and t_2 are S-terms, then t_1 = t_2 is an S-formula.\n(F2) If p is a relation of degree n in S, and t_1,t_2,\\dots,t_n are S-terms, then pt_1,t_2,\\dots,t_n is an S-formula.\n(F3) If \\phi is an S-formula, then \\lnot\\phi is also an S-formula.\n(F4) If \\phi and \\psi are S-formulas, then (\\phi \\land \\psi), (\\phi \\lor \\psi), (\\phi \\rightarrow \\psi), (\\phi \\leftrightarrow \\psi) are also S-formulas.\n(F5) If \\phi is an S-formula, and x is a variable, then \\forall x \\phi and \\exists x \\phi are also S-formula.\n\n\nS-formula formed from (F1) or (F2) are known as atomic formula as they don’t use any other formula in their language. Note that an S-formula is simply another word for a wff.\nWe can now introduce some new vocabulary\n\n\n\n\n\n\nDefinition\n\n\n\nGiven the S-formulas (wffs) \\phi, \\psi we have the following vocabulary\n\n\\lnot \\varphi is called the negation of \\phi\n(\\phi \\land \\psi) is called the conjunction of \\phi and \\psi\n(\\phi \\lor \\psi) is called the disjunction of \\phi and \\psi\n(\\phi \\rightarrow \\psi) is called the implication of \\phi and \\psi\n(\\phi \\leftrightarrow \\psi) is called the bi-implication of \\phi and \\psi\n\n\n\nWe denote the set of S-formulas with \\mathcal{L}^S. This set is called the first-order language associated with the symbol set S. And just like that we’ve created a first-order lanaguage! Lot’s of rather tricky notation, but the overall concept is no different than our example in the beginning.\nIt is worht nothing that the collection of all first-order languages is denoted \\mathcal{L}_1, and it will be a commonly used example."
  },
  {
    "objectID": "qmd/abstract/abstract.html",
    "href": "qmd/abstract/abstract.html",
    "title": "Basics",
    "section": "",
    "text": "Basic facts about sets, relations, and functions."
  },
  {
    "objectID": "qmd/abstract/abstract.html#relations",
    "href": "qmd/abstract/abstract.html#relations",
    "title": "Basics",
    "section": "Relations",
    "text": "Relations\nA binary relation on a set A is a subset R of A \\times A. We denote a ~ b \\rightarrow (a,b) \\in \\mathbb{R}.\nWe say ~ is an equivalence relation if it satisfies the following properties\n\n~ is reflexive, if \\forall a \\in A a ~ a\n~ is symmetric, if \\forall a,b \\in A a~ b \\rightarrow b ~ a\n~ is transitive, if \\forall a,b,c \\in A a ~ b \\land b ~ c \\rightarrow a ~ c\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf a,b \\in \\mathbb{Z} and a \\not = 0, we say a divides b if \\exists c \\in \\mathbb{Z} such that ac = b. This is denoted\n\na | b"
  },
  {
    "objectID": "qmd/abstract/intro.html",
    "href": "qmd/abstract/intro.html",
    "title": "Intro",
    "section": "",
    "text": "Its like algebra but more abstract ig idk"
  },
  {
    "objectID": "qmd/basics/abstract.html",
    "href": "qmd/basics/abstract.html",
    "title": "Basics",
    "section": "",
    "text": "Basic facts about sets, relations, and functions."
  },
  {
    "objectID": "qmd/basics/abstract.html#relations",
    "href": "qmd/basics/abstract.html#relations",
    "title": "Basics",
    "section": "Relations",
    "text": "Relations\nA binary relation on a set A is a subset R of A \\times A. We denote a ~ b \\rightarrow (a,b) \\in \\mathbb{R}.\nWe say ~ is an equivalence relation if it satisfies the following properties\n\n~ is reflexive, if \\forall a \\in A a ~ a\n~ is symmetric, if \\forall a,b \\in A a~ b \\rightarrow b ~ a\n~ is transitive, if \\forall a,b,c \\in A a ~ b \\land b ~ c \\rightarrow a ~ c\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf a,b \\in \\mathbb{Z} and a \\not = 0, we say a divides b if \\exists c \\in \\mathbb{Z} such that ac = b. This is denoted\n\na | b\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nLet ~ be an equivalence relation. The equivalence class of a \\in A is defined\n\n[a] = \\{x \\in A | x ~ a\\}\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nFind the equivalance classes of \n[x] = \\{y \\in \\mathbb{Z} \\mid 2 \\mid y - x\\}\n\nIf x is even then \\exists n \\in \\mathbb{Z} such that x = 2n.\n\n2 \\mid y - x = 2 \\mid y - 2n \\rightarrow \\exists m \\in \\mathbb{Z}, y = 2m\n\nIf x is odd then \\exists n \\in \\mathbb{Z} such that x = 2n + 1.\n\n2 \\mid y - x = 2 \\mid y - 2n + 1 \\rightarrow \\exists m \\in \\mathbb{Z}, y = 2m + 1\n\nThus we have two equivalance classes for x, [0] and [1]."
  },
  {
    "objectID": "qmd/basics/abstract.html#properties-of-the-integers",
    "href": "qmd/basics/abstract.html#properties-of-the-integers",
    "title": "Basics",
    "section": "Properties of the integers",
    "text": "Properties of the integers\nProperties of the set of integers, \\mathbb{Z}\n\n\n\n\n\n\nDefinition\n\n\n\nIf a,b \\in \\mathbb{Z} \\backslash \\{0\\}, then there exists a unique positive integer d, such that\n\nd \\mid a, \\; d \\mid b\nIf e \\mid a, \\; e \\mid b then e \\mid d.\n\nWe call d the greatest common divisor, denoted gcd(a,b).\n\n\n\n\n\n\n\n\nTheorem (The division algorithm)\n\n\n\nIf a,b \\in \\mathbb{Z}, b \\not = 0 then there uniquly exists q,r \\in \\mathbb{Z} such that a = qb + r.\nNote 0 \\leq r \\leq \\lvert b \\rvert\nWe call q the quoitent, and r the remainder.\n\n\nThe Eucldean algorithm provides the greatest common divisor of two non-zero integers by iterating the division algorithm.\n\\begin{align*}\na &= q_0 b + r_0\\\\\nb &= q_1 r_0 + r_1\\\\\nr_0 &= q_2 r_1 + r_2\\\\\n&\\vdots\\\\\nr_{n-2} &= q_n r_{n-1} + r_n\\\\\nr_{n-1} &= q_{n+1}r_n\n\\end{align*}\nIf m &lt; n, then r_m &gt; r_n. We have r_n = gcd(a,b).\n\n\n\n\n\n\nTheorem\n\n\n\nWhen using the Euclidean algorithm \ngcd(a,b) = gcd(b,r_0)\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nRearrange\nr_0 = a - q_0 b\nIf d \\mid a and d \\mid b then d \\mid a - q_0b \\rightarrow d \\mid r_0.\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nGiven a,b \\in \\mathbb{Z}, \\exists u,v \\in \\mathbb{Z} such that au + bv = gcd(a,b).\n\n\nWe basically just go backwords. Not that interesting.\n\n\n\n\n\n\nDefinition\n\n\n\nAn integer p &gt; 1 is prime if and only if it’s only positive divisors are p and 1.\n\n\n\n\n\n\n\n\nEuclids lemma\n\n\n\nGiven p as prime, for any a,b \\in \\mathbb{Z}\n\np \\mid ab \\implies p \\mid a \\lor p \\mid b\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe know p \\mid ab. If p \\mid a then gcd(a,p) = 1.\nThus we have integers u,v such that au + pv = 1.\nThen we multiply by b, giving p \\mid bau and p \\mid bpv.\n\n\n\n\n\n\n\n\nTheorem (Fundemental theorem of arithmatic)\n\n\n\nIf n \\in \\mathbb{Z} and n &gt; 1, then n can be factored into a unique product of prime numbers.\n\nn = p_1^{\\alpha_1}p_2^{\\alpha_2}p_3^{\\alpha_3}\\cdots p_s^{\\alpha_s}\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nThere exists infinitly many primes."
  },
  {
    "objectID": "qmd/matrix/unittwo.html",
    "href": "qmd/matrix/unittwo.html",
    "title": "Unit two",
    "section": "",
    "text": "We can put a matrix into upper triangular form as follows\n\\begin{align*}\nAx = b \\rightarrow\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n4 & 11 & 14\\\\\n2 & 8 & 17\n\\end{pmatrix} \\begin{pmatrix}\nx_1\\\\\nx_2\\\\\nx_3\n\\end{pmatrix} = \\begin{pmatrix}\nb_1\\\\\nb_2\\\\\nb_3\n\\end{pmatrix}\n\\end{align*}\n\\begin{align*}\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 5 & 6\\\\\n0 & 0 & 7\n\\end{pmatrix} \\begin{pmatrix}\nx_1\\\\\nx_2\\\\\nx_3\n\\end{pmatrix} = \\begin{pmatrix}\nb_1\\\\\nb_2 - 2b_1\\\\\nb_3 - b_2 + b_1\n\\end{pmatrix}\n\\end{align*}\nNote that we can rewrite this as an elementary row operation matrix\n\\begin{align*}\n\\begin{pmatrix}\n1 & 0 & 0\\\\\n-2 & 1 & 0\\\\\n-1 & 0 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n4 & 11 & 14\\\\\n2 & 8 & 17\n\\end{pmatrix} =\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 5 & 6\\\\\n0 & 5 & 13\n\\end{pmatrix}\n\\end{align*}\nWe call that first matrix e_1. Now we get\n\\begin{align*}\n\\begin{pmatrix}\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0 & -1 & 1\n\\end{pmatrix}\ne_1 A =\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 5 & 6\\\\\n0 & 0 & 7\n\\end{pmatrix}\n\\end{align*}\nGiving us\n\ne_2 e_1 (Ax = b) \\rightarrow Ux = b^\\prime\n\nLet\n\nL = e_1^{-1}e_2^{-1}\n\nWe then have\n\nLU = A\n\nNow take for example the matrix\n\nA = \\begin{pmatrix}\n2 & 3 & 4\\\\\n4 & 6 & 14\\\\\n2 & 8 & 17\n\\end{pmatrix}\n\nNotice it has the same e_1. However, this gives\n\ne_1A = \\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 0 & 6\\\\\n0 & 5 & 13\n\\end{pmatrix}\n\nWhich we can preform a row change to get\n\nF_1E_1A = \\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 5 & 13\\\\\n0 & 0 & 6\n\\end{pmatrix}\n\nWhere F_1 is not a lower triangular matrix.\n\nF_1 = \\begin{pmatrix}\n1 & 0 & 0\\\\\n0 & 0 & 1\\\\\n0 & 1 & 0\n\\end{pmatrix}\n\nThis creates\n\nE_1^{-1}F_1^{-1}U = A\n\nGiving us LPU decomposition."
  },
  {
    "objectID": "qmd/matrix/unittwo.html#elimination",
    "href": "qmd/matrix/unittwo.html#elimination",
    "title": "Unit two",
    "section": "",
    "text": "We can put a matrix into upper triangular form as follows\n\\begin{align*}\nAx = b \\rightarrow\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n4 & 11 & 14\\\\\n2 & 8 & 17\n\\end{pmatrix} \\begin{pmatrix}\nx_1\\\\\nx_2\\\\\nx_3\n\\end{pmatrix} = \\begin{pmatrix}\nb_1\\\\\nb_2\\\\\nb_3\n\\end{pmatrix}\n\\end{align*}\n\\begin{align*}\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 5 & 6\\\\\n0 & 0 & 7\n\\end{pmatrix} \\begin{pmatrix}\nx_1\\\\\nx_2\\\\\nx_3\n\\end{pmatrix} = \\begin{pmatrix}\nb_1\\\\\nb_2 - 2b_1\\\\\nb_3 - b_2 + b_1\n\\end{pmatrix}\n\\end{align*}\nNote that we can rewrite this as an elementary row operation matrix\n\\begin{align*}\n\\begin{pmatrix}\n1 & 0 & 0\\\\\n-2 & 1 & 0\\\\\n-1 & 0 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n4 & 11 & 14\\\\\n2 & 8 & 17\n\\end{pmatrix} =\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 5 & 6\\\\\n0 & 5 & 13\n\\end{pmatrix}\n\\end{align*}\nWe call that first matrix e_1. Now we get\n\\begin{align*}\n\\begin{pmatrix}\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0 & -1 & 1\n\\end{pmatrix}\ne_1 A =\n\\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 5 & 6\\\\\n0 & 0 & 7\n\\end{pmatrix}\n\\end{align*}\nGiving us\n\ne_2 e_1 (Ax = b) \\rightarrow Ux = b^\\prime\n\nLet\n\nL = e_1^{-1}e_2^{-1}\n\nWe then have\n\nLU = A\n\nNow take for example the matrix\n\nA = \\begin{pmatrix}\n2 & 3 & 4\\\\\n4 & 6 & 14\\\\\n2 & 8 & 17\n\\end{pmatrix}\n\nNotice it has the same e_1. However, this gives\n\ne_1A = \\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 0 & 6\\\\\n0 & 5 & 13\n\\end{pmatrix}\n\nWhich we can preform a row change to get\n\nF_1E_1A = \\begin{pmatrix}\n2 & 3 & 4\\\\\n0 & 5 & 13\\\\\n0 & 0 & 6\n\\end{pmatrix}\n\nWhere F_1 is not a lower triangular matrix.\n\nF_1 = \\begin{pmatrix}\n1 & 0 & 0\\\\\n0 & 0 & 1\\\\\n0 & 1 & 0\n\\end{pmatrix}\n\nThis creates\n\nE_1^{-1}F_1^{-1}U = A\n\nGiving us LPU decomposition."
  },
  {
    "objectID": "qmd/pde/introduction copy.html",
    "href": "qmd/pde/introduction copy.html",
    "title": "PDE",
    "section": "",
    "text": "When given the equation f(x) = 0, and f is a noninvertable function. We can apply newtons method. Take x_k to be close to our solution. Then we use the following \nx_{k+1} = x_k + \\delta\n\nWhere \\delta is the error. By taylor expanding f(x), we can get the following formula\n\nx_{k+1} = x_k - \\frac{f(x_k)}{f^\\prime(x_k)}"
  },
  {
    "objectID": "qmd/pde/introduction copy.html#newtons-method",
    "href": "qmd/pde/introduction copy.html#newtons-method",
    "title": "PDE",
    "section": "",
    "text": "When given the equation f(x) = 0, and f is a noninvertable function. We can apply newtons method. Take x_k to be close to our solution. Then we use the following \nx_{k+1} = x_k + \\delta\n\nWhere \\delta is the error. By taylor expanding f(x), we can get the following formula\n\nx_{k+1} = x_k - \\frac{f(x_k)}{f^\\prime(x_k)}"
  },
  {
    "objectID": "qmd/pde/introduction copy.html#second-order-linear-constant-coefficients",
    "href": "qmd/pde/introduction copy.html#second-order-linear-constant-coefficients",
    "title": "PDE",
    "section": "Second Order Linear Constant Coefficients",
    "text": "Second Order Linear Constant Coefficients\nThe general equation is\n\\begin{cases}\n      (p(x)y^{\\prime})^\\prime + q(x)y + \\lambda r(x)y = 0 \\\\\n      \\alpha_1 y(a) + \\beta_1 y^\\prime(a) = 0 \\\\\n      \\alpha_2 y(b) + \\beta_2 y^\\prime(b) = 0\n\\end{cases}\n\n\n\n\n\n\nTheorem\n\n\n\nAll eigenfunctions are orthagonal.\n\n\\int_a^b R(x)y_i(x)y_j(x)\\,dx = 0, \\iff y_i \\not = y_j\n\n\n\nTake the equation\n\\begin{cases}\n      y^{\\prime\\prime} + \\lambda y = 0 \\\\\n      y(0) = 0 \\\\\n      y(1) + y^\\prime(1) = 0\n\\end{cases}\nSolving the equation gets us\n\ny_i(x) = \\sin\\left(x\\sqrt{\\lambda}\\right)\n\nLet s_i = \\sqrt{\\lambda_i}. We can then plug this into our integral and get\n\n\\int_0^1 \\sin(s_i x) \\sin(s_j x)\\, dx.\n\nUsing wolframalpha,\n\n\\frac{b\\cos(b)\\sin(a) - a\\cos(a)\\sin(b)}{a^2 - b^2}\n\nUsing the equation\n\ns_i\\cos(s_i) + \\sin s_i = 0\n\nWe can simplify and get\n\n\\frac{b\\cos(b)\\sin(a) - a\\cos(a)\\sin(b)}{a^2 - b^2} = 0"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/intro.html",
    "href": "qmd/abstract/intro-to-groups/intro.html",
    "title": "Axioms and examples",
    "section": "",
    "text": "We start by defining what a binary operation\n\n\n\n\n\n\nDefinition\n\n\n\nA binary operation \\star on a set G is a function \\star \\colon G \\to G, such that \\star is associative.\n\n\nFor example, the ‘+’ operation is a binary operation on \\mathbb{Z}, as for all a and b in \\mathbb{Z}, a + b is also in \\mathbb{Z}.\n\nNote the following properties\n\n\n\n\n\n\nProposition\n\n\n\nGiven a group G under an binary operation \\star, the following hold\n\nThe identity element e of G is unique.\nFor each a \\in G, there exist a unique a^{-1}.\n(a^{-1})^{-1} = a for all a \\in G.\n(a \\star b)^{-1} = b^{-1} \\star a^{-1} for all a,b \\in G.\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\nThe identity element e of G is unique.\n\nSuppose there exists two identity elements e_1 and e_2. By the axiom of identity e_1 \\star e_2 = e_1 and e_1 \\star e_2 = e_2. Thus e_1 = e_2, so the identity is unique.\n\nFor each a \\in G, there exist a unique a^{-1}.\n\nSuppose b and c are both inverses of a and let e be the indentity of G. By the inverse axiom a \\star b = e and c \\star a = e. Note the following relation\n\nc = c \\star e = c \\star (a \\star b) = (c \\star a) \\star b = e \\star b = b"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/axioms.html",
    "href": "qmd/abstract/intro-to-groups/axioms.html",
    "title": "Definitions and basic properties",
    "section": "",
    "text": "This section examines the definitions and important properties of groups."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/axioms.html#order",
    "href": "qmd/abstract/intro-to-groups/axioms.html#order",
    "title": "Definitions and basic properties",
    "section": "Order",
    "text": "Order\nAs always, we start with a definition.\n\n\n\n\n\n\nDefinition\n\n\n\nFor a group G and x \\in G, the order of x is the smallest positive integer n such that x \\star x \\star x \\cdots \\star x = e, where that composition consists of n copies of x.\n\n\nNote that we notate x \\star x \\star x \\cdots as x^n. We also denote the order of x as |x|.\nFor example, for any group G such that e is an identity, |e| = 1. All non-zero elements of \\mathbb{Z}, \\mathbb{Q} or \\mathbb{R} under addition have order infinity."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/dihedral-groups.html",
    "href": "qmd/abstract/intro-to-groups/dihedral-groups.html",
    "title": "Symmetric Groups",
    "section": "",
    "text": "Symmetric groups are groups based on symmetries of certain mathematical objects and structures."
  },
  {
    "objectID": "qmd/matrix/unittwo.html#computing-inverses",
    "href": "qmd/matrix/unittwo.html#computing-inverses",
    "title": "Unit two",
    "section": "Computing inverses",
    "text": "Computing inverses\nSuppose we have an n \\times n matrix A. If A^{-1} exists, then there exists a sequence of row operations R such that R(A) = I. Thus\n\nR(\\,A \\mid I\\,) = R(\\, I \\mid A^{-1}\\,).\n\n\nLet A be an invertible square matrix of size n. Recall that A has an LU decomposition if and only if every upperleft square submatrix of A is invertable. (As you’ll never need row exchanges)\nWe can repeatedly apply row operations on A to arrive at U. Thus\n\nA = LU\n\nClaim, If L_1^{-1} is a lower matrix with some coefficients, L is the same with the negation of those coefficients. Remember that all LU decompositions are exact.\nTwo uppper triangular matrices when multiplied will have their diagonals multiplied.\n\nLDU decomposition\nIf A is an (n \\times n) invertable matrix with an LU factorization, then A has a factor LDU such that L is a lower triangular, D is a diagonal consisting of pivots, U is a unipotent upper triangular matrix. Note tha LDU is unique."
  },
  {
    "objectID": "qmd/matrix/unittwo.html#transpose",
    "href": "qmd/matrix/unittwo.html#transpose",
    "title": "Unit two",
    "section": "Transpose",
    "text": "Transpose\nThere is a fun relation\n\n(AB)^T = B^T A^T\n\nAnd another\n\n(A^T)^{-1} = (A^{-1})^T = A^{-T}\n\n\n\n\n\n\n\nDefinition\n\n\n\nThe matrix A_{n \\times n} is symmetric if A^T = A.\n\n\nIf A_{m\\times n} then AA^T is m \\times m and symmetric, and A^TA is n \\times n and symmetric.\nThis is because\n\n(AA^T)^T = (A^T)^TA^T = AA^T\n\nNote that if S is a symmetric matrix that has an LU decomposition, then LDU is actually LDL^T.\n\nS= LDU\n \nS = U^T D^T L^T\n\n\nPLU decomposition\nLet A be an arbitrary n\\times n invertable matrix. There there exists a unique factorizatio A = PLU such that P is a permutation matrix, L is a lower triangular with 1’s on the diagonal. U is upper triangular. They don’t alone give uniqueness though.\nA = (PLP^{-1})PU is something."
  },
  {
    "objectID": "qmd/numanal/fundementals.html#newtons-method",
    "href": "qmd/numanal/fundementals.html#newtons-method",
    "title": "Fundementals",
    "section": "Newtons method",
    "text": "Newtons method\n\n\n\n\n\n\nExample\n\n\n\nWrite the Newton Iteration to solve\n\nx = \\cos x\n\nNote that\n\nf(x) = x - \\cos x\n\n\nf^\\prime(x) = 1 + \\sin x\n\nSo\n\nx_{m+1} = x_m - \\frac{x_m - \\cos x_m}{1 + \\sin x_m}\n\n\n\nRemember that the error of Newtons method is approximatly equal to the multiplicity of the root\n\n\\varepsilon_{m+1} \\approxeq \\varepsilon_m^2 \\bigg\\lvert \\frac{f^{\\prime\\prime}(a)}{2f^\\prime(a)} \\bigg\\rvert\n\n\n\n\n\n\n\nExample\n\n\n\nWrite the Newton Iteration to solve\n\nf(x) = x^\\alpha\\quad \\alpha&gt;0\n\nWe want to write newtons iteration with an initial guess x_0 \\not = 0, and find for what values of \\alpha does newtons iteration converge to root?\nFirst\n\nx_{m+1} x_m - \\frac{x^\\alpha_m}{\\alpha x^{\\alpha-1}_m} = x_m\\left(1-\\frac{1}{\\alpha}\\right)\n\nThis will converge if\n\n-1 &lt; 1 - \\frac{1}{\\alpha} &lt; 1\n\nThus\n\n\\frac{1}{\\alpha} &lt; 2 \\implies \\alpha &gt; \\frac{1}{2}\n\n\n\nProvided the multiplicity of the root is 1, it converges quadratically. Otherwise the newton method converges linearly, with the rate equal to S = \\frac{m-1}{m}.\nLets assume you can’t calculate the derivative. We instead use the approximation\n\nf^\\prime(x) \\approx \\frac{f(x + h)-f(x)}{h}\n\nOr we use the secant method.\n\nf^\\prime(x_m) \\approx \\frac{f(x_m) - f(x_{m-1})}{x_m - x_{m-1}}\n\nThis is useful when f(x_m) is expensive to compute, but the disadvantage is the convergence is slightly slower.\n\n\\varepsilon_{m+1} \\approx \\varepsilon_m^\\alpha \\bigg\\lvert \\frac{f^{\\prime\\prime}(r)}{2f^\\prime(r)}\\bigg\\rvert\n\nCombination of Newton and Bisection\nFirst we draw a secant line from the points a to b. This gives us an equation\n\ny = f(a) + (x - a)\\frac{f(b)-f(a)}{b-a}\n\nWhich gives us\n\nx = \\frac{a(f(b)-f(a))(b-a)}{f(b)-f(a)} = \\frac{af(b)-bf(a)}{f(b)-f(a)}"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/dihedral-groups.html#dihedral-groups",
    "href": "qmd/abstract/intro-to-groups/dihedral-groups.html#dihedral-groups",
    "title": "Symmetric Groups",
    "section": "Dihedral groups",
    "text": "Dihedral groups\nAn important example of a group comes from symmetries of geometric objects, most notably, polygons.\nLets take a hexagon, and apply an operation s, which reflects it along a line of symmetry. We could also apply an operation r, which rotates the hexagon by \\pi / 3 radians. These operations swap the location of the vertices of the hexagon.\n\n\n\n\n\n\n(Insert picture of a hexagon being rotated and symetry)\n\n\n\n\n\nIf we represent the orignal labelling of the vertices as\n\n\\{1,2,3,4,5,6\\}\n\nThen we can represent our operations r and s as the permutations\n\nr = \\{2,3,4,5,6,1\\} \\quad s = \\{1,6,5,4,3,2\\}\n\n\n\n\n\n\n\nDefinition\n\n\n\nA symmetry is a reordering of the vertices on a geometric shape such that their structure remains. We typically denote a symmetry with \\sigma.\n\n\nFor polygons in 2-space, we say that the ‘structure’ of the polygon remains if it can be transferred to 3-space, rotated, and then placed back into 2-space.\nThus our operations r and s are symmetries of the polygon. They can be combined to produce additional symmetries. The set of all possible symmetries on a n-polygon is denoted D_{2n}.\n\n\n\n\n\n\nDefinition\n\n\n\nThe set of symmetries on an n-polygon is denoted D_{2n}, and called the dihedral group of order 2n.\n\n\nWe will prove that D_{2n} is indeed a group later, but for now it can be taken as fact. D_{2n} has 2n symmetries, all of which can be constructed via compositions of our symmetries r and s.\n\n\n\n\n\n\nExample\n\n\n\nLets examine the group D_{12}, the symmetries of a hexagon.\nFirst lets look at our possible rotations r. Let e be the orignal labelling of the vertices, and r be defined\n\nr \\colon \\{1,2,3,4,5,6\\} \\to \\{2,3,4,5,6,1\\}\n\nWe can repeatedly compose r to construct the following symmetries\n\ne, r, r^2, r^3, r^4, r^5.\n\nNote that r^6 = r^0 = e, thus |r| = 6.\nNext we can look at our reflections. Let s be defined\n\ns \\colon \\{1,2,3,4,5,6\\} \\to \\{1,6,5,4,3,2\\}\n\nNote that s^2 = e. Combining s and r, we can create \ns, sr, sr^2, sr^3, sr^5, sr^6\n\nGiving us six new symmetries. This gives us a total of 12 symmmetries in D_{12}.\n\n\nIt should be noted that D_{12} is not abelian, which can be clearly be seen with\n\nrs = \\{6,5,4,3,2,1\\} = sr^5 \\quad sr = \\{2,1,6,5,4,3\\}"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/dihedral-groups.html#symmetric-groups",
    "href": "qmd/abstract/intro-to-groups/dihedral-groups.html#symmetric-groups",
    "title": "Symmetric Groups",
    "section": "Symmetric Groups",
    "text": "Symmetric Groups\nLets define a new symmetric group \\Omega.\n\n\n\n\n\n\nDefinition\n\n\n\nWe define a set \\Omega by the following rules\nLet \\Omega \\not = \\varnothing.\nLet S_\\Omega be the set of all bijections from \\Omega \\to \\Omega, called a permutation.\nLet \\sigma,\\tau be permutations of \\Omega.\n\n\nThis gives \\Omega, and more precisly S_\\Omega some interesting properties.\n\nThe identity of S_\\Omega is the permutation 1 where 1(a) = a\\, \\forall a \\in \\Omega.\nSince function composition is associative, the operation is associative.\nEvery permutation has an inverse since it’s a bijection. Take \\sigma\\colon \\Omega \\to \\Omega, then \\sigma^{-1} \\colon \\Omega \\to \\Omega and \\sigma \\circ \\sigma^{-1} = 1\n\nTherefore, (S_\\Omega, \\circ) is a group and its called the symmetric group on \\Omega. Usually we take \\Omega as the first n natural numbers.\n\n\n\n\n\n\nExample\n\n\n\nLets examine \\Omega = \\{1,2,3\\}.\nWe have \\sigma \\in S_3, which we define by\n\n\\sigma \\colon \\{1,2,3\\} \\to \\{2,3,1\\}.\n\nThis is represented in shorthand by\n\n\\sigma \\colon (1\\,2\\,3)\n\nWe can also define a permutation \\tau \\in S_3 By\n\n\\tau \\colon \\{1,2,3\\} \\to \\{2,1,3\\}\n\nWhich is represented in shorthand by\n\n\\tau \\colon (1\\,2)(3) \\text{ or } \\tau \\colon (1\\,2)\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA cycle is a string of integers representing an element of S_n which cyclicly permutes the integers.\nEg. (1\\,2\\,3), (1\\,2)(3)::: {.callout-note icon=“false”} ## Definition\nD_{2n} with these operations is called the dihedral group of order 2n.\n\n\n\n\n\n\n\n\nExample\n\n\n\nContinuing to examine S_3, we know that there exist 3! = 6 total permutations of the set. We can denote the identity permutation\n\n(1)(2)(3)\n\nWe have three example where we leave one number untouched \n(1)(2\\,3), (2)(1\\,3), (3)(1\\,2)\n\nAnd two examples where we permute every number\n\n(1\\,2\\,3), (1\\,3\\,2)\n\n\n\nFor any \\sigma \\in S_n, the cycle decomposition of \\sigma^{-1} is obtained by writing the numbers in cycle of the cycle decomposition of \\sigma is in reverse order. For example, given\n\n\\sigma \\colon (1\\,2\\,3),\\quad \\sigma^{-1} \\colon (3\\,2\\,1)\n\nWhen composing in S_n, we read from right to left, for example, if we were in S^4, and given \n\\sigma \\colon (1\\,2\\,3)(4),\\quad \\tau \\colon (1\\,2)(3\\,4)\n\nWe can get \\sigma \\circ \\tau by combining the two. Rather tedious, but we eventually get\n\n\\sigma \\circ \\tau \\colon (1\\to 3)(2\\to 2)(3\\to4)(4\\to1) = (1\\,3\\,4)(2)\n\nNote that S_n is non-abelian for all n\\geq3. That being said, disjoint cycles will commute. The order of an element \\sigma \\in S_n is the l.c.m of the lengths in it’s cycle decomposition.\nA trasposition is an element of length 2."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/dihedral-groups.html#example-2",
    "href": "qmd/abstract/intro-to-groups/dihedral-groups.html#example-2",
    "title": "Symmetric Groups",
    "section": "Example",
    "text": "Example\nContinuing to examine S_3, we know that there exist 3! = 6 total permutations of the set. We can denote these\n\n(1)(2)(3), (1)(2\\,3), (2)(1\\,3), (3)(1\\,2)\n\n:::"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/dihedral-groups.html#homomorphisms-and-isomorphisms",
    "href": "qmd/abstract/intro-to-groups/dihedral-groups.html#homomorphisms-and-isomorphisms",
    "title": "Symmetric Groups",
    "section": "Homomorphisms and Isomorphisms",
    "text": "Homomorphisms and Isomorphisms"
  },
  {
    "objectID": "qmd/matrix/unittwo.html#permutation-matrices",
    "href": "qmd/matrix/unittwo.html#permutation-matrices",
    "title": "Unit two",
    "section": "Permutation matrices",
    "text": "Permutation matrices\n\n\n\n\n\n\nDefinition\n\n\n\nA permutation matrix is a matrix that permutes the order of the rows when left multiplied, and the columns when right multiplied.\n\n\nThe columns of P are the columns of I permuted. That is to say P is a product of exchange matricies.\nIf P is a permutation matrix, then P is invertible, and P^{-1} = P^T.\nThis is because\n\\begin{align*}\n(P^TP)_{ij} &= (Row_i P^T)\\cdot(Col_j P)\\\\\n&= (Col_i P) \\cdot (Col_j P)\n\\end{align*}\nThus we have 0 if i\\not = j, and 1 if i=j.\nTake the 3\\times3 matrix P sending Row 1 \\to Row 2 \\to Row 3\n\\begin{align*}\nP = \\begin{pmatrix}\n0 & 0 & 1\\\\\n1 & 0 & 0\\\\\n0 & 1 & 0\n\\end{pmatrix}\n\\end{align*}\nWe get this by thinking “What puts Row 3 into Row 1”, which is the following\n\nP = e_1e^T_3\n\nWhich can be repeated\n\nP = e_1e^T_3 + e_2e^T_1 + e_3e_2^T\n\nRecall the PLU decomposition of an invertible matrix A.\nIf A = PLU, then PLP^{-1} is also lower triangular, and the LPU decomposition is (PLP^{-1})PU.\nSuppose I want to turn the following matrix into upper triangular format\n\\begin{align*}\n\\begin{pmatrix}\n0 & 0 & *\\\\\n* & * & *\\\\\n* & * & *\n\\end{pmatrix}\n\\end{align*}\nI would need to switch Row 1 and Row 3. This can be accomplished by the matrix P^{-1}\n\\begin{align*}\nP^{-1} = \\begin{pmatrix}\n0 & 0 & 1\\\\\n0 & 1 & 0\\\\\n1 & 0 & 0\n\\end{pmatrix}\n\\end{align*}\nAnd then we would want to apply another matrix to generate a pivot in Row 2 (Assuming Row 1 \\not= Row 2). Thus U = L^{-1}P^{-1}A.\n\\begin{align*}\nL^{-1} = \\begin{pmatrix}\n1 & 0 & 0\\\\\n* & 1 & 0\\\\\n0 & 0 & 1\n\\end{pmatrix}\n\\end{align*}\nThrough algebra A = PLU. Now lets use our fact earlier to get (PLP^{-1})PU.\nWe have the following steps in our algorithm\n\nFind A = LPU\nTo find A = PLU, apply LU decomposition to P^TA\n\nFirst, apply lower triangular row operations to have only one non-zero entry in column 1, giving you the first pivot row.\nSecond, apply lower triangular row operations to leave only one non-zero entry in column 2, ignoring the first privot row.\nContinue, arriving at L^{-1}A = PU where L^{-1} is the row operations applied. So taking our old matrix.\n\\begin{align*}\n\\begin{pmatrix}\n0 & 0 & *\\\\\n* & * & *\\\\\n* & * & *\n\\end{pmatrix}\n\\end{align*}\nWe can delete the * in the thrid row of column 1 with the matrix\n\\begin{align*}\n\\begin{pmatrix}\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0 & * & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n0 & 0 & *\\\\\n* & * & *\\\\\n* & * & *\n\\end{pmatrix}\\to\n\\begin{pmatrix}\n0 & 0 & *\\\\\n* & * & *\\\\\n0 & * & *\n\\end{pmatrix}\n\\end{align*}\nThis gives us L^{-1}A = PU. But what is P? P is simply the permutation matrix consisting on non-zero entries in the pivot locations.\n\\begin{align*}\nP = \\begin{pmatrix}\n0 & 0 & 1\\\\\n1 & 0 & 0\\\\\n0 & 1 & 0\n\\end{pmatrix}\n\\end{align*}\nNow lets apply LU decomposition to P^TA In order to get the right L and U."
  },
  {
    "objectID": "qmd/matrix/unitthree.html",
    "href": "qmd/matrix/unitthree.html",
    "title": "Unit three",
    "section": "",
    "text": "We have vector spaces\n\n\\mathbb{R}^n \\text{ (scalars are in $\\mathbb{R}$) }\n\n\n\\mathbb{C}^n \\text{ (scalars are in $\\mathbb{C}$) }\n\nAnd subspaces, subsets of \\mathbb{R}^n closed under addition and scalar multiplication.\n\nx_1,x_2 \\in S \\implies c_1x_1 + c_2x_2 \\in S \\quad\\forall c_1,c_2 \\in \\mathbb{R}\n\nFun fact, Ax = b can be solved for x if and only if b \\in \\text{Col}(A), that meaning b is a linear combination of the columns of A."
  },
  {
    "objectID": "qmd/matrix/unitthree.html#vector-spaces-subspaces",
    "href": "qmd/matrix/unitthree.html#vector-spaces-subspaces",
    "title": "Unit three",
    "section": "",
    "text": "We have vector spaces\n\n\\mathbb{R}^n \\text{ (scalars are in $\\mathbb{R}$) }\n\n\n\\mathbb{C}^n \\text{ (scalars are in $\\mathbb{C}$) }\n\nAnd subspaces, subsets of \\mathbb{R}^n closed under addition and scalar multiplication.\n\nx_1,x_2 \\in S \\implies c_1x_1 + c_2x_2 \\in S \\quad\\forall c_1,c_2 \\in \\mathbb{R}\n\nFun fact, Ax = b can be solved for x if and only if b \\in \\text{Col}(A), that meaning b is a linear combination of the columns of A."
  },
  {
    "objectID": "qmd/matrix/unitthree.html#section-3.2",
    "href": "qmd/matrix/unitthree.html#section-3.2",
    "title": "Unit three",
    "section": "Section 3.2",
    "text": "Section 3.2\nLet A of size m \\times n be an arbitrary matrix.\nWe have\n\n\\text{Null}(A) = \\{x \\in \\mathbb{R}^n \\mid Ax = 0\\}\n\nIf \\text{Null}(A) is a subspace of \\mathbb{R}^n, then linearity applies.\nFact. Ax = 0 if and only if x \\perp \\text{RowSp}(A).\nWe say \\text{Null}(A) = \\text{Row}(A)^\\perp. How do we find \\text{Null}(A)? Row operations on A don’t affect the null space.\nA strategy to find the null space on A is to convert A into reduced row echelon form R. The row space remains the same so the null space remains the same. The column spaces however are entirely different.\nConverting to RREF is simple. So I won’t write it down."
  },
  {
    "objectID": "qmd/geometry/geometry.html",
    "href": "qmd/geometry/geometry.html",
    "title": "Geometry",
    "section": "",
    "text": "We have the following identities\n\n\\sin(\\alpha + \\beta) = \\sin(\\alpha)\\cos(\\beta) + \\sin(\\beta)\\cos(\\alpha)\n\n\n\\sin(\\alpha - \\beta) = \\sin(\\alpha)\\cos(\\beta) - \\sin(\\beta)\\cos(\\alpha)\n\n\n\\cos(\\alpha + \\beta) = \\cos(\\alpha)\\cos(\\beta) - \\sin(\\alpha)\\sin(\\beta)\n\n\n\\cos(\\alpha - \\beta) = \\cos(\\alpha)\\cos(\\beta) + \\sin(\\alpha)\\sin(\\beta)\n\n\n\n\n\n\n\nTheorem (De Moivre’s Theorem)\n\n\n\nA complex number raised to an integer power is given by \nZ^n = \\left(r(\\cos\\theta + i\\sin\\theta)\\right)^n= r^n(\\cos n\\theta + i\\sin\\theta)\n\n\n\nSo for example, if we were given the complex number\n\nZ = 2(\\cos\\theta + i \\sin \\theta)\n\nWe could easily compute\n\nZ^2 = 4(\\cos 2\\theta + i \\sin\\theta)\n\n\n\n\n\n\n\nProof\n\n\n\nWe begin a proof by induction. We have our base case\n\nn = 1 \\quad Z^1 = r^1(\\cos 1\\theta + i\\sin\\theta) = Z\n\nAssume the statement holds for k, then\n\\begin{align*}\nZ^{k+1} &= Z^kZ = \\left(r^k(\\cos k\\theta + i\\sin\\theta)\\right)\\left(r(\\cos \\theta + i\\sin\\theta)\\right)\\\\\n&= r^{k+1}\\bigg( \\left( \\cos k \\theta \\cos \\theta - \\sin \\theta \\sin \\theta \\right) + \\\\\n&\\quad \\quad \\quad \\quad \\quad \\quad i \\left( \\sin \\theta \\cos \\theta + \\cos k\\theta \\sin \\theta \\right)\\bigg)\\\\\n&= r^{k+1}(\\cos (k+1)\\theta + i\\sin\\theta)\n\\end{align*}"
  },
  {
    "objectID": "qmd/geometry/geometry.html#formal-languages",
    "href": "qmd/geometry/geometry.html#formal-languages",
    "title": "Geometry",
    "section": "Formal Languages",
    "text": "Formal Languages\nA formal language is defined by its symbols, such as quantifiers or connectives, and its syntax, rules for combining symbols. The most important class of formal language is known as first-order language, denoted \\mathcal{L}_1.\nThe symbols in a first-order language can be grouped into seven categories. Some authors may however chose to group the symbols into more or less categories, but the disctintion is arbitrary. These categories are\n\nConnectives - \\land, \\lor, \\implies, \\iff, \\lnot\nQuantifiers - \\forall, \\exists\nVariables - v_1,v_2,v_3 ect. A first-order language may consist of any countable amount of variables.\nConstants - c_0, c_1, c_2 ect. A first-order language may consist of any countable amount of constants.\nOperations - A first-order language can consist of any amount of countable operations (functions) f of any order.\nRelations - A first-order language can consist of any amount of countable relations p of any order.\nParentheses - Right ) and left (.\n\nMost of the time \\to will be used instead of \\implies, and \\leftrightarrow instead of \\iff, as the symbols are smaller are easier to read. For readibility sake, parenthesis occur in different sizes, or occansionally as brackets. Commas are also inserted to make formulas easier to read, but are not a formal symbol.\nNow we can begin constructing the syntax for first-order languages.\n\n\n\n\n\n\nDefinition\n\n\n\nEvery variable or constant is a term. Additionally, if f is an operator of degree n, and t_1,t_2,\\dots,t_n are terms, then f(t_1,t_2,\\dots,t_n) is a term.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf p is a relation of degree n, and t_1,t_2,\\dots,t_n are terms, then p(t_1,t_2,\\dots,t_n) is a formula.\nAdditionally, if P and Q are formulas, and x is a variable, then the expressions\n\nP \\iff Q, P \\implies Q, P \\land Q, P \\lor Q\\\\\n\\lnot P, \\forall x P, \\exists x P\n\nare also formulas.\n\n\nNote that mathematicians almost never write in unabbreviated notation. For example, the equation x + y would be wrote +(x,y), which looks silly.\nWe now can construct formulas from our symbols. Deciding truth values for these formulas is the role of a deductive system."
  },
  {
    "objectID": "qmd/geometry/geometry.html#deductive-systems",
    "href": "qmd/geometry/geometry.html#deductive-systems",
    "title": "Geometry",
    "section": "Deductive systems",
    "text": "Deductive systems\nA deductive system (deductive apparatus) is (usually) a set of axioms and rules of inference which are used to deduce one true statement from another. It is very common in math to use a Hilbert System, which consist of a large number of axioms, and few to no rules of inferences.\nBelow is an example of a Hilbert System which describes first-order logic.\n\n\n\n\n\n\nFOL Deductive system example1\n\n\n\nLogical Axioms\nThe first four axioms describe propositional logic, which is logic without quantifiers like \\land or \\lor.\nP1. \\phi \\rightarrow \\phi\nP2. \\phi \\rightarrow (\\psi \\rightarrow \\phi)\nP3. (\\phi \\rightarrow (\\psi \\rightarrow \\zeta)) \\rightarrow ((\\phi \\rightarrow \\psi) \\rightarrow (\\phi \\rightarrow \\zeta))\nP4. (\\lnot \\phi \\rightarrow \\lnot \\psi) \\rightarrow (\\psi \\rightarrow \\phi)\nHere, \\phi,\\psi and \\zeta refer to formulas, as constructed from our language. Thus, P1 could represent p \\rightarrow p or (p \\land q) \\rightarrow (p \\land q). This axiomitization is in no way unique, and in fact axiom P1 can be proven from P2 and P3.\nThe next three axioms allow us to manipulate quantifiers.\nQ5. \\forall x\\,(\\phi) \\rightarrow \\phi[x:=t] (Meaning t may be substituded for x in \\phi)\nQ6. \\forall x\\,(\\phi \\rightarrow \\psi) \\rightarrow (\\forall x\\,(\\phi) \\rightarrow \\forall x\\, (\\psi))\nQ7. \\phi \\rightarrow \\forall x \\,(\\phi) (where x is not free in \\phi)\nThese three axioms allow us to use the \\forall quantifier.\nFor formal systems where equality is not defined as a relation, the following two axioms are necessary.\nI8. x = x for every variable x.\nI9. (x = y) \\rightarrow (\\phi(x) = \\phi(y))\nRules of inference\nRules of inference are used to deduce a true statement from a previous. Modus ponens is typically the only used rule of inference.\nR1. Modus ponens\nModus ponens states that if p and p \\rightarrow q are true, then q is true.\n\n\nNote any connective can be formed using only \\lnot and \\rightarrow, and the exists quantifier can be defined using connectives and the for all quantifier.\nNow that we’ve defined a formal language to produce formulas, and a deduction system to define truth, we can construct a formal system."
  },
  {
    "objectID": "qmd/geometry/geometry.html#first-order-logic",
    "href": "qmd/geometry/geometry.html#first-order-logic",
    "title": "Geometry",
    "section": "First-order logic",
    "text": "First-order logic\nAlthough we can construct many formal systems by combining different languages with different deductive systems, the most popular formal systems belong to first-order logic, sometimes called predicate logic.\n\n\n\n\n\n\nDefinition\n\n\n\nFirst-order logic refers to a collection of formal systems composed of\n\nA first-order language\nA deductive system equivalent to the example shown above\n\n\n\nAs a concrete example, both ZF (Zermelo-Fraenkel set theory) and PA (Peano arithmetic) are theories in first-order logic. They both use a unique first-order language, and the same deductive system. So they both can be said to use first-order logic.\nWhat exactly ZF and PA are, and what a theory is, are explained in the next part."
  },
  {
    "objectID": "qmd/geometry/geometry.html#footnotes",
    "href": "qmd/geometry/geometry.html#footnotes",
    "title": "Geometry",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis section is copied from Wikipedia almost verbatim.↩︎"
  },
  {
    "objectID": "qmd/todo/todo.html#latin",
    "href": "qmd/todo/todo.html#latin",
    "title": "Todo",
    "section": "Latin",
    "text": "Latin\nM. Tullī Cicerō, quid agis? Istī prō multīs factīs malīs poenās dare nunc dēbent; eōs enim ad mortem dūcere dēbēs, quod Rōmam in multa perīcula trāxērunt. Saepe Rōmānī in hāc cīvitāte etiam cīvēs morte multāvērunt. Sed nōn dēbēs cōgitāre hōs malōs esse cīvēs, nam numquam in hāc urbe prōditōrēs patriae iūra cīvium tenuērunt; hī iūra sua āmīsērunt. Populus Rōmānus tibi magnās grātiās aget, M. Tullī, sī istōs cum virtūte nunc multābis.\nM. Tulli Cicero, what are you doing? Those men now ought to pay for their many evil deeds; you ought to lead them to death, because they dragged rome into multiple troubles. Often the state has punished Roman citizens by death. But you ought to think these evil men citizens, the betrayers of the Fatherland have never been citizens; these men have lost their rights as citizens. The Roman people will give you many great thanks, M. Tulli, if you now punish those men with virtue."
  },
  {
    "objectID": "qmd/measure/porous.html",
    "href": "qmd/measure/porous.html",
    "title": "Porous sets",
    "section": "",
    "text": "There are several ways to define a small set, like Meager and Measure-zero. Porous sets are an alternate way to measure how small a set is."
  },
  {
    "objectID": "qmd/measure/porous.html#definition",
    "href": "qmd/measure/porous.html#definition",
    "title": "Porous sets",
    "section": "Definition",
    "text": "Definition\nA set is porous if every interval I in \\mathbb{R} contains an interval I_2 completly missing the set, such that |I_2| = \\alpha |I| where 0 &lt; \\alpha &lt; 1.\nFormalizing this definition requires a few steps.\n\n\n\n\n\n\nDefinition\n\n\n\nLet E be a set in \\mathbb{R}, and x \\in \\mathbb{R}. The right porosity of E at x is denoted p^+(E,x) and is given by\n\np^+(E,x) = \\limsup_{\\varepsilon \\to 0^+} \\frac{k}{k+h}\n\nwhere (x + h, x + h + k) \\cap E = \\varnothing, h + k &lt; \\varepsilon and h,k &gt; 0, and \\sup refers to the lowest greater bound. Similary, the left porosity of E, denoted p^-(E,x) is defined by (x - h - k, x - h) \\cap E = \\varnothing\nThen the porosity of E at x is defined by\n\np(E,x) = \\max\\{p^-(E,x),p^+(E,x)\\}\n\nIt is clear the value of p is inbetween [0,1]. We say that E is porous at \\bf x if p(E,x) &gt; 0, and that E is porous if p(E,x) &gt; 0 for all x \\in E.\n\n\n\n\n\n\n\n\nExample\n\n\n\nAre the following sets porous at x?\n\nIs the set E = [0,1] porous at x = \\frac{1}{2}?\n\nLet’s start by trying to find the left porosity of E at x. It’s clear that when \\varepsilon &lt; \\frac{1}{2}, no values of h,k satisfy (x + h, x + h + k) \\cap E = \\varnothing, h + k &lt; \\varepsilon. Therefore, the set does not have a defined left porosity. Similary the set does not have a defined right porosity, so the set is not porous at x = \\frac{1}{2}.\n\nIs the set E = C porous at x = \\frac{1}{3}?\n\nIn this case C refers to the Cantor ternary set. At x = \\frac{1}{3}, it is clear that p^+(C,\\frac{1}{3}) = 1, because h can get arbitrarily small while completly avoiding C. Because p^- can’t possibly be greater than 1, p(C,\\frac{1}{3}) = 1, and the Cantor ternary set is porous at x = \\frac{1}{3}."
  },
  {
    "objectID": "qmd/measure/porous.html#beta-porous",
    "href": "qmd/measure/porous.html#beta-porous",
    "title": "Porous sets",
    "section": "Beta-porous",
    "text": "Beta-porous\n\n\n\n\n\n\nDefinition\n\n\n\nLet A \\subseteq \\mathbb{R}, \\beta \\in (0,1). Then A is \\beta-porous iff for every (a,b) \\  in \\mathbb{R}, \\exists(a^\\prime,b^\\prime) \\subseteq (a,b) such that (b^\\prime - a^\\prime) = \\beta(b-a)"
  },
  {
    "objectID": "qmd/measure/porous.html#f-porous",
    "href": "qmd/measure/porous.html#f-porous",
    "title": "Porous sets",
    "section": "f-porous",
    "text": "f-porous\nA set A is f-porous if for some f, there exists an \\varepsilon_n such that for all intervals |J| \\subset |I|, there exists an interval |K| \\subset |J| such that $$\n\n\n\n\n\n\nTheorem\n\n\n\nA set A is f-porous \\forall f iff A is discrete\n\n\n\n\n\n\n\n\nProof\n\n\n\nIf a set is discrete, then we can\nBy way of contradition, assume A is not discrete, and f-porous for every f. Then\n\n\\exists x \\in A \\mid \\forall \\varepsilon &gt; 0,\\quad \\mathcal{B}(x,\\varepsilon) - \\{x\\} \\cap A \\not = \\varnothing\n\nWithout loss of generality, let\n\n\\lvert x - x_{n-1} \\rvert &lt; \\lvert x - {x_n}\\rvert\n\nand\n\n|x_{n-1} - x_n| &lt; \\frac{x_n - x}{2}\n\nFor each n \\in \\mathbb{N}, let f_n be such that\n\nf_n(|x_n - x|) &gt; |x_n - x_{n+1}|\n\nWe choose a random interval x \\in I \\subset \\mathbb{R}, and let \\varepsilon_{I,n} &gt; 0 be this intervals associated epsilon for any f_n.\nLet J \\subset I such that |J| &lt; \\varepsilon_{I,n} and n \\in \\mathbb{N}.\nNeed to show that |x_n - x_{n-1}| &lt; |x_n - x|/2. Can’t prove.\n\n\n\n\n\n\n\n\nProof\n\n\n\nSuppose A is uncountable. Uncountable sets have the property that there exists some point x that is a limit point from both sides, symbollically.\n\n\\exists x \\in A \\mid \\forall \\varepsilon &gt; 0\n\n\n(x-\\varepsilon,x) \\cap A \\not = \\varnothing \\land (x, x + \\varepsilon) \\cap A \\not = \\varnothing\n\nWe can now construct a continually decreasing sequence. Let \\{x_n\\} \\to x. Without loss of generality, let\n\n|x - x_n{+1}| &lt; |x_{n+1} - x_n|\n\nRepeating for y. approaching from the oppsite side.\nLet \\ell n = |x_n - y_n|, c_n = |y_n - y_{n+1}| and m_n = |x_n - x_{n+1}|.\nLet I \\subseteq \\mathbb{R}, x \\in I. For each n \\in \\mathbb{N}, let\n\nf_n = \\mathbb{R}^+ \\to \\mathbb{R}^+ \\mid f_n(\\ell n) &gt; \\max\\{c_n,m_n\\}\n\nAnd let \\varepsilon_{I_n} be the associated value of epsilon. Let J \\subset I and n \\in \\mathbb{N} such that |J| &lt; \\varepsilon_{I,n}.\nLet J be such that x_n,y_n \\in J. Since f_n is a decreasing function,\n\nf_n(|J|) &gt; f_n(\\ell n) &gt; \\max\\{c_n,m_n\\}\n\nBecause either c_n or m_n is the biggest hole in (y_n,x_n), there is clearly no hole bigger than \\max\\{c_n,m_n\\}. Thus a contradiction, and if a set is f-porous for every f, then A is not uncountable."
  },
  {
    "objectID": "qmd/measure/research.html",
    "href": "qmd/measure/research.html",
    "title": "Porous sets",
    "section": "",
    "text": "There are several ways to define a small set, like Meager and Measure-zero. Porous sets are an alternate way to measure how small a set is."
  },
  {
    "objectID": "qmd/measure/research.html#nowhere-dense-sets",
    "href": "qmd/measure/research.html#nowhere-dense-sets",
    "title": "Porous sets",
    "section": "Nowhere dense sets",
    "text": "Nowhere dense sets\n\n\n\n\n\n\nDefinition\n\n\n\nA set A is nowhere dense (nwd) if for every interval I, there exists a subinterval J \\subset I such that\n\nJ \\cap A = \\varnothing\n\n\n\nThus, a set is nowhere dense if the set is full of ‘holes’. Lets look at an example of a nowhere dense set.\n\n\n\n\n\n\nExample\n\n\n\nLets see if the set \\mathbb{Z} is nowhere dense. Take any interval I = (a,b).\n\nIf I \\cap \\mathbb{Z}, then we are done. If I contains any point x \\in \\mathbb{Z}, we can construct subinterval J such that x \\not \\in J.\nThere are a finite amount of integers in any interval I, so this process can be repeated until J \\cap \\mathbb{Z} = \\varnothing.\n\n\nAnd an example of a not-nwd set\n\n\n\n\n\n\nExample\n\n\n\nThe set \\mathbb{Q} is dense in \\mathbb{R}. This means that for any interval I = (a,b), there exists a q \\in \\mathbb{Q} such that q \\in I. This means that every subinterval J will intersect \\mathbb{Q}, and \\mathbb{Q} is not a nowhere dense set."
  },
  {
    "objectID": "qmd/measure/research.html#f-porous-sets",
    "href": "qmd/measure/research.html#f-porous-sets",
    "title": "Porous sets",
    "section": "f-porous sets",
    "text": "f-porous sets\nWe define a set to be f-porous as follows\n\n\n\n\n\n\nDefinition\n\n\n\nLet f \\colon \\mathbb{R}^+ \\to \\mathbb{R}^+ such that f(x) &lt; \\frac{x}{2}.\nA set A is f-porous if and only if \\forall I, \\exists \\varepsilon_I &gt; 0 such that for any\nJ \\subseteq I where |J| &lt; \\varepsilon_I, \\exists K \\subseteq J such that |K| = f(|J|) and\nK \\cap A =\\varnothing.\n\n\nLets take for example the set of all integers \\mathbb{Z} and test if the function is f-porous for\n\nf(x) = \\frac{x}{3}.\n\nFor any interval I = (a,b), there should exists an \\varepsilon_I such that |J| &lt; \\varepsilon_I. We want to choose \\varepsilon_I such that |K| = f(|J|). I’ll choose\n\n\\varepsilon_I = 1.\n\nWe want to show that for any J \\subset I where J &lt; 1, there exists an interval K \\subseteq J such that |K| = f(|J|) and K \\cap A = \\varnothing.\nIf J does not intersect \\mathbb{Z}, we are done. J intersects the set at most once, as |J| &lt; 1 and the elements in \\mathbb{Z} are spaced apart by a length of 1. The intersection point between J and \\mathbb{Z} will be denoted x.\nWe want to find a K \\subseteq J of length |K| = f(|J|) = \\frac{|J|}{3} for every J. We can explicitly construct K by dividing J into three equal subintervals J_1, J_2, J_3 each with length \\frac{|J|}{3}. Because x is the singular intersection point, let K = J_n for whichever J_n \\cap \\mathbb{Z} = \\varnothing.\nThus, we have proved \\mathbb{Z} is f-porous for f(x) = \\frac{x}{3}.\n\n\n\n\n\n\nTheorem\n\n\n\nA set is f-porous if and only if the set is nowhere dense.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nIf a set A is f-porous for some f, then clearly the set is nowhere dense, as for any interval I, we have some interval K which misses the set.\nThe harder direction is proving that for some nowhere dense A, that A is f-porous. We will need to construct a function f for any arbitrary nowhere dense set.\nTake any interval I = (a,b). Lets divide the interval into three equal subintervals\n\nI_1 = (a,\\frac{b-a}{3})\\quad I_2 = (\\frac{b-a}{3},\\frac{2(b-a)}{3}) \\quad I_3 = (\\frac{2(b-a)}{3},b)\n\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nIf a set A is f-porous for every f, then A is countable."
  },
  {
    "objectID": "qmd/logic/intro.html#formal-languages",
    "href": "qmd/logic/intro.html#formal-languages",
    "title": "Introduction to Mathematical Logic",
    "section": "Formal languages",
    "text": "Formal languages"
  },
  {
    "objectID": "qmd/logic/intro.html#deductive-systems",
    "href": "qmd/logic/intro.html#deductive-systems",
    "title": "Introduction to Mathematical Logic",
    "section": "Deductive systems",
    "text": "Deductive systems"
  },
  {
    "objectID": "qmd/logic/formal-systems/formal-system.html",
    "href": "qmd/logic/formal-systems/formal-system.html",
    "title": "Formal languages",
    "section": "",
    "text": "A formal system consists of a formal language along with a deductive system."
  },
  {
    "objectID": "qmd/logic/formal-systems/deductive-system.html",
    "href": "qmd/logic/formal-systems/deductive-system.html",
    "title": "Deductive systems",
    "section": "",
    "text": "I"
  },
  {
    "objectID": "qmd/logic/formal-systems/deductive-system.html#first-order-languages",
    "href": "qmd/logic/formal-systems/deductive-system.html#first-order-languages",
    "title": "Formal languages",
    "section": "First order languages",
    "text": "First order languages\nFor a more in-depth look at a formal language, lets take a dive into first-order language. I’ll use the slightly obscure notation used in [Ebbinghaus, Flum, Thomas], as I personally feel they take a very formal approach to developing a formal language.\nThe alphabet of a first-order language has the following symbols\n\nConnectives - \\land, \\lor, \\rightarrow, \\leftrightarrow, \\lnot\nQuantifiers - \\forall, \\exists\nVariables - v_1,v_2,v_3, \\cdots, v_n\nEquality - The equal sign ‘=’\nParentheses - Right ) and left (.\nOperations - A first-order language can consist of any amount of countable operations (functions) f of any order.\nRelations - A first-order language can consist of any amount of countable relations p of any order.\nConstants - c_0, c_1, c_2 ect. A first-order language may consist of any countable amount of constants.\n\nFor readability sake, parenthesis occur in different sizes, or occasionally as brackets. Commas are also inserted to make formulas easier to read, but are not a formal symbol.\nThe first five groups listed are denoted \\mathbb{A}, and S denotes the unique operations, relations, and constants in the language. The set S determines the unique first-order language. We denote the shared alphabet \\mathbb{A}_S = \\mathbb{A} \\cup S.\nNow we can begin constructing the syntax for first-order languages. We start by defining terms\n\n\n\n\n\n\nDefinition\n\n\n\nS-terms are strings in \\mathbb{A}_S which can be formed by the finite application of the following rules\n(T1) Every variable is an S-term.\n(T2) Every constant is an S-term.\n(T3) If f is an operator of degree n in S, and t_1,t_2,\\dots,t_n are S-terms, then ft_1,t_2,\\dots,t_n is an S-term.\n\n\nThe set of all S-terms is denoted T^S. Through repeated applications of the three rules above, we can create larger terms. For example\n\\begin{alignat*}{2}\n& c_1 & \\quad &(T2)\\\\\n& v_1    &\\quad &(T1)\\\\\n& gc_1v_1   &\\quad &(T3) \\text{ with $c_1$ and $v_1$ applied to $g$}\n\\end{alignat*}\nSo gc_1v_1 is an S-term. Most of the time this is wrote g(c_1,v_1), but to keep things formal we’ll use the objectively worse notation for now. We will however introduce shorthand later. Now that we have S-terms, we can start creating formulas.\n\n\n\n\n\n\nDefinition\n\n\n\nS-formulas are strings in \\mathbb{A}_S which can be formed by the finite application of the following rules\n(F1) If t_1 and t_2 are S-terms, then t_1 = t_2 is an S-formula.\n(F2) If p is a relation of degree n in S, and t_1,t_2,\\dots,t_n are S-terms, then pt_1,t_2,\\dots,t_n is an S-formula.\n(F3) If \\phi is an S-formula, then \\lnot\\phi is also an S-formula.\n(F4) If \\phi and \\psi are S-formulas, then (\\phi \\land \\psi), (\\phi \\lor \\psi), (\\phi \\rightarrow \\psi), (\\phi \\leftrightarrow \\psi) are also S-formulas.\n(F5) If \\phi is an S-formula, and x is a variable, then \\forall x \\phi and \\exists x \\phi are also S-formula.\n\n\nS-formula formed from (F1) or (F2) are known as atomic formula as they don’t use any other formula in their language. Note that an S-formula is simply another word for a wff.\nWe can now introduce some new vocabulary\n\n\n\n\n\n\nDefinition\n\n\n\nGiven the S-formulas (wffs) \\phi, \\psi we have the following vocabulary\n\n\\lnot \\varphi is called the negation of \\phi\n(\\phi \\land \\psi) is called the conjunction of \\phi and \\psi\n(\\phi \\lor \\psi) is called the disjunction of \\phi and \\psi\n(\\phi \\rightarrow \\psi) is called the implication of \\phi and \\psi\n(\\phi \\leftrightarrow \\psi) is called the bi-implication of \\phi and \\psi\n\n\n\nWe denote the set of S-formulas with \\mathcal{L}^S. This set is called the first-order language associated with the symbol set S. And just like that we’ve created a first-order lanaguage! Lot’s of rather tricky notation, but the overall concept is no different than our example in the beginning."
  },
  {
    "objectID": "qmd/logic/formal-systems/deductive-system.html#footnotes",
    "href": "qmd/logic/formal-systems/deductive-system.html#footnotes",
    "title": "Formal languages",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis example was given by Noam Chomsky in his thesis The logical structure of linguistic theory↩︎"
  },
  {
    "objectID": "qmd/logic/formal-systems/truth-and-semantics.html",
    "href": "qmd/logic/formal-systems/truth-and-semantics.html",
    "title": "Truth and Semantics",
    "section": "",
    "text": "We now know how to create a formal language, and how to create new formulas in said system. However, as of now these formulas are merely strings of symbols with no meaning or truth attached to them. Logic isn’t very useful without truth, so lets establish some way of assigning truth to a formula."
  },
  {
    "objectID": "qmd/logic/formal-systems/truth-and-semantics.html#first-order-languages",
    "href": "qmd/logic/formal-systems/truth-and-semantics.html#first-order-languages",
    "title": "Truth and Semantics",
    "section": "First order languages",
    "text": "First order languages\nFor a more in-depth look at a formal language, lets take a dive into first-order language. I’ll use the slightly obscure notation used in [Ebbinghaus, Flum, Thomas], as I personally feel they take a very formal approach to developing a formal language.\nThe alphabet of a first-order language has the following symbols\n\nConnectives - \\land, \\lor, \\rightarrow, \\leftrightarrow, \\lnot\nQuantifiers - \\forall, \\exists\nVariables - v_1,v_2,v_3, \\cdots, v_n\nEquality - The equal sign ‘=’\nParentheses - Right ) and left (.\nOperations - A first-order language can consist of any amount of countable operations (functions) f of any order.\nRelations - A first-order language can consist of any amount of countable relations p of any order.\nConstants - c_0, c_1, c_2 ect. A first-order language may consist of any countable amount of constants.\n\nFor readability sake, parenthesis occur in different sizes, or occasionally as brackets. Commas are also inserted to make formulas easier to read, but are not a formal symbol.\nThe first five groups listed are denoted \\mathbb{A}, and S denotes the unique operations, relations, and constants in the language. The set S determines the unique first-order language. We denote the shared alphabet \\mathbb{A}_S = \\mathbb{A} \\cup S.\nNow we can begin constructing the syntax for first-order languages. We start by defining terms\n\n\n\n\n\n\nDefinition\n\n\n\nS-terms are strings in \\mathbb{A}_S which can be formed by the finite application of the following rules\n(T1) Every variable is an S-term.\n(T2) Every constant is an S-term.\n(T3) If f is an operator of degree n in S, and t_1,t_2,\\dots,t_n are S-terms, then ft_1,t_2,\\dots,t_n is an S-term.\n\n\nThe set of all S-terms is denoted T^S. Through repeated applications of the three rules above, we can create larger terms. For example\n\\begin{alignat*}{2}\n& c_1 & \\quad &(T2)\\\\\n& v_1    &\\quad &(T1)\\\\\n& gc_1v_1   &\\quad &(T3) \\text{ with $c_1$ and $v_1$ applied to $g$}\n\\end{alignat*}\nSo gc_1v_1 is an S-term. Most of the time this is wrote g(c_1,v_1), but to keep things formal we’ll use the objectively worse notation for now. We will however introduce shorthand later. Now that we have S-terms, we can start creating formulas.\n\n\n\n\n\n\nDefinition\n\n\n\nS-formulas are strings in \\mathbb{A}_S which can be formed by the finite application of the following rules\n(F1) If t_1 and t_2 are S-terms, then t_1 = t_2 is an S-formula.\n(F2) If p is a relation of degree n in S, and t_1,t_2,\\dots,t_n are S-terms, then pt_1,t_2,\\dots,t_n is an S-formula.\n(F3) If \\phi is an S-formula, then \\lnot\\phi is also an S-formula.\n(F4) If \\phi and \\psi are S-formulas, then (\\phi \\land \\psi), (\\phi \\lor \\psi), (\\phi \\rightarrow \\psi), (\\phi \\leftrightarrow \\psi) are also S-formulas.\n(F5) If \\phi is an S-formula, and x is a variable, then \\forall x \\phi and \\exists x \\phi are also S-formula.\n\n\nS-formula formed from (F1) or (F2) are known as atomic formula as they don’t use any other formula in their language. Note that an S-formula is simply another word for a wff.\nWe can now introduce some new vocabulary\n\n\n\n\n\n\nDefinition\n\n\n\nGiven the S-formulas (wffs) \\phi, \\psi we have the following vocabulary\n\n\\lnot \\varphi is called the negation of \\phi\n(\\phi \\land \\psi) is called the conjunction of \\phi and \\psi\n(\\phi \\lor \\psi) is called the disjunction of \\phi and \\psi\n(\\phi \\rightarrow \\psi) is called the implication of \\phi and \\psi\n(\\phi \\leftrightarrow \\psi) is called the bi-implication of \\phi and \\psi\n\n\n\nWe denote the set of S-formulas with \\mathcal{L}^S. This set is called the first-order language associated with the symbol set S. And just like that we’ve created a first-order lanaguage! Lot’s of rather tricky notation, but the overall concept is no different than our example in the beginning."
  },
  {
    "objectID": "qmd/logic/formal-systems/truth-and-semantics.html#footnotes",
    "href": "qmd/logic/formal-systems/truth-and-semantics.html#footnotes",
    "title": "Truth and Semantics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis example was given by Noam Chomsky in his thesis The logical structure of linguistic theory↩︎"
  },
  {
    "objectID": "qmd/logic/formal-systems/truth-and-semantics.html#truth-assignment-in-proposition-logic",
    "href": "qmd/logic/formal-systems/truth-and-semantics.html#truth-assignment-in-proposition-logic",
    "title": "Truth and Semantics",
    "section": "Truth Assignment in Proposition logic",
    "text": "Truth Assignment in Proposition logic\nIn order to keep things simple, we’ll be using propositional logic as our example for truth assignment. Proposition logic contains no quantifiers, functions, relations, or equality, so it’ll be simple to work with. Of course a formal definition of propositional logic will be given later, but for now it serves as a simple example for truth.\n\n\n\n\n\n\nDefinition\n\n\n\nA truth value is some value relating to the truth of a statement.\n\n\nMost logic contains only two truth values, truth denoted T or 1, and falsity denoted F or 0. There is however no limit to the amount of truth values one could have.\n\n\n\n\n\n\nDefinition\n\n\n\nA truth assignment is some function v such that for the set of terms T^S\n\nv \\colon T^S \\to \\{T,F\\}\n\n\n\nThus a truth assignment would take every term, and assign the term as either true or false. It is important to note that v only assigns truth to terms. This is to avoid seemingly contradictory statements like\n\nv(p \\land q) = T\\quad v(p) = F,\n\nwhich treats the ‘And’ operator very differently from common expection. The solution to this to define a function \\overline{v}, which operates on the set of wff for a language\n\n\\overline{v} \\colon \\mathcal{L}^S \\to \\{T,F\\},\n\nand assigns the correct truth value to each formula. We define this function such that for any term p, \\overline{v}(p) = v(p). We define our operators using truth tables, which gives the truth value for each operator depending on the truth value of the terms.\n\\begin{array}{|c c c c c c c|}\n% |c c|c| means that there are three columns in the table and\n% a vertical bar ’|’ will be printed on the left and right borders,\n% and between the second and the third columns.\n% The letter ’c’ means the value will be centered within the column,\n% letter ’l’, left-aligned, and ’r’, right-aligned.\np & q & \\lnot p & p \\land q & p \\lor q & p \\rightarrow q & p \\leftrightarrow q\\\\ % Use & to separate the columns\n\\hline % Put a horizontal line between the table header and the rest.\nT & T & F & T & T & T & T\\\\\nT & F & F & F & T & F & F\\\\\nF & T & T & F & T & T & F\\\\\nF & F & T & F & F & T & T\\\\\n\\end{array}\nThis is the standard truth table, used in almost all of classical logic. There exists seperate tables for systems with more than two truth values of course, but you’ll (likely) never see the \\land operator defined differently from the table above.\nOf course this is just how truth is defined in propositional logic. Truth is defined very different in logical systems like intuitionistic logic."
  },
  {
    "objectID": "qmd/logic/formal-systems/truth-and-semantics.html#semantic-consequence",
    "href": "qmd/logic/formal-systems/truth-and-semantics.html#semantic-consequence",
    "title": "Truth and Semantics",
    "section": "Semantic consequence",
    "text": "Semantic consequence\nNow that we have an example of a truth assignment, we can work with more general notions of truth.\n\n\n\n\n\n\nDefinition\n\n\n\nWe say a truth assignment v satisfies \\varphi if and only if \\overline{v}(\\varphi) = T.\n\n\nThis leads to our next definition\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\Gamma and \\varphi be sets of wff. We say \\varphi is a Semantic consequence of \\Gamma if and only if every truth assignment that satisfies \\Gamma also satisfies \\varphi. This is denoted\n\n\\Gamma \\models \\varphi\n\n\n\nThus, this simply means if \\Gamma is true, \\varphi is too. We define a tautology \\tau if\n\n\\models \\tau\n\nMeaning that \\tau is always true regardless of the truth assignment used. An example of a tautology in classic logic is the Law of the excluded middle, denoted\n\nP \\lor \\lnot P\n\nWhich is clearly true for all truth values P in propositional logic. However there are systems like intuitionistic logic where truth is defined in a way rejecting the Law of the excluded middle."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html",
    "title": "Homomorphisms and Isomorphisms",
    "section": "",
    "text": "In this section we define what it means for two groups to be equivalent, i.e. have the same group-theoretic structure."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html#properties-of-homomorphisms",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html#properties-of-homomorphisms",
    "title": "Homomorphisms and Isomorphisms",
    "section": "Properties of homomorphisms",
    "text": "Properties of homomorphisms\nNow we can be to look at some of the properties of homomorphisms.\n\n\n\n\n\n\nProposition 1.2.1\n\n\n\nLet \n(G, \\star) \\quad (H, \\diamond) \\quad (M, \\square).\n\nAlso let\n\nf \\colon G \\rightarrow H,\\quad g \\colon H \\rightarrow M\n\nbe homomorphisms. Then\n\ng \\circ f \\colon G \\rightarrow M\n\nis a homomorphism.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nThe proof is just a few lines of algebra\n\\begin{align*}\ng(f(x \\star y)) &= g(f(x) \\diamond f(y))\\\\\n&= g(f(x))\\, \\square \\,g(f(y)))\n\\end{align*}\n\n\n\nAdditionally\n\n\n\n\n\n\nProposition 1.2.2\n\n\n\nLet\n\n\\varphi \\colon G \\rightarrow H\n\nbe a homomorphism. Let e_H,e_G be the identity of H and G respectivly. Then\n\n\\varphi(e_G) = e_H\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nBy algebra\n\\begin{align*}\ne_G &= e_Ge_G\\\\\n\\varphi(e_G) = \\varphi&(e_Ge_G) = \\varphi(e_G)\\varphi(e_G)\\\\\n(\\varphi(e_G))^{-1}\\varphi(e_G) &= (\\varphi(e_G))^{-1}\\varphi(e_G)\\varphi(e_G)\\\\\ne_H &= e_H\\varphi(e_G)\\\\\ne_H &= \\varphi(e_G) \\quad\\square\n\\end{align*}\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nIf \\varphi \\colon G \\rightarrow H is an isomorphism, then\n\nThe cardinality of G and H are equivalent\nIf G is abelian, then H is abelian\nFor all x in G, the order of x is the order of \\varphi(x)\n\n\n\nWe will prove the third proposition using the following lemma\n\n\n\n\n\n\nLemma\n\n\n\nLet \\varphi \\colon G \\rightarrow H be a homomorphism. Then\n\n\\varphi(x^n) = \\varphi(x)^n \\quad \\forall n \\in \\mathbb{Z}\n\n\n\nNow the proof of the third proposition\n\n\n\n\n\n\nProof\n\n\n\nWe have three cases for this proposition\nCase 1:\nCase 2:\nSuppose the order |x| = \\infty, |\\phi(x)| = n &lt; \\infty\nNote that \n\\varphi (x^n) = \\varphi (x)^n = e_H\n\nBecause\n\n\\varphi (e_G) = e_H\n\nBy the injective property (which we can use because we have a bijection), we have\n\nx^n = e_G\n\nThus |x| \\leq n &lt; \\infty. Thus |x| and |\\varphi(x)| must either both be finite or infinite.\nCase 3:\nSuppose |x| = n, |\\varphi(x)| = m. Then\n\n\\varphi(x)^n = \\varphi(x^n) = \\varphi(e_G) = e_H \\implies m \\leq n.\n\nSimilarly,\n\n\\varphi (e_G)= e_H = \\varphi (x)^m = \\varphi(x^m) \\implies m \\geq n\n\nThus\n\nm = n\n\n\n\nWe denote an isomorphism \\cong. If there does not exist an isomorphism, we denote \\not \\cong.\nLets take the following groups S_3 and \\mathbb{Z}/6\\mathbb{Z}. There does not exist an isomorphism between these two, as S_3 is abelian, and \\mathbb{Z}/6\\mathbb{Z} is not. Thus\n\nS_3 \\not \\cong \\mathbb{Z}/6\\mathbb{Z}\n\nThere is however, an isomorphism between D_6 and S_3.\nLet\n\nD_6 = \\{r,s \\mid r^3 = s^2 = 1, sr = r^{-1}s\\}\n\nWe can map\n\nS_3 \\rightarrow D_6\n\n\n(1\\,2\\,3) \\rightarrowtail r\n\n\n(1\\,2) \\rightarrowtail s\n\nWhich maps the generators to each other. Thus\n\nD_6 \\cong S_3"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html#subgroups",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html#subgroups",
    "title": "Homomorphisms and Isomorphisms",
    "section": "Subgroups",
    "text": "Subgroups\n\n\n\n\n\n\nDefinition\n\n\n\nLet (G,\\star) be a group. A subgroup of G is a subset H \\subseteq G such that\n\ne \\in H\nx,y \\in H \\implies x \\star y \\in H\nx \\in H \\implies x^{-1} \\in H\n\n\n\nA subgroup H of G is merely a subset H of G such that H is a group under the same notation.\nThis is notated\n\nH \\leq G\n\n\n\n\n\n\n\nExample\n\n\n\nLets look at some subgroups\n\n(\\mathbb{Z},+) \\leq (\\mathbb{Q},+)\n(\\mathbb{Q}\\backslash \\{0\\},x) \\leq (\\mathbb{R}\\backslash\\{0\\},x)\n\n\n\nIf G is a group, and H = G, or H = \\{e_G\\}, these are both subgroups of G.\nA slightly harder example, if m \\in \\mathbb{Z}, then\n\nm\\mathbb{Z} := \\{ma \\mid a \\in \\mathbb{Z}\\} \\leq (\\mathbb{Z},+).\n\nLets define\n\n\\mathbb{Z}^+ := \\{n \\in \\mathbb{Z} \\mid n &gt; 0\\}.\n\nIt is clear that\n\n(\\mathbb{Z}^+,+) \\not \\leq (\\mathbb{Z},+),\n\nAs \\mathbb{Z}^+ has no identity element, or any inverses.\nThe relation \\leq (is subgroup of) is transitive. The relation is also reflexive, but the relation is not symmetric. This the relation is not an equivalence relation.\n\n\n\n\n\n\nTheorem\n\n\n\nIf H, K are both subgroups of G, then H \\cap K is a subgroup of G.\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe can prove that H \\cap K fufills the three properties of being a subgroup.\n\n(1)\\, e \\in H, e \\in K \\implies e \\in H \\cup K\n\n\n(2) x,y \\in H \\cup K \\implies\n\n\n\nThere is a simple way to check a subgroup\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nA group H is a subgroup of G if\n\nH \\not = \\varnothing\nx,y \\in H \\implies x \\star y^{-1} \\in H\n\n\n\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nIf H is a subgroup of G then e \\in H, thus H \\not = \\varnothing, and if x,y \\in H, then y^{-1} is in H. Thus x \\star y^{-1} is in H.\nNow if H satisfies the two properties, we have some x \\in H, as H is not empty. If y = x, then\n\nx,x \\in H \\implies x \\star x^{-1} \\in H \\implies e \\in H\n\nAnd then with e,x\n\ne,x \\in H \\implies e \\star x^{-1} \\in H \\implies x^{-1} \\in H\n\nIf x,y \\in H then y^{-1} \\in H. Thus\n\nx,y^{-1} \\in H \\implies x \\star (y^{-1})^{-1} \\in H \\implies x \\star y \\in H\n\nSo H is a group."
  },
  {
    "objectID": "qmd/geometry/geometry.html#trigonmetric-identities",
    "href": "qmd/geometry/geometry.html#trigonmetric-identities",
    "title": "Geometry",
    "section": "",
    "text": "We have the following identities\n\n\\sin(\\alpha + \\beta) = \\sin(\\alpha)\\cos(\\beta) + \\sin(\\beta)\\cos(\\alpha)\n\n\n\\sin(\\alpha - \\beta) = \\sin(\\alpha)\\cos(\\beta) - \\sin(\\beta)\\cos(\\alpha)\n\n\n\\cos(\\alpha + \\beta) = \\cos(\\alpha)\\cos(\\beta) - \\sin(\\alpha)\\sin(\\beta)\n\n\n\\cos(\\alpha - \\beta) = \\cos(\\alpha)\\cos(\\beta) + \\sin(\\alpha)\\sin(\\beta)\n\n\n\n\n\n\n\nTheorem (De Moivre’s Theorem)\n\n\n\nA complex number raised to an integer power is given by \nZ^n = \\left(r(\\cos\\theta + i\\sin\\theta)\\right)^n= r^n(\\cos n\\theta + i\\sin\\theta)\n\n\n\nSo for example, if we were given the complex number\n\nZ = 2(\\cos\\theta + i \\sin \\theta)\n\nWe could easily compute\n\nZ^2 = 4(\\cos 2\\theta + i \\sin\\theta)\n\n\n\n\n\n\n\nProof\n\n\n\nWe begin a proof by induction. We have our base case\n\nn = 1 \\quad Z^1 = r^1(\\cos 1\\theta + i\\sin\\theta) = Z\n\nAssume the statement holds for k, then\n\\begin{align*}\nZ^{k+1} &= Z^kZ = \\left(r^k(\\cos k\\theta + i\\sin\\theta)\\right)\\left(r(\\cos \\theta + i\\sin\\theta)\\right)\\\\\n&= r^{k+1}\\bigg( \\left( \\cos k \\theta \\cos \\theta - \\sin \\theta \\sin \\theta \\right) + \\\\\n&\\quad \\quad \\quad \\quad \\quad \\quad i \\left( \\sin \\theta \\cos \\theta + \\cos k\\theta \\sin \\theta \\right)\\bigg)\\\\\n&= r^{k+1}(\\cos (k+1)\\theta + i\\sin\\theta)\n\\end{align*}"
  },
  {
    "objectID": "qmd/geometry/geometry.html#eulers-identity",
    "href": "qmd/geometry/geometry.html#eulers-identity",
    "title": "Geometry",
    "section": "Eulers identity",
    "text": "Eulers identity\nEuler made some crazy identity thingamabob that goes\n\ne^{i\\pi} = -1\n\nWe want to prove this identity. We can start by taylor expanding e, \\cos and \\sin giving\n\ne^x = 1 + \\frac{x}{1!} + \\frac{x^2}{2!} + \\frac{x^3}{3!} \\cdots\n \n\\cos x = 1 - \\frac{x^2}{2!} + \\frac{x^4}{4!} - \\frac{x^6}{6!} \\cdots\n\n\n\\sin x = \\frac{x}{1!} - \\frac{x^3}{3!} + \\frac{x^5}{5!} \\cdots\n\nAllow us to expand e^{xi}, giving\n\ne^{xi} = 1 + \\frac{ix}{1!} - \\frac{x}{2!} - \\frac{ix^3}{3!} + \\frac{x^4}{4!} + \\frac{ix^5}{5!} \\cdots\n\nWhich is clearly\n\ne^{xi} = \\cos x + i\\sin x\n\nThus\n\ne^{\\pi i} = \\cos \\pi + i \\sin \\pi\n\n\ne^{\\pi i} = -1"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html#centralizers-normalizers-center",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html#centralizers-normalizers-center",
    "title": "Homomorphisms and Isomorphisms",
    "section": "Centralizers, Normalizers, Center",
    "text": "Centralizers, Normalizers, Center\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be a subset of a group G.\nThe Centralizer of A in G is a set of elements of G that commute with all elements of A. This is denoted\n\nC_G(A) = \\{g \\in G \\mid gag^{-1} = a, \\; \\forall a \\in A\\}\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nThe centralizer of a subset A of G is a subgroup of G. Symbollically \nC_G(A) \\leq G\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe know\n\ne \\in C_G(A)\n\nThus we can fufill the first property of a subgroup C_G(A) \\not = \\varnothing. Now, let x,y \\in C_G(A). We see\n\ny^{-1}yayy^{-1} = y^{-1}ay\n\n\na = y^{-1}ay = y^{-1}a(y^{-1})^{-1}\n\nThus y^{-1} \\in C_G(A).\nNow we wish to show xy \\in C_G(A)\n\n(xy)a(xy)^{-1} = xyay^{-1}x^{-1}\n\nBecause x,y \\in C_G(A), we have xy \\in C_G(A). Thus\n\nC_G(A) \\leq G\n\n\n\nNext\n\n\n\n\n\n\nDefinition\n\n\n\nThe center of G is denoted\n\nZ(G) = \\{g \\in G \\mid gx = xg,\\, \\forall x \\in G\\}\n\n\n\nThe center of G is the centralizer where A = G. Clearly Then\n\nZ(G) = C_G(G)\n\n\nZ(G) \\leq G\n\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be a subset of a group G, such that g \\in G.\n\ngAg^{-1} = \\{gag^{-1} \\mid a \\in A\\}\n\n\n\nWe use this definition immeditally\n\n\n\n\n\n\nDefinition\n\n\n\nThe normalizer of A in G is denoted\n\nN_G(A) = \\{g \\in G \\mid gAg^{-1} = A\\}\n\n\n\nNote that C_G(A) \\leq N_G(A).\nIf G is abelian, then\n\nZ(G) = G, \\quad C_G(A) = G, \\quad N_G(A) = G\n\n\n\n\n\n\n\nExample\n\n\n\nLet G = D_8, and our subset A = \\{e,r,r^2,r^3\\}.\nWe want to find C_{D_8}\nWe know that A \\subset C_{D_8}(A) because rotations are commutative, that meaning\n\nr^ir^j = r^{i+j} = r^{j+i} = r^jr^i\n\nWe know that sr \\not = rs, so s\\not \\in C_{D_8}(A). We now need to check the remaining elements of D_8, sr,sr^2,sr^3.\nBecause C_{D_8}(A) \\leq D_8 we have\n\nsr^i \\in C_{D_8}(A) \\implies sr^ir^{-1} = s \\in C_{D_8}\n\nWhich is a contradiction, thus\n\nC_{D_8}(A) = A\n\nNow lets find N_{D_8}(A).\nBecause C_{D_8} \\leq N_{D_8}, we know A \\subseteq N_{D_8}(A). We have then\n\nsAs^{-1} = \\{ses^{-1},srs^{-1},sr^2s^{-1},sr^3s^{-1}\\}\n\nTake as a fact r^is = sr^{-1}. Thus\n\nsAs^{-1} = \\{e,r^3,r^2,r\\}\n\nThus s \\in N_{D_8}. We need now check sr^i. Because N_{D_8}(A) \\leq D_8, we have that sr^i is in the normalizer. Thus\n\nN_{D_8}(A) = D_8\n\nWe now wish to find the center of D_8. Since\n\nZ(D_8) \\leq C_{D_8}(A)\n\nWe know that Z(D_8) \\subseteq A.\nWe can check these four elements of A to see if their commutative with everything. We have\n\nrs = sr^{-1} \\not =sr\n\nThus r is not commutative with s, and is not in the center.\n\nr^2s = sr^{-2} = sr^2\n\nSo r^2 commutes with s. Now we check if it commutes with sr^i.\n\nr^2sr^i = sr^{-2}r^i = sr^ir^{-2}\n\nThus our center is \nZ(D_8) = \\{e,r^2\\}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA group H is called cyclic if it is generated by one element. We denote H\n\nH = \\langle x \\rangle = \\{x^n \\mid n \\in \\mathbb{Z}\\}\n\nx is called a generator\n\n\nFor example, (\\mathbb{Z},+)\n\n\\langle 1 \\rangle = \\{+(n,1) \\mid n\\in \\mathbb{Z}\\}\n\nBut also\n\n\\langle -1 \\rangle = \\{+(n,-1) \\mid n\\in \\mathbb{Z}\\}\n\n\n\n\n\n\n\nExample\n\n\n\nWe can find a generator of\n\n(\\mathbb{Z}/n\\mathbb{Z},+)\n\nUsing\n\n\\langle [1] \\rangle = \\{[1],[2],\\cdots,[n]\\} = \\{+(n,[1])\\mid n \\in \\{ 1,2,\\cdots,n\\}\\}\n\n\n\n\n\n\n\n\n\nCorollary\n\n\n\n(1) Assume |x| = \\infty. Then H = &lt;x^a&gt; iff a = \\pm 1\n(2) Assume |x| = n &lt; \\infty then &lt;x^a&gt; = H iff gcd(a,n) = 1\n\n\nNotice\n\n\\mathbb{Z}/6\\mathbb{Z} = \\left&lt;[1]\\right&gt;,\\left&lt;[5]\\right&gt;.\n\n\n\n\n\n\n\nExample\n\n\n\nAll the generators\n\n(\\mathbb{Z}/12\\mathbb{Z},+)\n\nWhich are\n\n\\left&lt;[1]\\right&gt;,\\left&lt;[5]\\right&gt;,\\left&lt;[7]\\right&gt;,\\left&lt;[11]\\right&gt;\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nIf H = \\left&lt;x\\right&gt; is a cyclic groups\n(1) Every subgroup of H is cyclic\n(2) If |H| = n &lt; \\infty then for each positive integer a dividing n, there is a unique subgroup of H of order \\left&lt;x^{\\frac{n}{a}}\\right&gt;\n\n\n\n\n\n\n\n\nProof\n\n\n\n(1) Let K \\leq H = \\left&lt;x\\right&gt;\nIf K = \\{1\\} then done. Otherwise let a = \\min\\{K&gt;0\\mid x^k\\in K\\}.\nThe claim is that K is generated by \\left&lt;x^a\\right&gt;. Suppose not. Suppose there is some x^b \\in K such that a\\not| \\,b. Thus\n\nb = aq + r \\quad 0 &lt; r &lt; a\n\nNote that x^{aq} \\in K. Meaning x^{-aq} \\in K. Thus x^{b-aq} \\in K. Thus x^r \\in K. But because r is less than a, and we assumed a to be the smallest power of x in K, we have a contradiction. Thus every subgroup of H is cyclic.\n(2) If H has a finite order n, we use our previous proposition to note that |\\left&lt;x^\\frac{n}{a}\\right&gt;| = a.\n\n\n\n\n\n\n\n\nExample\n\n\n\nAll the subgroups of \\mathbb{Z}/12\\mathbb{Z} are\nOrder 12: \\left&lt;[1]\\right&gt;\nOrder 6: \\left&lt;[2]\\right&gt;\nOrder 4: \\left&lt;[3]\\right&gt;\nOrder 3: \\left&lt;[4]\\right&gt;\nOrder 2: \\left&lt;[6]\\right&gt;\nOrder 1: \\left&lt;[0]\\right&gt;"
  },
  {
    "objectID": "qmd/matrix/unitthree.html#section-3.4",
    "href": "qmd/matrix/unitthree.html#section-3.4",
    "title": "Unit three",
    "section": "Section 3.4",
    "text": "Section 3.4\nRecall that for vectors v_1,\\cdots,v_n in R^n.\n\n\\text{Span}(\\{v_1,\\ldots,v_n\\}) is the set of all linear combinations of v_1 to v_n.\nv_1,\\ldots,v_n are linearly dependent if \\exists c_1,\\ldots,c_n not all zero such that c_1v_1,\\ldots,c_nv_n = 0.\nIf the vectors are not linearly dependent, then they are linearly independent.\n\n\n\n\n\n\n\nTheorem 3.4.1\n\n\n\nSuppose v_1,\\ldots,v_n are linearly independent in \\mathbb{R}^m and \nw \\in \\mathbb{R}^m, w \\not \\in \\text{Span}(\\{v_1,\\ldots,v_n\\})\n\nThen \\{v_1,\\ldots,v_n,w\\} is linearly independent.\n\n\n\n\n\n\n\n\nProof 3.4.1\n\n\n\n\n\n\n\n\n\n\n\n\nTheorem 3.4.2\n\n\n\nSuppose v_1,\\ldots,v_n are linearly dependent in \\mathbb{R}^m. Then for some j\n\n\\text{Span}\\{v_1,\\ldots,v_{j-1},v_{j+1},\\ldots,v_n\\} = \\text{Span}\\{v_1,\\ldots,v_n\\}\n\n\n\n\n\n\n\n\n\nProof 3.4.2\n\n\n\n\n\n\n\n\n\n\n\n\nTheorem 3.4.3\n\n\n\nSuppose v_1,\\ldots,v_n are linearly dependent in \\mathbb{R}^m for n&gt;m, then the vectors are linearly dependent.\n\n\n\n\n\n\n\n\nProof 3.4.3\n\n\n\nSet\n\\begin{align*}\nA = \\begin{pmatrix}\n1 & & 1\\\\\nv_1 & \\cdots & v_n\\\\\n1 & & 1\n\\end{pmatrix}\n\\end{align*}\nNote n&gt;m \\implies \\text{Null}(A) \\not = \\varnothing, by row reduction. Thus there exist some Ac = 0, c \\not = 0. So the vectors are linearly dependent\n\n\n\n\n\n\n\n\nDefinition (Basis)\n\n\n\nLet V be a subspace of \\mathbb{R}^m. A basis of V is a linearly independent set of vectors v_1,\\ldots,v_r \\in V such that their span is equal to the span of V.\n\n\n\n\n\n\n\n\nTheorem 3.4.4\n\n\n\n\nAny linearly independent subset of V can be enlarged to a basis.\nAny subset of V which spans V can be shrunk to a basis.\n\n\n\n\n\n\n\n\n\nProof 3.4.4\n\n\n\nSuppose \\{w_i,\\ldots,w_s\\} are linearly independent in V. If their span is V, done. If not, take w_{s+1} in V, not in the span. Then w_i,\\ldots,w_{s+1} is linearly independent. By Fact 3.4.3, this terminates at some r \\leq m.\nGiven a set S of vectors which span V, let T be a subset of S of minimal size which spans V. S is linearly independent.\n\n\n\n\n\n\n\n\nTheorem 3.4.5\n\n\n\nSuppose V is a subspace of \\mathbb{R}^m. Let\n\nu_1,\\ldots,u_p span V\nw_1,\\ldots,u_r are linearly independent in V.\n\nUsing only vectors belonging to u, we can enlarge w to a basis.\n\n\n\n\n\n\n\n\nProof 3.4.5\n\n\n\nIf w spans V, we are done. If not, there exists some u not in \\text{Span}(w). Add u to w, and repeat until w spans V.\n\n\n\n\n\n\n\n\nTheorem 3.4.6\n\n\n\nSuppose V is a subspace of \\mathbb{R}^m, such that w_1,\\ldots,w_r is a basis of V. Suppose we also have u_1,\\ldots,u_p \\in V, p &gt; r. Then u_1,\\ldots,u_p are linearly dependent.\n\n\n\n\n\n\n\n\nProof 3.4.6\n\n\n\nWe want c's in \\mathbb{R}, not all 0, such that u_1c_1 + \\cdots + u_pc_p = 0. Because w is a basis, we have\n\nu_1 = w_1A_{11} + \\cdots + w_r A_{r1}\n \nu_2 = w_1A_{12} + \\cdots + w_r A_{r2}\n\n\n\\vdots\n \nu_p = w_1A_{1p} + \\cdots + w_r A_{rp}\n\nMultipliying each u_i by c_i, we get\n\nu_1c_1 + \\cdots + u_pc_p = w_1(Ac)_1 + \\cdots + w_p(Ac)_p\n\nBecause p &gt; r, we have a non empty null space, thus we prove that the c we want exists.\n\n\n\n\n\n\n\n\nTheorem 3.4.7\n\n\n\nSuppose V is a subspace of \\mathbb{R}^m. All bases of V are the same size, which is called the dimension of V.\n\n\n\n\n\n\n\n\nProof 3.4.7\n\n\n\nSuppose we have two bases w and u of size r and p respecitvly. If r &gt; p, then by fact 3.4.6, w would not be a basis. If p &lt; r, then u would not be a basis. Thus r = p."
  },
  {
    "objectID": "qmd/matrix/unitthree.html#section-3.5",
    "href": "qmd/matrix/unitthree.html#section-3.5",
    "title": "Unit three",
    "section": "Section 3.5",
    "text": "Section 3.5\n\n\n\n\n\n\nTheorem 3.5.1\n\n\n\nLet A be an (m\\times n) matrix. Row operations on A do not change the row space. Thus\n\n\\text{RowSp(EA) = RowSp(A)}\n\nIf E is an invertable matrix. Similarly for column space,\n\n\\text{ColSp(AE) = ColSp(A)}.\n\n\n\n\n\n\n\n\n\nProof 3.5.1\n\n\n\nEach row operation on A merely takes a linear combination of rows and and replaces some row with it. Thus the span of the rows remains the same.\n\n\n\n\n\n\n\n\nTheorem 3.5.2\n\n\n\nLet E be an (m\\times m) invertable matrix, V a subspace of \\mathbb{R}^m. Then EV = \\{Ev \\mid v \\in V\\} is also a subspace, and E maps bases of V to bases of EV.\n\n\n\n\n\n\n\n\nProof 3.5.2\n\n\n\nBecause c_1w_1, + \\cdots + c_rw_r = 0, We have Ew = E0 = 0. Thus Ew is linearly independent and a basis.\n\n\n\n\n\n\n\n\nTheorem 3.5.3\n\n\n\nRow operations do not change the dimension of the column space, nor the span of the column space. The same applies to column operations.\n\n\n\n\n\n\n\n\nProof 3.5.3\n\n\n\nThis immeditally follows from 3.5.2. After applying row operations we are left with EA.\n\n\\text{ColSp}(Ea) = E\\text{ColSp}(A).\n\nThe same applies to column operations.\n\n\n\n\n\n\n\n\nTheorem 3.5.4\n\n\n\nSuppose v_1,\\ldots,v_p in \\mathbb{R}^\\ell have span V.\n\n\n\n\n\n\n\n\nProof 3.5.4\n\n\n\nThis immeditally follows from 3.5.2. After applying row operations we are left with EA.\n\n\\text{ColSp}(Ea) = E\\text{ColSp}(A).\n\nThe same applies to column operations.\n\n\n\n\n\n\n\n\nTheorem 3.5.5\n\n\n\nThe row space and column space of any matrix A have the same dimension\n\n\n\n\n\n\n\n\nProof 3.5.5\n\n\n\nLet A_{m\\times n} be a linear map A \\colon \\mathbb{R^n} \\to \\mathbb{R}^m\nOur null space of A has dimension n - r, while our row space has dimension r. Note that\n\n\\text{Image}(A) = A(\\mathbb{R}^n) = \\text{ColSp}(A)\n\n\n\nNote that\n\n\\text{Rank}(A) = \\text{Rank}(A^T)\n\nThe dimension of our \\text{Null}(A) = n-r, where the basis is our special solutions.\nThe Nullspace matrix of the checkers matrix is\n\nA negated rowspace with the standard basis tacked on."
  },
  {
    "objectID": "qmd/pde/introduction copy.html#laplaces-equation",
    "href": "qmd/pde/introduction copy.html#laplaces-equation",
    "title": "PDE",
    "section": "Laplaces Equation",
    "text": "Laplaces Equation\nGiven the PDE\n\nu_{xx} + u_{yy} = 0\n\nWe rewrite using the \\overline{\\nabla} operator, defined\n\n\\overline{\\nabla} = \\frac{\\partial}{\\partial x}\\hat{i} + \\frac{\\partial}{\\partial y}\\hat{j} + \\frac{\\partial}{\\partial z}\\hat{k}\n\nRecall\n\n\\overline{\\nabla}^2u = 0\n\nWe have from the divergence theorem\n\n-k\\iint\\limits_S \\overline{\\nabla}u \\cdot \\hat{u}\\,dS = -k\\iiint\\limits_V \\overline{\\nabla}u \\, dV"
  },
  {
    "objectID": "qmd/pde/introduction copy.html#example-of-an-ill-posed-problem",
    "href": "qmd/pde/introduction copy.html#example-of-an-ill-posed-problem",
    "title": "PDE",
    "section": "Example of an ill posed problem",
    "text": "Example of an ill posed problem\nIf given a problem like\n\\begin{cases}\n      u_{xx} + u_{yy} = 0 \\\\\n      u(0,y) = u(\\pi,y) = 0 \\\\\n      u(x,0) = 1\\\\\n      \\frac{\\partial x}{\\partial y}(x,0) = 0\n\\end{cases}\nWe see that the fourier series diverges, and there is no solution for y &gt; 0.\nEllipitcal equations need to have boundary conditions upon their boundary, unlike parabloic or hyperbolic equations.\nOccasionally when we have a problem with a shperical boundary like a circle, we will need to set up a boundary problem in polar coordinates."
  },
  {
    "objectID": "qmd/numanal/fundementals.html#interpolation",
    "href": "qmd/numanal/fundementals.html#interpolation",
    "title": "Fundementals",
    "section": "Interpolation",
    "text": "Interpolation\nGiven m points (x_1,y_1) through (x_m,y_m), we want to find a continous function P_{m-1}(x) such that for all i = 1,\\ldots,m\n\nP_{m-1}(x_i) = y_i\n\nWe can find this function through Lagrange interpolation.\nDefine\n\nL_k(x) = \\frac{(x-x_1)(x-x_2)\\cdots(x-x_{k-1})(x-x_{k+1})\\cdots(x-x_m)}{(x_k-x_1)(x_k-x_2)\\cdots(x_k - x_{k-1})(x_k - x_{k+1})\\cdots(x_k - x_m)}\n\nWe can clearly see that\n\nL_k(x_k) = 1,\\quad L_k(x_i) = 0\n\nAnd that L_k is a polynomial of degree m-1. Here we can define\n\nP_{m-1}(x) = y_1L_1(x) + \\cdots + y_mL_m(x)\n\nAs a polynomial of degree \\leq m-1. This is called the Lagrange polynomial. This gives us a function P_{m-1}(x) such that\n\nP_{m-1}(x_i) = y_1L_1(x_i) + \\cdots + y_mL_m(x_i) = y_i\n\nWhich is pretty cool. But even better, this has the special property. Assume there exists some true function f(x) that we are interpolating at a finite amount of points through P_{m-1}(x). Then we have the error\n\ny(x) - P_{m-1}(x) = \\frac{y^{(m)}(c)}{m!}(x-x_1)(x-x_2)\\cdots(x-x_m)\n\nWhere c \\in (x_1,x_m). Note that we can make m as large as we want by adding more points, and due to the m! in the denominator, we can make our P_{m-1}(x) accurate incredibly quickly.\n\n\n\n\n\n\nExample\n\n\n\nInterpolate y(x) = \\sin(x) using interpolation points\n\nx_1 = 0\\; x_2 = \\frac{\\pi}{2} \\; x_3 = \\pi\n\nAnd compute the error.\nWe can see\n\ny_1 = 0 \\; y_2 = 1 \\; y_3 = 0\n\nWe therefore want a polynomial of degree two that interpolates the function.\n\nP_2(x) = y_1L_1 + y_2L_2 + y_3L_3\n\n\nP_2(x) = (0)\\frac{(x-\\pi /2)(x-\\pi)}{(0 - \\pi/2)(0-\\pi)} + (1)\\frac{(x-0)(x-\\pi)}{(\\pi /2 - 0)(\\pi /2 - \\pi)} + (0)\\frac{(x-0)(x- \\pi /2)}{(\\pi - 0) (\\pi - \\pi / 2)}\n\n\nP_2(x) = -x(x-\\pi)\\frac{4}{\\pi^2}\n\nThus we have a function that approximates \\sin(x) using a parabola. Now we need to compute the error.\n\n\\varepsilon = \\frac{f^{(m)}(c)}{m!}(x-x_1)\\cdots(x-x_m)\n\n\n\\varepsilon = \\frac{-\\cos(c)}{6}(x-0)\\left(x-\\frac{\\pi}{2}\\right)(x-\\pi)\n\nTaking the absolute value, and the maximum value of cosine, we get our error \n|\\varepsilon| \\leq \\frac{1}{6}|x\\left(x-\\frac{\\pi}{2}\\right)(x-\\pi)|\n\nWe can find the maximum error taking the derivative of \\varepsilon\n\n\\varepsilon^{\\prime} = 3x^2 + 3\\pi x + \\frac{\\pi^2}{2} = 0\n\nWe get\n\nx_{\\text{max}} = \\frac{-3\\pi \\pm \\pi \\sqrt{3}}{6}\n\n\n\nDefine the function\n\nh(x) = y(x) - P_{m-1}(x) - c(x-x_i)(x-x_2)\\cdots(x-x_m)\n\nThis has the property that for any i \\in 1,\\ldots,m\n\nh(x_i) = 0\n\nWe can choose a constant c such that for any x^* \\in (x_1,x_m)\n\nh(x^*) = 0\n\nThis gives us a function with m+1 zeros, specifically a polynomial of degree m+1. We can use Rolle’s theorem in order to get a function h^\\prime(x) which has m roots. We can repeat this process until h^{(m)}(x) has one zero. That being\n\nh^{(m)}(c) = 0 = y^{(m)}(c) - 0 - C(m!)\n\nThus\n\nC = \\frac{y^{(m)}(c)}{m!}\n\nThat directly leads to our error formula\n\ny(x) - P_{m-1}(x) = \\frac{y^{(m)}(c)}{m!}(x-x_1)(x-x_2)\\cdots(x-x_m)\n\nYou can choose specific x_1,x_2,x_3 in order to make the error as small as possible."
  },
  {
    "objectID": "qmd/matrix/unitfour.html#section-4.2",
    "href": "qmd/matrix/unitfour.html#section-4.2",
    "title": "Unit four",
    "section": "Section 4.2",
    "text": "Section 4.2"
  },
  {
    "objectID": "qmd/matrix/unitfour.html#section-4.4",
    "href": "qmd/matrix/unitfour.html#section-4.4",
    "title": "Unit four",
    "section": "Section 4.4",
    "text": "Section 4.4"
  },
  {
    "objectID": "qmd/matrix/unitfour.html#section-4.5",
    "href": "qmd/matrix/unitfour.html#section-4.5",
    "title": "Unit four",
    "section": "Section 4.5",
    "text": "Section 4.5\nSuppose we have a matrix A_{m,n}. This acts as a function mapping \\mathbb{R}^n to \\mathbb{R}^m.\n\n\n\n\n\n\nFact\n\n\n\nA matrix A maps \\text{RowSp}(A) bijectivly to \\text{ColSp}(A).\n\n\n\n\n\n\n\n\nProposition\n\n\n\nSuppose x_1,\\ldots,x_r is a basis of \\text{RowSp}(A). Then Ax_1,\\ldots,Ax_r is a basis of \\text{ColSp}(A).\n\n\n\n\n\n\n\n\nProof\n\n\n\nSuppose c_1Ax_1,\\ldots,c_rAx_r = 0. then\n\nA(c_1x_1,\\ldots,c_rx_r) = 0\n\nAll c_i must be zero as x_1,\\ldots,x_r is a basis. Thus Ax is independent.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nThe pseudoinverser of A, A^+ is basically\n\nA|_{\\text{RowSp}(A)} \\colon \\text{RowSp}(A) \\to \\text{ColSp}(A)\n\n\n\nNote that when we multiply A^+A, we get an n\\times n matrix. Lets look at what happens to each subspace under A^+A.\nThe Null space disapears, as A maps \\text{NullSp}(A) \\to 0. The row space is restored. Thus we have an interesting map\n\nA^+A|_{\\text{Row(A)}} = P_{\\text{Row}(A)}\n\nWe also have\n\nAA^A|_{\\text{Col(A)}} = P_{\\text{Col}(A)}\n\nSomewhat suprisingly, (A^+)^+ = A. Every subspace of A is the same under A^T and A^+.\n\n\n\n\n\n\nExample\n\n\n\nIf A_{(n\\times n)} is invertible, Then\n\nA^+ = A^{-1}.\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet\n\\begin{align*}\nA =\n\\begin{pmatrix}\n0 & 2\\\\\n0 & 0\n\\end{pmatrix}\n\\end{align*}\nThen\n\\begin{align*}\nA =\n\\begin{pmatrix}\n0 & 0\\\\\n\\frac{1}{2} & 0\n\\end{pmatrix}\n\\end{align*}\nNote that\n\\begin{align*}\nAA^+ =\n\\begin{pmatrix}\n1 & 0\\\\\n0 & 0\n\\end{pmatrix}= P_{\\text{Col}(A)}\n\\end{align*}\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet\n\\begin{align*}\nA =\n\\begin{pmatrix}\na & 0\\\\\n0 & 0\\\\\n0 & b\n\\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "qmd/matrix/unitfour.html",
    "href": "qmd/matrix/unitfour.html",
    "title": "Unit four",
    "section": "",
    "text": "Recall that\n\nv \\perp w \\iff  |v+w|^2 = |v|^2 + |w|^2\n\nWhich only occurs when\n\nv\\cdot w = 0\n\nAs\n\n|v+w|^2 = (v + w) \\cdot (v + w) = v \\cdot v + 2(v\\cdot w) + w\\cdot w\n\n\n\n\n\n\n\nDefinition 4.1.1\n\n\n\nTake V any subspace of \\mathbb{R}^n. Then\n\nV^\\perp = \\{x \\in \\mathbb{R}^n \\mid x \\cdot v = 0, \\forall v \\in V\\}\n\n\n\nBecause the dot product is linear, we know that V^\\perp is a subspace of \\mathbb{R}^n. For A (m\\times n), \\text{Null}(A) = \\text{RowSp}(A)^\\perp.\nThe dimension of V\\perp is equal to the dimension of n - dim V.\nWe can see this forming\n\\begin{align*}\nA = \\begin{pmatrix}\n& \\cdots & v_1^T\n\\end{pmatrix}\n\\end{align*}\nSuppose that V is a subspace of \\mathbb{R}^\\ell of dimension d.\nIf v_1,\\ldots,v_d are linearly independent in V, then they are a basis of V. If the vectors span V, they also form a basis.\nThis is because any LI subset of V can be enlarged into a basis. Thus the collection of d elements in V clearly forms a basis for V. Replace enlarge with shrink and you have a second proof.\n\n\n\n\n\n\nDefinition 4.1.1\n\n\n\nFor v,w subspaces of \\mathbb{R}^\\ell, V + W is defined to be \\text{Span}(V \\cup W).\n\n\nIf V \\cap W = \\{0\\},then the dimesnions of v + w is the dimesnion of v plus the dimension of w. The union of any two bases is a basis. Thus the set \\{v_1,w_e\\} Spans V + W\nSuppose c_1v_1 \\cdots c_d v_d + b_1 w _ e + \\cdots b_ew_e.\n\n\n\n\n\n\nDefinition 4.1.1\n\n\n\nWhen V \\cup W = 0. we then denote the sum V + W as a direct sum, and use a circle around the plus sign.\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nSay that the dimension v = d, and know that V^\\perp has dimension \\ell - d. Thus V \\intersect V^\\perp = \\varnothing.\n\n\nRemember that matrix theory doesn’t work over complex numbers.\nFor problem 14 on the homework, assume that v and w are subspaces of \\mathbb{R}^\\ell. Find the basis of V \\ cap W.\nForm A such that the column space is V + W, and the rank being the dimensoo. We can construct the Nullspace by using a basis. Thus A is a\nWe can take a basis of V \\+ W amd send it to a basis in order to get a result of dimension V W = the dimension of the Null space of A. The rank of V + w + V W = dim V plus dim W,=."
  },
  {
    "objectID": "qmd/matrix/unitfour.html#section-4.1",
    "href": "qmd/matrix/unitfour.html#section-4.1",
    "title": "Unit four",
    "section": "",
    "text": "Recall that\n\nv \\perp w \\iff  |v+w|^2 = |v|^2 + |w|^2\n\nWhich only occurs when\n\nv\\cdot w = 0\n\nAs\n\n|v+w|^2 = (v + w) \\cdot (v + w) = v \\cdot v + 2(v\\cdot w) + w\\cdot w\n\n\n\n\n\n\n\nDefinition 4.1.1\n\n\n\nTake V any subspace of \\mathbb{R}^n. Then\n\nV^\\perp = \\{x \\in \\mathbb{R}^n \\mid x \\cdot v = 0, \\forall v \\in V\\}\n\n\n\nBecause the dot product is linear, we know that V^\\perp is a subspace of \\mathbb{R}^n. For A (m\\times n), \\text{Null}(A) = \\text{RowSp}(A)^\\perp.\nThe dimension of V\\perp is equal to the dimension of n - dim V.\nWe can see this forming\n\\begin{align*}\nA = \\begin{pmatrix}\n& \\cdots & v_1^T\n\\end{pmatrix}\n\\end{align*}\nSuppose that V is a subspace of \\mathbb{R}^\\ell of dimension d.\nIf v_1,\\ldots,v_d are linearly independent in V, then they are a basis of V. If the vectors span V, they also form a basis.\nThis is because any LI subset of V can be enlarged into a basis. Thus the collection of d elements in V clearly forms a basis for V. Replace enlarge with shrink and you have a second proof.\n\n\n\n\n\n\nDefinition 4.1.1\n\n\n\nFor v,w subspaces of \\mathbb{R}^\\ell, V + W is defined to be \\text{Span}(V \\cup W).\n\n\nIf V \\cap W = \\{0\\},then the dimesnions of v + w is the dimesnion of v plus the dimension of w. The union of any two bases is a basis. Thus the set \\{v_1,w_e\\} Spans V + W\nSuppose c_1v_1 \\cdots c_d v_d + b_1 w _ e + \\cdots b_ew_e.\n\n\n\n\n\n\nDefinition 4.1.1\n\n\n\nWhen V \\cup W = 0. we then denote the sum V + W as a direct sum, and use a circle around the plus sign.\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nSay that the dimension v = d, and know that V^\\perp has dimension \\ell - d. Thus V \\intersect V^\\perp = \\varnothing.\n\n\nRemember that matrix theory doesn’t work over complex numbers.\nFor problem 14 on the homework, assume that v and w are subspaces of \\mathbb{R}^\\ell. Find the basis of V \\ cap W.\nForm A such that the column space is V + W, and the rank being the dimensoo. We can construct the Nullspace by using a basis. Thus A is a\nWe can take a basis of V \\+ W amd send it to a basis in order to get a result of dimension V W = the dimension of the Null space of A. The rank of V + w + V W = dim V plus dim W,=."
  },
  {
    "objectID": "qmd/matrix/unitfour.html#section-4.2-projections",
    "href": "qmd/matrix/unitfour.html#section-4.2-projections",
    "title": "Unit four",
    "section": "Section 4.2 Projections",
    "text": "Section 4.2 Projections\nFour subspaces for the rank 1 simple Matrix\n\nA = \\begin{pmatrix}\n1 & 0\\\\\n0 & 0  \n\\end{pmatrix}\n\nA three dimensional shadow can be visualized \nA = \\begin{pmatrix}\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0 & 0 & 0\n\\end{pmatrix}\n\nThe projection of b onto the line created by the vector a is\n\nP_ab = \\mu a\n\nFor some \\mu. Note that because the perpindicular lines are zero.\n\na \\cdot P_ab = a \\cdot \\mu a\n\nTherefore\n\nP_ab = \\frac{a \\cdot b}{a \\cdot a}a = \\frac{a a^T b}{a^Ta}\n\n\nP_a = \\frac{aa^T}{a^Ta}\n\nLet a = (1,2)\n\nP_a = \\frac{1}{5}\\{\\}\n\nFor homework problems 5,7, if a_1 \\perp a_2, then P_{a_1} + P_{a_2} is equal to the projection of the span. In \\mathbb{R}^3, if you have three orthogonal vectors, then the three projections are equal to the identity matrix."
  },
  {
    "objectID": "qmd/geometry/geometry.html#induction-duction-what-is-your-function",
    "href": "qmd/geometry/geometry.html#induction-duction-what-is-your-function",
    "title": "Geometry",
    "section": "Induction-duction what is your function",
    "text": "Induction-duction what is your function\nWe arrive at the following identites through less than rigourous means (Fishman wrote them on the board)\n\n1 + 2 + 3 + \\cdots + n = \\frac{n}{2}(n+1)\n\n\n1^2 + 2^2 + 3^2 + \\cdots n^2 = \\frac{n}{6}(n+1)(n+2)\n\n\n1^3 + 2^3 + 3^3 + \\cdots n^3 = \\left(\\frac{n}{2}(n+1)\\right)^2\n\nWe prove these using induction. But how do we come up with the formulas?\nThe following telescopic series\n\n\\sum^n_{k=1} k^2 - (k-1)^2 = n^2\n\nNote\n\n\\sum^n_{k=1} k^2 - (k-1)^2 = 2 \\sum^n_{k=1} k - n = n^2\n\nThus\n\n\\sum^n_{k=1} k = \\frac{n}{2}(n+1)\n\nWe can repeat the same thing to get the next identity.\n\n\\sum^n_{k=1} k^3 - (k-1)^3 = n^3\n\n\n\\sum^n_{k=1} k^3 - (k^3 - 3k^2 + 3k - 1)\n\n\n\\sum^n_{k=1} 3k^2 - 3k + 1 = 3\\sum^n_{k=1} k^2 - 3\\sum^n_{k=1} k + n = n^3\n\n\n3\\sum^n_{k=1} k^2 - 3\\sum^n_{k=1} k = n^3 - n\n\n\n3\\sum^n_{k=1} k^2 - 3\\frac{n}{2}(n+1) = n^3 - n\n\n\n\\sum^n_{k=1} k^2 = \\frac{n}{6}(n+1)(n+2)\n\nConsider the interval [a,b]. We say that P_n is a partition of [a,b] if\n\nP_n = \\{x_0,x_1,x_2,\\ldots,x_n\\}\n\nWhere x_0 = a, and x_n = b.\nWe say that P_m is a refinement of P_n if\n\nP_n \\subset P_m\n\nWe also want that if P_1 is a subset of P_2, is a subset of P_3, ect.\nThen the maximum distance between points as n \\to \\infty goes to 0."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html#subgroups-generated-by-subsets",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html#subgroups-generated-by-subsets",
    "title": "Homomorphisms and Isomorphisms",
    "section": "2.4 Subgroups generated by subsets",
    "text": "2.4 Subgroups generated by subsets\nCyclic groups generated by x are the smallest subgroups containing x.\n\n\n\n\n\n\nProposition\n\n\n\nFor any nonempty collection of subgroups of G, the intersection of all of them is also a subgroup of G.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf A is any subset of G, then\n\n\\left&lt;A\\right&gt; = \\bigcap \\limits_{\\substack{H\\leq G\\\\ A \\subseteq H}} H\n\nI.e, the intersection of all subgroups containing A. Thus \\left&lt;A\\right&gt; is the minimal subgroup of G containing A.\n\n\nAnother way to define \\left&lt;A\\right&gt; is by using generators. Say\n\n\\overline{A} = \\left\\{ a_1^{\\varepsilon_1},a_2^{\\varepsilon_2},\\cdots,a_n^{\\varepsilon_n} \\mid n + \\mathbb{Z},\\:n\\geq0,\\:a_1\\in A,\\: \\varepsilon_i = \\pm 1\\right\\}\n\nThus \\overline{A} is the set of finite products of elements of A and inverses of these elements.\n\n\n\n\n\n\nProposition\n\n\n\nOur definitions are equal. Symbollically \n\\overline{A} = \\left&lt; A \\right&gt;\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nFirst we prove that \\overline{A} is a group. Then\n\\overline{A} \\not= \\varnothing because A always has the identity.\nif a,b \\in A, then\n\\begin{align*}\na &= a_1^{\\varepsilon_1}a_2^{\\varepsilon_2}\\cdots a_n^{\\varepsilon_n}\\\\\nb &= b_1^{\\delta_1}b_2^{\\delta_2}\\cdots a_n^{\\delta_n}\n\\end{align*}\nthen\n\na(b^{-1}) = a_1^{\\varepsilon_1}a_2^{\\varepsilon_2}\\cdots a_n^{\\varepsilon_n}a_n^{\\delta_n}\\cdots b_2^{\\delta_2}b_1^{\\delta_1} \\in A\n\nThus\n\n\\overline{A} \\leq G\n\nSo \\left&lt;A\\right&gt; \\subseteq \\overline{A}.\nNow we must show \\overline{A} \\subseteq \\left&lt;A\\right&gt;. This is true because \\left&lt;A\\right&gt; is closed under multiplication and inverses.\n\n\n\n\n\n\n\n\nExample\n\n\n\nThe subgroup\n\n\\left&lt;(12),(13)(24)\\right&gt; \\leq S_4\n\nFun fact, (it’s not) the subset is isomorphic to D_8\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the kernal of \\varphi is the set\n\n\\ker\\varphi = \\{g \\in G \\mid \\varphi(g) = e_H\\}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the image of \\varphi is the set\n\n\\text{im} \\varphi = \\{\\varphi(x) \\mid x \\in G\\}\n\n\n\n\n\n\n\n\n\nProposition\n\n\n\nIf H,G are groups, \\varphi \\colon G \\to H is a homomorphism, then the \\ker \\varphi \\leq G and \\text{im} \\leq H.\n\n\n\n\n\n\n\n\nProof\n\n\n\nSince e_G is such that \\varphi(e_G) = e_H, we know \\ker \\varphi \\not = \\varnothing. If x,y are in the \\ker \\varphi, then xy^{-1} is in the kernal, thus \\ker \\phi is a subgroup of G.\nNow take the image of \\varphi. Note\n\n\\varphi(e_G) = e_H \\in \\text{im} \\varphi \\implies \\text{im} \\varphi \\not = \\varnothing\n\nGiven x,y \\in \\text{im} \\varphi, we know that xy^{-1} is in \\text{im} \\varphi. Thus \\text{im} \\varphi \\leq H."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html#quotient-groups",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html#quotient-groups",
    "title": "Homomorphisms and Isomorphisms",
    "section": "Quotient groups",
    "text": "Quotient groups\nAnother way to get a smaller subgroup from a group G is by forming a quotient group.\nSubgroups of H \\leq G are injective onto G.\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\varphi \\colon G \\to H be a homomorphism.\nFibers are sets of elements in G that map to single points in H.\nDraw a box and a line???"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/quotient-group.html",
    "href": "qmd/abstract/intro-to-groups/quotient-group.html",
    "title": "Quotient groups",
    "section": "",
    "text": "Definition\n\n\n\nLet \\varphi \\colon G \\to H be a surjective homomorphism with \\ker k. The quotient group G/K is the group whose elements are the fibers of \\varphi with group operation inherited from H.\n\n\nThis definition requires knowing \\varphi explictly. You can however define the group operation on fibers in terms of representatives.\n\n\n\n\n\n\nProposition\n\n\n\nLet \\varphi \\colon G \\to H be a homomorphism with \\ker k. Let X \\in G/K be the fiber above a \\in H. X = \\varphi^{-1}(a). Then for any u \\in X,\n\nX = \\{uk\\mid k \\in K\\}\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nLet u \\in X, then \\varphi(u) = a. Let\n\nuK = \\{uk \\mid k \\in K\\}\n\nWe want to show that X is equal to uK. We will first show that uK is a subset of X. For k \\in K \n\\varphi(uk) = \\varphi(u)\\varphi(k) = \\varphi(u) = a\n\nThus uK \\subseteq X. Now to show that X \\subseteq uK, let g \\in X and k = u^{-1}g. \n\\varphi(k) = \\varphi(u^{-1})\\varphi(g) = a^{-1}a = e_H\n\nThus k \\in \\ker \\varphi since k = u^{-1}g. Thus X \\subseteq uK\n\n\nThus we can write any elements of the quoitent group as the set uk for all k \\in K.\n\n\n\n\n\n\nDefinition\n\n\n\nFor any N \\leq G and g \\in G,\n\ngN = \\{gn\\mid n \\in N\\}\n\nThis is a (left) coset of N in G.\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nLet \\varphi \\colon G \\to H homomorphism with a kernal K. The set of cosets of K in G with operation uK \\star vK = (uv)K forms a group.\n\n\n\n\n\n\n\n\nProof\n\n\n\nLet X,Y \\in G/K, and Z = XY \\in G/K. Then for some a,b \\in H, \nX = \\varphi^{-1}(a)\\: Y = \\varphi^{-1}(b)\n\nThis implies Z = \\varphi^{-1}(ab). Let u,v be representations of X,Y respectivly. We want to show that uv \\in Z. Which is only true If\n\n\\varphi(uv) \\in ab \\leftrightarrow \\varphi(u)\\varphi(v) = ab\n\nWhich is true! Thus by our previous proposition Z = uvK.\n\n\nYou cannot define G/N for any N \\leq G.\n\n\n\n\n\n\nTheorem\n\n\n\nYou cannot define G/N for any N \\leq G.\n\n\n\n\n\n\n\n\nProof\n\n\n\nLet \\varphi \\colon G \\to H be a homomorphism with Kernal K. Then\n\ngKg^{-1} \\subseteq K \\; \\forall g \\in G\n\n\\varphi(gkg^{-1}) = e\n\n\nIf we have a subgroup N of $G such that gNg^{-1} \\subseteq N for all g \\in G, then multiplication in G/N is well defined.\n\n\n\n\n\n\nTheorem\n\n\n\nG/N \\times G/N \\rightarrow G/N\n (xN, xG)\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nIf x_1N = x_2N, y_1N=y_2N then x_1^{-1}x_2 \\in N and y_1^{-1}y_2 \\in N"
  },
  {
    "objectID": "qmd/pde/introduction copy.html#wave-function",
    "href": "qmd/pde/introduction copy.html#wave-function",
    "title": "PDE",
    "section": "Wave function",
    "text": "Wave function\nThe general solution for a wave equation is in the form\n\nu(x,t) = \\frac{f(x+ct)+f(x-ct)}{2} + \\frac{1}{2c}\\int_{x-ct}^{x+ct}g(s)ds\n\nWhen given a wave function in the form\n\\begin{cases}\n      u_{tt} = c^2u_{xx}\\\\\n      u(x,0) = f(x) \\\\\n      u_t(x,0) = g(x)\\\\\n      u(0,t) = 0\n\\end{cases}\nWe can invent a function f(x) such that f(x) is odd, forcing the solution to be zero. For example\n\\begin{cases}\n      u_{tt} = c^2u_{xx}\\\\\n      u(x,0) = x^2\\\\\n      u_t(x,0) = 0\\\\\n      u(0,t) = 0\n\\end{cases}\nClearly in this case the function x^2 is even. Because we are restricted to the positive realm, we can write f(x) = x|x|, which perfectly models x^2 when x&gt;0, but is an odd function. Thus we can easily find the solution.\n\n\n\n\n\n\nExample\n\n\n\nGiven the following, solve for x \\geq 0, t &gt; 0\n\\begin{cases}\n      u_{tt} = c^2u_{xx}\\\\\n      u(x,0) = e^{-x}\\\\\n      u_t(x,0) = \\sin(x)\\\\\n      u(0,t) = 0\n\\end{cases}\nNote that \\sin(x) is already odd, and we can convert e^{-x} to be odd using \\frac{x}{|x|}e^{-|x|}"
  },
  {
    "objectID": "qmd/numanal/fundementals.html#error",
    "href": "qmd/numanal/fundementals.html#error",
    "title": "Fundementals",
    "section": "Error",
    "text": "Error\nSuppose that we have an error\n\n\\varepsilon = \\frac{h^3}{4}f^{(4)}(c_1) + \\frac{h^3}{8}f^{\\prime\\prime}(c_2)\n\nWe have a simplified expression\n\n\\varepsilon = h^3(\\frac{1}{4}+\\frac{1}{8})f^{\\prime\\prime}(c)\n\nFor some c."
  },
  {
    "objectID": "qmd/numanal/fundementals.html#multi-panel-integration-formula",
    "href": "qmd/numanal/fundementals.html#multi-panel-integration-formula",
    "title": "Fundementals",
    "section": "Multi-panel integration formula",
    "text": "Multi-panel integration formula\n\n\\int\\limits^b_a f(s) ds = \\int\\limits^{a+h}_a f(s) ds + \\int\\limits^{a+2h}_{a+h} f(s) ds \\cdots \\int\\limits^{b}_{b-h} f(s) ds\n\nUsing the formula from last class, this is equal too\n\n\\int\\limits_a^{a+h}f(s)ds = \\frac{h}{2}(f(a)+f(a+h))-\\frac{h^3}{12}\nf^{\\prime\\prime}(c_1)\n\nExpanding our initial integral, we can see it’s telescoping. This gives\n\n\\int\\limits^b_a f(s) ds = \\frac{h}{2}\\left(f(a)+2f(a+h)\\cdots2f(b-h) + f(b)\\right) - \\varepsilon\n\n\n\\varepsilon = \\frac{h^3}{12}(f^{\\prime\\prime}(c_1)\\cdots f^{\\prime\\prime}(c_m))\n\nUsing the generalized intermediate value theorem, we can simplify\n\n\\varepsilon= \\frac{h^3}{12}mf^{\\prime\\prime}(c) = \\frac{(a-b)h^2}{12}f^{\\prime\\prime}(c)\n\nWhich gives us an error for the trapezoidal formula.\nfor what m is the error less than 10^{-6}/"
  },
  {
    "objectID": "qmd/numanal/fundementals.html#simpson-integration",
    "href": "qmd/numanal/fundementals.html#simpson-integration",
    "title": "Fundementals",
    "section": "Simpson integration",
    "text": "Simpson integration\n\n\\mathrlap{\\int\\limits_x^{x+2h}}\\quad\\quad f(s) \\,ds = \\frac{h^3}{3}(f(x) + 4f(x+h) + f(x+2h)) - \\frac{h^5}{90}f^{(4)}(c)"
  },
  {
    "objectID": "qmd/matrix/unitfive.html",
    "href": "qmd/matrix/unitfive.html",
    "title": "Unit four",
    "section": "",
    "text": "Suppose we have a matrix A_{m,n}. This acts as a function mapping \\mathbb{R}^n to \\mathbb{R}^m.\n\n\n\n\n\n\nFact\n\n\n\nA matrix A maps \\text{RowSp}(A) bijectivly to \\text{ColSp}(A).\n\n\n\n\n\n\n\n\nProposition\n\n\n\nSuppose x_1,\\ldots,x_r is a basis of \\text{RowSp}(A). Then Ax_1,\\ldots,Ax_r is a basis of \\text{ColSp}(A).\n\n\n\n\n\n\n\n\nProof\n\n\n\nSuppose c_1Ax_1,\\ldots,c_rAx_r = 0. then\n\nA(c_1x_1,\\ldots,c_rx_r) = 0\n\nAll c_i must be zero as x_1,\\ldots,x_r is a basis. Thus Ax is independent.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nThe pseudoinverser of A, A^+ is basically\n\nA|_{\\text{RowSp}(A)} \\colon \\text{RowSp}(A) \\to \\text{ColSp}(A)\n\n\n\nNote that when we multiply A^+A, we get an n\\times n matrix. Lets look at what happens to each subspace under A^+A.\nThe Null space disapears, as A maps \\text{NullSp}(A) \\to 0. The row space is restored. Thus we have an interesting map\n\nA^+A|_{\\text{Row(A)}} = P_{\\text{Row}(A)}\n\nWe also have\n\nAA^A|_{\\text{Col(A)}} = P_{\\text{Col}(A)}\n\nSomewhat suprisingly, (A^+)^+ = A. Every subspace of A is the same under A^T and A^+.\n\n\n\n\n\n\nExample\n\n\n\nIf A_{(n\\times n)} is invertible, Then\n\nA^+ = A^{-1}.\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet\n\\begin{align*}\nA =\n\\begin{pmatrix}\n0 & 2\\\\\n0 & 0\n\\end{pmatrix}\n\\end{align*}\nThen\n\\begin{align*}\nA =\n\\begin{pmatrix}\n0 & 0\\\\\n\\frac{1}{2} & 0\n\\end{pmatrix}\n\\end{align*}\nNote that\n\\begin{align*}\nAA^+ =\n\\begin{pmatrix}\n1 & 0\\\\\n0 & 0\n\\end{pmatrix}= P_{\\text{Col}(A)}\n\\end{align*}\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet\n\\begin{align*}\nA =\n\\begin{pmatrix}\na & 0\\\\\n0 & 0\\\\\n0 & b\n\\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "qmd/matrix/unitfive.html#section-4.5",
    "href": "qmd/matrix/unitfive.html#section-4.5",
    "title": "Unit four",
    "section": "",
    "text": "Suppose we have a matrix A_{m,n}. This acts as a function mapping \\mathbb{R}^n to \\mathbb{R}^m.\n\n\n\n\n\n\nFact\n\n\n\nA matrix A maps \\text{RowSp}(A) bijectivly to \\text{ColSp}(A).\n\n\n\n\n\n\n\n\nProposition\n\n\n\nSuppose x_1,\\ldots,x_r is a basis of \\text{RowSp}(A). Then Ax_1,\\ldots,Ax_r is a basis of \\text{ColSp}(A).\n\n\n\n\n\n\n\n\nProof\n\n\n\nSuppose c_1Ax_1,\\ldots,c_rAx_r = 0. then\n\nA(c_1x_1,\\ldots,c_rx_r) = 0\n\nAll c_i must be zero as x_1,\\ldots,x_r is a basis. Thus Ax is independent.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nThe pseudoinverser of A, A^+ is basically\n\nA|_{\\text{RowSp}(A)} \\colon \\text{RowSp}(A) \\to \\text{ColSp}(A)\n\n\n\nNote that when we multiply A^+A, we get an n\\times n matrix. Lets look at what happens to each subspace under A^+A.\nThe Null space disapears, as A maps \\text{NullSp}(A) \\to 0. The row space is restored. Thus we have an interesting map\n\nA^+A|_{\\text{Row(A)}} = P_{\\text{Row}(A)}\n\nWe also have\n\nAA^A|_{\\text{Col(A)}} = P_{\\text{Col}(A)}\n\nSomewhat suprisingly, (A^+)^+ = A. Every subspace of A is the same under A^T and A^+.\n\n\n\n\n\n\nExample\n\n\n\nIf A_{(n\\times n)} is invertible, Then\n\nA^+ = A^{-1}.\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet\n\\begin{align*}\nA =\n\\begin{pmatrix}\n0 & 2\\\\\n0 & 0\n\\end{pmatrix}\n\\end{align*}\nThen\n\\begin{align*}\nA =\n\\begin{pmatrix}\n0 & 0\\\\\n\\frac{1}{2} & 0\n\\end{pmatrix}\n\\end{align*}\nNote that\n\\begin{align*}\nAA^+ =\n\\begin{pmatrix}\n1 & 0\\\\\n0 & 0\n\\end{pmatrix}= P_{\\text{Col}(A)}\n\\end{align*}\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet\n\\begin{align*}\nA =\n\\begin{pmatrix}\na & 0\\\\\n0 & 0\\\\\n0 & b\n\\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "qmd/matrix/unitfive.html#section-5.1",
    "href": "qmd/matrix/unitfive.html#section-5.1",
    "title": "Unit four",
    "section": "Section 5.1",
    "text": "Section 5.1\nPermutations matrices are matrices with the same columns as I. For an n\\times n permutation matrix, there exists n! permutation matrices.\nHalf of these matrices are even. Meaning we can get to P via an even number of row exchanges on I. Half are odd.\n\n\n\n\n\n\nDefinition\n\n\n\nWe will define the operation \\text{Prod}(A\\colon P) as the product of all entries of A matching a non zero entry of P.\n\n\nThus we define the determinate \\det A as\n\n\\det A = \\sum\\limits_{\\text{Even perms }P} \\text{Prod}(A\\colon P) - \\sum\\limits_{\\text{Odd perms }P} \\text{Prod}(A\\colon P)\n\nThis is actually just the cofactor expansion formula wrote in a different way. If you multiply a single row of A by a constant \\mu, then your determinate gets multiplied by \\mu. If you exchange two rows of A, multiply the determinate by negative 1.\nAnd if you add a row to another, the determinate has no change. The determinate of A^T is equal to the determinate of A. This is all the same for rows and columnss.\nIf A is upper triangular, then \\text{Prod}(A\\colon P) = 0 if P \\not = I. Thus \\det A = \\text{Prod}(A \\colon I) = \\Pi of the diagonal entries.\nThe determinate of A is equal to\n\n\\det A = (-1)^{\\# \\text{ of row exhchanges}} \\cdot \\text{Product of pivots}\n\n\n\n\n\n\n\nCorollary\n\n\n\n\n\\det A \\not = 0\n\nIf and only if A is invertible\n\n\n\n\n\n\n\n\nTheorem\n\n\n\n\n\\det ZA = \\det Z \\det A\n\n\n\nThus the determinate of ZA is simply the product of the operations of Z on A."
  },
  {
    "objectID": "qmd/abstract/Problems.html",
    "href": "qmd/abstract/Problems.html",
    "title": "Problems",
    "section": "",
    "text": "Problem 1\nIs the function f \\colon \\mathbb{N} \\to \\mathbb{N}, f(x) = x + 1 surjective?\nYes, let n = x + 1.\n\n\nProblem 2\nLet G be a finite group such that the order of G is equal to n &gt; 2. Prove G cannot have a subgroup H of order n - 1.\nThis can proved using Lagranges theorem. Towards a contradiction, assume there exists a subgroup H or G with order n-1. By lagranges theorem, the order of H must divide the order of G. This means\n\n\\exists n \\in \\mathbb{N}, n &gt; 2, \\; n - 1 \\mid n\n\nWhich is a contradiction.\n\n\nProblem 3\nLet n \\geq 3. Prove D_{2n} has a normal subgroup \\left&lt;r\\right&gt;.\n\n\nProblem 5\nLet [42] \\in \\mathbb{Z}/180\\mathbb{Z}. Find |[42]|.\nBecause \\gcd(42,180) = 6, and |x| = \\frac{n}{\\gcd(x,n)}. Thus |[42]| = 30.\n\n\nProblem 10\nLet GL_n(R) be the group of (n\\times n) matrices with non-zero determinates. Let SL_n(R) be the group of (n \\times n) matrices with determinate 1. Prove that SL_N(R) \\leq GL_n(R)\nNote that SL_n(R) is a subset of GL_n(R), because for every A \\in SL_n(R), \\det(A) = 1 \\not = 0, thus A \\in GL_n(R). We know SL_n(R) is not empty as the (n \\times n) identity matrix has determinate 1.\nLet A,B \\in SL_n(R). Note that AB^{-1} has determinate 1. through algebra\n\n\\det(AB^{-1}) = \\det(A)\\det(B^{-1}) = 1 \\not = 0\n\nThus AB^{-1} \\in SL_n(R). Thus by subgroup criterian, we have shown SL_n(R) \\leq GL_n(R).\nNote that SL_n \\trianglelefteq GL_n(R). To see this, take L \\in Ln(R) with \\det(L) = x. Thus for any \\mathcal{o} \\in SL_n(R),\n\n\n\\det(LoL^{-1}) = \\det(L)\\det(o)\\det(L^{-1}) = 1.\n\n\n\nProblem 11\nGiven cycles\n\n\\sigma = (1523)(47)\n\n\n\\tau = (183462)((57))\n\nWe compute\n\n\\sigma\\tau = (18)(2543657)\n\nAnd the orders of \\sigma and \\tau as the lcm of the cycle lengths.\n\n\nProblem 12\nLet G be a group with a,b,c \\in G and a unique x such that axb = c.\nWe can prove x exists, because a^{-1},b^{-1} \\in G, and thus\n\nx = a^{-1}cb^{-1}.\n\nSuppose there exists two solutions x_1,x_2.\n\n\nProblem 13\nLet A be an abelian group, and B be a subgroup of A. Then A/B is also abelian.\nLet a_n \\in A, b_n \\in B, and n \\in \\mathbb{N}. Because were constructing a set A/B, we know that\n\naBa^{-1} \\subseteq B\n\nFor any b \\in B. Thus B can be though of as \\ker(\\phi) where\n\n\\phi \\colon A \\to A/B\n\nThus A/B is the group containing the fibers of \\phi. The fibers of \\phi will be denoted with x_n \\in A/B.\nEach x_n is related to a single a_n, so\n\na_1 \\star a_2 = a_2 \\star a_1 \\implies x_1 \\star x_2 = x_2 \\star x_1\n\n\n\nProblem 15\nProve the identity element e of a group is unique.\nTowards a contradiction, let G be a group with two identity elements e_1, and e_2.\n\n\nProblem 18\nLet G be a group with identity e. Suppose that the order of G is equal to n. Prove x^n = e."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/axioms.html#groups",
    "href": "qmd/abstract/intro-to-groups/axioms.html#groups",
    "title": "Definitions and basic properties",
    "section": "Groups",
    "text": "Groups\n\n\n\n\n\n\nDefinition\n\n\n\nA group is an ordered pair (G,\\star) where G is a set and \\star is an associative binary relation on that set, such that\n\nThere exists an element e in G known as the identity such that for all a \\in G,\n\n\na \\star e = e \\star a = a\n\n\nFor each a \\in G, there exists an element a^{-1} \\in G called the inverse of a, such that\n\n\na \\star a^{-1} = a^{-1} \\star a = e\n\n\n\nWe call a group abelian if the binary operation \\star is commutative on G.\n\n\n\n\n\n\nExample\n\n\n\nIs the ordered pair (\\mathbb{Z},+) a group?\nWe know the addition operator is associative, so we just need to prove that there exists an identity element in G, and an inverse element for each a \\in \\mathbb{Z}.\n\nThe element 0 is the identity of (\\mathbb{Z},+), as for every a \\in \\mathbb{Z}\n\n\na + 0 = 0 + a = a\n\n\nFor each a \\in G, a^{-1} = -a, because\n\n\na + (-a) = (-a) + a = 0\n\nTherefore (\\mathbb{Z},+) is a group.\n\n\nGroups have the following properties\n\n\n\n\n\n\nProposition 1.1\n\n\n\nGiven a group G under an binary operation \\star, the following hold\n(1) The identity element e of G is unique.\n(2) For each a \\in G, there exist a unique a^{-1}.\n(3) (a^{-1})^{-1} = a for all a \\in G.\n(4) (a \\star b)^{-1} = b^{-1} \\star a^{-1} for all a,b \\in G.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(1) Suppose there exists two identity elements e_1 and e_2. By the definition of an identity element, e_1 \\star e_2 = e_1 and e_1 \\star e_2 = e_2. Thus e_1 = e_2, so the identity is unique.\n(2) Suppose b and c are both inverses of a and let e be the identity of G. By the definition of an inverse element a \\star b = e and c \\star a = e. Note the following relation\n\nc = c \\star e = c \\star (a \\star b) = (c \\star a) \\star b = e \\star b = b\n\n(3) Rather straightforwardly a \\star a^{-1} = a^{-1} \\star a = e. So by the definition of an inverse element, (a^{-1})^{-1} = a.\n(4) Let c = (a \\star b)^{-1}. Therefore (a \\star b) \\star c = e. Using algebra\n\\begin{align*}\n\na^{-1} \\star (a \\star b) \\star c &= a^{-1} \\star e\\\\\n(a^{-1} \\star a) \\star (b \\star c) &= a^{-1}\\\\\n(b \\star c) &= a^{-1}\\\\\nc &= b^{-1} \\star a^{-1}\n\\end{align*}\n\n\n\nNext\n\n\n\n\n\n\nProposition\n\n\n\nLet G be a group under an binary operation \\star, and a,b \\in G. The equations a \\star x = b and y \\star a = b have unique solutions for all x,y \\in G. In particular\n(1) If a \\star u = a \\star v then u = v\n(2) If u \\star b = v \\star b then u = v\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(1) The existence of a solution to a \\star x = b is given by x = a^{-1} \\star b. This is unique as proved in the previous proposition.\n(2) The proof is nearly identical for (y \\star a) = b, where y = b \\star a^{-1}."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/axioms.html#binary-operations",
    "href": "qmd/abstract/intro-to-groups/axioms.html#binary-operations",
    "title": "Definitions and basic properties",
    "section": "Binary operations",
    "text": "Binary operations\nWe start by examining binary operations\n\n\n\n\n\n\nDefinition\n\n\n\nA binary operation \\star on a set G is a function \\star \\colon G \\to G.\n\n\nWe commonly denote \\star(a,b) as a \\star b. Binary operations may have the following two properties\n\nA binary relation is associative on a set G if for all a,b \\in G\n\n\n(a \\star b) \\star c = a \\star (b \\star c)\n\n\nA binary operation is commutative on a set G if for all a,b \\in G,\n\n\na \\star b = b \\star a\n\nAddition is an example of an associative and commutative binary operation on \\mathbb{Z}. Multiplication is also an associative and commutative binary operation, whereas something like subtraction is neither associative nor commutative."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/definitions.html",
    "href": "qmd/abstract/intro-to-groups/definitions.html",
    "title": "Definitions and basic properties",
    "section": "",
    "text": "This section examines the definitions and important properties of groups."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/definitions.html#binary-operations",
    "href": "qmd/abstract/intro-to-groups/definitions.html#binary-operations",
    "title": "Definitions and basic properties",
    "section": "Binary operations",
    "text": "Binary operations\nWe start by examining binary operations\n\n\n\n\n\n\nDefinition\n\n\n\nA binary operation \\star on a set G is a function \\star \\colon G \\times G \\to G.\n\n\nWe commonly denote \\star(a,b) as a \\star b. Binary operations may have the following two properties\n\nA binary relation is associative on a set G if for all a,b \\in G\n\n\n(a \\star b) \\star c = a \\star (b \\star c)\n\n\nA binary operation is commutative on a set G if for all a,b{\\;\\in\\;}G,\n\n\na \\star b = b \\star a\n\nAddition is an example of an associative and commutative binary operation on \\mathbb{Z}. Multiplication is also an associative and commutative binary operation, whereas something like subtraction is neither associative nor commutative."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/definitions.html#groups",
    "href": "qmd/abstract/intro-to-groups/definitions.html#groups",
    "title": "Definitions and basic properties",
    "section": "Groups",
    "text": "Groups\n\n\n\n\n\n\nDefinition\n\n\n\nA group is an ordered pair (G,\\star) where G is a set and \\star is an associative binary relation on that set, such that\n\nThere exists an element e in G known as the identity such that for all a \\in G,\n\n\na \\star e = e \\star a = a\n\n\nFor each a \\in G, there exists an element a^{-1} \\in G called the inverse of a, such that\n\n\na \\star a^{-1} = a^{-1} \\star a = e\n\n\n\nWe call a group abelian if the binary operation \\star is commutative on G.\n\n\n\n\n\n\nExample\n\n\n\nIs the ordered pair (\\mathbb{Z},+) a group?\nWe know the addition operator is associative, so we just need to prove that there exists an identity element in G, and an inverse element for each a \\in \\mathbb{Z}.\n\nThe element 0 is the identity of (\\mathbb{Z},+), as for every a \\in \\mathbb{Z}\n\n\na + 0 = 0 + a = a\n\n\nFor each a \\in G, a^{-1} = -a, because\n\n\na + (-a) = (-a) + a = 0\n\nTherefore (\\mathbb{Z},+) is a group.\n\n\nGroups have the following properties\n\n\n\n\n\n\nProposition 1.1.1\n\n\n\nGiven a group G under an binary operation \\star, the following hold\n(1) The identity element e of G is unique.\n(2) For each a \\in G, there exist a unique a^{-1}.\n(3) (a^{-1})^{-1} = a for all a \\in G.\n(4) (a \\star b)^{-1} = b^{-1} \\star a^{-1} for all a,b \\in G.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(1) Suppose there exists two identity elements e_1 and e_2. By the definition of an identity element, e_1 \\star e_2 = e_1 and e_1 \\star e_2 = e_2. Thus e_1 = e_2, so the identity is unique.\n(2) Suppose b and c are both inverses of a and let e be the identity of G. By the definition of an inverse element a \\star b = e and c \\star a = e. Note the following relation\n\nc = c \\star e = c \\star (a \\star b) = (c \\star a) \\star b = e \\star b = b\n\n(3) Rather straightforwardly a \\star a^{-1} = a^{-1} \\star a = e. So by the definition of an inverse element, (a^{-1})^{-1} = a.\n(4) Let c = (a \\star b)^{-1}. Therefore (a \\star b) \\star c = e. Using algebra\n\\begin{align*}\na^{-1} \\star (a \\star b) \\star c &= a^{-1} \\star e\\\\\n(a^{-1} \\star a) \\star (b \\star c) &= a^{-1}\\\\\n(b \\star c) &= a^{-1}\\\\\nc &= b^{-1} \\star a^{-1}\n\\end{align*}\n\n\n\nAdditionally\n\n\n\n\n\n\nProposition 1.1.2\n\n\n\nLet G be a group under an binary operation \\star, and a,b \\in G. The equations a \\star x = b and y \\star a = b have unique solutions for all x,y \\in G. In particular\n(1) If a \\star u = a \\star v then u = v\n(2) If u \\star b = v \\star b then u = v\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(1) The existence of a solution to a \\star x = b is given by x = a^{-1} \\star b. This is unique as proved in the previous proposition.\n(2) The proof is nearly identical for (y \\star a) = b, where y = b \\star a^{-1}.\n\n\n\nBecause it is often tedious to write the full notation of a group, it is often abbreviated. For example, the group (G,\\star) is commonly wrote as “the group G” where the operation is implied.\nAdditionally, we often write ab as an abbreviation for a \\star b. Because group operations are associative, we write a^n to abbreviate a\\star \\cdots \\star a (n times)."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/definitions.html#order",
    "href": "qmd/abstract/intro-to-groups/definitions.html#order",
    "title": "Definitions and basic properties",
    "section": "Order",
    "text": "Order\nAs always, we start with a definition.\n\n\n\n\n\n\nDefinition\n\n\n\nFor a group G and x \\in G, the order of x is the smallest positive integer n such that x \\star x \\star \\cdots \\star x (n times) is equal to the identity element e.\n\n\nNote that we notate x \\star x \\star x \\cdots as x^n. We also denote the order of x as |x|. This is an abuse of notation with both cardinailty and absolute value, so it is often neccessary to clarify the meaning of the bars.\nFor any group G, it’s clear that |e| = 1. If x^n \\not = e for any n, we say that x has order infinity. For example, given the group (\\mathbb{Z}/15\\mathbb{Z},\\times), the element 2 has an order of 4.\n\n2 = 2,\\quad 2^2 = 4,\\quad 2^3 = 8,\\quad 2^4 = 16 = 1 = e"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/symmetric-groups.html",
    "href": "qmd/abstract/intro-to-groups/symmetric-groups.html",
    "title": "Symmetric Groups",
    "section": "",
    "text": "Symmetric groups are groups based on symmetries of certain mathematical objects and structures."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/symmetric-groups.html#dihedral-groups",
    "href": "qmd/abstract/intro-to-groups/symmetric-groups.html#dihedral-groups",
    "title": "Symmetric Groups",
    "section": "Dihedral groups",
    "text": "Dihedral groups\nAn important example of a group comes from symmetries of geometric objects, most notably, polygons.\nLets take a hexagon, and apply an operation s, which reflects it along a line of symmetry. We could also apply an operation r, which rotates the hexagon by \\pi / 3 radians. These operations swap the location of the vertices of the hexagon.\n\n\n\n\n\n\n(Insert picture of a hexagon being rotated and symetry)\n\n\n\n\n\nIf we represent the orignal labelling of the vertices as\n\n\\{1,2,3,4,5,6\\}\n\nThen we can represent our operations r and s as the permutations\n\nr = \\{2,3,4,5,6,1\\} \\quad s = \\{1,6,5,4,3,2\\}\n\n\n\n\n\n\n\nDefinition\n\n\n\nA symmetry is a reordering of the vertices on a geometric shape such that their structure remains. We typically denote a symmetry with \\sigma.\n\n\nFor polygons in 2-space, we say that the ‘structure’ of the polygon remains if it can be transferred to 3-space, rotated, and then placed back into 2-space.\nThus our operations r and s are symmetries of the polygon. They can be combined to produce additional symmetries. The set of all possible symmetries on a n-polygon is denoted D_{2n}.\n\n\n\n\n\n\nDefinition\n\n\n\nThe set of symmetries on an n-polygon is denoted D_{2n}, and called the dihedral group of order 2n.\n\n\nWe will prove that D_{2n} is indeed a group later, but for now it can be taken as fact. D_{2n} has 2n symmetries, all of which can be constructed via compositions of our symmetries r and s.\n\n\n\n\n\n\nExample\n\n\n\nLets examine the group D_{12}, the symmetries of a hexagon.\nFirst lets look at our possible rotations r. Let e be the orignal labelling of the vertices, and r be defined\n\nr \\colon \\{1,2,3,4,5,6\\} \\to \\{2,3,4,5,6,1\\}\n\nWe can repeatedly compose r to construct the following symmetries\n\ne, r, r^2, r^3, r^4, r^5.\n\nNote that r^6 = r^0 = e, thus |r| = 6.\nNext we can look at our reflections. Let s be defined\n\ns \\colon \\{1,2,3,4,5,6\\} \\to \\{1,6,5,4,3,2\\}\n\nNote that s^2 = e. Combining s and r, we can create \ns, sr, sr^2, sr^3, sr^5, sr^6\n\nGiving us six new symmetries. This gives us a total of 12 symmmetries in D_{12}.\n\n\nIt should be noted that D_{12} is not abelian, which can be clearly be seen with\n\nrs = \\{6,5,4,3,2,1\\} = sr^5 \\quad sr = \\{2,1,6,5,4,3\\}"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/symmetric-groups.html#cyclic-groups",
    "href": "qmd/abstract/intro-to-groups/symmetric-groups.html#cyclic-groups",
    "title": "Symmetric Groups",
    "section": "Cyclic groups",
    "text": "Cyclic groups\n\n\n\n\n\n\nDefinition\n\n\n\nA cyclic group is generated by repeatedly applying the group operation to a single element\n\n\nWe notate a cyclic group G generated by an element S\n\nG = &lt;s&gt;"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/symmetric-groups.html#symmetric-groups",
    "href": "qmd/abstract/intro-to-groups/symmetric-groups.html#symmetric-groups",
    "title": "Symmetric Groups",
    "section": "Symmetric Groups",
    "text": "Symmetric Groups\nWe may expand our notion of symmetry to include all permutations of the same collection of elements. This creates the more general symmetric group S_\\Omega\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\Omega is a non-empty set. S_\\Omega is the set of all bijections from \n\\Omega \\to \\Omega\n\nThese bijections are called permutations any typically notated \\sigma or \\tau\n\n\nNote the following properties of S_\\Omega\n\nThe identity of S_\\Omega is the permutation e where\n\n\ne(a) = a\\quad \\forall a \\in \\Omega\n\n\nEvery permutation \\sigma \\colon \\Omega \\to \\Omega neccessarily has an inverse \\sigma^{-1}, because \\sigma is a bijection.\nThe composition of any two bijections \\sigma \\circ \\tau is itself a bijection, and therefore in S_\\Omega\n\nTherefore (S_\\Omega, \\circ) is a group and its called the symmetric group on \\Omega. Usually we take \\Omega as the first n natural numbers, and denote the symmetric group S_n.\n\n\n\n\n\n\nExample\n\n\n\nLets examine \\Omega = \\{1,2,3\\}.\nLet \\sigma,\\tau \\in S_3 be\n\n\\sigma \\colon \\{1,2,3\\} \\to \\{2,3,1\\}\n \n\\tau \\colon \\{1,2,3\\} \\to \\{2,1,3\\}\n\nWe can find \\sigma \\circ \\tau \n\\sigma \\circ \\tau \\colon \\{1,2,3\\} \\to \\{3,2,1\\}\n\nWhich is clearly in S_3\n\n\nThis notation is obtrusive and can be simplified using cycle decomposition.\n\n\n\n\n\n\nDefinition\n\n\n\nA cycle is a string of integers representing a permutation in S_n, denoted (a_1\\,a_2\\,\\ldots\\,a_n).\n\n\nA cycle represents the permutation\n\n\\{a_1,a_2,\\ldots,a_n\\} \\to \\{a_2,a_3,\\ldots,a_1\\}\n\nCycles can be concatenated to greatly reduce the amount of space needed to represent a permutation. For example the permutation\n\n\\{1,2,3,4,5,6\\} \\to \\{2,3,1,5,4,6\\}\n\nCan be represented as three cycles,\n\n(1\\,2\\,3)(4\\,5)(6)\n\nOften times cycles of length one are omitted.\n\n\n\n\n\n\nExample\n\n\n\nGiven S_3, we know there exist 3! = 6 total permutations of the set.\nThe identity permutation \n(1)(2)(3)\n\nThree examples where one number is left untouched \n(1)(2\\,3), (2)(1\\,3), (3)(1\\,2)\n\nAnd two examples where every number is permuted\n\n(1\\,2\\,3), (1\\,3\\,2)\n\n\n\nFor any \\sigma \\in S_n, the cycle decomposition of \\sigma^{-1} is obtained by writing the numbers in cycle of the cycle decomposition of \\sigma is in reverse order. For example\n\n\\sigma \\colon (1\\,2\\,3),\\quad \\sigma^{-1} \\colon (3\\,2\\,1).\n\nNote that S_n is non-abelian for all n\\geq3. That being said, disjoint cycles will commute. The order of an element \\sigma \\in S_n is the least common multiple of the lengths in it’s cycle decomposition. For example, the order of\n\n\\sigma = (1\\,2\\,3)(4\\,5)(6)\n\nWould be \\text{lcm}(3,2), thus |\\sigma| = 6."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html#homomorphisms-and-isomorphisms",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html#homomorphisms-and-isomorphisms",
    "title": "Homomorphisms and Isomorphisms",
    "section": "Homomorphisms and Isomorphisms",
    "text": "Homomorphisms and Isomorphisms\n\n\n\n\n\n\nDefinition\n\n\n\nLet (G,\\star) and (H,\\diamond) be groups.\nGiven a map \\varphi \\colon G \\to H, if we can show that\n\n\\forall x,y \\in G,\\, \\varphi (x \\star y) = \\varphi (x) \\diamond \\varphi(y)\n\nThe \\varphi is a homomorphism\n\n\nOne can think of a homomorphism as a map of sets that respect the group operations. When group operations are not specified, we often abbreviate\n\n\\varphi(xy) = \\varphi(x)\\varphi(y)\n\nWhere the LHS is the G operation, and the RHS is the operation in H.\n\n\n\n\n\n\nDefinition\n\n\n\nThe map\n\n\\varphi \\colon G \\to H\n\nis an Isomorphisms if \\varphi is both a homomorphism, and a bijection. If two groups are isomorphic, they are denoted\n\nG \\cong H\n\n\n\nIf two groups are isomorphic, they are essentially the same. Every property satisfied by G will be satisifed by H.\nA homomorphism from a group to itself is called an endomorphism, and an isomorphism from a group to itself is called an automorphism.\n\n\n\n\n\n\nExample\n\n\n\nTake the map \\varphi such that\n\n\\varphi \\colon (\\mathbb{Z},+) \\to (\\mathbb{Z}/m\\mathbb{Z}, +)\n\n\nx \\rightarrowtail [x]\n\nWe can prove \\varphi to be a homomorphism, as\n\n\\varphi (x+y) = [x + y]\n\n\n\\varphi (x) + \\varphi (y) = [x] + [y] = [x + y]\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nFor any group G, the identity map\n\nG \\rightarrow G\n\n\nx \\rightarrowtail x\n\nis an isomorphism, and an automorphism. Therefore for any group G, there exists some \\varphi such that G is isomorphic to itself.\n\n\n\n\n\n\n\n\nExample\n\n\n\nFor any groups G,H, the map \\varphi\n\n\\varphi \\colon G \\rightarrow H\n\n\ng \\rightarrowtail e_H\n\nis called the trivial homomorphism. As\n\n\\varphi(g_1g_2) = e_H\n\n\n\\varphi (g_1)\\varphi (g_2) = e_He_H = e_H"
  },
  {
    "objectID": "qmd/abstract/quotient-groups/quotient-group.html",
    "href": "qmd/abstract/quotient-groups/quotient-group.html",
    "title": "Quotient groups",
    "section": "",
    "text": "Quotient groups work like subgroups to obtain a “smaller” group from some base group G."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html#definitions",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html#definitions",
    "title": "Homomorphisms and Isomorphisms",
    "section": "Definitions",
    "text": "Definitions\n\n\n\n\n\n\nDefinition\n\n\n\nLet (G,\\star) and (H,\\diamond) be groups.\nGiven a map \\varphi \\colon G \\to H, if we can show that\n\n\\forall x,y \\in G,\\, \\varphi (x \\star y) = \\varphi (x) \\diamond \\varphi(y)\n\nThen \\varphi is a homomorphism\n\n\nOne can think of a homomorphism as a map of sets that respect the group operations. When group operations are not specified, we often abbreviate\n\n\\varphi(xy) = \\varphi(x)\\varphi(y)\n\nWhere the LHS is the G operation, and the RHS is the operation in H.\n\n\n\n\n\n\nDefinition\n\n\n\nThe map\n\n\\varphi \\colon G \\to H\n\nis an Isomorphisms if \\varphi is both a homomorphism, and a bijection.\n\n\nIf two groups are isomorphic, they are essentially the same. Every property satisfied by G will be satisifed by H. If two groups are isomorphic, they are denoted\n\nG \\cong H\n\nA homomorphism from a group to itself is called an endomorphism, and an isomorphism from a group to itself is called an automorphism.\n\n\n\n\n\n\nExample\n\n\n\nTake the map \\varphi such that\n\n\\varphi \\colon (\\mathbb{Z},+) \\to (\\mathbb{Z}/m\\mathbb{Z}, +)\n\n\nx \\rightarrowtail [x]\n\nWe can prove \\varphi to be a homomorphism, as\n\n\\varphi (x+y) = [x + y]\n\n\n\\varphi (x) + \\varphi (y) = [x] + [y] = [x + y]\n\nBut not an isomorphism, as the function is not injective.\n\n\n\n\n\n\n\n\nExample\n\n\n\nFor any group G, the identity map\n\nG \\rightarrow G\n\n\nx \\rightarrowtail x\n\nis an isomorphism, and an automorphism.\n\n\n\n\n\n\n\n\nExample\n\n\n\nFor any groups G,H, the map \\varphi\n\n\\varphi \\colon G \\rightarrow H\n\n\ng \\rightarrowtail e_H\n\nis called the trivial homomorphism. As\n\n\\varphi(g_1g_2) = e_H\n\n\n\\varphi (g_1)\\varphi (g_2) = e_He_H = e_H"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/homo-iso.html#properties-of-morphisms",
    "href": "qmd/abstract/intro-to-groups/homo-iso.html#properties-of-morphisms",
    "title": "Homomorphisms and Isomorphisms",
    "section": "Properties of morphisms",
    "text": "Properties of morphisms\nNow we can be to look at some of the properties of homomorphisms and Isomorphisms.\n\n\n\n\n\n\nProposition 1.2.1\n\n\n\nLet the following be groups \n(G, \\star) \\quad (H, \\diamond) \\quad (M, \\square).\n\nAnd the following maps be homomorphisms\n\nf \\colon G \\rightarrow H,\\quad g \\colon H \\rightarrow M\n\nThen\n\ng \\circ f \\colon G \\rightarrow M\n\nis a homomorphism.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nThe proof is just a few lines of algebra\n\\begin{align*}\ng(f(x \\star y)) &= g(f(x) \\diamond f(y))\\\\\n&= g(f(x))\\, \\square \\,g(f(y)))\n\\end{align*}\n\n\n\nAdditionally\n\n\n\n\n\n\nProposition 1.2.2\n\n\n\nLet\n\n\\varphi \\colon G \\rightarrow H\n\nbe a homomorphism. Let e_H,e_G be the identity of H and G respectivly. Then\n\n\\varphi(e_G) = e_H\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nBy algebra\n\\begin{align*}\ne_G &= e_Ge_G\\\\\n\\varphi(e_G) = \\varphi&(e_Ge_G) = \\varphi(e_G)\\varphi(e_G)\\\\\n(\\varphi(e_G))^{-1}\\varphi(e_G) &= (\\varphi(e_G))^{-1}\\varphi(e_G)\\varphi(e_G)\\\\\ne_H &= e_H\\varphi(e_G)\\\\\ne_H &= \\varphi(e_G)\n\\end{align*}\n\n\n\n\n\n\n\n\n\nProposition 1.2.3\n\n\n\nIf \\varphi \\colon G \\rightarrow H is an isomorphism, then\n\nThe cardinality of G and H are equivalent\nH is abelian if and only if G is abelian\nFor all x in G, the order of x is the order of \\varphi(x)\n\n\n\nThis porposition lists some of the properties preserved under isomorphism. The proof requires the use of the following Lemma\n\n\n\n\n\n\nLemma 1.2.4\n\n\n\nLet \\varphi \\colon G \\rightarrow H be a homomorphism. Then\n\n\\varphi(x^n) = \\varphi(x)^n \\quad \\forall n \\in \\mathbb{Z}\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nWe use a proof by induction. When n = 1\n\\begin{align*}\n\\varphi(x^1) = \\varphi(x)^1\n\\end{align*}\nWhen n &gt; 1\n\\begin{align*}\n\\varphi(x^{n-1}x) &= \\varphi(x)^{n-1}\\varphi(x)\\\\\n\\varphi(x^{n}) &= \\varphi(x)^{n}\n\\end{align*}\n\n\n\nNow to prove Proposition 1.2.3.\n\n\n\n\n\n\nProof (FINISH)\n\n\n\n\n\n(1) Isomorphisms are bijections, and by the Schröder–Bernstein theorem, bijections preserve cardinailty.\n(2) Let (G,\\star) and (H, \\diamond) be groups. If (G,\\star) is abelian, and {\\varphi(a)=x},{\\varphi(b)=y}, then\n\\begin{align*}\nx \\diamond y &= \\varphi(a) \\diamond \\varphi(b)\\\\\n&= \\varphi(a \\star b)\\\\\n&= \\varphi(b \\star a)\\\\\n&= \\varphi(b) \\diamond \\varphi(a)\\\\\n&= y \\diamond x\n\\end{align*}\n(3) We have three cases for this proposition\nCase 1:\nSuppose |x| = n is finite and |\\varphi(x)| is infinite. Then\n\n\\varphi(x)^n = \\varphi(x^n) = \\varphi(e_G) = e_H\n\nThus \\varphi(x) has finite order n, a contradiction.\nCase 2:\nSuppose |x| is infinite and |\\varphi(x)| = n is finite. Then\n\n\\varphi (x^n) = \\varphi (x)^n = e_H = \\varphi(e_G)\n\nBecause we have an isomorphism, \\varphi is injective, meaning\n\nx^n = e_G.\n\nThus |x| has finite order n, a contradiction.\nCase 3:\nSuppose |x| = n, |\\varphi(x)| = m. Then\n\n\\varphi(x)^n = \\varphi(x^n) = \\varphi(e_G) = e_H \\implies m \\leq n.\n\nSimilarly,\n\n\\varphi (e_G)= e_H = \\varphi (x)^m = \\varphi(x^m) \\implies m \\geq n\n\nThus\n\nm = n\n\n\n\n\nDetermining if two groups are isomorphic is an NP problem, so it can take a while to prove.\n\n\n\n\n\n\nProof (FINISH)\n\n\n\n\n\nLets take the following groups S_3 and \\mathbb{Z}/6\\mathbb{Z}. There does not exist an isomorphism between these two, as S_3 is abelian, and \\mathbb{Z}/6\\mathbb{Z} is not. Thus\n\nS_3 \\not \\cong \\mathbb{Z}/6\\mathbb{Z}\n\nThere is however, an isomorphism between D_6 and S_3.\nLet\n\nD_6 = \\{r,s \\mid r^3 = s^2 = 1, sr = r^{-1}s\\}\n\nWe can map\n\nS_3 \\rightarrow D_6\n\n\n(1\\,2\\,3) \\rightarrowtail r\n\n\n(1\\,2) \\rightarrowtail s\n\nWhich maps the generators to each other. Thus\n\nD_6 \\cong S_3"
  },
  {
    "objectID": "qmd/abstract/subgroups/definitions.html",
    "href": "qmd/abstract/subgroups/definitions.html",
    "title": "Subgroups",
    "section": "",
    "text": "Definition\n\n\n\nLet (G,\\star) be a group. A subgroup of G is a subset H \\subseteq G such that\n\ne \\in H\nx,y \\in H \\implies x \\star y \\in H\nx \\in H \\implies x^{-1} \\in H\n\n\n\nA subgroup H of G is merely a subset H of G such that H is a group under the same notation.\nThis is notated\n\nH \\leq G\n\n\n\n\n\n\n\nExample\n\n\n\nLets look at some subgroups\n\n(\\mathbb{Z},+) \\leq (\\mathbb{Q},+)\n(\\mathbb{Q}\\backslash \\{0\\},x) \\leq (\\mathbb{R}\\backslash\\{0\\},x)\n\n\n\nIf G is a group, and H = G, or H = \\{e_G\\}, these are both subgroups of G.\nA slightly harder example, if m \\in \\mathbb{Z}, then\n\nm\\mathbb{Z} := \\{ma \\mid a \\in \\mathbb{Z}\\} \\leq (\\mathbb{Z},+).\n\nLets define\n\n\\mathbb{Z}^+ := \\{n \\in \\mathbb{Z} \\mid n &gt; 0\\}.\n\nIt is clear that\n\n(\\mathbb{Z}^+,+) \\not \\leq (\\mathbb{Z},+),\n\nAs \\mathbb{Z}^+ has no identity element, or any inverses.\nThe relation \\leq (is subgroup of) is transitive. The relation is also reflexive, but the relation is not symmetric. This the relation is not an equivalence relation.\n\n\n\n\n\n\nTheorem\n\n\n\nIf H, K are both subgroups of G, then H \\cap K is a subgroup of G.\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe can prove that H \\cap K fufills the three properties of being a subgroup.\n\n(1)\\, e \\in H, e \\in K \\implies e \\in H \\cup K\n\n\n(2) x,y \\in H \\cup K \\implies\n\n\n\nThere is a simple way to check a subgroup\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nA group H is a subgroup of G if\n\nH \\not = \\varnothing\nx,y \\in H \\implies x \\star y^{-1} \\in H\n\n\n\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nIf H is a subgroup of G then e \\in H, thus H \\not = \\varnothing, and if x,y \\in H, then y^{-1} is in H. Thus x \\star y^{-1} is in H.\nNow if H satisfies the two properties, we have some x \\in H, as H is not empty. If y = x, then\n\nx,x \\in H \\implies x \\star x^{-1} \\in H \\implies e \\in H\n\nAnd then with e,x\n\ne,x \\in H \\implies e \\star x^{-1} \\in H \\implies x^{-1} \\in H\n\nIf x,y \\in H then y^{-1} \\in H. Thus\n\nx,y^{-1} \\in H \\implies x \\star (y^{-1})^{-1} \\in H \\implies x \\star y \\in H\n\nSo H is a group."
  },
  {
    "objectID": "qmd/abstract/subgroups/definitions.html#subgroups",
    "href": "qmd/abstract/subgroups/definitions.html#subgroups",
    "title": "Subgroups",
    "section": "",
    "text": "Definition\n\n\n\nLet (G,\\star) be a group. A subgroup of G is a subset H \\subseteq G such that\n\ne \\in H\nx,y \\in H \\implies x \\star y \\in H\nx \\in H \\implies x^{-1} \\in H\n\n\n\nA subgroup H of G is merely a subset H of G such that H is a group under the same notation.\nThis is notated\n\nH \\leq G\n\n\n\n\n\n\n\nExample\n\n\n\nLets look at some subgroups\n\n(\\mathbb{Z},+) \\leq (\\mathbb{Q},+)\n(\\mathbb{Q}\\backslash \\{0\\},x) \\leq (\\mathbb{R}\\backslash\\{0\\},x)\n\n\n\nIf G is a group, and H = G, or H = \\{e_G\\}, these are both subgroups of G.\nA slightly harder example, if m \\in \\mathbb{Z}, then\n\nm\\mathbb{Z} := \\{ma \\mid a \\in \\mathbb{Z}\\} \\leq (\\mathbb{Z},+).\n\nLets define\n\n\\mathbb{Z}^+ := \\{n \\in \\mathbb{Z} \\mid n &gt; 0\\}.\n\nIt is clear that\n\n(\\mathbb{Z}^+,+) \\not \\leq (\\mathbb{Z},+),\n\nAs \\mathbb{Z}^+ has no identity element, or any inverses.\nThe relation \\leq (is subgroup of) is transitive. The relation is also reflexive, but the relation is not symmetric. This the relation is not an equivalence relation.\n\n\n\n\n\n\nTheorem\n\n\n\nIf H, K are both subgroups of G, then H \\cap K is a subgroup of G.\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe can prove that H \\cap K fufills the three properties of being a subgroup.\n\n(1)\\, e \\in H, e \\in K \\implies e \\in H \\cup K\n\n\n(2) x,y \\in H \\cup K \\implies\n\n\n\nThere is a simple way to check a subgroup\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nA group H is a subgroup of G if\n\nH \\not = \\varnothing\nx,y \\in H \\implies x \\star y^{-1} \\in H\n\n\n\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nIf H is a subgroup of G then e \\in H, thus H \\not = \\varnothing, and if x,y \\in H, then y^{-1} is in H. Thus x \\star y^{-1} is in H.\nNow if H satisfies the two properties, we have some x \\in H, as H is not empty. If y = x, then\n\nx,x \\in H \\implies x \\star x^{-1} \\in H \\implies e \\in H\n\nAnd then with e,x\n\ne,x \\in H \\implies e \\star x^{-1} \\in H \\implies x^{-1} \\in H\n\nIf x,y \\in H then y^{-1} \\in H. Thus\n\nx,y^{-1} \\in H \\implies x \\star (y^{-1})^{-1} \\in H \\implies x \\star y \\in H\n\nSo H is a group."
  },
  {
    "objectID": "qmd/abstract/subgroups/definitions.html#centralizers-normalizers-center",
    "href": "qmd/abstract/subgroups/definitions.html#centralizers-normalizers-center",
    "title": "Subgroups",
    "section": "Centralizers, Normalizers, Center",
    "text": "Centralizers, Normalizers, Center\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be a subset of a group G.\nThe Centralizer of A in G is a set of elements of G that commute with all elements of A. This is denoted\n\nC_G(A) = \\{g \\in G \\mid gag^{-1} = a, \\; \\forall a \\in A\\}\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nThe centralizer of a subset A of G is a subgroup of G. Symbollically \nC_G(A) \\leq G\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe know\n\ne \\in C_G(A)\n\nThus we can fufill the first property of a subgroup C_G(A) \\not = \\varnothing. Now, let x,y \\in C_G(A). We see\n\ny^{-1}yayy^{-1} = y^{-1}ay\n\n\na = y^{-1}ay = y^{-1}a(y^{-1})^{-1}\n\nThus y^{-1} \\in C_G(A).\nNow we wish to show xy \\in C_G(A)\n\n(xy)a(xy)^{-1} = xyay^{-1}x^{-1}\n\nBecause x,y \\in C_G(A), we have xy \\in C_G(A). Thus\n\nC_G(A) \\leq G\n\n\n\nNext\n\n\n\n\n\n\nDefinition\n\n\n\nThe center of G is denoted\n\nZ(G) = \\{g \\in G \\mid gx = xg,\\, \\forall x \\in G\\}\n\n\n\nThe center of G is the centralizer where A = G. Clearly Then\n\nZ(G) = C_G(G)\n\n\nZ(G) \\leq G\n\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be a subset of a group G, such that g \\in G.\n\ngAg^{-1} = \\{gag^{-1} \\mid a \\in A\\}\n\n\n\nWe use this definition immeditally\n\n\n\n\n\n\nDefinition\n\n\n\nThe normalizer of A in G is denoted\n\nN_G(A) = \\{g \\in G \\mid gAg^{-1} = A\\}\n\n\n\nNote that C_G(A) \\leq N_G(A).\nIf G is abelian, then\n\nZ(G) = G, \\quad C_G(A) = G, \\quad N_G(A) = G\n\n\n\n\n\n\n\nExample\n\n\n\nLet G = D_8, and our subset A = \\{e,r,r^2,r^3\\}.\nWe want to find C_{D_8}\nWe know that A \\subset C_{D_8}(A) because rotations are commutative, that meaning\n\nr^ir^j = r^{i+j} = r^{j+i} = r^jr^i\n\nWe know that sr \\not = rs, so s\\not \\in C_{D_8}(A). We now need to check the remaining elements of D_8, sr,sr^2,sr^3.\nBecause C_{D_8}(A) \\leq D_8 we have\n\nsr^i \\in C_{D_8}(A) \\implies sr^ir^{-1} = s \\in C_{D_8}\n\nWhich is a contradiction, thus\n\nC_{D_8}(A) = A\n\nNow lets find N_{D_8}(A).\nBecause C_{D_8} \\leq N_{D_8}, we know A \\subseteq N_{D_8}(A). We have then\n\nsAs^{-1} = \\{ses^{-1},srs^{-1},sr^2s^{-1},sr^3s^{-1}\\}\n\nTake as a fact r^is = sr^{-1}. Thus\n\nsAs^{-1} = \\{e,r^3,r^2,r\\}\n\nThus s \\in N_{D_8}. We need now check sr^i. Because N_{D_8}(A) \\leq D_8, we have that sr^i is in the normalizer. Thus\n\nN_{D_8}(A) = D_8\n\nWe now wish to find the center of D_8. Since\n\nZ(D_8) \\leq C_{D_8}(A)\n\nWe know that Z(D_8) \\subseteq A.\nWe can check these four elements of A to see if their commutative with everything. We have\n\nrs = sr^{-1} \\not =sr\n\nThus r is not commutative with s, and is not in the center.\n\nr^2s = sr^{-2} = sr^2\n\nSo r^2 commutes with s. Now we check if it commutes with sr^i.\n\nr^2sr^i = sr^{-2}r^i = sr^ir^{-2}\n\nThus our center is \nZ(D_8) = \\{e,r^2\\}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA group H is called cyclic if it is generated by one element. We denote H\n\nH = \\langle x \\rangle = \\{x^n \\mid n \\in \\mathbb{Z}\\}\n\nx is called a generator\n\n\nFor example, (\\mathbb{Z},+)\n\n\\langle 1 \\rangle = \\{+(n,1) \\mid n\\in \\mathbb{Z}\\}\n\nBut also\n\n\\langle -1 \\rangle = \\{+(n,-1) \\mid n\\in \\mathbb{Z}\\}\n\n\n\n\n\n\n\nExample\n\n\n\nWe can find a generator of\n\n(\\mathbb{Z}/n\\mathbb{Z},+)\n\nUsing\n\n\\langle [1] \\rangle = \\{[1],[2],\\cdots,[n]\\} = \\{+(n,[1])\\mid n \\in \\{ 1,2,\\cdots,n\\}\\}\n\n\n\n\n\n\n\n\n\nCorollary\n\n\n\n(1) Assume |x| = \\infty. Then H = &lt;x^a&gt; iff a = \\pm 1\n(2) Assume |x| = n &lt; \\infty then &lt;x^a&gt; = H iff gcd(a,n) = 1\n\n\nNotice\n\n\\mathbb{Z}/6\\mathbb{Z} = \\left&lt;[1]\\right&gt;,\\left&lt;[5]\\right&gt;.\n\n\n\n\n\n\n\nExample\n\n\n\nAll the generators\n\n(\\mathbb{Z}/12\\mathbb{Z},+)\n\nWhich are\n\n\\left&lt;[1]\\right&gt;,\\left&lt;[5]\\right&gt;,\\left&lt;[7]\\right&gt;,\\left&lt;[11]\\right&gt;\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nIf H = \\left&lt;x\\right&gt; is a cyclic groups\n(1) Every subgroup of H is cyclic\n(2) If |H| = n &lt; \\infty then for each positive integer a dividing n, there is a unique subgroup of H of order \\left&lt;x^{\\frac{n}{a}}\\right&gt;\n\n\n\n\n\n\n\n\nProof\n\n\n\n(1) Let K \\leq H = \\left&lt;x\\right&gt;\nIf K = \\{1\\} then done. Otherwise let a = \\min\\{K&gt;0\\mid x^k\\in K\\}.\nThe claim is that K is generated by \\left&lt;x^a\\right&gt;. Suppose not. Suppose there is some x^b \\in K such that a\\not| \\,b. Thus\n\nb = aq + r \\quad 0 &lt; r &lt; a\n\nNote that x^{aq} \\in K. Meaning x^{-aq} \\in K. Thus x^{b-aq} \\in K. Thus x^r \\in K. But because r is less than a, and we assumed a to be the smallest power of x in K, we have a contradiction. Thus every subgroup of H is cyclic.\n(2) If H has a finite order n, we use our previous proposition to note that |\\left&lt;x^\\frac{n}{a}\\right&gt;| = a.\n\n\n\n\n\n\n\n\nExample\n\n\n\nAll the subgroups of \\mathbb{Z}/12\\mathbb{Z} are\nOrder 12: \\left&lt;[1]\\right&gt;\nOrder 6: \\left&lt;[2]\\right&gt;\nOrder 4: \\left&lt;[3]\\right&gt;\nOrder 3: \\left&lt;[4]\\right&gt;\nOrder 2: \\left&lt;[6]\\right&gt;\nOrder 1: \\left&lt;[0]\\right&gt;"
  },
  {
    "objectID": "qmd/abstract/subgroups/definitions.html#subgroups-generated-by-subsets",
    "href": "qmd/abstract/subgroups/definitions.html#subgroups-generated-by-subsets",
    "title": "Subgroups",
    "section": "2.4 Subgroups generated by subsets",
    "text": "2.4 Subgroups generated by subsets\nCyclic groups generated by x are the smallest subgroups containing x.\n\n\n\n\n\n\nProposition\n\n\n\nFor any nonempty collection of subgroups of G, the intersection of all of them is also a subgroup of G.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf A is any subset of G, then\n\n\\left&lt;A\\right&gt; = \\bigcap \\limits_{\\substack{H\\leq G\\\\ A \\subseteq H}} H\n\nI.e, the intersection of all subgroups containing A. Thus \\left&lt;A\\right&gt; is the minimal subgroup of G containing A.\n\n\nAnother way to define \\left&lt;A\\right&gt; is by using generators. Say\n\n\\overline{A} = \\left\\{ a_1^{\\varepsilon_1},a_2^{\\varepsilon_2},\\cdots,a_n^{\\varepsilon_n} \\mid n + \\mathbb{Z},\\:n\\geq0,\\:a_1\\in A,\\: \\varepsilon_i = \\pm 1\\right\\}\n\nThus \\overline{A} is the set of finite products of elements of A and inverses of these elements.\n\n\n\n\n\n\nProposition\n\n\n\nOur definitions are equal. Symbollically \n\\overline{A} = \\left&lt; A \\right&gt;\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nFirst we prove that \\overline{A} is a group. Then\n\\overline{A} \\not= \\varnothing because A always has the identity.\nif a,b \\in A, then\n\\begin{align*}\na &= a_1^{\\varepsilon_1}a_2^{\\varepsilon_2}\\cdots a_n^{\\varepsilon_n}\\\\\nb &= b_1^{\\delta_1}b_2^{\\delta_2}\\cdots a_n^{\\delta_n}\n\\end{align*}\nthen\n\na(b^{-1}) = a_1^{\\varepsilon_1}a_2^{\\varepsilon_2}\\cdots a_n^{\\varepsilon_n}a_n^{\\delta_n}\\cdots b_2^{\\delta_2}b_1^{\\delta_1} \\in A\n\nThus\n\n\\overline{A} \\leq G\n\nSo \\left&lt;A\\right&gt; \\subseteq \\overline{A}.\nNow we must show \\overline{A} \\subseteq \\left&lt;A\\right&gt;. This is true because \\left&lt;A\\right&gt; is closed under multiplication and inverses.\n\n\n\n\n\n\n\n\nExample\n\n\n\nThe subgroup\n\n\\left&lt;(12),(13)(24)\\right&gt; \\leq S_4\n\nFun fact, (it’s not) the subset is isomorphic to D_8\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the kernal of \\varphi is the set\n\n\\ker\\varphi = \\{g \\in G \\mid \\varphi(g) = e_H\\}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the image of \\varphi is the set\n\n\\text{im} \\varphi = \\{\\varphi(x) \\mid x \\in G\\}\n\n\n\n\n\n\n\n\n\nProposition\n\n\n\nIf H,G are groups, \\varphi \\colon G \\to H is a homomorphism, then the \\ker \\varphi \\leq G and \\text{im} \\leq H.\n\n\n\n\n\n\n\n\nProof\n\n\n\nSince e_G is such that \\varphi(e_G) = e_H, we know \\ker \\varphi \\not = \\varnothing. If x,y are in the \\ker \\varphi, then xy^{-1} is in the kernal, thus \\ker \\phi is a subgroup of G.\nNow take the image of \\varphi. Note\n\n\\varphi(e_G) = e_H \\in \\text{im} \\varphi \\implies \\text{im} \\varphi \\not = \\varnothing\n\nGiven x,y \\in \\text{im} \\varphi, we know that xy^{-1} is in \\text{im} \\varphi. Thus \\text{im} \\varphi \\leq H."
  },
  {
    "objectID": "qmd/abstract/subgroups/definitions.html#quotient-groups",
    "href": "qmd/abstract/subgroups/definitions.html#quotient-groups",
    "title": "Subgroups",
    "section": "Quotient groups",
    "text": "Quotient groups\nAnother way to get a smaller subgroup from a group G is by forming a quotient group.\nSubgroups of H \\leq G are injective onto G.\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\varphi \\colon G \\to H be a homomorphism.\nFibers are sets of elements in G that map to single points in H.\nDraw a box and a line???"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/subgroups.html",
    "href": "qmd/abstract/intro-to-groups/subgroups.html",
    "title": "Subgroups",
    "section": "",
    "text": "Subgroups are subsets of groups which are also groups in their own right."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/subgroups.html#definition",
    "href": "qmd/abstract/intro-to-groups/subgroups.html#definition",
    "title": "Subgroups",
    "section": "Definition",
    "text": "Definition\n\n\n\n\n\n\nDefinition\n\n\n\nLet (G,\\star) be a group. A subgroup of G is a subset H \\subseteq G such that\n\ne \\in H\nx,y \\in H \\implies x \\star y \\in H\nx \\in H \\implies x^{-1} \\in H\n\n\n\nA subgroup H of G is merely a subset H of G such that H is a group under the same operation.\nIf H is a subgroup of G, we write\n\nH \\leq G\n\n\n\n\n\n\n\nExample\n\n\n\nLet G be the group (\\mathbb{Q},+). We previously showed that (\\mathbb{Z},+) was a group. Because \\mathbb{Z} \\subseteq \\mathbb{Q}, we have\n\n(\\mathbb{Z},+) \\leq (\\mathbb{Q},+)\n\n\n\nTrivially, if G is a group, H = G and H = e_G are both subgroups of G.\n\n\n\n\n\n\nExample\n\n\n\nA slightly harder example, if m \\in \\mathbb{Z}, then\n\nm\\mathbb{Z} := \\{ma \\mid a \\in \\mathbb{Z}\\} \\leq (\\mathbb{Z},+).\n\nLets define\n\n\\mathbb{Z}^+ := \\{n \\in \\mathbb{Z} \\mid n &gt; 0\\}.\n\nIt is clear that\n\n(\\mathbb{Z}^+,+) \\not \\leq (\\mathbb{Z},+),\n\nAs \\mathbb{Z}^+ has no identity element, or any inverses.\n\n\nThe relation \\leq (is subgroup of) is transitive. The relation is also reflexive, but the relation is not symmetric.\n\n\n\n\n\n\nTheorem\n\n\n\nIf H, K are both subgroups of G, then H \\cap K is a subgroup of G.\n\n\n\n\n\n\n\n\nProof\n\n\n\nWe can prove that H \\cap K fufills the three properties of being a subgroup.\n\n(1)\\, e \\in H, e \\in K \\implies e \\in H \\cup K\n\n\n(2) x,y \\in H \\cup K \\implies\n\n\n\nThere is a simple way to check a subgroup\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nA group H is a subgroup of G if\n\nH \\not = \\varnothing\nx,y \\in H \\implies x \\star y^{-1} \\in H\n\n\n\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nIf H is a subgroup of G then e \\in H, thus H \\not = \\varnothing, and if x,y \\in H, then y^{-1} is in H. Thus x \\star y^{-1} is in H.\nNow if H satisfies the two properties, we have some x \\in H, as H is not empty. If y = x, then\n\nx,x \\in H \\implies x \\star x^{-1} \\in H \\implies e \\in H\n\nAnd then with e,x\n\ne,x \\in H \\implies e \\star x^{-1} \\in H \\implies x^{-1} \\in H\n\nIf x,y \\in H then y^{-1} \\in H. Thus\n\nx,y^{-1} \\in H \\implies x \\star (y^{-1})^{-1} \\in H \\implies x \\star y \\in H\n\nSo H is a group."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/subgroups.html#centralizers-normalizers-center",
    "href": "qmd/abstract/intro-to-groups/subgroups.html#centralizers-normalizers-center",
    "title": "Subgroups",
    "section": "Centralizers, Normalizers, Center",
    "text": "Centralizers, Normalizers, Center\n\n\n\n\n\n\nDefinition\n\n\n\nLet A be a subset of a group G.\nThe Centralizer of A in G is a set of elements of G that commute with all elements of A.\n\nC_G(A) = \\{g \\in G \\mid gag^{-1} = a, \\; \\forall a \\in A\\}\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nThe centralizer of a subset A of G is a subgroup of G. \nC_G(A) \\leq G\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nWe know\n\ne \\in C_G(A)\n\nThus we can fufill the first property of a subgroup C_G(A) \\not = \\varnothing. Now, let x,y \\in C_G(A). We see\n\ny^{-1}yayy^{-1} = y^{-1}ay\n\n\na = y^{-1}ay = y^{-1}a(y^{-1})^{-1}\n\nThus y^{-1} \\in C_G(A).\nNow we wish to show xy \\in C_G(A)\n\n(xy)a(xy)^{-1} = xyay^{-1}x^{-1}\n\nBecause x,y \\in C_G(A), we have xy \\in C_G(A). Thus\n\nC_G(A) \\leq G\n\n\n\n\nAttempting to give an explanation, the centralizer is an operation which when given a set G, and a subset A \\subset G, gives all elements of A which commute with every element in G.\n\n\n\n\n\n\nDefinition\n\n\n\nThe center of G is defined\n\nZ(G) = \\{g \\in G \\mid gx = xg,\\, \\forall x \\in G\\}\n\n\n\nThe center of G is the centralizer where A = G. Clearly Then\n\nZ(G) = C_G(G)\n\n\nZ(G) \\leq G\n\n\n\n\n\n\n\nNotation\n\n\n\nLet A be a subset of a group G, such that g \\in G.\n\ngAg^{-1} = \\{gag^{-1} \\mid a \\in A\\}\n\n\n\nNote that gag^{-1} does not neccessarily have to equal a. Given two elements a,b \\in A, such that \ngag^{-1} = b\\quad gbg^{-1} = a\n\nWe would still write gAg^{-1} = A.\n\n\n\n\n\n\nDefinition\n\n\n\nThe normalizer of A in G is denoted\n\nN_G(A) = \\{g \\in G \\mid gAg^{-1} = A\\}\n\n\n\nNote that C_G(A) \\leq N_G(A).\nIf G is abelian, then\n\nZ(G) = G, \\quad C_G(A) = G, \\quad N_G(A) = G\n\n\n\n\n\n\n\nExample (CHECK)\n\n\n\nLet G = D_8, and our subset A = \\{e,r,r^2,r^3\\}.\nWe want to find C_{D_8}\nWe know that A \\subset C_{D_8}(A) because rotations are commutative, that meaning\n\nr^ir^j = r^{i+j} = r^{j+i} = r^jr^i\n\nWe know that sr \\not = rs, so s\\not \\in C_{D_8}(A). We now need to check the remaining elements of D_8, sr,sr^2,sr^3.\nBecause C_{D_8}(A) \\leq D_8 we have\n\nsr^i \\in C_{D_8}(A) \\implies sr^ir^{-1} = s \\in C_{D_8}\n\nWhich is a contradiction, thus\n\nC_{D_8}(A) = A\n\nNow lets find N_{D_8}(A).\nBecause C_{D_8} \\leq N_{D_8}, we know A \\subseteq N_{D_8}(A). We have then\n\nsAs^{-1} = \\{ses^{-1},srs^{-1},sr^2s^{-1},sr^3s^{-1}\\}\n\nTake as a fact r^is = sr^{-1}. Thus\n\nsAs^{-1} = \\{e,r^3,r^2,r\\}\n\nThus s \\in N_{D_8}. We need now check sr^i. Because N_{D_8}(A) \\leq D_8, we have that sr^i is in the normalizer. Thus\n\nN_{D_8}(A) = D_8\n\nWe now wish to find the center of D_8. Since\n\nZ(D_8) \\leq C_{D_8}(A)\n\nWe know that Z(D_8) \\subseteq A.\nWe can check these four elements of A to see if their commutative with everything. We have\n\nrs = sr^{-1} \\not =sr\n\nThus r is not commutative with s, and is not in the center.\n\nr^2s = sr^{-2} = sr^2\n\nSo r^2 commutes with s. Now we check if it commutes with sr^i.\n\nr^2sr^i = sr^{-2}r^i = sr^ir^{-2}\n\nThus our center is \nZ(D_8) = \\{e,r^2\\}"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/subgroups.html#subgroups-generated-by-subsets",
    "href": "qmd/abstract/intro-to-groups/subgroups.html#subgroups-generated-by-subsets",
    "title": "Subgroups",
    "section": "2.4 Subgroups generated by subsets",
    "text": "2.4 Subgroups generated by subsets\nCyclic groups generated by x are the smallest subgroups containing x.\n\n\n\n\n\n\nProposition\n\n\n\nFor any nonempty collection of subgroups of G, the intersection of all of them is also a subgroup of G.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf A is any subset of G, then\n\n\\left&lt;A\\right&gt; = \\bigcap \\limits_{\\substack{H\\leq G\\\\ A \\subseteq H}} H\n\nI.e, the intersection of all subgroups containing A. Thus \\left&lt;A\\right&gt; is the minimal subgroup of G containing A.\n\n\nAnother way to define \\left&lt;A\\right&gt; is by using generators. Say\n\n\\overline{A} = \\left\\{ a_1^{\\varepsilon_1},a_2^{\\varepsilon_2},\\cdots,a_n^{\\varepsilon_n} \\mid n + \\mathbb{Z},\\:n\\geq0,\\:a_1\\in A,\\: \\varepsilon_i = \\pm 1\\right\\}\n\nThus \\overline{A} is the set of finite products of elements of A and inverses of these elements.\n\n\n\n\n\n\nProposition\n\n\n\nOur definitions are equal. Symbollically \n\\overline{A} = \\left&lt; A \\right&gt;\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nFirst we prove that \\overline{A} is a group. Then\n\\overline{A} \\not= \\varnothing because A always has the identity.\nif a,b \\in A, then\n\\begin{align*}\na &= a_1^{\\varepsilon_1}a_2^{\\varepsilon_2}\\cdots a_n^{\\varepsilon_n}\\\\\nb &= b_1^{\\delta_1}b_2^{\\delta_2}\\cdots a_n^{\\delta_n}\n\\end{align*}\nthen\n\na(b^{-1}) = a_1^{\\varepsilon_1}a_2^{\\varepsilon_2}\\cdots a_n^{\\varepsilon_n}a_n^{\\delta_n}\\cdots b_2^{\\delta_2}b_1^{\\delta_1} \\in A\n\nThus\n\n\\overline{A} \\leq G\n\nSo \\left&lt;A\\right&gt; \\subseteq \\overline{A}.\nNow we must show \\overline{A} \\subseteq \\left&lt;A\\right&gt;. This is true because \\left&lt;A\\right&gt; is closed under multiplication and inverses.\n\n\n\n\n\n\n\n\nExample\n\n\n\nThe subgroup\n\n\\left&lt;(12),(13)(24)\\right&gt; \\leq S_4\n\nFun fact, (it’s not) the subset is isomorphic to D_8\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the kernal of \\varphi is the set\n\n\\ker\\varphi = \\{g \\in G \\mid \\varphi(g) = e_H\\}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the image of \\varphi is the set\n\n\\text{im} \\varphi = \\{\\varphi(x) \\mid x \\in G\\}\n\n\n\n\n\n\n\n\n\nProposition\n\n\n\nIf H,G are groups, \\varphi \\colon G \\to H is a homomorphism, then the \\ker \\varphi \\leq G and \\text{im} \\leq H.\n\n\n\n\n\n\n\n\nProof\n\n\n\nSince e_G is such that \\varphi(e_G) = e_H, we know \\ker \\varphi \\not = \\varnothing. If x,y are in the \\ker \\varphi, then xy^{-1} is in the kernal, thus \\ker \\phi is a subgroup of G.\nNow take the image of \\varphi. Note\n\n\\varphi(e_G) = e_H \\in \\text{im} \\varphi \\implies \\text{im} \\varphi \\not = \\varnothing\n\nGiven x,y \\in \\text{im} \\varphi, we know that xy^{-1} is in \\text{im} \\varphi. Thus \\text{im} \\varphi \\leq H."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/subgroups.html#definition-and-properties",
    "href": "qmd/abstract/intro-to-groups/subgroups.html#definition-and-properties",
    "title": "Subgroups",
    "section": "Definition and Properties",
    "text": "Definition and Properties\n\n\n\n\n\n\nDefinition\n\n\n\nLet (G,\\star) be a group. A subgroup of G is a subset H \\subseteq G such that\n\ne \\in H\nx,y \\in H \\implies x \\star y \\in H\nx \\in H \\implies x^{-1} \\in H\n\n\n\nA subgroup H of G is merely a subset H of G such that H is a group under the same operation.\nIf H is a subgroup of G, we write\n\nH \\leq G\n\n\n\n\n\n\n\nExample\n\n\n\nLet G be the group (\\mathbb{Q},+). We previously showed that (\\mathbb{Z},+) was a group. Because \\mathbb{Z} \\subseteq \\mathbb{Q}, we have\n\n(\\mathbb{Z},+) \\leq (\\mathbb{Q},+)\n\n\n\nTrivially, if G is a group, H = G and H = e_G are both subgroups of G.\n\n\n\n\n\n\nExample\n\n\n\nA slightly harder example, if m \\in \\mathbb{Z}, then\n\nm\\mathbb{Z} := \\{ma \\mid a \\in \\mathbb{Z}\\} \\leq (\\mathbb{Z},+).\n\nLets define\n\n\\mathbb{Z}^+ := \\{n \\in \\mathbb{Z} \\mid n &gt; 0\\}.\n\nIt is clear that\n\n(\\mathbb{Z}^+,+) \\not \\leq (\\mathbb{Z},+),\n\nAs \\mathbb{Z}^+ has no identity element, or any inverses.\n\n\nThe relation \\leq (is subgroup of) is transitive. The relation is also reflexive, but the relation is not symmetric.\n\n\n\n\n\n\nProposition\n\n\n\nIf H, K are both subgroups of G, then H \\cap K is a subgroup of G.\n\n\n\n\n\n\n\n\nProof (FINISH)\n\n\n\n\n\nWe can prove that H \\cap K fufills the three properties of being a subgroup.\n\n(1)\\, e \\in H, e \\in K \\implies e \\in H \\cap K\n\n\n(2)\\,x,y \\in H \\cup K \\implies x \\star y \\in H \\cup\n\n\n\n\nThere is a simpler way however to check if a group H is a subgroup of G, called the Subgroup criterion.\n\n\n\n\n\n\nTheorem (Subgroup criterion)\n\n\n\nA group H is a subgroup of G if\n\nH \\not = \\varnothing\nx,y \\in H \\implies x \\star y^{-1} \\in H\n\n\n\n\n\n\n\n\n\nProof (Subgroup criterion)\n\n\n\n\n\nIf H is a subgroup of G then e \\in H, thus H \\not = \\varnothing, and if x,y \\in H, then y^{-1} is in H. Thus x \\star y^{-1} is in H.\nNow if H satisfies the two properties, we have some x \\in H, as H is not empty. If y = x, then\n\nx,x \\in H \\implies x \\star x^{-1} \\in H \\implies e \\in H\n\nAnd then with e,x\n\ne,x \\in H \\implies e \\star x^{-1} \\in H \\implies x^{-1} \\in H\n\nIf x,y \\in H then y^{-1} \\in H. Thus\n\nx,y^{-1} \\in H \\implies x \\star (y^{-1})^{-1} \\in H \\implies x \\star y \\in H\n\nSo H is a group."
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/subgroups.html#cyclic-groups",
    "href": "qmd/abstract/intro-to-groups/subgroups.html#cyclic-groups",
    "title": "Subgroups",
    "section": "Cyclic groups",
    "text": "Cyclic groups\n\n\n\n\n\n\nDefinition\n\n\n\nA group H is called cyclic if it is generated by one element. We denote H\n\nH = \\langle x \\rangle = \\{x^n \\mid n \\in \\mathbb{Z}\\}\n\nx is called a generator\n\n\nFor example, (\\mathbb{Z},+)\n\n\\langle 1 \\rangle = \\{+(n,1) \\mid n\\in \\mathbb{Z}\\}\n\nBut also\n\n\\langle -1 \\rangle = \\{+(n,-1) \\mid n\\in \\mathbb{Z}\\}\n\n\n\n\n\n\n\nExample\n\n\n\nWe can find a generator of\n\n(\\mathbb{Z}/n\\mathbb{Z},+)\n\nUsing\n\n\\langle [1] \\rangle = \\{[1],[2],\\cdots,[n]\\} = \\{+(n,[1])\\mid n \\in \\{ 1,2,\\cdots,n\\}\\}\n\n\n\n\n\n\n\n\n\nCorollary\n\n\n\n(1) Assume |x| = \\infty. Then H = &lt;x^a&gt; iff a = \\pm 1\n(2) Assume |x| = n &lt; \\infty then &lt;x^a&gt; = H iff gcd(a,n) = 1\n\n\nNotice\n\n\\mathbb{Z}/6\\mathbb{Z} = \\left&lt;[1]\\right&gt;,\\left&lt;[5]\\right&gt;.\n\n\n\n\n\n\n\nExample\n\n\n\nAll the generators\n\n(\\mathbb{Z}/12\\mathbb{Z},+)\n\nWhich are\n\n\\left&lt;[1]\\right&gt;,\\left&lt;[5]\\right&gt;,\\left&lt;[7]\\right&gt;,\\left&lt;[11]\\right&gt;\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nIf H = \\left&lt;x\\right&gt; is a cyclic groups\n(1) Every subgroup of H is cyclic\n(2) If |H| = n &lt; \\infty then for each positive integer a dividing n, there is a unique subgroup of H of order \\left&lt;x^{\\frac{n}{a}}\\right&gt;\n\n\n\n\n\n\n\n\nProof\n\n\n\n(1) Let K \\leq H = \\left&lt;x\\right&gt;\nIf K = \\{1\\} then done. Otherwise let a = \\min\\{K&gt;0\\mid x^k\\in K\\}.\nThe claim is that K is generated by \\left&lt;x^a\\right&gt;. Suppose not. Suppose there is some x^b \\in K such that a\\not| \\,b. Thus\n\nb = aq + r \\quad 0 &lt; r &lt; a\n\nNote that x^{aq} \\in K. Meaning x^{-aq} \\in K. Thus x^{b-aq} \\in K. Thus x^r \\in K. But because r is less than a, and we assumed a to be the smallest power of x in K, we have a contradiction. Thus every subgroup of H is cyclic.\n(2) If H has a finite order n, we use our previous proposition to note that |\\left&lt;x^\\frac{n}{a}\\right&gt;| = a.\n\n\n\n\n\n\n\n\nExample\n\n\n\nAll the subgroups of \\mathbb{Z}/12\\mathbb{Z} are\nOrder 12: \\left&lt;[1]\\right&gt;\nOrder 6: \\left&lt;[2]\\right&gt;\nOrder 4: \\left&lt;[3]\\right&gt;\nOrder 3: \\left&lt;[4]\\right&gt;\nOrder 2: \\left&lt;[6]\\right&gt;\nOrder 1: \\left&lt;[0]\\right&gt;"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/subgroups.html#cyclic-groups-rewrite",
    "href": "qmd/abstract/intro-to-groups/subgroups.html#cyclic-groups-rewrite",
    "title": "Subgroups",
    "section": "Cyclic groups (REWRITE)",
    "text": "Cyclic groups (REWRITE)\n\n\n\n\n\n\nDefinition\n\n\n\nA group H is called cyclic if it is generated by one element. We denote H\n\nH = \\langle x \\rangle = \\{x^n \\mid n \\in \\mathbb{Z}\\}\n\nx is called a generator\n\n\nFor example, (\\mathbb{Z},+)\n\n\\langle 1 \\rangle = \\{+(n,1) \\mid n\\in \\mathbb{Z}\\}\n\nBut also\n\n\\langle -1 \\rangle = \\{+(n,-1) \\mid n\\in \\mathbb{Z}\\}\n\n\n\n\n\n\n\nExample\n\n\n\nWe can find a generator of\n\n(\\mathbb{Z}/n\\mathbb{Z},+)\n\nUsing\n\n\\langle [1] \\rangle = \\{[1],[2],\\cdots,[n]\\} = \\{+(n,[1])\\mid n \\in \\{ 1,2,\\cdots,n\\}\\}\n\n\n\n\n\n\n\n\n\nCorollary\n\n\n\n(1) Assume |x| = \\infty. Then H = &lt;x^a&gt; iff a = \\pm 1\n(2) Assume |x| = n &lt; \\infty then &lt;x^a&gt; = H iff gcd(a,n) = 1\n\n\nNotice\n\n\\mathbb{Z}/6\\mathbb{Z} = \\left&lt;[1]\\right&gt;,\\left&lt;[5]\\right&gt;.\n\n\n\n\n\n\n\nExample\n\n\n\nAll the generators\n\n(\\mathbb{Z}/12\\mathbb{Z},+)\n\nWhich are\n\n\\left&lt;[1]\\right&gt;,\\left&lt;[5]\\right&gt;,\\left&lt;[7]\\right&gt;,\\left&lt;[11]\\right&gt;\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nIf H = \\left&lt;x\\right&gt; is a cyclic groups\n(1) Every subgroup of H is cyclic\n(2) If |H| = n &lt; \\infty then for each positive integer a dividing n, there is a unique subgroup of H of order \\left&lt;x^{\\frac{n}{a}}\\right&gt;\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(1) Let K \\leq H = \\left&lt;x\\right&gt;\nIf K = \\{1\\} then done. Otherwise let a = \\min\\{K&gt;0\\mid x^k\\in K\\}.\nThe claim is that K is generated by \\left&lt;x^a\\right&gt;. Suppose not. Suppose there is some x^b \\in K such that a\\not| \\,b. Thus\n\nb = aq + r \\quad 0 &lt; r &lt; a\n\nNote that x^{aq} \\in K. Meaning x^{-aq} \\in K. Thus x^{b-aq} \\in K. Thus x^r \\in K. But because r is less than a, and we assumed a to be the smallest power of x in K, we have a contradiction. Thus every subgroup of H is cyclic.\n(2) If H has a finite order n, we use our previous proposition to note that |\\left&lt;x^\\frac{n}{a}\\right&gt;| = a.\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nAll the subgroups of \\mathbb{Z}/12\\mathbb{Z} are\nOrder 12: \\left&lt;[1]\\right&gt;\nOrder 6: \\left&lt;[2]\\right&gt;\nOrder 4: \\left&lt;[3]\\right&gt;\nOrder 3: \\left&lt;[4]\\right&gt;\nOrder 2: \\left&lt;[6]\\right&gt;\nOrder 1: \\left&lt;[0]\\right&gt;"
  },
  {
    "objectID": "qmd/abstract/intro-to-groups/subgroups.html#subsets",
    "href": "qmd/abstract/intro-to-groups/subgroups.html#subsets",
    "title": "Subgroups",
    "section": "Subsets",
    "text": "Subsets\nCyclic groups generated by x are the smallest subgroups containing x.\n\n\n\n\n\n\nProposition\n\n\n\nFor any nonempty collection of subgroups of G, the intersection of all of them is also a subgroup of G.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf A is any subset of G, then\n\n\\left&lt;A\\right&gt; = \\bigcap \\limits_{\\substack{H\\leq G\\\\ A \\subseteq H}} H\n\nI.e, the intersection of all subgroups containing A. Thus \\left&lt;A\\right&gt; is the minimal subgroup of G containing A.\n\n\nAnother way to define \\left&lt;A\\right&gt; is by using generators. Say\n\n\\overline{A} = \\left\\{ a_1^{\\varepsilon_1},a_2^{\\varepsilon_2},\\cdots,a_n^{\\varepsilon_n} \\mid n + \\mathbb{Z},\\:n\\geq0,\\:a_1\\in A,\\: \\varepsilon_i = \\pm 1\\right\\}\n\nThus \\overline{A} is the set of finite products of elements of A and inverses of these elements.\n\n\n\n\n\n\nProposition\n\n\n\nOur definitions are equal. Symbollically \n\\overline{A} = \\left&lt; A \\right&gt;\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nFirst we prove that \\overline{A} is a group. Then\n\\overline{A} \\not= \\varnothing because A always has the identity.\nif a,b \\in A, then\n\\begin{align*}\na &= a_1^{\\varepsilon_1}a_2^{\\varepsilon_2}\\cdots a_n^{\\varepsilon_n}\\\\\nb &= b_1^{\\delta_1}b_2^{\\delta_2}\\cdots a_n^{\\delta_n}\n\\end{align*}\nthen\n\na(b^{-1}) = a_1^{\\varepsilon_1}a_2^{\\varepsilon_2}\\cdots a_n^{\\varepsilon_n}a_n^{\\delta_n}\\cdots b_2^{\\delta_2}b_1^{\\delta_1} \\in A\n\nThus\n\n\\overline{A} \\leq G\n\nSo \\left&lt;A\\right&gt; \\subseteq \\overline{A}.\nNow we must show \\overline{A} \\subseteq \\left&lt;A\\right&gt;. This is true because \\left&lt;A\\right&gt; is closed under multiplication and inverses.\n\n\n\n\n\n\n\n\nExample\n\n\n\nThe subgroup\n\n\\left&lt;(12),(13)(24)\\right&gt; \\leq S_4\n\nFun fact, (it’s not) the subset is isomorphic to D_8"
  },
  {
    "objectID": "qmd/abstract/quotient-groups/quotient-group.html#definitions",
    "href": "qmd/abstract/quotient-groups/quotient-group.html#definitions",
    "title": "Quotient groups",
    "section": "Definitions",
    "text": "Definitions\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\varphi be a homomorphism from G to H. The fibers of \\varphi are the sets of elements of G that map to single elements of H.\n\n\nFor example, given the groups G = (\\mathbb{Z},+) and H = Z_n be the cyclic group of order n under multiplication. We can then define the map\n\n\\varphi \\colon \\mathbb{Z} \\to Z_n\n\n\na \\rightarrowtail x^a\n\nThe fiber of \\varphi over x^a is therefore\n\nPut fiber\n\nThe homomorphism \\varphi has two fibers, we will notate X_{[1]} as the fiber over [1], and X_{[0]} as the fiber over [0]. Then\n\nX_{[1]} = \\{1,3,5,\\cdots\\} \\quad X_{[0]} = \\{0,2,4,\\cdots\\}\n\nThe set of fibers of \\varphi forms a group. We define our group operation as follows\n\nX_{a}X_{b} = X_{ab}\n\nWhere X_{ab} is the fiber over the product ab. This is called the quotient group of \\varphi. Below is a formal proof the collection of fibers forms a group.\n\n\n\n\n\n\nProof [Finish]\n\n\n\n\n\nProve the set of fibers of \\varphi is a group.\n\n\n\nWe can now look at some properties of homomorphisms\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the kernal of \\varphi is the set\n\n\\ker\\varphi = \\{g \\in G \\mid \\varphi(g) = e_H\\}\n\n\n\nThe kernal is therefore the fiber over e_H, the identity element of H.\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the image of \\varphi is the set\n\n\\text{im}\\,\\varphi = \\{\\varphi(g) \\mid g \\in G\\}\n\n\n\nThe kernal and image of \\varphi are subgroups of G and H respectivly.\n\n\n\n\n\n\nProposition\n\n\n\nIf G,H are groups, and \\varphi \\colon G \\to H is a homomorphism, then\n\n\\ker \\varphi \\leq G \\: \\text{ and } \\: \\text{im} \\,\\varphi \\leq H\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nSince e_G is such that \\varphi(e_G) = e_H, we know \\ker \\varphi \\not = \\varnothing. If x,y are in the \\ker \\varphi, then xy^{-1} is in the kernal, thus \\ker \\varphi is a subgroup of G.\nNow take the image of \\varphi. Note\n\n\\varphi(e_G) = e_H \\in \\text{im } \\varphi \\implies \\text{im } \\varphi \\not = \\varnothing\n\nGiven x,y \\in \\text{im } \\varphi, we know that xy^{-1} is in \\text{im } \\varphi. Thus \\text{im } \\varphi \\leq H.\n\n\n\nAnd we can now provide a formal definition for a quotient group\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\varphi \\colon G \\to H be a surjective homomorphism with \\ker K. The quotient group G/K is the group whose elements are the fibers of \\varphi with group operation inherited from H.\n\n\nThis definition requires knowing \\varphi explictly. You can however define the group operation on fibers in terms of representatives.\n\n\n\n\n\n\nProposition\n\n\n\nLet \\varphi \\colon G \\to H be a homomorphism with \\ker k. Let X \\in G/K be the fiber above a \\in H. X = \\varphi^{-1}(a). Then for any u \\in X,\n\nX = \\{uk\\mid k \\in K\\}\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nLet u \\in X, then \\varphi(u) = a. Let\n\nuK = \\{uk \\mid k \\in K\\}\n\nWe want to show that X is equal to uK. We will first show that uK is a subset of X. For k \\in K \n\\varphi(uk) = \\varphi(u)\\varphi(k) = \\varphi(u) = a\n\nThus uK \\subseteq X. Now to show that X \\subseteq uK, let g \\in X and k = u^{-1}g. \n\\varphi(k) = \\varphi(u^{-1})\\varphi(g) = a^{-1}a = e_H\n\nThus k \\in \\ker \\varphi since k = u^{-1}g. Thus X \\subseteq uK\n\n\nThus we can write any elements of the quoitent group as the set uk for all k \\in K.\n\n\n\n\n\n\nDefinition\n\n\n\nFor any N \\leq G and g \\in G,\n\ngN = \\{gn\\mid n \\in N\\}\n\nThis is a (left) coset of N in G.\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nLet \\varphi \\colon G \\to H homomorphism with a kernal K. The set of cosets of K in G with operation uK \\star vK = (uv)K forms a group.\n\n\n\n\n\n\n\n\nProof\n\n\n\nLet X,Y \\in G/K, and Z = XY \\in G/K. Then for some a,b \\in H, \nX = \\varphi^{-1}(a)\\: Y = \\varphi^{-1}(b)\n\nThis implies Z = \\varphi^{-1}(ab). Let u,v be representations of X,Y respectivly. We want to show that uv \\in Z. Which is only true If\n\n\\varphi(uv) \\in ab \\leftrightarrow \\varphi(u)\\varphi(v) = ab\n\nWhich is true! Thus by our previous proposition Z = uvK.\n\n\nYou cannot define G/N for any N \\leq G.\n\n\n\n\n\n\nTheorem\n\n\n\nYou cannot define G/N for any N \\leq G.\n\n\n\n\n\n\n\n\nProof\n\n\n\nLet \\varphi \\colon G \\to H be a homomorphism with Kernal K. Then\n\ngKg^{-1} \\subseteq K \\; \\forall g \\in G\n\n\\varphi(gkg^{-1}) = e\n\n\nIf we have a subgroup N of $G such that gNg^{-1} \\subseteq N for all g \\in G, then multiplication in G/N is well defined.\n\n\n\n\n\n\nTheorem\n\n\n\nG/N \\times G/N \\rightarrow G/N\n (xN, xG)\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nIf x_1N = x_2N, y_1N=y_2N then x_1^{-1}x_2 \\in N and y_1^{-1}y_2 \\in N"
  },
  {
    "objectID": "qmd/abstract/intro.html#abstract",
    "href": "qmd/abstract/intro.html#abstract",
    "title": "Intro",
    "section": "",
    "text": "Its like algebra but more abstract ig idk"
  },
  {
    "objectID": "qmd/abstract/quotient-groups/quotient-group.html#today",
    "href": "qmd/abstract/quotient-groups/quotient-group.html#today",
    "title": "Quotient groups",
    "section": "Today",
    "text": "Today\nDefine \nb = g \\dot a \\rightarrowtail gG_a\n\nFINISH PROOF LATER"
  },
  {
    "objectID": "qmd/abstract/quotient-groups/quotient-group.html#orbit-stabalizers",
    "href": "qmd/abstract/quotient-groups/quotient-group.html#orbit-stabalizers",
    "title": "Quotient groups",
    "section": "Orbit stabalizers",
    "text": "Orbit stabalizers\nDefine \nb = g \\cdot a \\rightarrowtail gG_a\n\n\n\n\n\n\n\nDefinition\n\n\n\nThe action of G on a is called transitive if there is only one orbit\n\n\n\n\n\n\n\n\nExample\n\n\n\nD_8 acts transitivly on each of it’s 4 vertices.\n\n\nIf G acts trivially on A, then G_a = G,\\, \\forall a \\in A. Then the orbits\n\norb(a) = \\{b \\mid b = g \\cdot a \\text{ for } g \\in G\\} = a.\n\nThis is an example of a non-transitive action. If however\n\nG = S_n\n\nThen there always exists a g \\in G such that a = g \\cdot b.\nLet (G,\\diamond) be a group, and A = G. Define\n\ng \\cdot a = g \\diamond a\n\nthen\n\n(1) g_2 \\cdot (g_1 \\cdot a) = g_2 g_1 a\n\n\ne\\cdot a = ea = a\n\nLet G be a group such that H \\leq G\n\nA = \\{gH\\mid g\\in G\\}\n\nDefine g \\cdot aH = gaH.\nSuppose A has n elements\n\na_1H \\dots a_nH\n\nWe can describe \\sigma_g as \\sigma_g(i) = j iff ga_i = a_j\n\n\n\n\n\n\nExample\n\n\n\nLet G = D_8, and H = \\langle s \\rangle. Then\n\nA = \\{eH,rH,r^2H,r^3H\\}\n\nLabel the four elements 1,2,3,4 respectivly. We can compute \\sigma_s\n\\begin{align*}\n&s\\cdot eH = sH = H\\quad &\\sigma_s(1) = 1\\\\\n&s\\cdot rH = srH = r^3H\\quad &\\sigma_s(2) = 4\\\\\n&s\\cdot r^2H = sr^2H = r^2H\\quad &\\sigma_s(3) = 3\\\\\n&s\\cdot r^3H = sr^3H = rH\\quad &\\sigma_s(4) = 2\n\\end{align*}\nThus \\sigma_s = (24). Similarly \\sigma_r(1234).\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nLet G be a group H \\leq G, A = \\{gh\\mid g \\in G\\}. Let G act on A by left multiplication.\n\nG acts transitivly on A\nThe stabalizer of 1H \\in A in G is H\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n(1) Let aH,bH be elements of A. Let g = ba^{-1}.\n\ng\\cdot aH = gaH = ba^{-1}aH = bH\n\nThus orb(aH) = A so the group action is transitive.\n(2) The stabalizer of 1H is\n\n\\{g\\in G \\mid g \\cdot 1H = 1H\\} = \\{g \\in G \\mid gH = H\\} = H\n\n(3) The kernal of the action\n\\begin{align*}\n\\ker(A) &=\\{g \\in G \\mid gxH = xH \\quad \\forall x \\in G\\}\\\\\n&= \\{g \\in G \\mid x^{-1}gxH = H\\quad \\forall x \\in G\\}\\\\\n&= \\{g \\in G \\mid x^{-1}gx \\in H \\quad \\forall x \\in G\\}\\\\\n&= \\{g \\in G \\mid g \\in xHx^{-1} \\quad x \\in G\\}\\\\\n&= \\bigcap_{x\\in G} xHx^{-1}\n\\end{align*}\n\n\n\n\n\n\n\n\nCorollary\n\n\n\nEvery group is isomorphic to a subgroup of some symmetric group. If |G| = n then G is isomorphic to a subgroup of S_n.\n\n\n\n\n\n\n\n\nProof\n\n\n\nLet H = 1. Take the permutation representatives\n\n\\varphi \\colon G \\to S_g\n\nBy the previous theorem, \\ker(\\varphi) is contained in H, meaning \\ker(\\varphi) = e. By the first isomorphism theorem,\n\ng \\cong G/\\ker(\\varphi) \\cong \\text{im}(\\varphi) \\leq S_G\n\n\n\n\n\n\n\n\n\nCorollary\n\n\n\nIf G is a finite group of order n, and p is the smallest prime dividing n, then any subgroup of index p is normal."
  },
  {
    "objectID": "qmd/abstract/quotient-groups/quotient-group.html#where-x_ab-is-the-fiber-over-the-product-ab.-this-is-called-the-quotient-group-of-varphi.",
    "href": "qmd/abstract/quotient-groups/quotient-group.html#where-x_ab-is-the-fiber-over-the-product-ab.-this-is-called-the-quotient-group-of-varphi.",
    "title": "Quotient groups",
    "section": "Where X_{ab} is the fiber over the product ab. This is called the quotient group of \\varphi.",
    "text": "Where X_{ab} is the fiber over the product ab. This is called the quotient group of \\varphi.\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the kernal of \\varphi is the set\n\n\\ker\\varphi = \\{g \\in G \\mid \\varphi(g) = e_H\\}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\varphi \\colon G \\to H is a homomorphism, the image of \\varphi is the set\n\n\\text{im}\\,\\varphi = \\{\\varphi(g) \\mid g \\in G\\}\n\n\n\n\n\n\n\n\n\nProposition\n\n\n\nIf H,G are groups, \\varphi \\colon G \\to H is a homomorphism, then\n\n\\ker \\varphi \\leq G \\: \\text{ and } \\: \\text{im} \\leq H\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nSince e_G is such that \\varphi(e_G) = e_H, we know \\ker \\varphi \\not = \\varnothing. If x,y are in the \\ker \\varphi, then xy^{-1} is in the kernal, thus \\ker \\varphi is a subgroup of G.\nNow take the image of \\varphi. Note\n\n\\varphi(e_G) = e_H \\in \\text{im} \\varphi \\implies \\text{im} \\varphi \\not = \\varnothing\n\nGiven x,y \\in \\text{im} \\varphi, we know that xy^{-1} is in \\text{im} \\varphi. Thus \\text{im} \\varphi \\leq H.\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\varphi \\colon G \\to H be a surjective homomorphism with \\ker k. The quotient group G/K is the group whose elements are the fibers of \\varphi with group operation inherited from H.\n\n\nThis definition requires knowing \\varphi explictly. You can however define the group operation on fibers in terms of representatives.\n\n\n\n\n\n\nProposition\n\n\n\nLet \\varphi \\colon G \\to H be a homomorphism with \\ker k. Let X \\in G/K be the fiber above a \\in H. X = \\varphi^{-1}(a). Then for any u \\in X,\n\nX = \\{uk\\mid k \\in K\\}\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nLet u \\in X, then \\varphi(u) = a. Let\n\nuK = \\{uk \\mid k \\in K\\}\n\nWe want to show that X is equal to uK. We will first show that uK is a subset of X. For k \\in K \n\\varphi(uk) = \\varphi(u)\\varphi(k) = \\varphi(u) = a\n\nThus uK \\subseteq X. Now to show that X \\subseteq uK, let g \\in X and k = u^{-1}g. \n\\varphi(k) = \\varphi(u^{-1})\\varphi(g) = a^{-1}a = e_H\n\nThus k \\in \\ker \\varphi since k = u^{-1}g. Thus X \\subseteq uK\n\n\nThus we can write any elements of the quoitent group as the set uk for all k \\in K.\n\n\n\n\n\n\nDefinition\n\n\n\nFor any N \\leq G and g \\in G,\n\ngN = \\{gn\\mid n \\in N\\}\n\nThis is a (left) coset of N in G.\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nLet \\varphi \\colon G \\to H homomorphism with a kernal K. The set of cosets of K in G with operation uK \\star vK = (uv)K forms a group.\n\n\n\n\n\n\n\n\nProof\n\n\n\nLet X,Y \\in G/K, and Z = XY \\in G/K. Then for some a,b \\in H, \nX = \\varphi^{-1}(a)\\: Y = \\varphi^{-1}(b)\n\nThis implies Z = \\varphi^{-1}(ab). Let u,v be representations of X,Y respectivly. We want to show that uv \\in Z. Which is only true If\n\n\\varphi(uv) \\in ab \\leftrightarrow \\varphi(u)\\varphi(v) = ab\n\nWhich is true! Thus by our previous proposition Z = uvK.\n\n\nYou cannot define G/N for any N \\leq G.\n\n\n\n\n\n\nTheorem\n\n\n\nYou cannot define G/N for any N \\leq G.\n\n\n\n\n\n\n\n\nProof\n\n\n\nLet \\varphi \\colon G \\to H be a homomorphism with Kernal K. Then\n\ngKg^{-1} \\subseteq K \\; \\forall g \\in G\n\n\\varphi(gkg^{-1}) = e\n\n\nIf we have a subgroup N of $G such that gNg^{-1} \\subseteq N for all g \\in G, then multiplication in G/N is well defined.\n\n\n\n\n\n\nTheorem\n\n\n\nG/N \\times G/N \\rightarrow G/N\n (xN, xG)\n\n\n\n\n\n\n\n\n\nProof\n\n\n\nIf x_1N = x_2N, y_1N=y_2N then x_1^{-1}x_2 \\in N and y_1^{-1}y_2 \\in N"
  },
  {
    "objectID": "qmd/abstract/quotient-groups/quotient-group.html#sylow-theorem",
    "href": "qmd/abstract/quotient-groups/quotient-group.html#sylow-theorem",
    "title": "Quotient groups",
    "section": "Sylow theorem",
    "text": "Sylow theorem\nRecall that Lagranges theorem tells you that the order of a subgroup divides the order of a group. This does not guarentee the existance of a subgroup H_d for every divisor d of a group.\nWe start with the following Lemma.\n\n\n\n\n\n\nLemma\n\n\n\nIf G is a finite abelian group, and p is a prime dividing |G| then G contains an element of order p.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nIf G is a finite abelian group, and p is a prime dividing |G| then G contains an element of order p.\nUse induction on |G|. We know that x \\not = e. We have the base case p = |G|. Thus \\exists x, x^p = e by Lagranges theorem. Now suppose p &lt; |G|.\nIf p \\mid |x|, then |x| = pn for some n \\in \\mathbb{Z}\n\n|x^n| = \\frac{pn}{\\gcd(n,pn)} = \\frac{pn}{n} = p\n\nThus x has order p. If p \\not \\mid |x|, then let \\langle x \\rangle = N. Because G is an abelian group, N \\trianglelefteq G since N \\not = \\{e\\},\n\np \\mid |G/N|\n\nThus G/N contains an element of order p. Using the induction hypothesis \n|y^p| = \\frac{|y|}{p}\n\n\n\n\nNow we get some tricky Definitions\n\n\n\n\n\n\nDefinition\n\n\n\nLet G be a group and p be a prime. A group of order p^\\alpha for \\alpha \\geq 0 is called a p-group.\nA subgroup of a p-group is called a p-subgroup.\nIf G is a group of order mp^\\alpha where p \\nmid m, then a subgroup of order p^\\alpha is called a Sylow p-subgroup\n\n\nLet G be a group. The set of Sylow p-subgroups is denoted\n\nSyl_p(G)\n\nAnd the number of Sylow p-subgroups\n\nn_p(G)\n\nSylow had three major theorems in Abstract Algebra relating to these Sylow p-subgroups\n\n\n\n\n\n\nTheorem (Sylow 1)\n\n\n\nLet G be a group of order mp^\\alpha where p is a prime not dividing m, then there exists a Sylow p-subgroup.\n\n\n\n\n\n\n\n\nTheorem (Sylow 2)\n\n\n\nIf P is a Sylow p-subgroup of G and Q is any p-subgroup of G\n\n\\exists g \\in G \\mid Q \\leq gPg^{-1}\n\nIn particular, any two Sylow p-subgroups are conjugate if Q is a Sylow p-subgroup \\exists g such that Q = gPg^{-1}.\n\n\n\n\n\n\n\n\nTheorem (Sylow 3)\n\n\n\nThe number of Sylow p-subgroups of G is of the form 1 + kp, i.e.\n\nn_p(G) = 1 \\mod p\n\nFuthermore, n_p(G) = [G \\colon N_g(p)] and n_p(G) \\mid m.\n\n\nWe need only prove the first theorem however.\n\n\n\n\n\n\nProof (Sylow 1)\n\n\n\n\n\nWe start our proof using induction on |G|.\nFor our base case, if |G| = 1, there is nothing to prove. Assume (for the induction hypothesis), Sylow subgroups exist for all groups smaller than |G|.\nIf p \\mid |Z(G)|, by lemma Z(G) has an element of order p and thus a subgroup of order p. Call this subgroup N.\nLet \\overline{G} = G/N. Note\n\n\\frac{|G|}{|N|} = \\frac{p^{\\alpha}m}{p} = \\frac{p^{\\alpha - 1}}{m}.\n\nSo |\\overline{G}| = p^{\\alpha - 1}m. By the induction hypothesis, \\overline{G} has a subgroup of order p^{\\alpha + 1}. Call this subgroup \\overline{P}. By the correspondence isomorphism theorem, let P be such that P / N = \\overline{P}. Note\n\n|P| = |P/N| |N| = p^{\\alpha - 1}p = p^{\\alpha}\n\nSo P is a Sylow p-subgroup of G.\nIf p\\nmid{}|Z(G)|, let g_1\\dots{}g_r be representatives of distinct, non-central congruancy classes of G. Then\n\n|G| = |Z(G)| + \\sum\\limits^r_{i=1}[G \\colon C_G(g_i)]\n\nNote that\n\\forall i,\\,p \\mid [G \\colon C_G(g_i)] \\implies p \\mid \\sum\\limits^r_{i=1}[G \\colon C_G(g_i)]\nWould imply p \\mid Z(G) which we know is false. So therefore there exists some i such that p \\nmid [G \\colon C_G(g_i)]. For this i, let H = C_g(g_i).\n\n[G \\colon C_G(g_i)] = \\frac{|G|}{|C_G(g_i)|} = \\frac{|G|}{|H|}\n\nSo H = p^{\\alpha}k for some k such that p \\nmid k. Since g_i \\not = Z(G), C_G(g_i) \\not = G. Therefore k &lt; m. Because |H| &lt; |G| by induction H has a sylow p-subgroup |p| = p^{\\alpha}, so P is a Sylow p-subgroup of G."
  },
  {
    "objectID": "qmd/abstract/quotient-groups/group-actions.html",
    "href": "qmd/abstract/quotient-groups/group-actions.html",
    "title": "Orbit stabalizers",
    "section": "",
    "text": "Group actions are vital to understanding and constructing quotient groups.\n\n\n\n\n\n\nDefinition\n\n\n\nA group action of a group (G,\\star) on a set A is a map G \\times A \\to A (denoted g \\cdot a) such that for all g_1, g_2 \\in G and a \\in A\n(1) g_1 \\cdot (g_2 \\cdot a) = (g_1 \\star g_2) \\cdot a, and\n(2) e_G \\cdot a = a\nWhere e_G is the identity element of G.\n\n\nIt is common for g \\cdot a to be abbreviated ga. This may be confusing at times, as (g_1 \\star g_2) \\cdot a above could be abbreviated as g_1g_2a, so discretion is required.\nLet G be a group acting on the set A. For every g \\in G we have a map defined\n\n\\sigma_g \\colon A \\to A\n\n\n\\sigma_g(a) = g \\cdot a.\n\n\n\n\n\n\n\nProposition\n\n\n\nGiven the above definition for \\sigma_g,\n(1) For each fixed g \\in G, \\sigma_g is a permutation of A\n(2) The map G \\to S_A defined by g \\rightarrowtail \\sigma_g is a homomorphism.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(1) We prove \\sigma_g is a permutation of A by showing\n\n\\sigma_g \\colon A \\times A\n\nIs a bijection. We prove this by showing there exists a two-sided inverse \\sigma_{g^{-1}}.\n\\begin{align*}\n\\sigma_{g^{-1}}(\\sigma_g(a)) &= g^{-1}\\cdot(g\\cdot a)\\\\\n&= (g^{-1}\\star g) \\cdot a\\\\\n&= e_G \\cdot a\\\\\n&= a\n\\end{align*}\nSince g was arbitrary, we may replace g with g^{-1} to obtain another identity map on A. Thus \\sigma_g is a bijection, and a permutation.\n(2) To show the map a homomorphism, we first define \\varphi \\colon G \\to S_A, such that\n\n\\varphi(g) = \\sigma_g.\n\nThen through a series of equivalances\n\\begin{align*}\n\\varphi(g_1 \\star g_2)(a) &= \\sigma_{g_1g_2}(a)\\\\\n&= (g_1 \\star g_2) \\cdot a\\\\\n&= g_1 \\cdot (g_2 \\cdot a)\\\\\n&= \\sigma_{g_1}(\\sigma_{g_2}(a))\\\\\n&= (\\varphi(g_1) \\circ \\varphi(g_2))(a)\n\\end{align*}\nThus the map is a homomorphism.\n\n\n\nA group action of G on a set A intuitvly means that every element of G acts as a permutation on A, in some manner consistent with the group operation of G. The homomorphism from G to S_A given above is called the permutation representation associated to the given group action.\nThe definition given above could be more precisely called the left action as the group elements are left to the set elements. A right action could be defined identically."
  },
  {
    "objectID": "qmd/abstract/quotient-groups/group-actions.html#introduction",
    "href": "qmd/abstract/quotient-groups/group-actions.html#introduction",
    "title": "Group actions",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\nDefinition\n\n\n\nA group action of a group G on a set A is a map G \\times A \\to A (denoted g \\cdot a) such that for all g_1, g_2 \\in G and a \\in A\n(1) g_1 \\cdot (g_2 \\cdot a) = (g_1 g_2) \\cdot a, and\n(2) e_G \\cdot a = a\nWhere e_G is the identity element of G.\n\n\nWe usually refer to G as a group acting on a set A, and commonly write ga in place of g \\cdot a."
  },
  {
    "objectID": "qmd/abstract/quotient-groups/group-actions.html#groups",
    "href": "qmd/abstract/quotient-groups/group-actions.html#groups",
    "title": "Group actions",
    "section": "Groups",
    "text": "Groups\n\n\n\n\n\n\nDefinition\n\n\n\nA group is an ordered pair (G,\\star) where G is a set and \\star is an associative binary relation on that set, such that\n\nThere exists an element e in G known as the identity such that for all a \\in G,\n\n\na \\star e = e \\star a = a\n\n\nFor each a \\in G, there exists an element a^{-1} \\in G called the inverse of a, such that\n\n\na \\star a^{-1} = a^{-1} \\star a = e\n\n\n\nWe call a group abelian if the binary operation \\star is commutative on G.\n\n\n\n\n\n\nExample\n\n\n\nIs the ordered pair (\\mathbb{Z},+) a group?\nWe know the addition operator is associative, so we just need to prove that there exists an identity element in G, and an inverse element for each a \\in \\mathbb{Z}.\n\nThe element 0 is the identity of (\\mathbb{Z},+), as for every a \\in \\mathbb{Z}\n\n\na + 0 = 0 + a = a\n\n\nFor each a \\in G, a^{-1} = -a, because\n\n\na + (-a) = (-a) + a = 0\n\nTherefore (\\mathbb{Z},+) is a group.\n\n\nGroups have the following properties\n\n\n\n\n\n\nProposition 1.1.1\n\n\n\nGiven a group G under an binary operation \\star, the following hold\n(1) The identity element e of G is unique.\n(2) For each a \\in G, there exist a unique a^{-1}.\n(3) (a^{-1})^{-1} = a for all a \\in G.\n(4) (a \\star b)^{-1} = b^{-1} \\star a^{-1} for all a,b \\in G.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(1) Suppose there exists two identity elements e_1 and e_2. By the definition of an identity element, e_1 \\star e_2 = e_1 and e_1 \\star e_2 = e_2. Thus e_1 = e_2, so the identity is unique.\n(2) Suppose b and c are both inverses of a and let e be the identity of G. By the definition of an inverse element a \\star b = e and c \\star a = e. Note the following relation\n\nc = c \\star e = c \\star (a \\star b) = (c \\star a) \\star b = e \\star b = b\n\n(3) Rather straightforwardly a \\star a^{-1} = a^{-1} \\star a = e. So by the definition of an inverse element, (a^{-1})^{-1} = a.\n(4) Let c = (a \\star b)^{-1}. Therefore (a \\star b) \\star c = e. Using algebra\n\\begin{align*}\na^{-1} \\star (a \\star b) \\star c &= a^{-1} \\star e\\\\\n(a^{-1} \\star a) \\star (b \\star c) &= a^{-1}\\\\\n(b \\star c) &= a^{-1}\\\\\nc &= b^{-1} \\star a^{-1}\n\\end{align*}\n\n\n\nAdditionally\n\n\n\n\n\n\nProposition 1.1.2\n\n\n\nLet G be a group under an binary operation \\star, and a,b \\in G. The equations a \\star x = b and y \\star a = b have unique solutions for all x,y \\in G. In particular\n(1) If a \\star u = a \\star v then u = v\n(2) If u \\star b = v \\star b then u = v\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(1) The existence of a solution to a \\star x = b is given by x = a^{-1} \\star b. This is unique as proved in the previous proposition.\n(2) The proof is nearly identical for (y \\star a) = b, where y = b \\star a^{-1}.\n\n\n\nBecause it is often tedious to write the full notation of a group, it is often abbreviated. For example, the group (G,\\star) is commonly wrote as “the group G” where the operation is implied.\nAdditionally, we often write ab as an abbreviation for a \\star b. Because group operations are associative, we write a^n to abbreviate a\\star \\cdots \\star a (n times)."
  },
  {
    "objectID": "qmd/abstract/quotient-groups/group-actions.html#order",
    "href": "qmd/abstract/quotient-groups/group-actions.html#order",
    "title": "Group actions",
    "section": "Order",
    "text": "Order\nAs always, we start with a definition.\n\n\n\n\n\n\nDefinition\n\n\n\nFor a group G and x \\in G, the order of x is the smallest positive integer n such that x \\star x \\star \\cdots \\star x (n times) is equal to the identity element e.\n\n\nNote that we notate x \\star x \\star x \\cdots as x^n. We also denote the order of x as |x|. This is an abuse of notation with both cardinailty and absolute value, so it is often neccessary to clarify the meaning of the bars.\nFor any group G, it’s clear that |e| = 1. If x^n \\not = e for any n, we say that x has order infinity. For example, given the group (\\mathbb{Z}/15\\mathbb{Z},\\times), the element 2 has an order of 4.\n\n2 = 2,\\quad 2^2 = 4,\\quad 2^3 = 8,\\quad 2^4 = 16 = 1 = e"
  },
  {
    "objectID": "qmd/measure/Measure.html",
    "href": "qmd/measure/Measure.html",
    "title": "Lebesgue Measure",
    "section": "",
    "text": "Measures are used to formalize notions of length, area, and volume and expand the notions into more cases. There are many ways to define a measure functions, but they each satisfy the following properties.\n\n\n\n\n\n\nNote\n\n\n\nWe will define \\ell(I_k) to be the length of the interval. For example \\ell([a,b]) = b - a\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA measure is a function from the measurable sets \\mathscr{M} to the non-negative real numbers m \\colon \\mathscr{M} \\to \\mathbb{R}_{\\geq 0} such that the following hold.\n\nThe measure of an interval is its length. Meaning the measure of every nonempty interval I is \nm(I) = \\ell(I)\n\nMeasure is translation invariant. Meaning that if E is a measurable set, than E + y = \\{x+y | x \\in E\\} is also measurable and\n\n\nm(E) = m(E + y)\n\n\nMeasure is countably additive over a disjoint union of sets. Meaning that if \\{E_k\\}_{k=1}^\\infty if a collection of disjoint measurable sets, then\n\n\nm\\left(\\bigcup_{k=1}^\\infty E_k \\right) = \\sum_{k=1}^{\\infty}m(E_k)\n\n\n\nIn order to construct the Lebesgue measure can, we define a function m^* \\colon \\mathcal{P}(\\mathbb{R}) \\to \\mathbb{R} called the outer measure. We then define a collection \\mathcal{M} such that m^* restricted to \\mathscr{M} fufills our requirements of being measure as defined above.\n\n\n\n\n\n\nDefinition\n\n\n\nFor any subset E \\subseteq \\mathbb{R} A Lebesgue outer measure on E is defined\n\nm^*(E) = inf\\left\\{ \\sum_{k=1}^{\\infty} \\ell(I_k) \\right\\}\n\nWhere E \\subseteq \\bigcup_{k=1}^\\infty I_k\n\n\nIn English, the Lebesgue Outer Measure is composed of the least collection of intervals which cover E without overlapping. The total of the outer measure may overestimate E however, as the intervals may contain points that aren’t in E.\n\n\n\n\n\n\nDefinition\n\n\n\nA set E \\subseteq \\mathbb{R} is measurable if and only if for any A \\subseteq \\mathbb{R}\n\nm^*(A) = m^*(A \\cap E) + m^*(A \\cap E^c)"
  },
  {
    "objectID": "qmd/geometry/geometry.html#wednesday-april-3rd",
    "href": "qmd/geometry/geometry.html#wednesday-april-3rd",
    "title": "Geometry",
    "section": "Wednesday April 3rd",
    "text": "Wednesday April 3rd"
  },
  {
    "objectID": "qmd/abstract/quotient-groups/group-actions.html#group-actions",
    "href": "qmd/abstract/quotient-groups/group-actions.html#group-actions",
    "title": "Orbit stabalizers",
    "section": "",
    "text": "Group actions are vital to understanding and constructing quotient groups.\n\n\n\n\n\n\nDefinition\n\n\n\nA group action of a group (G,\\star) on a set A is a map G \\times A \\to A (denoted g \\cdot a) such that for all g_1, g_2 \\in G and a \\in A\n(1) g_1 \\cdot (g_2 \\cdot a) = (g_1 \\star g_2) \\cdot a, and\n(2) e_G \\cdot a = a\nWhere e_G is the identity element of G.\n\n\nIt is common for g \\cdot a to be abbreviated ga. This may be confusing at times, as (g_1 \\star g_2) \\cdot a above could be abbreviated as g_1g_2a, so discretion is required.\nLet G be a group acting on the set A. For every g \\in G we have a map defined\n\n\\sigma_g \\colon A \\to A\n\n\n\\sigma_g(a) = g \\cdot a.\n\n\n\n\n\n\n\nProposition\n\n\n\nGiven the above definition for \\sigma_g,\n(1) For each fixed g \\in G, \\sigma_g is a permutation of A\n(2) The map G \\to S_A defined by g \\rightarrowtail \\sigma_g is a homomorphism.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(1) We prove \\sigma_g is a permutation of A by showing\n\n\\sigma_g \\colon A \\times A\n\nIs a bijection. We prove this by showing there exists a two-sided inverse \\sigma_{g^{-1}}.\n\\begin{align*}\n\\sigma_{g^{-1}}(\\sigma_g(a)) &= g^{-1}\\cdot(g\\cdot a)\\\\\n&= (g^{-1}\\star g) \\cdot a\\\\\n&= e_G \\cdot a\\\\\n&= a\n\\end{align*}\nSince g was arbitrary, we may replace g with g^{-1} to obtain another identity map on A. Thus \\sigma_g is a bijection, and a permutation.\n(2) To show the map a homomorphism, we first define \\varphi \\colon G \\to S_A, such that\n\n\\varphi(g) = \\sigma_g.\n\nThen through a series of equivalances\n\\begin{align*}\n\\varphi(g_1 \\star g_2)(a) &= \\sigma_{g_1g_2}(a)\\\\\n&= (g_1 \\star g_2) \\cdot a\\\\\n&= g_1 \\cdot (g_2 \\cdot a)\\\\\n&= \\sigma_{g_1}(\\sigma_{g_2}(a))\\\\\n&= (\\varphi(g_1) \\circ \\varphi(g_2))(a)\n\\end{align*}\nThus the map is a homomorphism.\n\n\n\nA group action of G on a set A intuitvly means that every element of G acts as a permutation on A, in some manner consistent with the group operation of G. The homomorphism from G to S_A given above is called the permutation representation associated to the given group action.\nThe definition given above could be more precisely called the left action as the group elements are left to the set elements. A right action could be defined identically."
  },
  {
    "objectID": "qmd/numtheo/multiples.html",
    "href": "qmd/numtheo/multiples.html",
    "title": "Multiples and Divisors",
    "section": "",
    "text": "Multiples and divisors are the most essential concepts in number theory and come up in nearly every problem."
  },
  {
    "objectID": "qmd/numtheo/multiples.html#formal-languages",
    "href": "qmd/numtheo/multiples.html#formal-languages",
    "title": "Multiples",
    "section": "Formal Languages",
    "text": "Formal Languages\nA formal language is defined by its symbols, such as quantifiers or connectives, and its syntax, rules for combining symbols. The most important class of formal language is known as first-order language, denoted \\mathcal{L}_1.\nThe symbols in a first-order language can be grouped into seven categories. Some authors may however chose to group the symbols into more or less categories, but the disctintion is arbitrary. These categories are\n\nConnectives - \\land, \\lor, \\implies, \\iff, \\lnot\nQuantifiers - \\forall, \\exists\nVariables - v_1,v_2,v_3 ect. A first-order language may consist of any countable amount of variables.\nConstants - c_0, c_1, c_2 ect. A first-order language may consist of any countable amount of constants.\nOperations - A first-order language can consist of any amount of countable operations (functions) f of any order.\nRelations - A first-order language can consist of any amount of countable relations p of any order.\nParentheses - Right ) and left (.\n\nMost of the time \\to will be used instead of \\implies, and \\leftrightarrow instead of \\iff, as the symbols are smaller are easier to read. For readibility sake, parenthesis occur in different sizes, or occansionally as brackets. Commas are also inserted to make formulas easier to read, but are not a formal symbol.\nNow we can begin constructing the syntax for first-order languages.\n\n\n\n\n\n\nDefinition\n\n\n\nEvery variable or constant is a term. Additionally, if f is an operator of degree n, and t_1,t_2,\\dots,t_n are terms, then f(t_1,t_2,\\dots,t_n) is a term.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf p is a relation of degree n, and t_1,t_2,\\dots,t_n are terms, then p(t_1,t_2,\\dots,t_n) is a formula.\nAdditionally, if P and Q are formulas, and x is a variable, then the expressions\n\nP \\iff Q, P \\implies Q, P \\land Q, P \\lor Q\\\\\n\\lnot P, \\forall x P, \\exists x P\n\nare also formulas.\n\n\nNote that mathematicians almost never write in unabbreviated notation. For example, the equation x + y would be wrote +(x,y), which looks silly.\nWe now can construct formulas from our symbols. Deciding truth values for these formulas is the role of a deductive system."
  },
  {
    "objectID": "qmd/numtheo/multiples.html#deductive-systems",
    "href": "qmd/numtheo/multiples.html#deductive-systems",
    "title": "Multiples",
    "section": "Deductive systems",
    "text": "Deductive systems\nA deductive system (deductive apparatus) is (usually) a set of axioms and rules of inference which are used to deduce one true statement from another. It is very common in math to use a Hilbert System, which consist of a large number of axioms, and few to no rules of inferences.\nBelow is an example of a Hilbert System which describes first-order logic.\n\n\n\n\n\n\nFOL Deductive system example1\n\n\n\nLogical Axioms\nThe first four axioms describe propositional logic, which is logic without quantifiers like \\land or \\lor.\nP1. \\phi \\rightarrow \\phi\nP2. \\phi \\rightarrow (\\psi \\rightarrow \\phi)\nP3. (\\phi \\rightarrow (\\psi \\rightarrow \\zeta)) \\rightarrow ((\\phi \\rightarrow \\psi) \\rightarrow (\\phi \\rightarrow \\zeta))\nP4. (\\lnot \\phi \\rightarrow \\lnot \\psi) \\rightarrow (\\psi \\rightarrow \\phi)\nHere, \\phi,\\psi and \\zeta refer to formulas, as constructed from our language. Thus, P1 could represent p \\rightarrow p or (p \\land q) \\rightarrow (p \\land q). This axiomitization is in no way unique, and in fact axiom P1 can be proven from P2 and P3.\nThe next three axioms allow us to manipulate quantifiers.\nQ5. \\forall x\\,(\\phi) \\rightarrow \\phi[x:=t] (Meaning t may be substituded for x in \\phi)\nQ6. \\forall x\\,(\\phi \\rightarrow \\psi) \\rightarrow (\\forall x\\,(\\phi) \\rightarrow \\forall x\\, (\\psi))\nQ7. \\phi \\rightarrow \\forall x \\,(\\phi) (where x is not free in \\phi)\nThese three axioms allow us to use the \\forall quantifier.\nFor formal systems where equality is not defined as a relation, the following two axioms are necessary.\nI8. x = x for every variable x.\nI9. (x = y) \\rightarrow (\\phi(x) = \\phi(y))\nRules of inference\nRules of inference are used to deduce a true statement from a previous. Modus ponens is typically the only used rule of inference.\nR1. Modus ponens\nModus ponens states that if p and p \\rightarrow q are true, then q is true.\n\n\nNote any connective can be formed using only \\lnot and \\rightarrow, and the exists quantifier can be defined using connectives and the for all quantifier.\nNow that we’ve defined a formal language to produce formulas, and a deduction system to define truth, we can construct a formal system."
  },
  {
    "objectID": "qmd/numtheo/multiples.html#first-order-logic",
    "href": "qmd/numtheo/multiples.html#first-order-logic",
    "title": "Multiples",
    "section": "First-order logic",
    "text": "First-order logic\nAlthough we can construct many formal systems by combining different languages with different deductive systems, the most popular formal systems belong to first-order logic, sometimes called predicate logic.\n\n\n\n\n\n\nDefinition\n\n\n\nFirst-order logic refers to a collection of formal systems composed of\n\nA first-order language\nA deductive system equivalent to the example shown above\n\n\n\nAs a concrete example, both ZF (Zermelo-Fraenkel set theory) and PA (Peano arithmetic) are theories in first-order logic. They both use a unique first-order language, and the same deductive system. So they both can be said to use first-order logic.\nWhat exactly ZF and PA are, and what a theory is, are explained in the next part.\n\n\n\n\n\n\nAlcumus - Level 16 (#33994)\n\n\n\nHow many positive and negative integers are factors of 12?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe number 12 can be factored 2^2*3^1. This gives a total of 6 factors. Including negative factors gives a total of 12 integers."
  },
  {
    "objectID": "qmd/numtheo/multiples.html#footnotes",
    "href": "qmd/numtheo/multiples.html#footnotes",
    "title": "Multiples",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis section is copied from Wikipedia almost verbatim.↩︎"
  },
  {
    "objectID": "qmd/numtheo/multiples.html#information",
    "href": "qmd/numtheo/multiples.html#information",
    "title": "Multiples and Divisors",
    "section": "Information",
    "text": "Information"
  },
  {
    "objectID": "qmd/numtheo/basenumber.html",
    "href": "qmd/numtheo/basenumber.html",
    "title": "Base Number Arithmetic",
    "section": "",
    "text": "Addition\nAddition in other bases works the exact same as base 10. We could either add the numbers directly,\n\n21_6 + 14_6 = 25_6 + 10_6 = 35_6\n\nOr convert to base 10 and preform our addition normally\n\n21_6 + 14_6 = 13_(10) + 10_(10) = 23_(10) = 35_6\n\n\n\n\n\n\n\nAlcumus - Level 16 (#33994)\n\n\n\nHow many positive and negative integers are factors of 12?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe number 12 can be factored 2^2*3^1. This gives a total of 6 factors. Including negative factors gives a total of 12 integers."
  },
  {
    "objectID": "qmd/numtheo/intro.html",
    "href": "qmd/numtheo/intro.html",
    "title": "Introduction",
    "section": "",
    "text": "This section is largely based on the book “Introduction to Number Theory” by Mathew Crawford, and uses problems from ‘Alcumus’, by the Art of Problem Solving.\nAs such, the topics in this section will have a special emphasis on competitional mathematics.\n\nTable of Contents\n1 - Primes and Composites\n2 - Multiples and Divisors\n3 - Prime Factorization\n4 - Divisor Problems\n5 - Special Numbers\n6 - Algebra With Integers\n7 - Base Numbers\n8 - Base Number Arithmetic - In progress\n9 - Units Digits\n10 - Decimals and Fractions\n11 - Introduction to.Modular Arithmetic\n12 - Divisibility Rules\n13 - Linear Congruences\n14 - Number Sense"
  },
  {
    "objectID": "qmd/numtheo/multiples.html#essential",
    "href": "qmd/numtheo/multiples.html#essential",
    "title": "Multiples and Divisors",
    "section": "Essential",
    "text": "Essential\n\n\n\n\n\n\nAlcumus - Level 16 (#33994)\n\n\n\nHow many positive and negative integers are factors of 12?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe number 12 can be factored 2^2*3^1. This gives a total of 6 factors. Including negative factors gives a total of 12 integers."
  },
  {
    "objectID": "qmd/numtheo/multiples.html#difficult",
    "href": "qmd/numtheo/multiples.html#difficult",
    "title": "Multiples and Divisors",
    "section": "Difficult",
    "text": "Difficult\n\n\n\n\n\n\nAlcumus - Level 16 (#33994)\n\n\n\nHow many positive and negative integers are factors of 12?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe number 12 can be factored 2^2*3^1. This gives a total of 6 factors. Including negative factors gives a total of 12 integers."
  },
  {
    "objectID": "qmd/numtheo/basenumberarith.html",
    "href": "qmd/numtheo/basenumberarith.html",
    "title": "Base Number Arithmetic",
    "section": "",
    "text": "Arithmetic in different bases works exactly the same, but takes some getting used to. It’s easy to forget when to carry and make compounding mistakes."
  },
  {
    "objectID": "qmd/numtheo/basenumberarith.html#review",
    "href": "qmd/numtheo/basenumberarith.html#review",
    "title": "Base Number Arithmetic",
    "section": "Review",
    "text": "Review\n\n\n\n\n\n\nAlcumus - Level 18 (#29673)\n\n\n\nFind the positive base b in which the equation 13\\cdot15=243 is valid.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nBy simply multiplying the equation out, we get a quadratic\n\n(b + 3)(b + 5) = 2b^2 + 4b + 3\n\nSimplifying to\n\n(b - 6)(b + 2) = 0\n\nSince b must be positive, b must be equal to 6."
  },
  {
    "objectID": "qmd/numtheo/basenumberarith.html#challenge",
    "href": "qmd/numtheo/basenumberarith.html#challenge",
    "title": "Base Number Arithmetic",
    "section": "Challenge",
    "text": "Challenge\n\n\n\n\n\n\nAlcumus - Level 23 (#29671)\n\n\n\nIf S, H, and E are all distinct non-zero digits less than 5 and the following is true, find the sum of the three values S, H, and E, expressing your answer in base 5.\n\n\\begin{array}{cccc}\n&S&H&E_5\\\\\n&+&H&E_5\\\\\n\\hline &S&E&S_5\\\\\n\\end{array}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nRemoving the leftmost digit gives us\n\n\\begin{array}{cccc}\n&&H&E_5\\\\\n&+&H&E_5\\\\\n\\hline &&E&S_5\\\\\n\\end{array}\n\nAssuming there is no carry on the rightmost digit, we have S = 2E and E = 2H. After some algebra we arrive at S = 4, H = 1, E = 2. Thus we have the sum 12_5"
  },
  {
    "objectID": "qmd/numtheo/multiples.html#challenge",
    "href": "qmd/numtheo/multiples.html#challenge",
    "title": "Multiples and Divisors",
    "section": "Challenge",
    "text": "Challenge"
  },
  {
    "objectID": "qmd/numtheo/multiples.html#properties",
    "href": "qmd/numtheo/multiples.html#properties",
    "title": "Multiples and Divisors",
    "section": "Properties",
    "text": "Properties\n\nTotal factors\nSay you want to find the total number of factors for an integer. Instead of hashing it out manually, there exist an easier method.\n\n\n\n\n\n\nExample\n\n\n\nFind the total number of factors to the integer 72.\n\nWe begin by finding the prime factorization of 72, in this case\n\n72 = 2^3 * 3^2.\n\nNotice that each factor of 72 contains between zero and three 2’s, and between zero and two 3’s. This gives us a total of 4 \\times 3 = 12 factors for 72.\n\n\nWe use this trick to quickly calculate the total number of factors for an integer!\n\n\n\n\n\n\nTheorem\n\n\n\nThe total factors of an integer\n\nn = p_1^{k_1} \\cdot p_2^{k_2} \\cdots p_m^{k_m}\n\nis the product (k_1 + 1)(k_2 + 1)\\cdots(k_m + 1)"
  },
  {
    "objectID": "qmd/realanal/intro.html",
    "href": "qmd/realanal/intro.html",
    "title": "Real Analysis",
    "section": "",
    "text": "Real analysis is the study of real numbers."
  },
  {
    "objectID": "qmd/realanal/simple/intpart.html",
    "href": "qmd/realanal/simple/intpart.html",
    "title": "Integration by parts",
    "section": "",
    "text": "There will often be integrals where substitution cannot simplify the integrand into one term. We can use the following as our motivating example\n\\int x e^{6x} dx\nAttempting to use a substitution, such as u = 6x gives us\n\\int ue^u\\,du\nwhich while technically simpler gets us nowhere. We need a new technique to be able to properly separate functions where substitution fails. This is where integration by parts comes in.\nLets try to use the formula to solve our example. We can choose u to be either term in our example.\nAnd voila, our integral is solved."
  },
  {
    "objectID": "qmd/realanal/simple/intpart.html#tabular-method",
    "href": "qmd/realanal/simple/intpart.html#tabular-method",
    "title": "Integration by parts",
    "section": "Tabular method",
    "text": "Tabular method\nAn easier (faster) way to do integration by parts is known as the Tabular method. The tabular method can quickly calculate repeated integration by parts.\n\n\n\n\n\n\nExample (Stop 1)\n\n\n\n\n\nThe following example will show the first ‘stop’ used in tabular integration.\nFind the solution to the following integral\n\n\\int x^2 \\sin(3x) \\, dx\n\nThis could be solved using our formula for integration by parts, but this results in a messy calculation using repeated integration by parts. In order to solve these problems faster, we will use the Tabular method.\nFirst, choose two terms to work with in the integral. We will choose x^2 and \\sin(3x). We want to choose a term that will eventually default to 0 after repeated differention. Place this term under the D in your table, and the other term under the I. Draw a plus to the left of your terms.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} x^2 \\hspace{0.25in} & \\sin(3x)\n\\end{array}\nTo begin, we will differentiate the term under our D, and integrate the term under our I, then flip the sign.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} x^2 \\hspace{0.25in} & \\sin(3x)\\\\\n- & \\hspace{0.25in} 2x \\hspace{0.25in} & \\frac{1}{3}\\cos(3x)\n\\end{array}\nRepeating this process eventually gives us a 0 in our D column. This is our first stop, meaning we don’t need any more steps.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} x^2 \\hspace{0.25in} & \\sin(3x)\\\\\n- & \\hspace{0.25in} 2x \\hspace{0.25in} & -(1/3)\\cos(3x)\\\\\n+ & \\hspace{0.25in} 2 \\hspace{0.25in} & -(1/9)\\sin(3x)\\\\\n- & \\hspace{0.25in} 0 \\hspace{0.25in} & (1/27)\\cos(3x)\\\\\n\\end{array}\nMultiply the n^{th} under the D by the (n+1)^{th} term under the I. Then add or subtract the product by the sign the the left of the D column. This is the answer to our integral.\n\n\\int x^2 \\sin (3x) \\,dx = -\\frac{1}{3}x^2\\cos(3x) + \\frac{2}{9}x\\sin(3x) - \\frac{2}{27}\\cos(3x) + C\n\nAnd we’re done!\n\n\n\n\n\n\n\n\n\nExample (Stop 2)\n\n\n\n\n\nThe following example will show the second ‘stop’ used in tabular integration.\n\n\\int x^4 \\ln x \\,dx\n\nAlthough it seems obvious we should put x^4 under the D column, we quickly realize that we cannot integrate \\ln x without integration by parts. Because of this, we have no choice but to but \\ln x under the D column. Carrying on with our calculations\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} \\ln x \\hspace{0.25in} & x^4\\\\\n- & \\hspace{0.25in} x^{-1} \\hspace{0.25in} & (1/5)x^5\n\\end{array}\nWe can quickly notice that 0 will never appear under the D column. This is where our second stop comes in. If we can easily calculate the integral of a rows product (That is, the product of terms under the D and I columns for a singular row) than we stop, and add the integral of that row to our diagonal solution.\n\n\\int x^4 \\ln x \\,dx = \\frac{1}{5}x^5\\ln x  - \\frac{1}{5} \\int x^{-1}x^5\n\nThis is formula for regular integration by parts, so unfortunately this didn’t save us any time, but we still got the right answer!\n\n\\int x^4 \\ln x \\,dx = \\frac{1}{5}x^5\\ln x  - \\frac{1}{25} x^5\n\n\n\n\n\n\n\n\n\n\nExample (Stop 3)\n\n\n\n\n\nThe following example will show the third ‘stop’ used in tabular integration.\n\n\\int e^x \\sin x \\,dx\n\nIntegrating e^x and \\sin x are both easy. I’ll choose to integrate e^x for simplicity sake.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} \\sin x \\hspace{0.25in} & e^x\\\\\n- & \\hspace{0.25in} \\cos x \\hspace{0.25in} & e^x\\\\\n+ & \\hspace{0.25in} -\\sin x \\hspace{0.25in} & e^x\\\\\n- & \\hspace{0.25in} -\\cos x \\hspace{0.25in} & e^x\n\\end{array}\nClearly this will go on forever without a 0 under our D column, or an easily integrable row. This introduces our third stop. Notice that our first and third rows only differ by a constant coefficient. When this happens, we write our diagonalization and our integral, stopping at the repeated row.\n\n\\int e^x \\sin x \\,dx = e^x \\sin x - e^x \\cos(x) - \\int e^x \\sin x \\, dx\n\nNotice how this is the same integral on the left and right hand of the equation. Moving the integral over gives us\n\n2\\int e^x \\sin x \\,dx = e^x \\sin x - e^x \\cos(x)\n\nDiving by 2\n\n\\int e^x \\sin x \\,dx = \\frac{e^x \\sin x - e^x \\cos(x)}{2}\n\nAnd we have our answer.\n\n\n\nClearly the tabular method is a huge time saver for repeated integration by parts."
  },
  {
    "objectID": "qmd/realanal/simple/intpart.html#examples",
    "href": "qmd/realanal/simple/intpart.html#examples",
    "title": "Integration by parts",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\n\nProblem\n\n\n\nEvaluate the following integral\n\n\\int \\ln x \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSolving this is a little counter intuitive seeing as it only has one term. If we let 1 be the second term however, we can evaluate with the tabular method. We pretty cleary have the integrate 1, as we can’t integrate \\ln x.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} \\ln x \\hspace{0.25in} & 1\\\\\n- & \\hspace{0.25in} \\frac{1}{x} \\hspace{0.25in} & x\n\\end{array}\nBecause the product of the second row is easy to integrate, we stop using the tabular method and compute.\n\n\\int \\ln x \\, dx = x \\ln x - \\int 1 \\, dx = x \\ln x - x + C\n\nWhich solves our integral.\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus II - 7.1.1)\n\n\n\nEvaluate the following integral\n\n\\int 4x \\cos \\left( {2 - 3x} \\right)\\,dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe have two terms, 4x and \\cos (2-3x). Its clear that differentiaing 4x will give us 0 quickly, so we begin with the tabular method.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} 4x \\hspace{0.25in} & \\cos (2-3x)\\\\\n- & \\hspace{0.25in} 4 \\hspace{0.25in} & -(1/3)\\sin (2-3x)\\\\\n+ & \\hspace{0.25in} 0 \\hspace{0.25in} & -(1/9)\\cos (2-3x)\\\\\n\\end{array}\nWe use the first stop, and get the following solution to the integral\n\n\\int 4x \\cos \\left( {2 - 3x} \\right)\\,dx = -\\frac{4x}{3}\\sin (2-3x) - \\frac{4}{9} \\cos (2-3x) + C\n\nWhich solves our integral.\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus II - 7.1.5)\n\n\n\nEvaluate the following integral\n\n\\int{{e}^{2x}}\\cos \\left( {\\frac{1}{4}x} \\right)\\,dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWithout any leads on which term to integrate, I choose to integrate cos(\\frac{1}{4}x) on a whim. You may integrate either term however, and the answer will be the same.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} e^{2x} \\hspace{0.25in} & \\cos ((1/4)x)\\\\\n- & \\hspace{0.25in} 2e^{2x} \\hspace{0.25in} & 4\\sin ((1/4)x)\\\\\n+ & \\hspace{0.25in} 4e^{2x} \\hspace{0.25in} & -16\\cos ((1/4)x)\\\\\n\\end{array}\nNotice how the product of row three is a multiple of our initial integral. This is the third stop, so we evaluate our table to get.\n\n\\int{{e}^{2x}}\\cos \\left( {\\frac{1}{4}x} \\right)\\,dx = 4e^{2x}\\sin(\\frac{1}{4}x) + 32e^{2x}\\cos(\\frac{1}{4}x) - 64\\int{{e}^{2x}}\\cos \\left( {\\frac{1}{4}x} \\right)\\,dx\n\n\n65 \\int{{e}^{2x}}\\cos \\left( {\\frac{1}{4}x} \\right)\\,dx = 4e^{2x}\\sin(\\frac{1}{4}x) + 32e^{2x}\\cos(\\frac{1}{4}x)\n\n\n\\int{{e}^{2x}}\\cos \\left( {\\frac{1}{4}x} \\right)\\,dx = \\frac{4e^{2x}\\sin(\\frac{1}{4}x) + 32e^{2x}\\cos(\\frac{1}{4}x)}{65}\n\nWhich solves our integral.\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus II - A7.1.12)\n\n\n\nEvaluate the following integral\n\n\\int 8\\arctan\\left( 2x \\right)\\,dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nBecause integrating \\arctan is the question, we will derive it instead, and integrate the 8.\n\\begin{array}{ll}\n& \\hspace{0.25in} D \\hspace{0.25in} & I\\\\\n+ & \\hspace{0.25in} \\arctan(2x) \\hspace{0.25in} & 8\\\\\n- & \\hspace{0.25in} 2/(1+4x^2) \\hspace{0.25in} & 8x\\\\\n\\end{array}\nUsing our third stop and integrating the second row, we get\n\n\\int 8\\arctan\\left(2x\\right)\\,dx = 8x\\arctan(2x) - \\int \\frac{8x}{1+4x^2}\n\nApplying a substitution \nu = 4x^2\n\nWe get \n\\int 8\\arctan\\left(2x \\right)\\,dx = 8x\\arctan(2x) - \\ln |1+4x^2| + C\n\nSolving our integral."
  },
  {
    "objectID": "qmd/realanal/simple/decomp.html",
    "href": "qmd/realanal/simple/decomp.html",
    "title": "Partial fraction decomposition",
    "section": "",
    "text": "Consider the integral shown below.\n\\int{{\\frac{{3x + 11}}{{{x^2} - x - 6}}\\,dx}}\nOur current methods will not work to evaluate the integral. There is no simple way to apply a substitution or the tabular method. However, if we break up the fraction\n\\frac{{3x + 11}}{{{x^2} - x - 6}} = \\frac{4}{x - 3} - \\frac{1}{x + 2}\nThe solution becomes trivial\n\\int{{\\frac{{3x + 11}}{{{x^2} - x - 6}}\\,dx}} = 4\\ln |x - 3| - \\ln |x + 2| + C.\nFinding ways to break up the fractions is known as partial fraction decomposition."
  },
  {
    "objectID": "qmd/realanal/simple/decomp.html#method",
    "href": "qmd/realanal/simple/decomp.html#method",
    "title": "Partial fraction decomposition",
    "section": "Method",
    "text": "Method\nWhen given an integral in the form\n\n\\int \\frac{P(X)}{Q(X)} \\, dx\n\nWhere P(x) and Q(x) are polynomials such that the degree of Q(x) is higher than the degree of P(x). We can decompose the fraction based on the factors of Q(x). There are four cases for the factors of Q(x).\n\n\n\n\n\n\nDecomposition cases\n\n\n\n\n\nCase I: Distinct linear factors\nWhen Q(x) has distinct linear factors, i.e.\n\nQ(x) = (a_1 x + b_1)(a_2 x + b_2)\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A}{a_1x + b_1} + \\frac{B}{a_2x + b_2}\n\nCase 2: Repeated linear factors\nWhen Q(x) has repeated linear factors, i.e.\n\nQ(x) = (a x + b)^k\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A_1}{ax + b} + \\frac{A_2}{(ax + b)^2} + \\cdots + \\frac{A_k}{(a x + b)^k}\n\nCase 3: Distinct quadratic factors\nWhen Q(x) has distinct quadratic factors, i.e.\n\nQ(x) = (a_1 x^2 + b_1x + c_1)(a_2 x^2 + b_2x + c_2)\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A_1 + B_1}{a_1 x^2 + b_1x + c_1} + \\frac{A_2 + B_2}{a_2 x^2 + b_2x + c_2}\n\nCase 4: Repeated quadratic factors\nWhen Q(x) has repeated quadratic factors, i.e.\n\nQ(x) = (a x^2 + bx + c)^k\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A_1x + B_1}{a x^2 + bx + c} + \\cdots + \\frac{A_kx + B_k}{(a x^2 + bx + c)^k}\n\n\n\n\nNote that Q(x) does not have one case of factors exculsivly. For example\n\nQ(x) = (a_1x+b_1)(a_2x^2 + b_2x + c_2)^2\n\nWill decompose into\n\n\\frac{P(x)}{Q(x)} = \\frac{A}{a_1x + b_1} + \\frac{Bx + C}{a_2 x^2 + b_2x + c_2} + \\frac{Dx + E}{(a_2 x^2 + b_2x + c_2)^2}\n\nNext we need a method for finding the value of the constants in the numerator.\n\n\n\n\n\n\nEvaluating constants\n\n\n\n\n\nConsider the integral from the beginning\n\n\\int \\frac{3x + 11}{x^2 - x - 6} \\,dx\n\nWe can now decompose the integrand to obtain\n\n\\frac{3x + 11}{x^2 - x - 6} = \\frac{A}{x - 3} + \\frac{B}{x + 2}\n\nThe problem is now finding values for the constants A,B which make the relation true. By cross multiplying the right side of the equation we get\n\n\\frac{3x + 11}{x^2 - x - 6} = \\frac{A(x + 2) + B(x - 3)}{(x - 3)(x + 2)}\n\nWhich simplifies to\n\n3x + 11 = A(x + 2) + B(x - 3).\n\nWe can then create a system of equations such that the above expression is always true. This method is long but will always work. The faster method (that isn’t always possible) is to find values of x such that the equation reduces. Using the faster method, we obtain\n\nx = 3 \\: : \\: 3(3) + 11 = A(3 + 2) + B(3 - 3) \\implies A = 4\\\\\nx = -2 \\: : \\: 3(-2) + 11 = A(-2 + 2) + B(-2 - 3) \\implies B = -1\n\nWhich gives us our final expression\n\n\\frac{3x + 11}{x^2 - x - 6} = \\frac{4}{x - 3} - \\frac{1}{x + 2}\n\nWhich as shown above, makes the integral trivial to solve.\n\n\\int{{\\frac{{3x + 11}}{{{x^2} - x - 6}}\\,dx}} = 4\\ln |x - 3| - \\ln |x + 2| + C."
  },
  {
    "objectID": "qmd/realanal/simple/decomp.html#examples",
    "href": "qmd/realanal/simple/decomp.html#examples",
    "title": "Partial fraction decomposition",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\n\nJoe Foster (Integration by parts - C3)\n\n\n\nEvaluate the following integral\n\n\\int \\frac{x^3 + x^2 + 2x + 1}{(x^2 + 1)(x^2 + 2)} \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can break up the integral as it contains distinct quadratic factors.\n\n\\frac{x^3 + x^2 + 2x + 1}{(x^2 + 1)(x^2 + 2)} =  \\frac{Ax + B}{x^2 + 1} + \\frac{Cx + D}{x^2 + 2}\n\nCross multiplying \nx^3 + x^2 + 2x + 1 = (Ax + B)(x^2 + 2) + (Cx + D)(x^2 + 1)\n\nGives us the following system of equations\n\\begin{array}{ll}\nx^3  & = (A + C)x^3\\\\\nx^2 & = (B + D)x^2\\\\\n2x & = (2A + C)x \\\\\n1 & = (2B + D)\n\\end{array}\nSolving the system yields\n\\begin{array}{ll}\nA = 1  & B = 0\\\\\nC = 0 & D = 1\n\\end{array}\nThis solves our decomposition. We now have to integrate\n\n\\int \\frac{x}{x^2 + 1} + \\frac{1}{x^2 + 2} \\, dx\n\nThe first term can be solved by the substitution u = x^2, and the second term can be evaluated with an \\arctan x. This gives us\n\n\\int \\frac{x^3 + x^2 + 2x + 1}{(x^2 + 1)(x^2 + 2)} \\, dx = \\frac{1}{2}\\ln |x^2 + 1| + \\frac{1}{\\sqrt{2}} \\arctan \\left( \\frac{x}{\\sqrt{2}} \\right) + C"
  },
  {
    "objectID": "qmd/realanal/simple/substitution.html",
    "href": "qmd/realanal/simple/substitution.html",
    "title": "Substitution",
    "section": "",
    "text": "The motivating example for this section will be the integral shown below.\n\\int \\sec^2(x)e^{1 + \\tan{x}} \\, dx\nThe techniques shown in the last section don’t work here. Linearity does not allow for separation of products, and we don’t have an identity which gets us a solution. In order to solve these types of integrals, we’ll need a new rule.\nSubstitution for integrals is often in the form\n\\int f(g(x))g^\\prime(x)\\, dx = \\int f(u)\\, du, \\text{where } u = g(x)."
  },
  {
    "objectID": "qmd/realanal/simple/substitution.html#examples",
    "href": "qmd/realanal/simple/substitution.html#examples",
    "title": "Substitution",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.3.1)\n\n\n\nEvaluate the following integral\n\n\\int   {{\\left( {8x - 12} \\right){{\\left( {4{x^2} - 12x} \\right)}^4}\\,dx}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the substitution\n\nu = 4x^2 - 12x\n\nWe get \n\\int   {{\\left( {8x - 12} \\right){{\\left( {4{x^2} - 12x} \\right)}^4}\\,dx}} = \\frac{1}{5}(4x^2 - 12x)^5 + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.3.2)\n\n\n\nEvaluate the following integral\n\n\\int{{3{t^{ - 4}}{{\\left( {2 + 4{t^{ - 3}}} \\right)}^{ - 7}}\\,dt}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the substitution\n\nu = 2 - 4t^{-3}\n\nWe get \n\\int{{3{t^{ - 4}}{{\\left( {2 + 4{t^{ - 3}}} \\right)}^{ - 7}}\\,dt}} = \\frac{1}{24}(2+4t^{-3})^{-6} + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.3.14)\n\n\n\nEvaluate the following integral\n\n\\int \\frac{\\csc x \\cot c}{2- \\csc x} \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFirst notice how \\csc x \\cot x is clearly the derivative of -\\csc x. This leads us to try some form of \\csc x for u. I use\n\nu = \\csc x\n\nLeading too \n\\int \\frac{\\csc x \\cot c}{2- \\csc x} \\, dx = - \\int \\frac{1}{2 - u} \\, du\n\nWhich is clearly\n\n\\int \\frac{\\csc x \\cot c}{2- \\csc x} \\, dx = \\ln |2 - u| + C = \\ln |2 - \\csc x| + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.3.13)\n\n\n\nEvaluate the following integral\n\n\\int{{10\\sin \\left( {2x} \\right)\\cos \\left( {2x} \\right)\\sqrt {{{\\cos }^2}\\left( {2x} \\right) - 5} \\,dx}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWhile the integral looks incredibly complex, if we substitute the term inside the radical (the usual choice) we can start to break it down.\n\nu = \\cos^2(2x) - 5\n\nThus \n\\int{{10\\sin \\left( {2x} \\right)\\cos \\left( {2x} \\right)\\sqrt {{{\\cos }^2}\\left( {2x} \\right) - 5} \\,dx}} = -\\frac{5}{2} \\int \\sqrt{u} \\, du\n\nWhich leads too\n\n\\int{{10\\sin \\left( {2x} \\right)\\cos \\left( {2x} \\right)\\sqrt {{{\\cos }^2}\\left( {2x} \\right) - 5} \\,dx}} = -\\frac{5}{3}(\\cos^2(2x) - 5)^\\frac{3}{2} + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.3.15)\n\n\n\nEvaluate the following integral\n\n\\int \\frac{6}{7 + y^2} \\,dy\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis does not follow our usual f(g(x))g^\\prime(x) example. For this case, we’ll try to convert into an identity we know. It is clear we can’t have y^2 be a term in u, as this would only make the integral more complicated (as thers no y to be consumed in the du). The integrand sorta resembles the derivative of \\arctan y, so we can try to rewrite it\n\n\\int \\frac{6}{7 + y^2} \\,dy = \\frac{6}{7} \\int \\frac{1}{1 + \\frac{y^2}{7}} \\, dy\n\nNotice that if we make the substitution \nu = \\frac{y}{\\sqrt{7}}\n\nWe get\n\n\\int \\frac{6}{7 + y^2} \\,dy = \\frac{6\\sqrt{7}}{7} \\int \\frac{1}{1 + u^2} \\, du\n\nWhich gives us\n\n\\int \\frac{6}{7 + y^2} \\,dy = \\frac{6\\sqrt{7}}{7} \\arctan \\left(\\frac{y}{\\sqrt{7}}\\right) + C\n\n\n\n\n\n\n\n\n\n\nProblem - Arctan generalization\n\n\n\nEvaluate the previous integral in it’s general form\n\n\\int \\frac{1}{a^2 + x^2} \\,dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLike last time, we’ll factor out a^2 from the bottom and then use a substitution.\n\n\\int \\frac{1}{a^2 + x^2} \\,dx = \\frac{1}{a^2} \\int \\frac{1}{1 + (x^2/a^2)} \\, dy\n\nMakeing the substitution \nu = \\frac{x}{a}\n\nWe get\n\n\\int \\frac{1}{a^2 + x^2} \\,dx = \\frac{1}{a} \\int \\frac{1}{1 + u^2} \\, dx\n\nWhich gives us\n\n\\int \\frac{1}{a^2 + x^2} \\,dx = \\frac{1}{a} \\arctan \\left(\\frac{x}{a}\\right) + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.4.6)\n\n\n\nEvaluate the following integral\n\n\\int{{20{{e}^{2 - 8w}}\\sqrt {1 + {{e}}^{2 - 8w}}} \\, + 7{w^3} - 6\\,\\,\\sqrt[3]{w}\\,dw}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing linearity on the integral allows us to do different substitutions. Seeing as the last two terms can be integrated with the inverse power rule, we only need to a substitution on the first term. Luckily this is an easy case.\n\nu = 1 + e^{2-8w}\n\nGives\n\n\\int{{20{{e}^{2 - 8w}}\\sqrt {1 + {{e}}^{2 - 8w}}} \\,dw} = -\\frac{5}{2}\\int \\sqrt{u}\\, du\n\nWhich is\n\n\\int{{20{{e}^{2 - 8w}}\\sqrt {1 + {{e}}^{2 - 8w}}} \\,dw} = -\\frac{5}{3}(1 + e^{2-8w})^\\frac{3}{2} + C\n\nThen solving the other terms gives us our solution.\n\n= -\\frac{5}{3}(1 + e^{2-8w})^\\frac{3}{2} + \\frac{7}{4}w^4 - \\frac{9}{2}w^\\frac{4}{3} + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus II - A7.1.18)\n\n\n\nEvaluate the following integral\n\n\\int{{\\frac{{{x^7}}}{{\\sqrt {{x^4} + 1} }}\\,dx}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the substitution\n\nu = x^4 + 1\n\nWe get\n\n\\int{{\\frac{{{x^7}}}{{\\sqrt {{x^4} + 1} }}\\,dx}} = \\frac{1}{4}\\int \\frac{u - 1}{\\sqrt{u}}\n\nWhich we can then apply linearity and inverse power rule to, giving us\n\n\\int{{\\frac{{{x^7}}}{{\\sqrt {{x^4} + 1} }}\\,dx}} = \\frac{1}{4}\\left( \\frac{2}{3}(x^4 + 1)^\\frac{3}{2} + 2(x^4 + 1)^\\frac{1}{2}\\right) + C"
  },
  {
    "objectID": "qmd/realanal/simple/basics.html",
    "href": "qmd/realanal/simple/basics.html",
    "title": "Basics",
    "section": "",
    "text": "Integration is the inverse of the differentiation. If f^\\prime(x) = g(x), then\n\\int g(x)\\,dx = f(x) + C.\nIntegrals have a property called linearity. This means they are closed under linear transformations of functions, as shown below.\n\\int \\alpha f(x) + \\beta g(x) \\,dx = \\alpha \\int f(x) \\,dx+ \\beta \\int g(x) \\,dx"
  },
  {
    "objectID": "qmd/realanal/simple/basics.html#inverse-power-rule",
    "href": "qmd/realanal/simple/basics.html#inverse-power-rule",
    "title": "Basics",
    "section": "Inverse power rule",
    "text": "Inverse power rule\nOne of the basic rules of differentiation is that of power rule.\n\n\\frac{d}{dx} x^m = mx^{m-1}\n\nSuspecting this will be a useful property, we can derive an expression for the inverse power rule from the definition of an integral.\n\n\\int mx^{m-1} dx = x^m\n\nApply linearity and the substituion n = m-1\n\n\\int x^{n} dx = \\frac{x^{n+1}}{n+1}\n\n\n\n\n\n\n\nExample\n\n\n\n\n\nFind the solution to the following integral\n\n\\int 2x^2 - 3x - 1 \\, dx\n\nWe first begin by applying linearity\n\n= 2 \\int x^2 \\,dx - 3\\int x \\, dx - \\int 1x^0 \\, dx\n\nThen inverse power rule\n\n= \\frac{2x^3}{3} - \\frac{3x^2}{2} - x + C\n\nGiving us a solution to the polynomial. This process can be done for any standard polynomial.\n\n\n\n\n\n\n\n\n\nTheorem (Integration of a polynomial)\n\n\n\nLet f(x) be a polynomial in the form\n\nf(x) = a_nx^n + a_{n-1}x^{n-1} + \\cdots + a_1x + c\n\nThen\n\n\\int f(x)\\,dx = \\frac{a_nx^{n+1}}{n+1} + \\frac{a_{n-1}x^{n}}{n} +  \\cdots + \\frac{a_1x^2}{2} + cx + C\n\n\n\n\nEdge case\nOne may notice that when n=-1, inverse power rules gives us an undefined result\n\n\\int x^{-1}\\,dx = \\frac{1}{0} + C.\n\nFor this particular value of n, we get the expression\n\n\\int x^{-1}\\,dx = \\ln|x| + C.\n\nNote the absolute value bars. This is because the function \\ln is not defined for negative values of x, where our integrand is."
  },
  {
    "objectID": "qmd/realanal/simple/basics.html#common-identities",
    "href": "qmd/realanal/simple/basics.html#common-identities",
    "title": "Basics",
    "section": "Common identities",
    "text": "Common identities\nThis section will cover many commonly used integration identities without much explanation.\n\nTrig identities\nTrigonometry is a huge part of the integration bee, and will repeatedly appear in almost every section of this guide. As such it is crucial to have a complete understanding of these functions and how they interact.\nThe integrals below are the direct inverse of differentiating the six primary trig functions.\n\\begin{array}{ll}\n\\displaystyle\\int{{\\cos x\\,dx}} = \\sin x + C \\hspace{0.5in} & \\displaystyle\\int{{\\sin x\\,dx}} =  - \\cos x + C\\\\\n\n\\displaystyle\\int{{{{\\sec }^2}x\\,dx}} = \\tan x + C \\hspace{0.5in} & \\displaystyle\\int{{{{\\csc }^2}x\\,dx}} =  - \\cot x + C\\\\\n\n\\displaystyle\\int{{\\sec x\\tan x\\,dx}} = \\sec x + C \\hspace{0.5in} & \\displaystyle\\int{{\\csc x\\cot x\\,dx}} =  - \\csc x + C\n\\end{array}\nIt is helpful (for me at least) to memorize the left column of the table, and then derive the right side by replacing each function with its ‘compliment’, and then negating the result.\n\n\nInverse Trig identities\nWe can use special formulas to differentiate inverse functions. By differentiating \\arcsin(x) and \\arctan(x), we get\n\n\\int \\frac{1}{x^2 + 1} \\, dx = \\arctan(x) + C \\hspace{0.5in} \\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = \\arcsin(x) + C\n\nIt is worth noting that\n\n\\frac{d}{dx}\\arccos(x) = -\\frac{1}{1-x^2}.\n\nSo the second integral can also be solved\n\n\\int \\frac{1}{\\sqrt{1-x^2}}\\,dx = -\\arccos(x) + C.\n\nThis is because \\arcsin and -\\arccos differ by a constant (\\frac{\\pi}{2}).\n\n\nExponential and logarithmic functions\nBy once again inverting common derivative rules, we get the following identities.\n\n\\int e^x \\, dx = e^x + C \\hspace{0.5in} \\int a^x \\,dx = \\frac{a^x}{\\ln{x}} + C"
  },
  {
    "objectID": "qmd/realanal/simple/basics.html#examples",
    "href": "qmd/realanal/simple/basics.html#examples",
    "title": "Basics",
    "section": "Examples",
    "text": "Examples\nSome example problems from various websites\n\nInverse power rule\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.1.1)\n\n\n\nEvaluate the following integral\n\n\\int 6x^5 - 18x^2 + 7 \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the formula for evaluating polynomials\n\n\\int 6x^5 - 18x^2 + 7 \\, dx = x^6 - 6x^3 + 7x + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.1.1)\n\n\n\nEvaluate the following integral\n\n\\int 6x^5\\, dx - 18x^2 + 7\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNotice the integral ends at the dx, meaning the solution is\n\n\\int 6x^5 - 18x^2 + 7 \\, dx = x^6 - 18x^2 + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.1.3)\n\n\n\nEvaluate the following integral\n\n\\int 12t^7 - t^2 - t + 3 \\, dt\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nClassic polynomial, the only difference is the use of t instead of x\n\n\\int 12t^7 - t^2 - t + 3 \\, dt = \\frac{3}{2}t^8 - \\frac{1}{3}t^3 - \\frac{1}{2}t^2 + 3t + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.6)\n\n\n\nEvaluate the following integral\n\n\\int \\sqrt[3]{w} + 10\\sqrt[5]{w^3}\\, dw\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nConvert the radicals to fractional exponets\n\n\\int \\sqrt[3]{w} + 10\\sqrt[5]{w^3}\\, dw = \\int w^\\frac{1}{3} + 10w^\\frac{3}{5} \\, dw\n\nAnd then apply inverse power rule\n\n\\int \\sqrt[3]{w} + 10\\sqrt[5]{w^3}\\, dw = \\frac{3}{4}w^\\frac{4}{3} + \\frac{25}{4}w^\\frac{8}{5} + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.9)\n\n\n\nEvaluate the following integral\n\n\\int \\frac{7}{3y^6} + \\frac{1}{y^{10}} - \\frac{2}{\\sqrt[3]{y^4}} \\, dy\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nConvert the radicals to fractional exponents\n\n\\int \\frac{7}{3y^6} + \\frac{1}{y^{10}} - \\frac{2}{\\sqrt[3]{y^4}} \\, dy = \\int \\frac{7}{3}y^{-6} + y^{-10} - 2y^{\\frac{4}{3}} \\, dy\n\nAnd then apply inverse power rule\n\n\\int \\frac{7}{3y^6} + \\frac{1}{y^{10}} - \\frac{2}{\\sqrt[3]{y^4}} \\, dy = -\\frac{7}{15}y^{-5} - \\frac{1}{9} y^{-9} + 6y^{-\\frac{1}{3}} + C\n\nBe careful to make sure you have the right answer.\n\n\n\n\n\nCommon identites\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.14)\n\n\n\nEvaluate the following integral\n\n\\int \\sin x + 10 \\csc^2 x \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSimply use linearity to break up the integral, and then apply identities\n\n\\int \\sin x + 10 \\csc^2 x \\, dx = -\\cos x - 10 \\cot x + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.15)\n\n\n\nEvaluate the following integral\n\n\\int 2\\cos x - \\sec x\\tan x \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSimply use linearity to break up the integral, and then apply identities\n\n\\int 2\\cos x - \\sec x\\tan x \\, dx = 2 \\sin x - \\sec x + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.16)\n\n\n\nEvaluate the following integral\n\n\\int 12 + \\csc \\theta \\left( {\\sin  \\theta  + \\csc  \\theta } \\right)\\,d\\theta\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nMultiply out and simplify the equation. \n\\int 12 + \\csc \\theta \\left( {\\sin  \\theta  + \\csc  \\theta } \\right)\\,d\\theta = \\int 12 + 1 + \\csc^2 \\theta \\, d\\theta\n\nBecause\n\n\\csc x= \\frac{1}{\\sin x}\n\nSo we get the answer\n\n\\int 12 + \\csc \\theta \\left( {\\sin  \\theta  + \\csc  \\theta } \\right)\\,d\\theta = 13 \\theta + \\cot \\theta + C\n\n\n\n\n\n\n\n\n\n\nPauls Online Notes (Calculus - 5.2.20)\n\n\n\nEvaluate the following integral\n\n\\int{{\\frac{1}{{1 + {x^2}}} + \\frac{{12}}{{\\sqrt {1 - {x^2}} }}\\,dx}}\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the inverse trig identities\n\n\\int{{\\frac{1}{{1 + {x^2}}} + \\frac{{12}}{{\\sqrt {1 - {x^2}} }}\\,dx}} = \\arctan x + 12 \\arcsin x + C"
  },
  {
    "objectID": "qmd/realanal/simple/trigsub.html",
    "href": "qmd/realanal/simple/trigsub.html",
    "title": "Trig substitutions",
    "section": "",
    "text": "Our motivation for this section is the following integral\n\\int \\frac{\\sqrt{25x^2 - 4}}{x} \\, dx\nThis integral is very difficult to solve with the previous techniques. The trick comes from the substitution\nx = \\frac{2}{5}\\sec \\theta\nWhich after a fair amount of algebra and calculus gives us\n\\int \\frac{\\sqrt{25x^2 - 4}}{x} \\, dx = \\sqrt{25x^2 - 4} + 2\\arccos \\left(\\frac{2}{5x}\\right) + C\nSolving these integrals relies on a method known as trigonometric substitutions."
  },
  {
    "objectID": "qmd/realanal/simple/trigsub.html#method",
    "href": "qmd/realanal/simple/trigsub.html#method",
    "title": "Trig substitutions",
    "section": "Method",
    "text": "Method\nFirst, lets explain how we solved the previous integral.\n\n\n\n\n\n\nExample\n\n\n\n\n\nWe have the following integral, which is difficult to solve using previous techniques.\n\n\\int \\frac{\\sqrt{25x^2 - 4}}{x} \\, dx\n\nUsing the substitution\n\nx = \\frac{2}{5}\\sec \\theta\n\nWe can reduce the integral and get a solution in terms of \\theta.\n\\begin{array}{ll}\n\n& = \\displaystyle \\int \\frac{\\sqrt{25(\\frac{2}{5}\\sec \\theta)^2 - 4}}{\\frac{2}{5}\\sec \\theta} \\, (\\frac{2}{5}\\tan \\theta \\sec \\theta \\, d\\theta)\\\\\n& =  \\displaystyle\\int \\sqrt{4\\sec^2 \\theta - 4} \\, \\tan \\theta \\, d\\theta\\\\\n& = \\displaystyle2\\int \\sqrt{\\sec^2 \\theta - 1} \\, \\tan \\theta \\, d\\theta = 2\\int\\tan^2\\theta \\, d\\theta\\\\\n& = 2\\left(\\tan \\theta + \\theta\\right) + C\n\\end{array}\nNow we only need to undo our substitution. Notice that\n\n\\sec \\theta = \\frac{\\text{hyp}}{\\text{adj}} = \\frac{5x}{2}\n\nThis can be visualized in the triangle.\n\n\nCode\n\\usetikzlibrary{graphs,graphs.standard,angles,quotes}\n\n\\begin{tikzpicture}\n\n\\draw[fill=black] (0,0);\n\\draw[fill=black] (3,0);\n\\draw[fill=black] (3,2);\n\\draw[line width=1pt] (0,0) -- (3,0) -- (3,2) -- (0,0);\n\\node at (1.75,-.25) {$2$};\n\\node at (1.2,1.25) {$5x$};\n\\node at (3.9,1) {$\\sqrt{25x^2 - 4}$};\n\n\\coordinate (origo) at (0,0);\n\\coordinate (pivot) at (3,2);\n\\coordinate (mary) at (3,0);\n\n\\pic[draw, -, \"$\\theta$\", angle eccentricity=1.5]{angle = mary--origo--pivot};\n\\end{tikzpicture}\n\n\n\n\n\n\n\n\n\nFrom here can see that \n\\tan \\theta = \\frac{\\sqrt{25x^2-4}}{2}\n\n\n\\theta = \\arccos \\left(\\frac{2}{5x}\\right)\n\nGiving us our final answer\n\n\\int \\frac{\\sqrt{25x^2 - 4}}{x} \\, dx = \\sqrt{25x^2-4} + 2\\arccos \\left(\\frac{2}{5x}\\right) + C\n\n\n\n\nWhen faced with an integral containing a radical expression in the form \\sqrt{\\pm(bx + c)^2 \\pm a}, we can usually find some subtitution for x which simplifies the expression into a singular trigonometric identity. This is achievable due to the following three identities.\n\\begin{array}{ll}\n1 - \\sin^2x &=& \\cos^2 x\\\\\n\\tan^2x + 1 &=& \\sec^2 x\\\\\n\\sec^2x - 1 &=& \\tan^2 x\n\\end{array}\nLets see how these identites allow us to reduce certain radicals.\n\n\n\n\n\n\nTrig substitutions\n\n\n\n\n\nLets examine the three cases where trig identities allow us to simplify a radical expression.\nCase I: \\sqrt{a - (bx + c)^2}\nNotice how this case is a constant, subtracted by a squared variable term. This resembles our first expression, 1 - \\sin^2x = \\cos^2 x. We want to get the expression in these terms so we can reduce the radicle. Notice by making the substitution\n\n(bx + c) = \\sqrt{a}\\sin \\theta\n\nWe get the equation\n\n\\sqrt{a - (\\sqrt{a}\\sin\\theta)^2} = \\sqrt{a}\\sqrt{1-\\sin^2\\theta} = \\sqrt{a}\\cos\\theta\n\nWe have now elimated the variable from the radical.\nCase II: \\sqrt{(bx + c)^2 + a}\nThis case resembles our identity \\tan^2x + 1 = \\sec^2 x. So lets try the substitution\n\n(bx + c) = \\sqrt{a}\\tan \\theta\n\nWhich gives us\n\n\\sqrt{(\\sqrt{a}\\tan \\theta)^2 + a} = \\sqrt{a}\\sqrt{\\tan^2 \\theta + 1} = \\sqrt{a}\\sec\\theta\n\nWe have now elimated the variable from the radical.\nCase III: \\sqrt{(bx + c)^2 - a}\nThis case resembles \\sec^2x - 1. Using the substitution\n\n(bx + c) = \\sqrt{a}\\sec \\theta\n\nWe get the equation\n\n\\sqrt{(\\sqrt{a}\\sec \\theta)^2 - a} = \\sqrt{a}\\sqrt{\\sec^2\\theta - 1} = \\sqrt{a}\\tan\\theta\n\nWe have now elimated the variable from the radical.\n\n\n\nFor ease of use, the following table shows what substitution to make depending on the case.\n\\begin{array}{ll}\n\\text{Radical expression} \\hspace{0.25in} & \\text{Substitution}\\\\\n&\\\\\n\\sqrt{a - (bx + c)^2} \\hspace{0.25in} & (bx + c) = \\sqrt{a}\\sin\\theta\\\\\n&\\\\\n\\sqrt{(bx + c)^2 + a} \\hspace{0.25in} & (bx + c) = \\sqrt{a}\\tan\\theta\\\\\n&\\\\\n\\sqrt{(bx + c)^2 - a} \\hspace{0.25in} & (bx + c) = \\sqrt{a}\\sec\\theta\n\\end{array}"
  },
  {
    "objectID": "qmd/realanal/simple/trigsub.html#examples",
    "href": "qmd/realanal/simple/trigsub.html#examples",
    "title": "Trig substitutions",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\n\nProblem\n\n\n\nEvaluate the following integral\n\n\\int \\frac{\\sqrt{9 - x^2}}{x^2}\\,dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNotice that the radicle expression resembles the third row of our table. If we make the substitution\n\nx = 3\\sin \\theta\\\\\ndx = 3\\cos\\theta\\,d\\theta\n\nWe get\n\n\\int \\frac{\\sqrt{9 - x^2}}{x^2}\\,dx = \\int\\frac{3\\sqrt{1-\\sin^2\\theta}}{9\\sin^2\\theta}(3\\cos\\theta)\\,d\\theta = \\int\\frac{\\cos^2\\theta}{\\sin^2\\theta} d\\theta\n\nWhich evaulates to \n\\int\\frac{\\cos^2\\theta}{\\sin^2\\theta} d\\theta = -\\cot\\theta - \\theta + C\n\nThis however, is only half the problem. We still need to convert the equation back to its orginal variable. Once again, the method of drawing a triangle will help to simplify the final expression.\nNote that \\sin \\theta = \\displaystyle\\frac{\\text{opp}}{\\text{hyp}} = \\displaystyle\\frac{x}{3}\n\n\nCode\n\\usetikzlibrary{graphs,graphs.standard,angles,quotes}\n\n\\begin{tikzpicture}\n\n\\draw[fill=black] (0,0);\n\\draw[fill=black] (3,0);\n\\draw[fill=black] (3,2);\n\\draw[line width=1pt] (0,0) -- (3,0) -- (3,2) -- (0,0);\n\\node at (1.75,-.3) {$\\sqrt{9 -x^2}$};\n\\node at (1.2,1.25) {$3$};\n\\node at (3.2,1) {$x$};\n\n\\coordinate (origo) at (0,0);\n\\coordinate (pivot) at (3,2);\n\\coordinate (mary) at (3,0);\n\n\\pic[draw, -, \"$\\theta$\", angle eccentricity=1.5]{angle = mary--origo--pivot};\n\\end{tikzpicture}\n\n\n\n\n\n\n\n\n\nSo\n\n\\cot \\theta = \\frac{\\text{adj}}{\\text{opp}} = \\frac{\\sqrt{9 -x^2}}{x}\n\nGiving us a final answer of\n\n\\int \\frac{\\sqrt{9 - x^2}}{x^2}\\,dx = \\frac{-\\sqrt{9-x^2}}{x} - \\arcsin\\left(\\frac{x}{3}\\right) + C"
  },
  {
    "objectID": "qmd/realanal/continuity/converge.html",
    "href": "qmd/realanal/continuity/converge.html",
    "title": "Partial fraction decomposition",
    "section": "",
    "text": "Consider the integral shown below.\n\\int{{\\frac{{3x + 11}}{{{x^2} - x - 6}}\\,dx}}\nOur current methods will not work to evaluate the integral. There is no simple way to apply a substitution or the tabular method. However, if we break up the fraction\n\\frac{{3x + 11}}{{{x^2} - x - 6}} = \\frac{4}{x - 3} - \\frac{1}{x + 2}\nThe solution becomes trivial\n\\int{{\\frac{{3x + 11}}{{{x^2} - x - 6}}\\,dx}} = 4\\ln |x - 3| - \\ln |x + 2| + C.\nFinding ways to break up the fractions is known as partial fraction decomposition."
  },
  {
    "objectID": "qmd/realanal/continuity/converge.html#method",
    "href": "qmd/realanal/continuity/converge.html#method",
    "title": "Partial fraction decomposition",
    "section": "Method",
    "text": "Method\nWhen given an integral in the form\n\n\\int \\frac{P(X)}{Q(X)} \\, dx\n\nWhere P(x) and Q(x) are polynomials such that the degree of Q(x) is higher than the degree of P(x). We can decompose the fraction based on the factors of Q(x). There are four cases for the factors of Q(x).\n\n\n\n\n\n\nDecomposition cases\n\n\n\n\n\nCase I: Distinct linear factors\nWhen Q(x) has distinct linear factors, i.e.\n\nQ(x) = (a_1 x + b_1)(a_2 x + b_2)\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A}{a_1x + b_1} + \\frac{B}{a_2x + b_2}\n\nCase 2: Repeated linear factors\nWhen Q(x) has repeated linear factors, i.e.\n\nQ(x) = (a x + b)^k\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A_1}{ax + b} + \\frac{A_2}{(ax + b)^2} + \\cdots + \\frac{A_k}{(a x + b)^k}\n\nCase 3: Distinct quadratic factors\nWhen Q(x) has distinct quadratic factors, i.e.\n\nQ(x) = (a_1 x^2 + b_1x + c_1)(a_2 x^2 + b_2x + c_2)\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A_1 + B_1}{a_1 x^2 + b_1x + c_1} + \\frac{A_2 + B_2}{a_2 x^2 + b_2x + c_2}\n\nCase 4: Repeated quadratic factors\nWhen Q(x) has repeated quadratic factors, i.e.\n\nQ(x) = (a x^2 + bx + c)^k\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A_1x + B_1}{a x^2 + bx + c} + \\cdots + \\frac{A_kx + B_k}{(a x^2 + bx + c)^k}\n\n\n\n\nNote that Q(x) does not have one case of factors exculsivly. For example\n\nQ(x) = (a_1x+b_1)(a_2x^2 + b_2x + c_2)^2\n\nWill decompose into\n\n\\frac{P(x)}{Q(x)} = \\frac{A}{a_1x + b_1} + \\frac{Bx + C}{a_2 x^2 + b_2x + c_2} + \\frac{Dx + E}{(a_2 x^2 + b_2x + c_2)^2}\n\nNext we need a method for finding the value of the constants in the numerator.\n\n\n\n\n\n\nEvaluating constants\n\n\n\n\n\nConsider the integral from the beginning\n\n\\int \\frac{3x + 11}{x^2 - x - 6} \\,dx\n\nWe can now decompose the integrand to obtain\n\n\\frac{3x + 11}{x^2 - x - 6} = \\frac{A}{x - 3} + \\frac{B}{x + 2}\n\nThe problem is now finding values for the constants A,B which make the relation true. By cross multiplying the right side of the equation we get\n\n\\frac{3x + 11}{x^2 - x - 6} = \\frac{A(x + 2) + B(x - 3)}{(x - 3)(x + 2)}\n\nWhich simplifies to\n\n3x + 11 = A(x + 2) + B(x - 3).\n\nWe can then create a system of equations such that the above expression is always true. This method is long but will always work. The faster method (that isn’t always possible) is to find values of x such that the equation reduces. Using the faster method, we obtain\n\nx = 3 \\: : \\: 3(3) + 11 = A(3 + 2) + B(3 - 3) \\implies A = 4\\\\\nx = -2 \\: : \\: 3(-2) + 11 = A(-2 + 2) + B(-2 - 3) \\implies B = -1\n\nWhich gives us our final expression\n\n\\frac{3x + 11}{x^2 - x - 6} = \\frac{4}{x - 3} - \\frac{1}{x + 2}\n\nWhich as shown above, makes the integral trivial to solve.\n\n\\int{{\\frac{{3x + 11}}{{{x^2} - x - 6}}\\,dx}} = 4\\ln |x - 3| - \\ln |x + 2| + C."
  },
  {
    "objectID": "qmd/realanal/continuity/converge.html#examples",
    "href": "qmd/realanal/continuity/converge.html#examples",
    "title": "Partial fraction decomposition",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\n\nJoe Foster (Integration by parts - C3)\n\n\n\nEvaluate the following integral\n\n\\int \\frac{x^3 + x^2 + 2x + 1}{(x^2 + 1)(x^2 + 2)} \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can break up the integral as it contains distinct quadratic factors.\n\n\\frac{x^3 + x^2 + 2x + 1}{(x^2 + 1)(x^2 + 2)} =  \\frac{Ax + B}{x^2 + 1} + \\frac{Cx + D}{x^2 + 2}\n\nCross multiplying \nx^3 + x^2 + 2x + 1 = (Ax + B)(x^2 + 2) + (Cx + D)(x^2 + 1)\n\nGives us the following system of equations\n\\begin{array}{ll}\nx^3  & = (A + C)x^3\\\\\nx^2 & = (B + D)x^2\\\\\n2x & = (2A + C)x \\\\\n1 & = (2B + D)\n\\end{array}\nSolving the system yields\n\\begin{array}{ll}\nA = 1  & B = 0\\\\\nC = 0 & D = 1\n\\end{array}\nThis solves our decomposition. We now have to integrate\n\n\\int \\frac{x}{x^2 + 1} + \\frac{1}{x^2 + 2} \\, dx\n\nThe first term can be solved by the substitution u = x^2, and the second term can be evaluated with an \\arctan x. This gives us\n\n\\int \\frac{x^3 + x^2 + 2x + 1}{(x^2 + 1)(x^2 + 2)} \\, dx = \\frac{1}{2}\\ln |x^2 + 1| + \\frac{1}{\\sqrt{2}} \\arctan \\left( \\frac{x}{\\sqrt{2}} \\right) + C"
  },
  {
    "objectID": "qmd/realanal/sequences/convergence.html",
    "href": "qmd/realanal/sequences/convergence.html",
    "title": "Convergence",
    "section": "",
    "text": "We are primarily interested in how sequences tend towards infinity.\nWhere |s_n - s| is the distance between the points s_n and s. Essentially, a sequence is convergent if the elements of (s_n) get arbitrarily close to a point s as the sequence progresses.\nIf a sequence does not converge, than we say it is divergent.\nWe typically abbreviate \\lim_{n\\to\\infty}s_n = s as \\lim s_n = s\nSuppose we have a sequence (s_n) which appears to converge to a number s. How would we go about proving the sequence fufills the definition of convergence?\nSee Practice for more examples.\nThis Theorem can be applied quite liberally to help with a great variety of limit problems.\nThe contrapositive is of course also true, any unbounded sequence is divergent. However, not all divergent sequences are unbounded."
  },
  {
    "objectID": "qmd/realanal/sequences/convergence.html#method",
    "href": "qmd/realanal/sequences/convergence.html#method",
    "title": "Convergence",
    "section": "Method",
    "text": "Method\nWhen given an integral in the form\n\n\\int \\frac{P(X)}{Q(X)} \\, dx\n\nWhere P(x) and Q(x) are polynomials such that the degree of Q(x) is higher than the degree of P(x). We can decompose the fraction based on the factors of Q(x). There are four cases for the factors of Q(x).\n\n\n\n\n\n\nDecomposition cases\n\n\n\n\n\nCase I: Distinct linear factors\nWhen Q(x) has distinct linear factors, i.e.\n\nQ(x) = (a_1 x + b_1)(a_2 x + b_2)\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A}{a_1x + b_1} + \\frac{B}{a_2x + b_2}\n\nCase 2: Repeated linear factors\nWhen Q(x) has repeated linear factors, i.e.\n\nQ(x) = (a x + b)^k\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A_1}{ax + b} + \\frac{A_2}{(ax + b)^2} + \\cdots + \\frac{A_k}{(a x + b)^k}\n\nCase 3: Distinct quadratic factors\nWhen Q(x) has distinct quadratic factors, i.e.\n\nQ(x) = (a_1 x^2 + b_1x + c_1)(a_2 x^2 + b_2x + c_2)\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A_1 + B_1}{a_1 x^2 + b_1x + c_1} + \\frac{A_2 + B_2}{a_2 x^2 + b_2x + c_2}\n\nCase 4: Repeated quadratic factors\nWhen Q(x) has repeated quadratic factors, i.e.\n\nQ(x) = (a x^2 + bx + c)^k\n\nWe decompose into the following terms\n\n\\frac{P(x)}{Q(x)} = \\frac{A_1x + B_1}{a x^2 + bx + c} + \\cdots + \\frac{A_kx + B_k}{(a x^2 + bx + c)^k}\n\n\n\n\nNote that Q(x) does not have one case of factors exculsivly. For example\n\nQ(x) = (a_1x+b_1)(a_2x^2 + b_2x + c_2)^2\n\nWill decompose into\n\n\\frac{P(x)}{Q(x)} = \\frac{A}{a_1x + b_1} + \\frac{Bx + C}{a_2 x^2 + b_2x + c_2} + \\frac{Dx + E}{(a_2 x^2 + b_2x + c_2)^2}\n\nNext we need a method for finding the value of the constants in the numerator.\n\n\n\n\n\n\nEvaluating constants\n\n\n\n\n\nConsider the integral from the beginning\n\n\\int \\frac{3x + 11}{x^2 - x - 6} \\,dx\n\nWe can now decompose the integrand to obtain\n\n\\frac{3x + 11}{x^2 - x - 6} = \\frac{A}{x - 3} + \\frac{B}{x + 2}\n\nThe problem is now finding values for the constants A,B which make the relation true. By cross multiplying the right side of the equation we get\n\n\\frac{3x + 11}{x^2 - x - 6} = \\frac{A(x + 2) + B(x - 3)}{(x - 3)(x + 2)}\n\nWhich simplifies to\n\n3x + 11 = A(x + 2) + B(x - 3).\n\nWe can then create a system of equations such that the above expression is always true. This method is long but will always work. The faster method (that isn’t always possible) is to find values of x such that the equation reduces. Using the faster method, we obtain\n\nx = 3 \\: : \\: 3(3) + 11 = A(3 + 2) + B(3 - 3) \\implies A = 4\\\\\nx = -2 \\: : \\: 3(-2) + 11 = A(-2 + 2) + B(-2 - 3) \\implies B = -1\n\nWhich gives us our final expression\n\n\\frac{3x + 11}{x^2 - x - 6} = \\frac{4}{x - 3} - \\frac{1}{x + 2}\n\nWhich as shown above, makes the integral trivial to solve.\n\n\\int{{\\frac{{3x + 11}}{{{x^2} - x - 6}}\\,dx}} = 4\\ln |x - 3| - \\ln |x + 2| + C."
  },
  {
    "objectID": "qmd/realanal/sequences/convergence.html#examples",
    "href": "qmd/realanal/sequences/convergence.html#examples",
    "title": "Convergence",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\n\nJoe Foster (Integration by parts - C3)\n\n\n\nEvaluate the following integral\n\n\\int \\frac{x^3 + x^2 + 2x + 1}{(x^2 + 1)(x^2 + 2)} \\, dx\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can break up the integral as it contains distinct quadratic factors.\n\n\\frac{x^3 + x^2 + 2x + 1}{(x^2 + 1)(x^2 + 2)} =  \\frac{Ax + B}{x^2 + 1} + \\frac{Cx + D}{x^2 + 2}\n\nCross multiplying \nx^3 + x^2 + 2x + 1 = (Ax + B)(x^2 + 2) + (Cx + D)(x^2 + 1)\n\nGives us the following system of equations\n\\begin{array}{ll}\nx^3  & = (A + C)x^3\\\\\nx^2 & = (B + D)x^2\\\\\n2x & = (2A + C)x \\\\\n1 & = (2B + D)\n\\end{array}\nSolving the system yields\n\\begin{array}{ll}\nA = 1  & B = 0\\\\\nC = 0 & D = 1\n\\end{array}\nThis solves our decomposition. We now have to integrate\n\n\\int \\frac{x}{x^2 + 1} + \\frac{1}{x^2 + 2} \\, dx\n\nThe first term can be solved by the substitution u = x^2, and the second term can be evaluated with an \\arctan x. This gives us\n\n\\int \\frac{x^3 + x^2 + 2x + 1}{(x^2 + 1)(x^2 + 2)} \\, dx = \\frac{1}{2}\\ln |x^2 + 1| + \\frac{1}{\\sqrt{2}} \\arctan \\left( \\frac{x}{\\sqrt{2}} \\right) + C"
  },
  {
    "objectID": "qmd/diffeq/introduction.html",
    "href": "qmd/diffeq/introduction.html",
    "title": "Differential equations",
    "section": "",
    "text": "Let f \\colon \\mathbb{R} \\to \\mathbb{R}. The derivative is denoted\n\n\\frac{df}{dt} = f^\\prime(t) = \\lim_{h\\to 0} \\frac{f(t+h)-f(t)}{h}\n\nAnd denotes the rate of change of f with respect to t. Graphically this would be the slope of the tangent line to f at t.\nAlgebraic equations have numerical solutions, if they exists. Differential equations have functions as solutions, where derivatives are involved in the equation. For example, the differential equation\n\n\\frac{df}{dx} = \\sin(x)\n\nhas solutions\n\nf(x) = -\\cos(x) + C\n\nThere are mainly two groups of differential equations, those being ordinary differnetial equations (ODEs) and partial differential equations (PDEs).\nOrdinary differential equations are equations such that the unknown function depends only on one variable, whereas partial differential equations depend on more than one variable.\nThe order of a differential equation is simply the highest derivative that appears in the equation.\n\n\n\n\n\n\nExample\n\n\n\nFind the order of the following PDEs\n\n(a) \\quad \\frac{\\partial f(x,y,z)}{\\partial x} + \\frac{\\partial f(x,y,z)}{\\partial z} = -\\left(\\frac{\\partial f(x,y,z)}{\\partial y}\\right)^7\n\n\n(b) \\quad \\frac{\\partial u(x,y)}{\\partial x} - \\frac{\\partial^2 f(x,y,z)}{\\partial y^2} = u(1-u)\n \n(c) \\quad \\sin(u(x_1,x_2)) + \\left(e^{\\frac{\\partial^2u(x_1,x_2)}\n{\\partial x_1^2}}\\right)^3 + \\frac{\\partial^4 u(x_1,x_2)}{\\partial x_1^3 \\partial x_2} = 2\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLaplace Equation\n\n\\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2} = 0\n\nHeat Equation\n\n\\frac{\\partial f}{\\partial t} - \\left(\\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2}\\right) = u(x,y,t)\n\nWave Equation\n\n\\frac{\\partial^2 f}{\\partial t^2} - c^2\\left(\\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2}\\right) = 0\n\n\n\nThese have massive applications in physics, predicting fluid motion, the deformation of solids, and signaling. They also have applications in biology and ecology studying tumor growth, populations of bacteria, and blood clotting. There are also aplications in economics, weather, and most other fields. Any effect can be modeled with a PDE.\nPDEs are useful in representing many interesting problems, but also incredibly difficult to solve.\nSecond order homogenous linear equations with constant coefficents can be solved with a charateristic equation.\nBrush up on ODEs soecifically second order."
  },
  {
    "objectID": "qmd/realanal/sequences/convergence.html#section",
    "href": "qmd/realanal/sequences/convergence.html#section",
    "title": "Convergence",
    "section": "",
    "text": "Definition\n\n\n\nA sequence (S_n) of real numbers converges to a real number s if\n\n\\forall \\varepsilon &gt; 0, \\exists N \\in \\mathbb{N} \\mid \\forall n \\geq N, |S_n - s| &lt; \\varepsilon\n\nEssentially, a sequence is convergent if the elements of (S_n) get arbitrarily close to a point s.\nIf a sequence does not converge, than we say it is divergent\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf (S_n) converges to s, then we say that s is the limit of (S_n) and we write\n\n\\lim_{n \\to \\infty} S_n = s\n\n\n\nA quick note on notation, (S_n) refers to the sequence as a whole, where as S_n refers to an indivual element of the sequence.\n\n\n\n\n\n\nTheorem (Archimedean property)\n\n\n\nThe Archimedean property states that the natural numbers are unbounded in \\mathbb{R}.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nTo-do\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nGiven the sequence S_n = 1/n, we claim\n\n\\lim_{n \\to \\infty} \\frac{1}{n} = 0.\n\nWe can show this using our definition of a convergent sequence. We need to prove that their exists some N \\in \\mathbb{N} such that for all n \\geq N, we have\n\n|\\frac{1}{n} - 0| = |\\frac{1}{n}| = \\frac{1}{n} &lt; \\varepsilon\n\nBy the Archimedean property, we know there always exists some N \\in \\mathbb{N} such that 0 &lt; \\frac{1}{N} &lt; \\varepsilon. Therefore our sequence converges to 0.\n\n\nLet s \\in \\mathbb{R} and let S_n = s for all n \\in \\mathbb{N}. Then,\n\n\\lim_{n \\to \\infty} S_n = s.\n\nWe call this the constant sequence.\n\n\n\n\n\n\nDefinition\n\n\n\nA sequence (S_n) is bounded if there exists M \\geq 0 such that |S_n| \\leq M.\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nEvery convergent sequence is bounded.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nBecause (S_n) is a convergent sequence, S_n \\to s. In the definition of a convergent sequence, let \\varepsilon = 1. This means that there exists some N \\in \\mathbb{N} such that for all n \\geq N, we have that |S_n - s| &lt; 1.\nThrough the triangle inequality, we have that, for all n \\geq N\n\n|S_n| - |s| \\leq |S_n - s| &lt; 1 \\iff |S_n| &lt; 1 + |s|.\n\nLet M = \\sup\\{|S_1|,|S_2|,\\ldots,|S_N|,|s| + 1\\}. Therefore we have that for all n \\in \\mathbb{N}, |S_n| \\leq M and hence (S_n) is bounded.\n\n\n\n\nThe contrapositive of course is also true, any unbounded sequence is divergent. However, not all divergent sequences are unbounded.\n\n\n\n\n\n\nExample\n\n\n\nGiven the sequence (S_n) = (-1)^n\nTO DO\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nIf a sequence converges, its limit is unique.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLet (S_n) be a convergent sequence and S_n \\to s and S_n \\to t. We want to show that s and t are arbitrarily close and therefore s = t."
  },
  {
    "objectID": "qmd/realanal/sequences/convergence.html#definition-and-properties",
    "href": "qmd/realanal/sequences/convergence.html#definition-and-properties",
    "title": "Convergence",
    "section": "",
    "text": "Definition\n\n\n\nA sequence (s_n) of real numbers converges to a real number s if\n\n\\forall \\varepsilon &gt; 0, \\exists N \\in \\mathbb{N} \\;s.t.\\; \\forall n \\geq N, |s_n - s| &lt; \\varepsilon\n\n\n\nWhere |s_n - s| is the distance between the points s_n and s. Essentially, a sequence is convergent if the elements of (s_n) get arbitrarily close to a point s as the sequence progresses.\nIf a sequence does not converge, than we say it is divergent.\n\n\n\n\n\n\nDefinition\n\n\n\nIf (s_n) converges to s, then we say that s is the limit of (s_n) and we write\n\n\\lim_{n \\to \\infty} s_n = s\n\n\n\nWe use (s_n) to denote the sequence as a whole, where as s_n refers to an indivual element of the sequence. We also typically abbreviate \\lim_{n\\to\\infty}s_n = s as \\lim s_n = s\nSuppose we have a sequence (s_n) which appears to converge to a number s. How would we go about proving the sequence fufills the definition of convergence?\n\n\n\n\n\n\n\nExample\n\n\n\nClaim: Given the sequence s_n = 1/n, we have\n\n\\lim_{n \\to \\infty} \\frac{1}{n} = 0.\n\nIn order to show this sequence converges, we need to prove that for all \\varepsilon &gt; 0 there exists some N \\in \\mathbb{N} such that for all n \\geq N, we have\n\n|s_n - s| = \\left|\\frac{1}{n} - 0\\right| = \\left|\\frac{1}{n}\\right| = \\frac{1}{n} &lt; \\varepsilon.\n\nBy the Archimedean property, we know there always exists some n \\in \\mathbb{N} such that xn &gt; y for any positive x,y \\in \\mathbb{R}. It is then clear there exists some n such that 1/n &lt; y/x.\nTherefore for any \\varepsilon &gt; 0, we simply choose N such that 0 &lt; \\frac{1}{N} &lt; \\varepsilon. Then for any n \\geq N, we have |1/n - 0| = 1/n \\leq 1/N &lt; \\varepsilon. Thus our sequence converges, and \\lim s_n = 0.\n\n\n\nSee Practice for more examples.\n\n\n\n\n\n\nTheorem 1.1.1\n\n\n\nLet (s_n) and (a_n) be sequences of real numbers and let s \\in \\mathbb{R}. If for some k &gt; 0 and some m \\in \\mathbb{N} we have\n\n|s_n - s| \\leq k|a_n|, \\forall n \\geq m\n\nand if \\lim a_n = 0, then it follows that \\lim s_n = s.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nGiven any \\varepsilon &gt; 0, since \\lim a_n = 0 there exists N_1 \\in \\mathbb{N} such that n \\geq N_1 implies |a_n| &lt; \\varepsilon/k. Let N = \\max\\{m,N_1\\}. Then for n \\geq \\mathbb{N} we have n \\geq m and n \\geq N_1, so\n\n|s_n - s| \\leq k|a_n| &lt; k\\left(\\frac{\\varepsilon}{k}\\right) = \\varepsilon.\n\nThus \\lim s_n = s.\n\n\n\nThis Theorem can be applied quite liberally to help with a great variety of limit problems.\n\n\n\n\n\n\nExample\n\n\n\nClaim: The \\lim(4n^2 - 3)/(5^2 -2n) = 4/5.\nWe start with some algebraic manipulation\n\n\\left|\\frac{4n^2 - 3}{5n^2 - 2n} - \\frac{4}{5}\\right| = \\left| \\frac{8n-15}{5(5n^2-2n)}\\right|\n\nWe aim to find an upper bound to simplify the fraction. For the numerator, |8n - 15| &lt; 8n for all n \\in \\mathbb{N} (Note 0 \\not \\in \\mathbb{N}). For the denominator, we want some relation in the form 5n^2 - 2n \\geq kn^2 for some k &gt; 0. We use k = 4 to obtain\n\n5n^2 - 2n \\geq 4n^2 \\implies n^2 \\geq 2n \\implies n \\geq 2.\n\nWhen n \\geq 2, we now have the relation\n\n\\left| \\frac{8n-15}{5(5n^2-2n)}\\right| &lt; \\frac{8n}{5(4n^2)} = \\frac{2}{5}\\left(\\frac{1}{n}\\right).\n\nWe can turn this into a formal proof. If n \\geq 2, then n^2 \\geq 2n and 5n^2 -2n\\geq 4n^2 such that\n\n\\left|\\frac{4n^2 - 3}{5n^2 - 2n} - \\frac{4}{5}\\right| = \\left| \\frac{8n-15}{5(5n^2-2n)}\\right| &lt; \\frac{8n}{5(4n^2)} = \\frac{2}{5}\\left(\\frac{1}{n}\\right)\n\nSince \\lim (1/n) = 0 as shown in our last example, Theorem 1.1.1 states that\n\n\\lim \\frac{4n^2-3}{5n^2 - 2n} = \\frac{4}{5}.\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA sequence (s_n) is bounded if there exists M \\geq 0 such that |s_n| \\leq M.\n\n\n\n\n\n\n\n\nTheorem 1.1.2\n\n\n\nEvery convergent sequence is bounded.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLet (s_n) be a convergent sequence and let \\lim s_n = s. Choose \\varepsilon = 1. Because (s_n) is convergent, there exists some N \\in \\mathbb{N} such that for all n \\geq N, |s_n - s| &lt; 1.\nThrough the triangle inequality, we have that, for all n \\geq N\n\n|s_n| - |s| \\leq |s_n - s| &lt; 1 \\iff |s_n| &lt; |s| + 1.\n\nLet M = \\max\\{|s_1|,|s_2|,\\ldots,|s_N|,|s| + 1\\}. Thus for all n \\in \\mathbb{N}, |s_n| \\leq M and (s_n) is bounded.\n\n\n\nThe contrapositive is of course also true, any unbounded sequence is divergent. However, not all divergent sequences are unbounded.\n\n\n\n\n\n\nExample\n\n\n\nLet (s_n) = (-1)^n. This sequence is clearly bounded by M = 1, but not convergent.\n\n\n\n\n\n\n\n\nTheorem 1.1.3\n\n\n\nIf a sequence converges, its limit is unique.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLet (s_n) be a convergent sequence and suppose \\lim s_n = s and \\lim s_n = t. We want to show that s and t are arbitrarily close and therefore s = t.\nBy the definition of convergence we have\n\n\\exists N_1 \\in \\mathbb{N} \\text{ such that }\\forall n \\geq N_1, |s_n - s| &lt; \\frac{\\varepsilon}{2}.\n\nand\n\n\\exists N_2 \\in \\mathbb{N} \\text{ such that }\\forall n \\geq N_2, |s_n - t| &lt; \\frac{\\varepsilon}{2}.\n\nLet N = \\max\\{N_1,N_2\\}. From the triangle inequality we have\n\\begin{align*}\n|s-t| &= |s - s_n + s_n - t|\\\\\n&\\leq |s-s_n|+|s_n-t|\\\\\n&&lt; \\frac{\\varepsilon}{2} + \\frac{\\varepsilon}{2} = \\varepsilon\n\\end{align*}\nSince this holds for all \\varepsilon &gt; 0, we have s = t."
  },
  {
    "objectID": "qmd/realanal/sequences/convergence.html#sequences",
    "href": "qmd/realanal/sequences/convergence.html#sequences",
    "title": "Convergence",
    "section": "",
    "text": "A sequence is a function whose domain is the set of natural numbers, \\mathbb{N}. We denote a sequence with\n\n(S_n) = (S_1,S_2,S_3,\\ldots)\n\n\n\n\n\n\n\nExample\n\n\n\nThe function f \\colon \\mathbb{N} \\to \\mathbb{Q} such that n \\rightarrowtail \\frac{1}{n} is a sequence. We would denote this sequence\n\n\\left(\\frac{1}{n}\\right) = \\left(1,\\frac{1}{2},\\frac{1}{3},\\ldots\\right)\n\nSimilarly, the function f \\colon \\mathbb{N} \\to \\mathbb{N} where n \\rightarrowtail 2n is represented\n\n(2n) = (2,4,6,\\ldots)\n\n\n\nNormally we will consider sequences where the codomain is \\mathbb{R}."
  },
  {
    "objectID": "qmd/realanal/sequences/limittheo.html",
    "href": "qmd/realanal/sequences/limittheo.html",
    "title": "Limit Theorems",
    "section": "",
    "text": "We begin the section by showing that algebraic operations are compatible with limits.\nAnother useful property of limits is that they are preserved under inequality operations.\nThis leads to a the following corollary\nThese results lead us to the Ratio test. This test is used to show that certain sequences converge to zero.\nIn simple english, if s_n is a sequence of positive terms, where each subsequent term is smaller than the last, the sequence must converge to zero."
  },
  {
    "objectID": "qmd/pde/heatequ/heatEquation.html",
    "href": "qmd/pde/heatequ/heatEquation.html",
    "title": "Derivation of the conduction of heat in a one-dimensional rod",
    "section": "",
    "text": "We will need the following unknowns:"
  },
  {
    "objectID": "qmd/pde/heatequ/heatEquation.html#consevation-of-heat-energy-susbections",
    "href": "qmd/pde/heatequ/heatEquation.html#consevation-of-heat-energy-susbections",
    "title": "Derivation of the conduction of heat in a one-dimensional rod",
    "section": "Consevation of heat energy (susbections)",
    "text": "Consevation of heat energy (susbections)\nWe want to derive an equation to see how heat energy in a rod changes overtime.\nWe first consider a rod of length L, stretching from x = 0 to {x=L.} Consider a subsection of the rod x = x^\\prime to x = x^\\prime + \\Delta x.\nThe total thermal energy in this subsection of the rod is the product of the thermal energy density and the volume of the subsection. This is given by the equation\n\n\\text{Heat Energy } = e(x,t)A\\Delta x\n\nwhere A is the cross sectional area of the rod.\nTo find the rate of change of heat energy in time in the subsection, we have to find the heat energy entering the subsection, the heat energy leaving the subsection, and the heat energy generated inside the subsection per unit time. This is given by the equation\n\n\\text{Change in Heat Energy } = \\frac{\\partial}{\\partial t}\\left[e(x,t)A\\Delta x\\right]\n\nClearly then\n\n\\frac{\\partial}{\\partial t}\\left[e(x,t)A\\Delta x\\right] = \\phi(x,t)A - \\phi(x + \\Delta x)A + Q(x,t)A\\Delta x\n\nFrom here we can divide both sides by A \\Delta x to get\n\n\\frac{\\partial}{\\partial t}e(x,t) = \\frac{\\phi(x,t) - \\phi(x + \\Delta x)}{\\Delta x} + Q(x,t)\n\nAs \\Delta x \\to 0 we have\n\n\\frac{\\partial}{\\partial t}e(x,t) = -\\lim_{\\Delta x \\to 0}\\frac{\\phi(x + \\Delta x) - \\phi(x,t)}{\\Delta x} + Q(x,t)\n\nThis is the limit definition of a derivative. We can simplify to obtain\n\n\\frac{\\partial}{\\partial t}e(x,t) = -\\frac{\\partial \\phi}{\\partial x} + Q\n\nWhich we call the formula for conservation of heat energy."
  },
  {
    "objectID": "qmd/pde/heatequ/heatEquation.html#consevation-of-heat-energy-exact",
    "href": "qmd/pde/heatequ/heatEquation.html#consevation-of-heat-energy-exact",
    "title": "Derivation of the conduction of heat in a one-dimensional rod",
    "section": "Consevation of heat energy (exact)",
    "text": "Consevation of heat energy (exact)\nAn alternate derivation for conservation of heat energy which does not use any approximations is as follows.\nGiven a rod from x = 0 to x = L, we can calculate the total energy in the rod from [a,b] (where 0 \\leq a &lt; b \\leq L) as the contribution of all infinitisimal slices. We do this with\n\n\\text{Total heat energy between } [a,b] = \\int^b_a e(x,t)A\\;dx\n\nThe rate of change of energy between a and b will be the heat energy flowing across the boundaries per unit time, in addition to the heat energy generated inside per unit time. This is given with the equation\n\n\\frac{d}{dt}\\left(\\int^b_a e(x,t)A\\;dx\\right) = \\phi(a,t)A - \\phi(b,t)A + \\int^b_a Q(x,t)A\\;dx\n\nThis can be simplified\n\n\\int^b_a \\frac{\\partial}{\\partial t} e(x,t)\\;dx = -\\int^b_a \\frac{\\partial \\phi(x,t)}{\\partial x}\\; dx + \\int^b_a Q(x,t)\\;dx\n\nThis equation is called integral conservation law, and is more generally useful. We will use the equation to derive the conservation of heat energy formula we got earlier. We simplify the integral conservation law into\n\n\\int^b_a \\left[\\frac{\\partial}{\\partial t} e(x,t)+ \\frac{\\partial \\phi}{\\partial x} -  Q\\right] dx = 0\n\nThis integral must be zero for arbitrary values of a and b. This is possible only if the integrand itself is zero. Thus we have\n\n\\frac{\\partial}{\\partial t} e(x,t) + \\frac{\\partial \\phi}{\\partial x} -  Q = 0\n\nWhich can be rewrote to be identical to our first derivation\n\n\\frac{\\partial}{\\partial t}e(x,t) = -\\frac{\\partial \\phi}{\\partial x} + Q"
  },
  {
    "objectID": "qmd/pde/heatequ/heatEquation.html#tempature-and-specific-heat",
    "href": "qmd/pde/heatequ/heatEquation.html#tempature-and-specific-heat",
    "title": "Derivation of the conduction of heat in a one-dimensional rod",
    "section": "Tempature and specific heat",
    "text": "Tempature and specific heat\nWe describe materials by their tempature, instead of their thermal energy.\n\nu(x,t) = \\text{ Tempature}\n\nIt may take different levels of thermal energy to raise two different materials from one tempature to another. We introduce the quantity called specific heat or heat capacity. The specific heat is the heat energy that must be supplied to a unit of mass of a substance to raise its tempature one unit\n\nc = \\text{ Specific heat}\n\nIn general, the specific heat depends on the tempature of the material. That is to say it may require less energy to go from 0^\\circ to 10^\\circ then it does to go from 10^\\circ to 20^\\circ. In our case, we will consider just c(x), and in many cases let c be constant.\nThe mass density of a material is mass per unit volume.\n\n\\rho(x) = \\text{ Mass density}\n\nGiven a subsection of a one-dimensional rod, the rotal mass of the subsection is \\rho(x) A \\Delta x, and the total thermal energy in any given slice is thus c(x)u(x,t)\\rho(x) A \\Delta x. This gives us the relation\n\ne(x,t)A\\Delta x = c(x)u(x,t)\\rho(x) A \\Delta x\n\nWhich can be simplified\n\ne(x,t) = c(x)u(x,t)\\rho(x)\n\nThis also changes our conservation of heat energy equation into\n\nc(x)\\rho(x)\\frac{\\partial u}{\\partial t} = -\\frac{\\partial \\phi}{\\partial x} + Q."
  },
  {
    "objectID": "qmd/pde/heatequ/heatEquation.html#fouriers-law",
    "href": "qmd/pde/heatequ/heatEquation.html#fouriers-law",
    "title": "Derivation of the conduction of heat in a one-dimensional rod",
    "section": "Fouriers law",
    "text": "Fouriers law\nWhat is the relation between \\phi(x,t) and u(x,t)? Fourier experimented and realized four main relations between the two quantities\n\nIf the tempature of the rod is constant, the energy does not flow.\nIf tempature is not constant, the heat energy flows from the hotter region towards the colder region.\nThe greater the tempature differences (for the same material), the greater the flow of heat energy.\nThe flow of heat energy will vary for different materials, even with the same tempature differences.\n\nFourier wanted to create an equation to summarize these properties, and used the formula\n\n\\phi = -K_0 \\frac{\\partial u}{\\partial x}\n\nKnown as Fouriers law of heat conduction. But does this formula accuratly model our results?\nStarting with the first observation, if tempature is constant then no heat energy flows. When tempature is constant, our formula gives us\n\n\\phi = -K_0 \\frac{\\partial u}{\\partial x} = -K_0 (0) = 0\n\nMatching our observations. The second property states if tempature differences are present, the heat energy flows from the hotter to colder regions. If the tempature with respect to position of the rod is increasing, we have \\partial u / \\partial x &gt; 0, and therefore \\phi = -K_0 (\\partial u / \\partial x) &lt; 0. Because \\phi is less than zero, energy is flowing to the left, from the hotter to colder region. When \\partial u / \\partial x &lt; 0, we have \\phi &gt; 0, as expected. This explains the minus sign present in the formula.\nWhen the tempature differences are greater, \\partial u / \\partial x is greater, and the flow of heat energy \\phi is also greater.\nThe thermal conductivity of the material K_0. Experiments indicate that different materials conduct heat differently, where K_0 depends on a specific material. This is how we satisfy our fourth property."
  },
  {
    "objectID": "qmd/pde/heatequ/heatEquation.html#heat-equation",
    "href": "qmd/pde/heatequ/heatEquation.html#heat-equation",
    "title": "Derivation of the conduction of heat in a one-dimensional rod",
    "section": "Heat equation",
    "text": "Heat equation\nIf Fouriers law is substituted into the conservation of heat energy equation, we get the following\n\ncp\\frac{\\partial u}{\\partial t} = \\frac{\\partial}{\\partial x}\\left(K_0\\frac{\\partial u}{\\partial x}\\right) + Q.\n\nIn particular, if c,p,K_0 are all constants, the partial differential equation becomes\n\ncp\\frac{\\partial u}{\\partial t} = K_0 \\frac{\\partial^2 u}{\\partial x^2} + Q.\n\nIn addition, there are no sources of energy, Q = 0, then dividing by the constant c\\rho, we have\n\n\\frac{\\partial u}{\\partial t} = k\\frac{\\partial^2 u}{\\partial x^2}\n\nwhere the constant k,\n\nk = \\frac{K_0}{c\\rho}\n\nis called the thermal diffusivity. We call this the heat equation; it corresponds to no sources and constant thermal properties."
  },
  {
    "objectID": "qmd/pde/heatequ/heatEquation.html#diffusion-of-a-chemical-pollutant",
    "href": "qmd/pde/heatequ/heatEquation.html#diffusion-of-a-chemical-pollutant",
    "title": "Derivation of the conduction of heat in a one-dimensional rod",
    "section": "Diffusion of a chemical pollutant",
    "text": "Diffusion of a chemical pollutant\nConsdier a one-dimensional region between x=a and x=b. Let u(x,t) be the density of a chemical per unit volume, and \\phi(x,t) be the amount of chemical flowing per unit surface. These behave similary to our equations for heat.\nWe apply the conservation law to our model, meaning the rate of change of the chemical in [a,b] is equal to the amount of chemical flowing in, subtracted by the amount of chemical flowing out. We use the folowing formula to model this\n\n\\frac{d}{dt} \\int_a^b u(x,t) dx = \\phi(a,t) - \\phi(b,t).\n\nWe simplify the equation to obtain\n\n\\frac{\\partial u}{\\partial t} + \\frac{\\partial \\phi}{\\partial x} = 0\n\nThis is called the conservation law for chemical concentration.\nAdolf Fick studied the relationship between \\phi and u and derived the following formula\n\n\\phi = -k \\frac{\\partial u}{\\partial x}\n\nThis is known as Fick’s law of diffusion, where k is called the chemicals diffusivity and can be measured experimentally. When combining our equations we get\n\n\\frac{\\partial u}{\\partial t} = k\\frac{\\partial^2 u}{\\partial x^2}\n\nWhich is known as the diffusion equation. Notice the similarities between chemical diffusion and heat diffusion. We therefore call this formula the diffusion equation, as it can model many different types of diffusion."
  },
  {
    "objectID": "qmd/pde/heatequ/heatEquation.html#diffusion-of-a-chemical-pollutant.",
    "href": "qmd/pde/heatequ/heatEquation.html#diffusion-of-a-chemical-pollutant.",
    "title": "Derivation of the conduction of heat in a one-dimensional rod",
    "section": "Diffusion of a chemical pollutant.",
    "text": "Diffusion of a chemical pollutant.\nConsdier a one-dimensional region between x=a and x=b. Let u(x,t) be the density of a chemical per unit volume, and \\phi(x,t) be the amount of chemical flowing per unit surface. These behave similary to our equations for heat.\nWe apply the conservation law to our model, meaning the rate of change of the chemical in [a,b] is equal to the amount of chemical flowing in, subtracted by the amount of chemical flowing out. We use the folowing formula to model this\n\n\\frac{d}{dt} \\int_a^b u(x,t) dx = \\phi(a,t) - \\phi(b,t).\n\nWe simplify the equation to obtain\n\n\\frac{\\partial u}{\\partial t} + \\frac{\\partial \\phi}{\\partial x} = 0\n\nThis is called the conservation law for chemical concentration.\nAdolf Fick studied the relationship between \\phi and u and derived the following formula\n\n\\phi = -k \\frac{\\partial u}{\\partial x}\n\nThis is known as Fick’s law of diffusion, where k is called the chemicals diffusivity and can be measured experimentally. When combining our equations we get\n\n\\frac{\\partial u}{\\partial t} = k\\frac{\\partial^2 u}{\\partial x^2}\n\nWhich is known as the diffusion equation. Notice the similarities between chemical diffusion and heat diffusion. We therefore call this formula the diffusion equation, as it can model many different types of diffusion."
  },
  {
    "objectID": "qmd/pde/heatequ/heatEquation.html#diffusion-of-gas-filling-a-tube",
    "href": "qmd/pde/heatequ/heatEquation.html#diffusion-of-gas-filling-a-tube",
    "title": "Derivation of the conduction of heat in a one-dimensional rod",
    "section": "Diffusion of gas filling a tube",
    "text": "Diffusion of gas filling a tube\nGiven a one-dimensional tube between x = a and x=b, let c be the number of particles of gas in the tube. We assume particles behave randomly (Brownian motion) such that they move to the left or right each with probability \\frac{1}{2}.\nWe denote the discrete derivative\n\n\\int_t c_i = \\frac{c_i(t_1)-c_i(t_0)}{\\Delta t}\n\nThe change in particles in a subsection [t_0,t_1] is equa to the particles entering from either side, minus the particles leaving from either side.\nTake the change in the number of particles in the middle subsection. We have\n\n\\phi_{II} = c_{II}(t_1) - c_{II}(t_0) = \\frac{1}{2}c_{I}(t_0) + \\frac{1}{2}c_{III}(t_0) - \\frac{1}{2}c_{II}(t_0) - \\frac{1}{2}c_{II}(t_0)\n\nWe use our notation to model this\n\n\\Delta t \\int_t c_{II} = \\frac{1}{2}[c_{III}(t_0)- c_{II}(t_0)] - \\frac{1}{2}[c_{II}(t_0) - c_{I}(t_0)]\n\n\n\\Delta t \\int_t c_{II} = \\frac{1}{2}\\Delta x \\int_x c_{III}(t_0) - \\frac{1}{2} \\Delta x c_{II}\n\n\n\\Delta t \\int_t c_{II} = \\frac{1}{2} \\Delta x\\left[\\int_x c_{III}(t_0) - \\int_x c_{II}(t_0)\\right]\n\n\n\\Delta t \\int_t c_{II} = \\frac{1}{2} \\Delta x\\left[\\Delta x\\int_x\\left(\\int_x c_{II}(t_0)\\right)\\right]\n\n\n\\int_t c_{II} =\\frac{(\\Delta x)^2}{2\\Delta t}\\int_x\\left(\\int_x c_{II}(t_0)\\right)\n\nAs the length of our slices and the time between measuring the particles goes to zero, our function becomes\n\n\\frac{\\partial c}{\\partial t} = D\\frac{\\partial^2 x}{\\partial x^2}"
  },
  {
    "objectID": "qmd/pde/heatequ/heatEquation.html#conclusion",
    "href": "qmd/pde/heatequ/heatEquation.html#conclusion",
    "title": "Derivation of the conduction of heat in a one-dimensional rod",
    "section": "Conclusion",
    "text": "Conclusion\nThe heat equation we have derived is essentially identical to an abstracted diffusion process, and can therefore be used to model many different applications."
  },
  {
    "objectID": "qmd/pde/heatequ/boundaryCond.html",
    "href": "qmd/pde/heatequ/boundaryCond.html",
    "title": "Boundary Conditions",
    "section": "",
    "text": "When solving the heat equation from the last section, we require two boundary conditions, each end of the rod."
  },
  {
    "objectID": "qmd/pde/heatequ/boundaryCond.html#boundary-conditions",
    "href": "qmd/pde/heatequ/boundaryCond.html#boundary-conditions",
    "title": "Boundary Conditions",
    "section": "Boundary conditions",
    "text": "Boundary conditions\nThere are many types of boundary conditions\n\n\n\n\n\n\nDefinition\n\n\n\nPrescribed tempature. If the ends of the rod are in contact with a material, we may approximate the tempature at the end of the rod with the tempature of the material.\n\nu(0,t) = u_L(t)\n\nWhere u_L(t) is the tempature of the material. This is also called the Dirichlet boundary condition.\nPrescribed flux. In other cases, it is possible to prescribe the heat flux rather than the tempature.\n\n-K_0(0)\\frac{\\partial u}{\\partial x}(0,t) = \\phi_L(t)\n\nThis is also known as Neumann boundary condition.\nNewtons law of cooling. When a one-dimensional rod is losing heat to it’s enviorment, the air near the end of the rod is hotter than the air further away. We model this approximately with\n\n-K_0(0)\\frac{\\partial u}{\\partial x}(0,t) = -H[u(0,t) - u_B(t)]\n\nWhere H is known as the heat transfer coefficient. This is also known as the Robin boundary condition.\n\n\nYou can mix and match boundary conditions however you please."
  },
  {
    "objectID": "qmd/pde/heatequ/boundaryCond.html#consevation-of-heat-energy-susbections",
    "href": "qmd/pde/heatequ/boundaryCond.html#consevation-of-heat-energy-susbections",
    "title": "Boundary Conditions",
    "section": "Consevation of heat energy (susbections)",
    "text": "Consevation of heat energy (susbections)\nWe want to derive an equation to see how heat energy in a rod changes overtime.\nWe first consider a rod of length L, stretching from x = 0 to {x=L.} Consider a subsection of the rod x = x^\\prime to x = x^\\prime + \\Delta x.\nThe total thermal energy in this subsection of the rod is the product of the thermal energy density and the volume of the subsection. This is given by the equation\n\n\\text{Heat Energy } = e(x,t)A\\Delta x\n\nwhere A is the cross sectional area of the rod.\nTo find the rate of change of heat energy in time in the subsection, we have to find the heat energy entering the subsection, the heat energy leaving the subsection, and the heat energy generated inside the subsection per unit time. This is given by the equation\n\n\\text{Change in Heat Energy } = \\frac{\\partial}{\\partial t}\\left[e(x,t)A\\Delta x\\right]\n\nClearly then\n\n\\frac{\\partial}{\\partial t}\\left[e(x,t)A\\Delta x\\right] = \\phi(x,t)A - \\phi(x + \\Delta x)A + Q(x,t)A\\Delta x\n\nFrom here we can divide both sides by A \\Delta x to get\n\n\\frac{\\partial}{\\partial t}e(x,t) = \\frac{\\phi(x,t) - \\phi(x + \\Delta x)}{\\Delta x} + Q(x,t)\n\nAs \\Delta x \\to 0 we have\n\n\\frac{\\partial}{\\partial t}e(x,t) = -\\lim_{\\Delta x \\to 0}\\frac{\\phi(x + \\Delta x) - \\phi(x,t)}{\\Delta x} + Q(x,t)\n\nThis is the limit definition of a derivative. We can simplify to obtain\n\n\\frac{\\partial}{\\partial t}e(x,t) = -\\frac{\\partial \\phi}{\\partial x} + Q\n\nWhich we call the formula for conservation of heat energy."
  },
  {
    "objectID": "qmd/pde/heatequ/boundaryCond.html#consevation-of-heat-energy-exact",
    "href": "qmd/pde/heatequ/boundaryCond.html#consevation-of-heat-energy-exact",
    "title": "Boundary Conditions",
    "section": "Consevation of heat energy (exact)",
    "text": "Consevation of heat energy (exact)\nAn alternate derivation for conservation of heat energy which does not use any approximations is as follows.\nGiven a rod from x = 0 to x = L, we can calculate the total energy in the rod from [a,b] (where 0 \\leq a &lt; b \\leq L) as the contribution of all infinitisimal slices. We do this with\n\n\\text{Total heat energy between } [a,b] = \\int^b_a e(x,t)A\\;dx\n\nThe rate of change of energy between a and b will be the heat energy flowing across the boundaries per unit time, in addition to the heat energy generated inside per unit time. This is given with the equation\n\n\\frac{d}{dt}\\left(\\int^b_a e(x,t)A\\;dx\\right) = \\phi(a,t)A - \\phi(b,t)A + \\int^b_a Q(x,t)A\\;dx\n\nThis can be simplified\n\n\\int^b_a \\frac{\\partial}{\\partial t} e(x,t)\\;dx = -\\int^b_a \\frac{\\partial \\phi(x,t)}{\\partial x}\\; dx + \\int^b_a Q(x,t)\\;dx\n\nThis equation is called integral conservation law, and is more generally useful. We will use the equation to derive the conservation of heat energy formula we got earlier. We simplify the integral conservation law into\n\n\\int^b_a \\left[\\frac{\\partial}{\\partial t} e(x,t)+ \\frac{\\partial \\phi}{\\partial x} -  Q\\right] dx = 0\n\nThis integral must be zero for arbitrary values of a and b. This is possible only if the integrand itself is zero. Thus we have\n\n\\frac{\\partial}{\\partial t} e(x,t) + \\frac{\\partial \\phi}{\\partial x} -  Q = 0\n\nWhich can be rewrote to be identical to our first derivation\n\n\\frac{\\partial}{\\partial t}e(x,t) = -\\frac{\\partial \\phi}{\\partial x} + Q"
  },
  {
    "objectID": "qmd/pde/heatequ/boundaryCond.html#tempature-and-specific-heat",
    "href": "qmd/pde/heatequ/boundaryCond.html#tempature-and-specific-heat",
    "title": "Boundary Conditions",
    "section": "Tempature and specific heat",
    "text": "Tempature and specific heat\nWe describe materials by their tempature, instead of their thermal energy.\n\nu(x,t) = \\text{ Tempature}\n\nIt may take different levels of thermal energy to raise two different materials from one tempature to another. We introduce the quantity called specific heat or heat capacity. The specific heat is the heat energy that must be supplied to a unit of mass of a substance to raise its tempature one unit\n\nc = \\text{ Specific heat}\n\nIn general, the specific heat depends on the tempature of the material. That is to say it may require less energy to go from 0^\\circ to 10^\\circ then it does to go from 10^\\circ to 20^\\circ. In our case, we will consider just c(x), and in many cases let c be constant.\nThe mass density of a material is mass per unit volume.\n\n\\rho(x) = \\text{ Mass density}\n\nGiven a subsection of a one-dimensional rod, the rotal mass of the subsection is \\rho(x) A \\Delta x, and the total thermal energy in any given slice is thus c(x)u(x,t)\\rho(x) A \\Delta x. This gives us the relation\n\ne(x,t)A\\Delta x = c(x)u(x,t)\\rho(x) A \\Delta x\n\nWhich can be simplified\n\ne(x,t) = c(x)u(x,t)\\rho(x)\n\nThis also changes our conservation of heat energy equation into\n\nc(x)\\rho(x)\\frac{\\partial u}{\\partial t} = -\\frac{\\partial \\phi}{\\partial x} + Q."
  },
  {
    "objectID": "qmd/pde/heatequ/boundaryCond.html#fouriers-law",
    "href": "qmd/pde/heatequ/boundaryCond.html#fouriers-law",
    "title": "Boundary Conditions",
    "section": "Fouriers law",
    "text": "Fouriers law\nWhat is the relation between \\phi(x,t) and u(x,t)? Fourier experimented and realized four main relations between the two quantities\n\nIf the tempature of the rod is constant, the energy does not flow.\nIf tempature is not constant, the heat energy flows from the hotter region towards the colder region.\nThe greater the tempature differences (for the same material), the greater the flow of heat energy.\nThe flow of heat energy will vary for different materials, even with the same tempature differences.\n\nFourier wanted to create an equation to summarize these properties, and used the formula\n\n\\phi = -K_0 \\frac{\\partial u}{\\partial x}\n\nKnown as Fouriers law of heat conduction. But does this formula accuratly model our results?\nStarting with the first observation, if tempature is constant then no heat energy flows. When tempature is constant, our formula gives us\n\n\\phi = -K_0 \\frac{\\partial u}{\\partial x} = -K_0 (0) = 0\n\nMatching our observations. The second property states if tempature differences are present, the heat energy flows from the hotter to colder regions. If the tempature with respect to position of the rod is increasing, we have \\partial u / \\partial x &gt; 0, and therefore \\phi = -K_0 (\\partial u / \\partial x) &lt; 0. Because \\phi is less than zero, energy is flowing to the left, from the hotter to colder region. When \\partial u / \\partial x &lt; 0, we have \\phi &gt; 0, as expected. This explains the minus sign present in the formula.\nWhen the tempature differences are greater, \\partial u / \\partial x is greater, and the flow of heat energy \\phi is also greater.\nThe thermal conductivity of the material K_0. Experiments indicate that different materials conduct heat differently, where K_0 depends on a specific material. This is how we satisfy our fourth property."
  },
  {
    "objectID": "qmd/pde/heatequ/boundaryCond.html#heat-equation",
    "href": "qmd/pde/heatequ/boundaryCond.html#heat-equation",
    "title": "Boundary Conditions",
    "section": "Heat equation",
    "text": "Heat equation\nIf Fouriers law is substituted into the conservation of heat energy equation, we get the following\n\ncp\\frac{\\partial u}{\\partial t} = \\frac{\\partial}{\\partial x}\\left(K_0\\frac{\\partial u}{\\partial x}\\right) + Q.\n\nIn particular, if c,p,K_0 are all constants, the partial differential equation becomes\n\ncp\\frac{\\partial u}{\\partial t} = K_0 \\frac{\\partial^2 u}{\\partial x^2} + Q.\n\nIn addition, there are no sources of energy, Q = 0, then dividing by the constant c\\rho, we have\n\n\\frac{\\partial u}{\\partial t} = k\\frac{\\partial^2 u}{\\partial x^2}\n\nwhere the constant k,\n\nk = \\frac{K_0}{c\\rho}\n\nis called the thermal diffusivity. We call this the heat equation; it corresponds to no sources and constant thermal properties."
  },
  {
    "objectID": "qmd/pde/heatequ/boundaryCond.html#diffusion-of-a-chemical-pollutant",
    "href": "qmd/pde/heatequ/boundaryCond.html#diffusion-of-a-chemical-pollutant",
    "title": "Boundary Conditions",
    "section": "Diffusion of a chemical pollutant",
    "text": "Diffusion of a chemical pollutant\nConsdier a one-dimensional region between x=a and x=b. Let u(x,t) be the density of a chemical per unit volume, and \\phi(x,t) be the amount of chemical flowing per unit surface. These behave similary to our equations for heat.\nWe apply the conservation law to our model, meaning the rate of change of the chemical in [a,b] is equal to the amount of chemical flowing in, subtracted by the amount of chemical flowing out. We use the folowing formula to model this\n\n\\frac{d}{dt} \\int_a^b u(x,t) dx = \\phi(a,t) - \\phi(b,t).\n\nWe simplify the equation to obtain\n\n\\frac{\\partial u}{\\partial t} + \\frac{\\partial \\phi}{\\partial x} = 0\n\nThis is called the conservation law for chemical concentration.\nAdolf Fick studied the relationship between \\phi and u and derived the following formula\n\n\\phi = -k \\frac{\\partial u}{\\partial x}\n\nThis is known as Fick’s law of diffusion, where k is called the chemicals diffusivity and can be measured experimentally. When combining our equations we get\n\n\\frac{\\partial u}{\\partial t} = k\\frac{\\partial^2 u}{\\partial x^2}\n\nWhich is known as the diffusion equation. Notice the similarities between chemical diffusion and heat diffusion. We therefore call this formula the diffusion equation, as it can model many different types of diffusion."
  },
  {
    "objectID": "qmd/pde/heatequ/boundaryCond.html#diffusion-of-gas-filling-a-tube",
    "href": "qmd/pde/heatequ/boundaryCond.html#diffusion-of-gas-filling-a-tube",
    "title": "Boundary Conditions",
    "section": "Diffusion of gas filling a tube",
    "text": "Diffusion of gas filling a tube\nGiven a one-dimensional tube between x = a and x=b, let c be the number of particles of gas in the tube. We assume particles behave randomly (Brownian motion) such that they move to the left or right each with probability \\frac{1}{2}.\nWe denote the discrete derivative\n\n\\int_t c_i = \\frac{c_i(t_1)-c_i(t_0)}{\\Delta t}\n\nThe change in particles in a subsection [t_0,t_1] is equa to the particles entering from either side, minus the particles leaving from either side.\nTake the change in the number of particles in the middle subsection. We have\n\n\\phi_{II} = c_{II}(t_1) - c_{II}(t_0) = \\frac{1}{2}c_{I}(t_0) + \\frac{1}{2}c_{III}(t_0) - \\frac{1}{2}c_{II}(t_0) - \\frac{1}{2}c_{II}(t_0)\n\nWe use our notation to model this\n\n\\Delta t \\int_t c_{II} = \\frac{1}{2}[c_{III}(t_0)- c_{II}(t_0)] - \\frac{1}{2}[c_{II}(t_0) - c_{I}(t_0)]\n\n\n\\Delta t \\int_t c_{II} = \\frac{1}{2}\\Delta x \\int_x c_{III}(t_0) - \\frac{1}{2} \\Delta x c_{II}\n\n\n\\Delta t \\int_t c_{II} = \\frac{1}{2} \\Delta x\\left[\\int_x c_{III}(t_0) - \\int_x c_{II}(t_0)\\right]\n\n\n\\Delta t \\int_t c_{II} = \\frac{1}{2} \\Delta x\\left[\\Delta x\\int_x\\left(\\int_x c_{II}(t_0)\\right)\\right]\n\n\n\\int_t c_{II} =\\frac{(\\Delta x)^2}{2\\Delta t}\\int_x\\left(\\int_x c_{II}(t_0)\\right)\n\nAs the length of our slices and the time between measuring the particles goes to zero, our function becomes\n\n\\frac{\\partial c}{\\partial t} = D\\frac{\\partial^2 x}{\\partial x^2}"
  },
  {
    "objectID": "qmd/pde/heatequ/boundaryCond.html#conclusion",
    "href": "qmd/pde/heatequ/boundaryCond.html#conclusion",
    "title": "Boundary Conditions",
    "section": "Conclusion",
    "text": "Conclusion\nThe heat equation we have derived is essentially identical to an abstracted diffusion process, and can therefore be used to model many different applications."
  },
  {
    "objectID": "qmd/pde/heatequ/boundaryCond.html#equilibruim-temperature-distribution",
    "href": "qmd/pde/heatequ/boundaryCond.html#equilibruim-temperature-distribution",
    "title": "Boundary Conditions",
    "section": "Equilibruim temperature distribution",
    "text": "Equilibruim temperature distribution\nAn equilibruim tempature distribution would or steady-state solution is a solution independent of time.\nA very typical problem in heat flow is one where the thermal coefficients are constant and there are no sources of thermal energy. In this case, the tempature in a one-dimensional rod 0 \\leq x \\leq L satisfies\n\n\\frac{\\partial u}{\\partial t} = k\\frac{\\partial^2 u}{\\partial x^2}\n\nWith the initial conditions\n\\begin{align*}\nu(0,t) &= T_1\\\\\nu(L,t) &= T_2\\\\\nu(x,0) &= f(x)\\\\\n\\end{align*}\nWe know that if our desired function u_{eq}(x) is not dependent on time, then\n\n\\frac{\\partial u}{\\partial t} = 0 = k\\frac{\\partial^2 u}{\\partial x^2}\n\nIntegrating twice gives us\n\nu_{eq}(x) = C_1x + C_2\n\nUsing our boundaries, we have that u_{eq}(0) = T_1 and u_{eq}(L) = T_2. Thus T_1 = C_2 and T_2 = C_1L + C_2. Solving for the constants we have\n\nu_{eq}(x) = \\frac{T_2 - T_1}{L}x + T_1.\n\nLets try the same problem with an insulated rod. That is\n\\begin{align*}\n\\frac{\\partial u}{\\partial t} &= k\\frac{\\partial^2 u}{\\partial x^2}\\\\\n\\phi(0,t) &= 0\\\\\n\\phi(L,t) &= 0\\\\\nu(x,0) &= f(x)\n\\end{align*}.\n\n\\frac{d}{dt} \\int_0^L e(x,t)= c \\int_0^L u(x,t \\;dx)  = 0\n.\n\nIf f(x) \\geq 0 and Q(x,t) \\geq 0, then u(x,t) \\geq 0 for all t.\nIf f(x) \\leq M and Q(x,t) \\leq 0, then u(x,t) \\leq M."
  },
  {
    "objectID": "qmd/realanal/limits-cont/funclim.html",
    "href": "qmd/realanal/limits-cont/funclim.html",
    "title": "Limits of Functions",
    "section": "",
    "text": "The limits of a functions determine how close the values of f(x) are to some real number L, as x approaches c, although not neccessarily at c itself.\nIn English, a function has a limit L at c if, as x gets arbitrarily close to c, f(x) gets arbitrarily close to L."
  },
  {
    "objectID": "qmd/realanal/limits-cont/funclim.html#definition-and-properties",
    "href": "qmd/realanal/limits-cont/funclim.html#definition-and-properties",
    "title": "Limits of Functions",
    "section": "Definition and properties",
    "text": "Definition and properties\n\n\n\n\n\n\nDefinition\n\n\n\nA sequence (S_n) of real numbers converges to a real number s if\n\n\\forall \\varepsilon &gt; 0, \\exists N \\in \\mathbb{N} \\mid \\forall n \\geq N, |S_n - s| &lt; \\varepsilon\n\nEssentially, a sequence is convergent if the elements of (S_n) get arbitrarily close to a point s.\nIf a sequence does not converge, than we say it is divergent\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf (S_n) converges to s, then we say that s is the limit of (S_n) and we write\n\n\\lim_{n \\to \\infty} S_n = s\n\n\n\nA quick note on notation, (S_n) refers to the sequence as a whole, where as S_n refers to an indivual element of the sequence.\n\n\n\n\n\n\nTheorem (Archimedean property)\n\n\n\nThe Archimedean property states that the natural numbers are unbounded in \\mathbb{R}.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nTo-do\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nGiven the sequence S_n = 1/n, we claim\n\n\\lim_{n \\to \\infty} \\frac{1}{n} = 0.\n\nWe can show this using our definition of a convergent sequence. We need to prove that their exists some N \\in \\mathbb{N} such that for all n \\geq N, we have\n\n|\\frac{1}{n} - 0| = |\\frac{1}{n}| = \\frac{1}{n} &lt; \\varepsilon\n\nBy the Archimedean property, we know there always exists some N \\in \\mathbb{N} such that 0 &lt; \\frac{1}{N} &lt; \\varepsilon. Therefore our sequence converges to 0.\n\n\nLet s \\in \\mathbb{R} and let S_n = s for all n \\in \\mathbb{N}. Then,\n\n\\lim_{n \\to \\infty} S_n = s.\n\nWe call this the constant sequence.\n\n\n\n\n\n\nDefinition\n\n\n\nA sequence (S_n) is bounded if there exists M \\geq 0 such that |S_n| \\leq M.\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nEvery convergent sequence is bounded.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nBecause (S_n) is a convergent sequence, S_n \\to s. In the definition of a convergent sequence, let \\varepsilon = 1. This means that there exists some N \\in \\mathbb{N} such that for all n \\geq N, we have that |S_n - s| &lt; 1.\nThrough the triangle inequality, we have that, for all n \\geq N\n\n|S_n| - |s| \\leq |S_n - s| &lt; 1 \\iff |S_n| &lt; 1 + |s|.\n\nLet M = \\sup\\{|S_1|,|S_2|,\\ldots,|S_N|,|s| + 1\\}. Therefore we have that for all n \\in \\mathbb{N}, |S_n| \\leq M and hence (S_n) is bounded.\n\n\n\n\nThe contrapositive of course is also true, any unbounded sequence is divergent. However, not all divergent sequences are unbounded.\n\n\n\n\n\n\nExample\n\n\n\nGiven the sequence (S_n) = (-1)^n\nTO DO\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nIf a sequence converges, its limit is unique.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLet (S_n) be a convergent sequence and S_n \\to s and S_n \\to t. We want to show that s and t are arbitrarily close and therefore s = t.\nBy the definition of convergence we have\n\n\\exists N_1 \\in \\mathbb{N} \\text{ such that }\\forall n \\geq N_1, |S_n - s| &lt; \\frac{\\varepsilon}{2}.\n\nand\n\n\\exists N_2 \\in \\mathbb{N} \\text{ such that }\\forall n \\geq N_2, |S_n - t| &lt; \\frac{\\varepsilon}{2}.\n\n\n\\text{ and } |S_n - t| &lt; \\frac{\\varepsilon}{2}\n\nLet N = \\max\\{N_1,N_2\\}"
  },
  {
    "objectID": "qmd/realanal/sequences.html",
    "href": "qmd/realanal/sequences.html",
    "title": "Sequences",
    "section": "",
    "text": "Sequences play a vital part in analysis, and build to notions of continuity, limits, derivatives, and series."
  },
  {
    "objectID": "qmd/realanal/limits-cont.html",
    "href": "qmd/realanal/limits-cont.html",
    "title": "Limits and Continuity",
    "section": "",
    "text": "In this section we extend the notion of limits to functions, and introduces the concept of a continuous functions."
  },
  {
    "objectID": "qmd/realanal/differentiation.html",
    "href": "qmd/realanal/differentiation.html",
    "title": "Differentiation",
    "section": "",
    "text": "In calculus we learned about derivatives, being the instantanious rate of change of a function. We formalize that notion in this section."
  },
  {
    "objectID": "qmd/realanal/integration.html",
    "href": "qmd/realanal/integration.html",
    "title": "Integration",
    "section": "",
    "text": "Integrals measure the signed area between the function and the x-axis."
  },
  {
    "objectID": "qmd/realanal/infinite-series.html",
    "href": "qmd/realanal/infinite-series.html",
    "title": "Sequences",
    "section": "",
    "text": "Real analysis is the study of real numbers"
  },
  {
    "objectID": "qmd/realanal/limits-cont/cont-func.html",
    "href": "qmd/realanal/limits-cont/cont-func.html",
    "title": "Continuous Functions",
    "section": "",
    "text": "Definition\n\n\n\nLet f \\colon D \\to \\mathbb{R}, where x,c \\in D. We say that f is continuous at c if\n\n\\forall \\varepsilon &gt; 0, \\exists \\delta &gt; 0, |x-c| &lt; \\delta \\implies |f(x) - f(c)| &lt; \\varepsilon.\nIn English, this means a function is continuous if x approaching c implies the difference between f(x) and f(c) is arbitrarily small.\nIf f is continuous at all points x \\in D, we say that f is continuous on D. Note that this definition of continuity is a pointwise notion.\nTaking the negation of (a) and (b) in this Theorem, we have a useful Corollary for what it means for a function to be discontinous.\nNote that the pre-image of a set may not exist. In this case we would say f^{-1}(U) is the empty set, \\varnothing.\n$And when D is \\mathbb{R}, we can write"
  },
  {
    "objectID": "qmd/realanal/intro.html#table-of-contents",
    "href": "qmd/realanal/intro.html#table-of-contents",
    "title": "Real Analysis",
    "section": "Table of Contents",
    "text": "Table of Contents\n\n\n\n\nDedekind cut at square root of two1"
  },
  {
    "objectID": "qmd/realanal/sequences/convergence.html#sec-practice",
    "href": "qmd/realanal/sequences/convergence.html#sec-practice",
    "title": "Convergence",
    "section": "Practice",
    "text": "Practice\n\n\n\n\n\n\nProblem \\star\n\n\n\nProve if |x| &lt; 1, then \\lim_{n\\to\\infty} x^n = 0 using Bernoulii’s inequality,\n\n(1 + y)^n \\geq 1 + ny.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf x = 0, the proof is trivial, so we need to prove the case where 0 &lt; |x| &lt; 1. Bernoulii’s inequality states\n\n(1 + y)^n \\geq 1 + ny.\n\nIf we let x = 1/(1+y) for some y &gt; 0, we get\n\n(1 + \\frac{1}{x} - 1)^n \\geq 1 + n\\left(\\frac{1}{x} - 1\\right) \\implies \\frac{1}{x^n} \\geq 1 + \\frac{n}{x} - n\n\nFlipping both sides of the inequality gets us\n\nx^n \\leq \\frac{1}{1 + \\frac{n}{x} - n}.\n\nTaking the right hand side of the equation, and using our substitution for y, we obtain\n\n\\frac{1}{1 + \\frac{n}{x} + n} = \\frac{1}{1 + yn + 2n}.\n\nLet 1 + yn + 2n = k For any \\varepsilon &gt; 0, there exists N \\in \\mathbb{N} such that for all n \\geq N,\n\n\\left|\\frac{1}{1 + yn + 2n} - 0\\right| = \\left|\\frac{1}{k} - 0 \\right| \\leq \\frac{1}{k} \\leq \\varepsilon\n\nWe know by the Archimedian property there exists some n giving us a suffienct value of k. Thus \\lim 1/(1 + n/x - n) = 0. We have\n\n|x^n - 0| = x^n \\leq \\frac{1}{1 + \\frac{n}{x} - n}\n\nWhich by Theorem 1.1.1, gives us \\lim x^n = 0."
  },
  {
    "objectID": "qmd/realanal/intro.html#footnotes",
    "href": "qmd/realanal/intro.html#footnotes",
    "title": "Real Analysis",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMelikamp, CC BY-SA 4.0 https://creativecommons.org/licenses/by-sa/4.0, via Wikimedia Commons↩︎"
  },
  {
    "objectID": "qmd/realanal/sequences/mono-cauchy.html",
    "href": "qmd/realanal/sequences/mono-cauchy.html",
    "title": "Monotone sequences and Cauchy sequences",
    "section": "",
    "text": "Most of the previous methods for proving the limit of a sequence require us to have some idea of the limit before we proceed. This section will cover techniques to prove that a limit exists, even if we don’t know the precise value the sequence converges to."
  },
  {
    "objectID": "qmd/pde/heatequ/heatEquation-Dim.html",
    "href": "qmd/pde/heatequ/heatEquation-Dim.html",
    "title": "Derivation of the conduction of heat in mutliple dimensions",
    "section": "",
    "text": "Let R be some three dimensional region, and S be the surface area of said region.\nUsing the conservation law we have that the rate of change of energy in R is the sum of the energy entering the boundary, with the energy generated inside the region, minus the energy leaving the boundary.\nWe have\n\\text{Flux} = \\vec{\\phi}(x,t)\nAnd the energy across the border is the normal component to the boundary with the flux.\n\\frac{d}{dt}\\left(\\iiint_R c(x)\\rho(x)u(x,t) dx\\right) = - \\oiint_S(\\phi \\cdot n) dn + \\iiint_R Q(x,t) dx\nThe divergence theorem states that if \\vec{A} is a continously differentiable vector, \\vec{A} = (A_x,A_y,A_z). Thus\n\\iiint_R (\\nabla \\cdot \\vec{A}) dx = \\oiint_S (\\vec{A} \\cdot n)dn\nWhere\n\\nabla \\cdot \\vec{A} = \\frac{\\partial A_x}{\\partial x} + \\frac{\\partial A_y}{\\partial y} + \\frac{\\partial A_z}{\\partial z}\nUsing the Divergence theorem, we can rewrite our equation for heat as\n\\iiint_R c(x)\\rho(x)\\frac{\\partial u}{\\partial t}(x,t) + \\nabla \\cdot \\phi(x,t) - Q(x,t)\\; dx = 0\nTherefore\nc(x)\\rho(x)\\frac{\\partial u}{\\partial t}(x,t) + \\nabla \\cdot \\phi(x,t) - Q(x,t)\\; = 0\nWe can convert flux into tempature using Fouriers law from our one dimensional case,\n\\bar\\phi(\\bar x,t) = -k_0(\\bar x)\\nabla u\nThus we get for our multiple dimensional heat equation\nc(x)\\rho(x)\\frac{\\partial u}{\\partial t}(x,t) = \\nabla \\cdot (k_0(\\bar x)\\nabla u) + Q(x,t)\\;\nIf \\rho, k_0 are both constants we achieve\n\\frac{\\partial u}{\\partial t}(\\bar x,t) = k\\nabla \\cdot (\\nabla u) + \\frac{1}{c\\rho}Q(\\bar x,t)\nWhere k = k_0/c\\rho and is our thermal diffusitivy. We sometimes write\n\\nabla \\cdot (\\nabla u) = \\nabla^2 u = \\Delta u\nWhere\n\\Delta u = \\nabla(\\frac{\\partial U_x}{\\partial x}, \\frac{\\partial U_y}{\\partial y},\\frac{\\partial U_z}{\\partial z}) = \\frac{\\partial^2 U_x}{\\partial x^2} + \\frac{\\partial^2 U_y}{\\partial y^2} + \\frac{\\partial^2 U_z}{\\partial z^2}\nIf Q = 0, then the heat equation becomes\n\\frac{\\partial u}{\\partial t} = k\\Delta u\nWe now must complement the system with initial conditions and boundary conditions."
  },
  {
    "objectID": "qmd/pde/heatequ/heatEquation-Dim.html#boundary-conditions",
    "href": "qmd/pde/heatequ/heatEquation-Dim.html#boundary-conditions",
    "title": "Derivation of the conduction of heat in mutliple dimensions",
    "section": "Boundary conditions",
    "text": "Boundary conditions\nWe have prescribed tempature\n\nu(\\bar x,t) = T(\\bar x, t) \\quad \\forall \\bar x \\in S\n\nPrescribed Flux\n\n\\bar \\phi (\\bar x, t) \\cdot \\bar n(\\bar x) = g(\\bar x,t)\\quad \\forall \\bar x \\in S\n\nIn the case of an insulated surface, you would have \\bar \\phi \\cdot \\bar n = 0 = \\nabla u \\cdot \\bar n.\nWe also have Newtons law of cooling\n\n-k_0(\\bar x) \\nabla u \\cdot \\bar n = H(u(\\bar x,t)- U(\\bar x,t)) \\quad \\forall \\bar x \\in S\n\nWhere U(\\bar x,t) is the tempature of the surrounding material.\nBoundary conditions can be different in different parts of the domain.\nIf the boundary conditions and sources of heat (Q) are independent of time, there will exist a steady state solution such that\n\nu_{eq}(\\bar x) \\implies \\frac{\\partial u_{eq}}{\\partial t} = 0\n\nIf c,\\rho,k_0 are constants, then\n\n- k\\Delta u = \\frac{Q}{c\\rho} \\iff - \\Delta u = \\frac{Q}{k_0}\n\nThis is called the Poisson equation. In the particular case that Q is zero, then \\Delta u = 0. This is called the Laplace equation.\nHarmonic functions satisfy the equation\n\n-\\Delta u (\\bar x) = 0\\quad \\bar x \\in \\mathbb{R}"
  },
  {
    "objectID": "qmd/pde/sep-var/heatEquation-Dim.html",
    "href": "qmd/pde/sep-var/heatEquation-Dim.html",
    "title": "Method of seperation of variables",
    "section": "",
    "text": "A function has input scalars/vectors, and output scalars/vectors. Similarly operators input functions and output functions.\nAn operator is linear if and only if it is satisifed that\n\nL(c_1u_1 + c_2u_2) = c_1L(u_1) + c_2L(u_2)\n\nWhere u_1,u_2 are arbitrary functions and c_1,c_2 are arbitrary constants.\nThe heat operator is\n\nL(u) = \\frac{\\partial u}{\\partial t} - k\\frac{\\partial^2 u}{\\partial x^2}\n\nA linear equation for the unknown u is of the format\n\nL(u) = f(x,t)\n\nWhere L is a linear operator and f(x,t) does not depend on u.\nMoreover if in the linear equation L(u) = f(x,t) we have f(x,t) = 0 we say the equation is Linear and homogeneous."
  },
  {
    "objectID": "qmd/realanal/limits-cont/uniform-continuity.html",
    "href": "qmd/realanal/limits-cont/uniform-continuity.html",
    "title": "Uniform Continuity",
    "section": "",
    "text": "Continuity is defined on each point c \\in D, we want to define a notion of continuity that is not pointwise, and is instead defined on the whole domain D."
  },
  {
    "objectID": "qmd/pde/sep-var/method.html",
    "href": "qmd/pde/sep-var/method.html",
    "title": "Method of seperation of variables",
    "section": "",
    "text": "A function has input scalars/vectors, and output scalars/vectors. Similarly operators input functions and output functions.\nAn operator is linear if and only if it is satisifed that\nL(c_1u_1 + c_2u_2) = c_1L(u_1) + c_2L(u_2)\nWhere u_1,u_2 are arbitrary functions and c_1,c_2 are arbitrary constants.\nThe heat operator is\nL(u) = \\frac{\\partial u}{\\partial t} - k\\frac{\\partial^2 u}{\\partial x^2}\nA linear equation for the unknown u is of the format\nL(u) = f(x,t)\nWhere L is a linear operator and f(x,t) does not depend on u.\nMoreover if in the linear equation L(u) = f(x,t) we have f(x,t) = 0 we say the equation is linear and homogeneous. If f(x,t) \\not = 0, we say the equation is nonhomogeneous."
  },
  {
    "objectID": "qmd/pde/sep-var/method.html#principle-of-superposition",
    "href": "qmd/pde/sep-var/method.html#principle-of-superposition",
    "title": "Method of seperation of variables",
    "section": "Principle of Superposition",
    "text": "Principle of Superposition\nThe fundemental property of linear operators allows solutions to be added together as such:\n\n\n\n\n\n\nTheorem (Principle of Superposition)\n\n\n\nIf u_1 and u_2 satsify a linear homogeneous equation, then an arbitrary linear combination of them c_1u_1 + c_2u_2 also satisfies the same linear homogeneous equation.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nGiven a linear homogeneous operator L, if u_1,u_2 satisfy this equation, then L(u_1) = L(u_2) = 0. Thus\n\nL(c_1u_1 + c_2u_2) = c_1L(u_1) + c_2L(u_2) = 0\n\nby the definition of linearity.\n\n\n\nThe concept of linearity and homogeneity also apply to boundary conditions."
  },
  {
    "objectID": "qmd/pde/sep-var/heat-equ-zero-temp.html",
    "href": "qmd/pde/sep-var/heat-equ-zero-temp.html",
    "title": "Heat Equation with zero temperature at endpoints",
    "section": "",
    "text": "Consider the problem\n\\begin{cases}\n\\frac{\\partial u}{\\partial t} = k \\frac{\\partial^2 u}{\\partial x^2}\\\\\nu(0,t) = 0\\\\\nu(L,t) = 0\\\\\nu(x,0) = f(x)\n\\end{cases}\nWe want to find u(x,t) where 0 &lt; x &lt; L, t&gt; 0. Here we use the method of seperation of variables.\nWe assume the function is of the form u(x,t) = A(x)G(t) where A is a function depending only on x and G only on t. We call solutions in this form product solutions.\nPlugging our product solution into the partial differential equation, we get\n\n\\frac{\\partial u}{\\partial t} = k \\frac{\\partial^2 u}{\\partial x^2} \\iff \\frac{\\partial (A(x)G(t))}{\\partial t} = k \\frac{\\partial^2 (A(x)G(t))}{\\partial x^2}\n\nWhich simplifies too\n\nA(x)\\frac{dG(t)}{dt} = kG(t)\\frac{d^2A(x)}{dx^2} \\iff \\frac{1}{kG(t)}\\frac{dG(t)}{dt} = \\frac{1}{A(x)}\\frac{d^2A(x)}{dx^2}\n\nWe set both of these terms equal to a constant, -\\lambda. We then have\n\n\\frac{dG}{dt} = -\\lambda kG(t) \\qquad \\frac{d^2A}{dx^2} = -\\lambda A(x)\n\nWe now must satisfy our boundary conditions.\n\nu(0,t) = A(0)G(t) = 0 \\qquad u(L,t) = A(L)G(t)\n\nThus either G(t) = 0 for all times t, or A(0) = A(L) = 0. We call the case where G(t) = 0 the trivial case, and only focus on the case where A(0) = A(L) = 0 We have\n\n\\frac{dG}{dt} = -\\lambda kG(t) \\implies G(t) = Ce^{-\\lambda k t}\n\nIf \\lambda &gt; 0, then the solution exponentially decays as t \\to \\infty. If \\lambda = 0, then the solution is constant for some c. If \\lambda &lt; 0, then the solution increases to infinity. We want too find the values of lambda for A such that non-trivial solutions exist. We must introduce eigenvalues and eigenfunctions in order to do this. For each eigenvalue we have one corresponding eigenfunction.\nWe use the characteristic equation\n\nr^2 = -\\lambda \\implies r = \\pm \\sqrt{-\\lambda}\n\nWhen \\lambda &gt; 0\n\nr = \\pm i \\sqrt{\\lambda} \\implies A(x) = c_1 \\cos (\\sqrt{\\lambda}x) + c_2\\sin (\\sqrt{\\lambda}x)\n\nWorking this into our boundary conditions, we have\n\nA(0) = c_1\\cos(0) + c_2\\sin(0) = c_1 \\implies c_1 = 0\n\nThus\n\nA(x) = c_2 \\sin(\\sqrt{\\lambda}x)\n\nUsing the second boundary conditions\n\nA(L) = c_2\\sin(\\sqrt{\\lambda}L) \\implies \\lambda = (\\frac{\\pi n}{L})^2\n\nSo \\lambda &gt; 0 gives us\n\nA(x) = c_2\\sin\\left(\\frac{nx\\pi}{L}\\right)\n\nNext we have to consider the case where \\lambda = 0.\n\n\\frac{d^2 A}{dA^2} = 0 \\implies c_3x + c_4\n\nThis immeditally implies that A(0) = c_4 = 0. Thus we have A(x) = c_3 x. But A(L) = Lc_3 = 0 \\implies c_3 = 0. Thus we have no solutions. Thus \\lambda = 0 is not an eigenvalue.\nNext we consider \\lambda &lt; 0. This gives us r = \\pm\\sqrt{+ \\lambda}\n\nA(x) = c_1e^{\\sqrt{-\\lambda}x} + c_2e^{-\\sqrt{-\\lambda}x}\n\nWe get\n\nu(x,t) = B\\sin\\left(\\frac{n\\pi x}{L}\\right)e^{-k\\left(\\frac{n\\pi}{L}\\right)^2t}\n\nSomething something\n\nu(x,t) = 7\\sin\\left(\\frac{8\\pi x}{L}\\right)e^{-k(8\\pi/L)^2t}\n\nWe use the principle of superposition, which states that any solution can be in the form\n\nu(x,t) = \\sum_{n=1}^NB_n\\sin\\left(\\frac{n\\pi x}{L}\\right)e^{-k(n\\pi/L)^2t}\n\nWe know that the sum of multiple solutions is a solution due to linearity. We have infinite solutions. The sum of all possible solutions is\n\nu(x,t) = \\sum_{n=1}^\\infty B_n\\sin\\left(\\frac{n\\pi x}{L}\\right)e^{-k(n\\pi/L)^2t}\n\nThis will work for any initial condition u(x,0) = f(x). We need functions that can wrote as an infinite sum we can apply linearity to. We claim any function can be wrote as an infinite linear combination of \\sin functions, known as a Fourier Series\n\nf(x) = \\sum_{n=1}^\\infty B_n \\sin \\frac{n\\pi x}{L}.\n\nBut how do we determine the constant B_n for a given function f(x)? For this we need to check\n\n\\int_0^L \\sin(\\frac{n\\pi x}{L}) \\sin(\\frac{m\\pi x}{L}) \\; dx.\n\nWhen n \\not = m we use the product of \\sin to get\n\n\\frac{1}{2} \\int_0^L \\cos(\\frac{(n-m)\\pi x}{L}) \\; dx - \\frac{1}{2}\\int_0^L \\cos\\left(\\frac{(n+m)\\pi x}{L}\\right) \\; dx\n\nWhich is equal to\n\n\\frac{1}{2}\\frac{L}{(n-m)\\pi}\\left.\\sin\\left(\\frac{(n-m)\\pi x}{L}\\right)\\right|^L_0 - \\frac{1}{2}\\frac{L}{(n+m)\\pi}\\left.\\sin\\left(\\frac{(n+m)\\pi x}{L}\\right)\\right|^L_0 = 0\n\nWhen n = m we have\n\n\\frac{1}{2}\\int_0^L \\cos(0)\\; dx - \\frac{1}{2}\\int_0^L \\cos\\left(\\frac{2n\\pi x}{L}\\right)\\; dx = \\frac{L}{2}\n\nThus we have\n\n\\int_0^L \\sin\\left(\\frac{n\\pi x}{L}\\right) \\sin\\left(\\frac{m\\pi x}{L}\\right) \\; dx = \\begin{cases}\n0 & n \\not = m\\\\\nL/2 & n = m\n\\end{cases}\n\nSo lets find B_m. We know\n\nf(x) = \\sum_{n=1}^\\infty B_n \\sin \\frac{n\\pi x}{L}.\n\nMultiplying both sides by \\sin(m\\pi x/L) gets us\n\n\\sin\\left(\\frac{m\\pi x}{L}\\right)f(x) = \\sin\\left(\\frac{m\\pi x}{L}\\right)\\sum_{n=1}^\\infty B_n \\sin \\frac{n\\pi x}{L} = \\sum_{n=1}^\\infty B_n \\sin \\frac{n\\pi x}{L}\\sin\\frac{m\\pi x}{L}\n\nIntegrating both sides from 0 to L with respect to x gives\n\n\\int_0^L\\sin\\left(\\frac{m\\pi x}{L}\\right)f(x)\\; dx = \\sum_{n=1}^\\infty B_n \\int_0^L \\sin \\frac{n\\pi x}{L}\\sin\\frac{m\\pi x}{L} \\; dx\n\nWhich we solved earlier. We can expand the sum\n\\begin{align*}\n\\sum_{n=1}^\\infty B_n \\int_0^L \\sin \\frac{n\\pi x}{L}\\sin\\frac{m\\pi x}{L} \\; dx &= B_1 \\int_0^L \\sin \\frac{\\pi x}{L}\\sin\\frac{m\\pi x}{L} \\; dx\\\\\n&+ B_2 \\int_0^L \\sin \\frac{2\\pi x}{L}\\sin\\frac{m\\pi x}{L} \\; dx\\\\\n&+ B_3\\int_0^L \\sin \\frac{3\\pi x}{L}\\sin\\frac{m\\pi x}{L} \\; dx\\\\\n&+ B_4\\int_0^L \\sin \\frac{4\\pi x}{L}\\sin\\frac{m\\pi x}{L} \\; dx\\\\\n&+ \\cdots\\\\\n&+ B_m\\int_0^L \\sin \\frac{m\\pi x}{L}\\sin\\frac{m\\pi x}{L} \\; dx\\\\\n&+ B_{m+1}\\int_0^L \\sin \\frac{(m+1)\\pi x}{L}\\sin\\frac{m\\pi x}{L} \\; dx\\\\\n&+ \\cdots\\\\\n&= B_m \\frac{L}{2}\n\\end{align*}\nThus\n\nB_m = \\frac{2}{L} \\int_0^L f(x) \\sin\\left(\\frac{m\\pi x}{L}\\right)\\; dx\n\nIf we want to represent f(x), we just use the coeffiencts given by the above integral.\nLets say for example we have u(x,0) = f(x) = 100. To write the solution, we need to compute B_n.\n\\begin{align*}\nB_n &= \\frac{2}{L} \\int_0^L f(x) \\sin\\left(\\frac{n\\pi x}{L}\\right)\\; dx\\\\\n&= \\frac{2}{L} \\int_0^L 100 \\sin\\left(\\frac{n\\pi x}{L}\\right)\\; dx\\\\\n&= \\frac{200}{L} \\frac{L}{n\\pi} \\left.\\left(- \\cos\\left(\\frac{n\\pi x}{L}\\right)\\right)\\right|^L_0\\\\\n&= \\frac{200}{n\\pi}\\left[-\\cos(n\\pi) + \\cos(0)\\right]\n\\end{align*}\nThus we have\nB_n = \\begin{cases}\n400/n\\pi  & \\text{if } n \\mod 2 = 1\\\\\n0 & \\text{if } n \\mod 2 = 0\n\\end{cases}\n\nThen f(x) is\n\nf(x) = \\sum_{n=0}^\\infty \\frac{400}{(2n+1)\\pi} \\sin \\frac{(2n+1)\\pi x}{L}.\n\nThen we can rewrite our heat equation as\n\nu(x,t) = \\left(\\sum_{n=0}^\\infty \\frac{400}{(2n+1)\\pi} \\sin \\frac{(2n+1)\\pi x}{L}\\right)e^{-k((2n+1)\\pi/L)^2t}\n\nAnother problem with different boundary conditions\n\nu(x,t) = C\\cos\\left(\\frac{n\\pi x}{L}\\right)e^{-k(n\\pi/L)^2t}\n\nUsing the superposition principle\n\nu(x,t) = \\sum_{n=0}^\\infty A_n \\cos\\left(\\frac{n\\pi x}{L}\\right) e^{-k(n\\pi/L)^2t}\n\nIs also a solution. What do we need in the solution to satisfy the initial condition u(x,0) = f(x) = \\sum A_n\\cos(n\\pi x/L). Same idea as before but with \\cos instead of \\sin. Again we need to find A_n.\nTo determine A_n, we will need\n\n\\int_0^L \\cos\\left(\\frac{n\\pi x}{L}\\right) \\cos\\left(\\frac{m\\pi x}{L}\\right) \\; dx = \\begin{cases}\n0 & n \\not = m\\\\\nL/2 & n = m\\\\\nL & n = m = 0\n\\end{cases}"
  },
  {
    "objectID": "qmd/realanal/sequences/limittheo.html#infinite-limits",
    "href": "qmd/realanal/sequences/limittheo.html#infinite-limits",
    "title": "Limit Theorems",
    "section": "Infinite Limits",
    "text": "Infinite Limits\nCertain sequences like s_n = n are clearly not convergent, but behave predictably; growing without bounds towards infinity. We introduce the notion of divergence for these sequences.\n\n\n\n\n\n\nDefinition\n\n\n\nA sequence (s_n) is said to diverge to +\\infty, notated\n\n\\lim s_n = +\\infty\n\nIf for every M \\in \\mathbb{R}, there exists a natural number N such that n \\geq N implies that s_n &gt; M.\nSimilarly a sequence (s_n) is said to diverge to -\\infty, notated\n\n\\lim s_n = -\\infty\n\nIf for every M \\in \\mathbb{R} there exists a natural number N such that n \\geq N implies that s_n &lt; M.\n\n\nA divergent sequence is NOT convergent, and our limit notation is only used for simplicity. Theorems which require a convergent sequence do not apply to divergent sequences.\n\n\n\n\n\n\nExample\n\n\n\nClaim: \\lim n^2 = + \\infty\nTo show the sequence (s_n) where s_n = n^2 diverges to positive infinity, we must show for every M \\in \\mathbb{R}, there exists a natural number N such that n \\geq N implies s_n &gt; M.\nLet N be equal to the smallest integer greater than |M|. For all integers N^2 \\geq N. Thus for all n \\geq N, s_n = n^2 &gt; n &gt; M. Thus our sequence (s_n) diverges to positive infinity.\n\n\nThe above example is very simple, and gives a general idea for how infinite limit proofs are done. More technical examples can be found in the practice.\n\n\n\n\n\n\nTheorem 1.2.5\n\n\n\nSuppose that (s_n) and (t_n) are sequences such that s_n \\leq t_n for all n \\in \\mathbb{N}.\n(a) If \\lim s_n = + \\infty then \\lim t_n = + \\infty.\n(b) If \\lim t_n = - \\infty then \\lim s_n = - \\infty.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(a) We are given that (s_n) diverges to posiitve infinity. Then for every M there exists a naturaul number N such that n \\geq N implies s_n &gt; M. Because s_n \\leq t_n for all n, we have t_n \\geq s_n &gt; M. Thus for any M, there exists some natural number N such that n \\geq N implies t_n &gt; M, and we have that \\lim t_n = + \\infty.\n\n(b) We are given that (t_n) diverges to negative infinity. Then for every M there exists a natural number N such that n \\geq N implies t_n &lt; M. Because s_n \\leq t_n for all n, we have s_n \\leq t_n &lt; M. Thus for every M, there exists some natural number N such that n \\geq N implies s_n &lt; M, and we have that \\lim s_n = - \\infty\n\n\n\n\n\n\n\n\n\nTheorem 1.2.6\n\n\n\nLet (s_n) be a sequence of positive numbers. Then \\lim s_n = + \\infty if and only if \\lim 1/s_n = 0.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nSuppose that \\lim s_n = + \\infty. Given any \\varepsilon &gt; 0, let M = 1/\\varepsilon. There exists a natural number N such that n \\geq N implies s_n &gt; M = 1/\\varepsilon. Since s_n is positive, we have\n\n\\left|\\frac{1}{s_n} - 0\\right| &lt; \\varepsilon = \\frac{1}{M}\n\nThus \\lim 1/s_n = 0. For the converse, assume \\lim 1/s_n = 0. Then there exists a natural number N such that for all n \\geq N, we have\n\n\\left|\\frac{1}{s_n} - 0\\right|  = \\frac{1}{s_n} &lt; \\varepsilon.\n\nLet M = 1/\\varepsilon. Flipping both sides of the inequality gives us s_n &gt; 1/\\varepsilon = M. Thus for some natural number N, for all n \\geq N we have s_n &gt; M. Thus \\lim s_n = + \\infty."
  },
  {
    "objectID": "qmd/realanal/sequences/convergence.html#recap",
    "href": "qmd/realanal/sequences/convergence.html#recap",
    "title": "Convergence",
    "section": "Recap",
    "text": "Recap\nIn this section we proved the following theorems and results.\n\n\n\n\n\n\nTheorem 1.1.1\n\n\n\nLet (s_n) and (a_n) be sequences of real numbers and let s \\in \\mathbb{R}. If for some k &gt; 0 and some m \\in \\mathbb{N} we have\n\n|s_n - s| \\leq k|a_n|, \\forall n \\geq m\n\nand if a_n = 0, then it follows that \\lim s_n = s.\n\n\n\n\n\n\n\n\nTheorem 1.1.2\n\n\n\nEvery convergent sequence is bounded.\n\n\n\n\n\n\n\n\nTheorem 1.1.3\n\n\n\nIf a sequence converges, its limit is unique.\n\n\n\n\n\n\n\n\nResult\n\n\n\nIf |x| &lt; 1, then \\lim_{n\\to\\infty} x^n = 0."
  },
  {
    "objectID": "qmd/realanal/differentiation/Derivatives.html",
    "href": "qmd/realanal/differentiation/Derivatives.html",
    "title": "The Derivative",
    "section": "",
    "text": "Next we talk about differentialbility\n\n\n\n\n\n\nDefinition\n\n\n\nLet f \\colon I \\to \\mathbb{R} and let c \\in I. We say that f is differentiable at c if the limit \\lim_{x \\to c}(f(x)-f(c))/x-c exists and is finite.\n\n\nThis is of course a pointwise notion of differentiability. To construct a more global definition of differentiability, we have\n\n\n\n\n\n\nDefinition\n\n\n\nIf f is differentiable at every point in a subset S \\subseteq I, we say that f is differentiable on S.\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet f \\colon \\mathbb{R} \\to \\mathbb{R} be a constant function. That is f(x) = d for some d \\in \\mathbb{R}.\nClaim: The derivative of f is zero at every point c \\in \\mathbb{R}.\nWe use out formula for differentiability\n\nf^\\prime(c) = \\lim_{x \\to c} \\frac{f(x) - f(c)}{x - c} = \\lim_{x \\to c} \\frac{d - d}{x - c} = 0\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet f \\colon \\mathbb{R} \\to \\mathbb{R} be the identity function. That is f(x) = x for all x \\in \\mathbb{R}.\nClaim: The derivative of f is one at every point c \\in \\mathbb{R}.\nWe use out formula for differentiability\n\nf^\\prime(c) = \\lim_{x \\to c} \\frac{f(x) - f(c)}{x - c} = \\lim_{x \\to c} \\frac{x - c}{x - c} = 1\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet f \\colon \\mathbb{R} \\to \\mathbb{R} where f(x) = x^2.\nClaim: The derivative of f is 2c at every point c \\in \\mathbb{R}.\nWe use our formula for differentiability\n\nf^\\prime(c) = \\lim_{x \\to c} \\frac{f(x) - f(c)}{x - c} = \\lim_{x \\to c} \\frac{x^2 - c^2}{x - c}\n\nUsing the formula x^2 - y^2 = (x-y)(x+y), we get\n\nf^\\prime(c) = \\lim_{x \\to c} \\frac{(x-c)(x+c)}{x - c} = \\lim_{x \\to c} x + c = 2c\n\n\n\nWe introduce another theorem\n\n\n\n\n\n\nTheorem (Sequential criterion for differentiability)\n\n\n\nA function f \\colon I \\to \\mathbb{R} is differentiable at c if and only if for all sequences (x_n) in I we have\n\n\\frac{f(x_n)-f(c)}{x_n - c}\n\nconverges, given \\forall n, x_n \\not = c and x_n \\to c. Furthermore, if f is differentiable at c, then the above sequence of quotients will converge to f^\\prime(c).\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet f \\colon \\mathbb{R} \\to \\mathbb{R} where f(x) = |x|.\nClaim: The function f is non-differentiable on \\mathbb{R}.\nWe claim there exists some c \\in \\mathbb{R} such that f is not differentiabile at c. Using our sequence criterion, we consider the sequence (x_n) = (-1)^n/n.\nWe have that x_n \\to 0 and \\forall n,x_n \\not = 0. If we assume that this sequence converges, then any subsequence must also converge and converge to the same value. However, when n is even\n\n\\frac{f(x_n) - f(0)}{x_n - 0} = \\frac{1/n - 0}{1/n -0} = 1\n\nand when n is odd,\n\n\\frac{f(x_n) - f(0)}{x_n - 0} = \\frac{1/n - 0}{-1/n -0} = -1.\n\nOur subsequences converge to different values, so the original sequence does not converge. Thus f is not differentiable at 0.\n\n\nThe above is an example of a function that is continous everywhere, but not differentiabile everywhere. Below is another example of this phenomonea\n\n\n\n\n\n\nExample\n\n\n\nLet f \\colon \\mathbb{R} \\to \\mathbb{R} where\n\nf(x)=\\begin{cases}\n            x\\sin(1/x), & x \\not = 0\\\\\n            0, & x = 0\n         \\end{cases}\n\nClaim: The function f is non-differentiable at x = 0.\nFor x \\not = 0, we have that\n\n\\frac{f(x) - f(0)}{x - 0} = \\frac{x\\sin(1/x) - 0}{x -0} = \\sin(1/x)\n\nBut \\lim_{x\\to 0}\\sin(1/x) does not exists. Thus \n\\lim_{x\\to 0}\\frac{f(x) - f(0)}{x - 0}\n\ndoes not exists, and f is not differentiable at x = 0.\n\n\nThus continuity does not apply differentiability. Does differentiability imply continuity? Yes!\n\n\n\n\n\n\nTheorem\n\n\n\nIf f \\colon I \\to \\mathbb{R} is differentiable at c, then f is continous at c.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nWe want to show that \\lim_{x\\to c} f(x) = f(c). We do this by adding zero in a clever way. Note that\n\nf(x) =\\left(\\frac{f(x)-f(c)}{x-c}\\right)(x-c) + f(c)\n\nWhen x \\not = c. Since the derivative f^\\prime(c) exists and is finite, we know that the \\lim_{x\\to c} (f(x)-f(c))/x-c exists and is a real number. Taking the limit of the above equation\n\n\\lim_{x \\to c}f(x) = \\lim{x\\to c}\\left(\\frac{f(x)-f(c)}{x-c}\\right)(x-c) + f(c)\n\nWhich gives\n\n\\lim_{x \\to c}f(x) = 0 + f(c) = f(c).\n\nThus we have shown our desired equation.\n\n\n\n\n\n\n\n\n\nTheorem (Algebraic Properties of Derivatives)\n\n\n\nLet f,g \\colon I \\to \\mathbb{R} be differentiable at c \\in I. Then\n(a) (kf)^\\prime(c) = kf^\\prime(c), for all k \\in \\mathbb{R}\n(b) (f + g)^\\prime(c) = f^\\prime(c) + g^\\prime(c).\n(c) (fg)^\\prime(c) = f(c)g^\\prime(c) + f^\\prime(c)g(c).\n(d) (f/g)^\\prime(c) = (f(c)g^\\prime(c) - f^\\prime(c)g(c))/g^2(c), provided g(c) \\not = 0\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(c) For x \\in I, x \\not = c, we have \n\\frac{f(x)g(x) - f(c)g(c)}{x-c} = f(x)\\left(\\frac{g(x) - g(c)}{x-c}\\right) + g(c)\\left(\\frac{f(x)-f(c)}{x-c}\\right)\n\nWe want to evaluate the limit of the right hand side as x approaches c. Using our limit rules we have\n\n\\lim_{x\\to c} (fg)^\\prime(x) = \\lim_{x \\to c}f(x)\\left(\\frac{g(x) - g(c)}{x-c}\\right) + \\lim_{x \\to c} g(c)\\left(\\frac{f(x)-f(c)}{x-c}\\right)\n\nBecause f is differentiable at c, f is continous at c, thus\n\n\\lim_{x \\to c}f(x)\\left(\\frac{g(x) - g(c)}{x-c}\\right) = f(c)g^\\prime(c)\n\nAnd similarly,\n\n\\lim_{x \\to c} g(c)\\left(\\frac{f(x)-f(c)}{x-c}\\right) = f^\\prime(c)g(c)\n\nThus\n\n\\lim_{x\\to c} (fg)^\\prime(x) = f(c)g^\\prime(c) + f^\\prime(c)g(c).\n\n\n(d)\n\n\n\n\n\n\n\n\n\nTheorem (Chain Rule)\n\n\n\nLet I,J be intervals in \\mathbb{R} and f \\colon I \\to \\mathbb{R}, g \\colon J \\to \\mathbb{R}, where f(I)\\subseteq J and c \\in I. If f is differentiable at c and g is differentiable at f(c), then the composite function g \\circ f is differentiable at c and\n\n(g \\circ f)^\\prime(c) = g^\\prime(f(c))f^\\prime(c).\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nSince g is differentiable at f(c), we have\n\n\\lim_{y \\to f(c)} \\frac{g(y)-g(f(c))}{y - f(c)} = g^\\prime(f(c)).\n\nDefine h \\colon J \\to \\mathbb{R}, where\n\nh(y) = \\begin{cases}\n\\frac{g(y)-g(f(c))}{y-f(c)} & \\text{if } y \\not =  f(c)\\\\\ng^\\prime(f(c)) & \\text{if } y = f(c)\n\\end{cases}\n\nBy the first statement, we know that h is continous at f(c). Since f is differentiable at c, f is continous at c, and thus\n\n\\lim_{x\\to c} (h \\circ f)(x) = h(f(c)) = g^\\prime(f(c)).\n\nSkipped some steps\n\ng(f(c)) - g(f(c)) = h(f(x))(f(x)-f(c))"
  },
  {
    "objectID": "qmd/realanal/sequences/limittheo.html#practice",
    "href": "qmd/realanal/sequences/limittheo.html#practice",
    "title": "Limit Theorems",
    "section": "Practice",
    "text": "Practice"
  },
  {
    "objectID": "qmd/realanal/sequences/limittheo.html#recap",
    "href": "qmd/realanal/sequences/limittheo.html#recap",
    "title": "Limit Theorems",
    "section": "Recap",
    "text": "Recap\nIn this section we proved the following theorems and results.\n\n\n\n\n\n\nTheorem 1.2.1 (Algebraic Relations for limits)\n\n\n\nLet \\lim s_n = s and \\lim t_n = t. Then\n(a) \\; \\lim (s_n + t_n) = s + t. \\newline (b) \\; \\lim(ks_n) = ks and \\lim(k + s_n) = k + s. \\newline (c) \\; \\lim(s_nt_n) = st. \\newline (d) \\; \\lim(s_n/t_n) = s/t provided \\forall n,t_n \\not = 0\n\n\n\n\n\n\n\n\nTheorem 1.2.2 (Inequality operations on limits)\n\n\n\nLet (s_n) \\to s and (t_n) \\to t. If \\forall n \\in \\mathbb{N},\\;s_n \\leq t_n. Then s \\leq t.\n\n\n\n\n\n\n\n\nCorollary 1.2.3\n\n\n\nIf (t_n) converges to t and t_n \\geq 0 for all n \\in \\mathbb{N}, then t \\geq 0\n\n\n\n\n\n\n\n\nTheorem 1.2.4 (Ratio test)\n\n\n\nSuppose that (s_n) is a sequence of positive terms and that the sequence of ratios (s_{n+1}/s_n) converges to L. If L &gt; 1, then \\lim_{s_n} = 0\n\n\n\n\n\n\n\n\nTheorem 1.2.5\n\n\n\nSuppose that (s_n) and (t_n) are sequences such that s_n \\leq t_n for all n \\in \\mathbb{N}.\n(a) If \\lim s_n = + \\infty then \\lim t_n = + \\infty.\n(b) If \\lim t_n = - \\infty then \\lim s_n = - \\infty.\n\n\n\n\n\n\n\n\nTheorem 1.2.6\n\n\n\nLet (s_n) be a sequence of positive numbers. Then \\lim s_n = + \\infty if and only if \\lim 1/s_n = 0."
  },
  {
    "objectID": "qmd/realanal/sequences/mono-cauchy.html#monotone-sequences",
    "href": "qmd/realanal/sequences/mono-cauchy.html#monotone-sequences",
    "title": "Monotone sequences and Cauchy sequences",
    "section": "Monotone Sequences",
    "text": "Monotone Sequences\n\n\n\n\n\n\nDefinition\n\n\n\nA sequence (s_n) of real numbers is increasing if s_n \\leq s_{n+1} for all n \\in \\mathbb{N}, and is decreasing if s_n \\geq s_{n+1} for all n \\in \\mathbb{N}. A sequence is monotone if it is increasing or decreasing.\n\n\n\n\n\n\n\n\nTheorem 1.3.1 (Monotone Convergence Theorem)\n\n\n\nA monotone sequence is convergent if and only if it is bounded.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nSuppose (s_n) is a bounded increasing sequence. Let S denote the nonempty bounded set \\{s_n \\colon n \\in \\mathbb{N}\\}. By the completness axiom, S has a least upper bound, and we let s = \\sup S. We claim that \\lim s_n = s. Given any \\varepsilon &gt; 0, s - \\varepsilon is not an upper bound for S. Thus there exists a natural number N such that s_N &gt; s - \\varepsilon. Since (s_n) is increasing and s is an upper bound for S, we have\n\ns - \\varepsilon &lt; s_N \\leq s_n \\leq s\n\nfor all n \\geq N. Hence (s_n) converges to s. When the sequence is decreasing, we let s = \\inf S and the proof is nearly identical. For completness sake\nWe claim that \\lim s_n = s. Given any \\varepsilon &gt; 0, s + \\varepsilon is not a lower bound for S. Thus there exists some natural number N such that s_N &lt; s + \\varepsilon. Since (s_n) is decreasing and s is a lower bound for S, we have\n\ns + \\varepsilon &gt; s_N \\geq s_n \\geq s\n\nfor all n \\geq N. Thus (s_n) converges to s.\nThe converse, that a convergent sequence is bounded, was proved in Theorem 1.1.3.\n\n\n\nThis allows us to prove sequences are convergent without using the defintion of convergence, and without knowledge of what the sequence converges to.\n\n\n\n\n\n\nExample\n\n\n\nLet (s_n) be the sequence defined by s_1 = 1 and s_{n+1} = \\sqrt{1 + s_n} for n \\geq 1.\nClaim: (s_n) is a bounded increasing sequence.\nWe can manually compute the first few terms of the sequences\n\\begin{align*}\ns_1 &= 1\\\\\ns_2 &= \\sqrt{1 + 1} &\\approx 1.414\\\\\ns_3 &= \\sqrt{1 + \\sqrt{2}} &\\approx 1.554\\\\\ns_4 &= \\sqrt{1 + \\sqrt{1 + \\sqrt{2}}} &\\approx 1.598\n\\end{align*}\nIt appears that the sequence is bounded by 2. We can prove this via induction. Suppose s_k &lt; 2 for some k \\in \\mathbb{N}. Then\n\ns_{k+1} = \\sqrt{1 + s_k} &lt; \\sqrt{1 + 2} = \\sqrt{3} &lt; 2.\n\nBecause s_1 = 1, we can conclude via induction that s_n &lt; 2 for all n \\in \\mathbb{N}. Thus we know (s_n) is bounded. We now want to prove that it’s increasing. We also use induction to prove this. Suppose s_k &lt; s_{k+1} for some natural number k. Then we have\n\ns_{k+1} = \\sqrt{1 + s_k} &lt; \\sqrt{1 + s_{k+1}} = s_{k+2}\n\nTherefore our induction step is complete. Because s_1 &lt; s_2, we have that s_n &lt; s_{n+1} for all n \\in \\mathbb{N}. Thus (s_n) is an increasing sequence and is bounded by the interval [1,2]. By Theorem 1.3.1, we can conclude that the sequence is convergent, even though we don’t know the value s the sequence converges to.\nBecause \\lim s_{n+1} = \\lim s_n (Proof needed), we know that the value of s must satisfy the equation\n\ns = \\sqrt{1 + s}.\n\nThis can be reasoned intuitively, as the difference s_{n+1} - s_n must shrink to zero as n grows. Solving through algebra\n\\begin{align*}\ns &= \\sqrt{1 + s}\\\\\ns^2 - s - 1 &= 0\\\\\ns &= \\frac{1 \\pm \\sqrt{5}}{2} = \\phi\n\\end{align*}\nWhere \\phi is the Golden ratio. We take the positive value since s_n \\geq 1 for all n. Thus \\lim s_n = \\phi.\n\n\n\n\n\n\n\n\nTheorem 1.3.2\n\n\n\n(a) If (s_n) is an unbounded increasing sequence, then \\lim s_n = + \\infty\n(b) If (s_n) is an unbounded decreasing sequence, then \\lim s_n = - \\infty\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(a) Let (s_n) be an increasing sequence and suppose that the set S = \\{s_n \\colon n \\in \\mathbb{N}\\} is unbounded. Since (s_n) is increasing, S is bounded below by s_1. Hence S must be unbounded above. Given any M \\in \\mathbb{R}, there exists a natural number N such that s_N &gt; M. Since (s_n) is increasing, we have M &lt; s_N \\leq s_n, so \\lim s_n = + \\infty.\nIdentically\n(b) Let (s_n) be a decreasing sequence and suppose that the set S = \\{s_n \\colon n \\in \\mathbb{N}\\} is unbounded. Since (s_n) is decreasing, S is bounded above by s_1. Thus S must be unbounded below. Given any M \\in \\mathbb{R}, there exists a natrual number N such that s_N &lt; M. Since (s_n) is decreasing, we have s_n &lt; s_N &lt; M. Therefore \\lim s_n = - \\infty."
  },
  {
    "objectID": "qmd/realanal/sequences/mono-cauchy.html#cauchy-sequences",
    "href": "qmd/realanal/sequences/mono-cauchy.html#cauchy-sequences",
    "title": "Monotone sequences and Cauchy sequences",
    "section": "Cauchy sequences",
    "text": "Cauchy sequences\nWhen a sequence converges, not only do the terms get closer to the limit, they get closer to each other for sufficient large n. It turns out that if the terms in a sequence get continually closer to each other, the sequence itself converges.\n\n\n\n\n\n\nDefinition\n\n\n\nA sequence (s_n) is said to be a Cauchy sequence if for all \\varepsilon &gt; 0, there exists a natural number N such that m,n \\geq N implies that |s_n - s_m| &lt; \\varepsilon.\n\n\nEssentially, a sequence is Cauchy if the terms get arbitrarily close to each other.\n\n\n\n\n\n\nLemma 1.3.3\n\n\n\nEvery convergent sequence is a Cauchy sequence.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nSuppose that (s_n) converges to s. To show that s_n is close to s_m for sufficiently large n,m, we use the fact that they are both close to s. The triangle inequality gives\n\n|s_n - s_m| = |s_n - s + s - s_m| \\leq |s_n - s| + |s - s_m|.\n\nFor any \\varepsilon &gt; 0, choose some natural number N such that k \\geq N implies |s_k - s| &lt; \\varepsilon/2. This k exists, because \\lim s_n = s. Then for m,n \\geq N we have\n\n|s_n - s_m| \\leq |s_n - s| + |s - s_m| &lt; \\frac{\\varepsilon}{2} + \\frac{\\varepsilon}{2} = \\varepsilon\n\nTherefore (s_n) is a Cauchy sequence.\n\n\n\n\n\n\n\n\n\nLemma 1.3.4\n\n\n\nEvery Cauchy sequence is bounded.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLet (s_n) be a Cauchy sequence. Then there exists a natural number N such that for all n,m \\geq N, |s_n - s_m| &lt; \\varepsilon. Let \\varepsilon = 1. Let m = N. Through the triangle inequality we have\n\n|s_n| - |s_N| \\leq |s_n - s_N| &lt; 1 \\implies |s_n| &lt; 1 + |s_N|\n\nLet M = \\max\\{|s_1|,\\dots,|s_N|,1 + |s_N|\\}. Then for all n \\in \\mathbb{N}, |s_n| \\leq M. Thus (s_n) is bounded.\n\n\n\nThe above lemma is very similar to Theorem 1.1.3.\n\n\n\n\n\n\nTheorem 1.3.5 (Cauchy Convergence Criterion)\n\n\n\nA sequence (s_n) is convergent if and only if it is a Cauchy sequence.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nWe have already proved in Lemma 1.3.3 that every convergent sequence is a Cauchy sequence, so we only need to prove the reverse direction. Suppose (s_n) is a Cauchy sequence and let S = \\{s_n \\colon n \\in \\mathbb{N}\\} be the range of the sequence. We consider two cases, when S is finite, and when S is infinite.\nIf S is finite, then the minimum distant \\varepsilon between any two points is positive. Since (s_n) is Cauchy, there exists a natural number N such that m,n \\geq N implies |s_n - s_m| &lt; \\varepsilon. Given any m \\geq N, s_m and s_N are both in S. If the distant between them is less than \\varepsilon, then it must be zero. Thus s_m = s_N for all m \\geq N. Therefore \\lim s_n = s_N.\nNext, suppose that S is infinite. From Lemma 1.3.4 we know S is bounded. From the Bolzano-Weierstrass theorem there exists a point s in \\mathbb{R} that is an accumulation point of S. We claim (s_n) converges to s. Given any \\varepsilon &gt; 0, there exists a natural number N such that |s_n - s_m| &lt; \\varepsilon/2 for any n,m \\geq N. Since s is an accumulation point of S, the neighborhood N(s;\\varepsilon/2) contains an infinite amount of points in S. Thus there exists some integer m \\geq N such that s_m \\in N(s;\\varepsilon/2). Hence for any n \\geq N we have\n\n|s_n - s| = |s_n - s_m + s_m - s| \\leq |s_n - s_m| + |s_m - s| &lt; \\frac{\\varepsilon}{2} + \\frac{\\varepsilon}{2} = \\varepsilon\n\nThus \\lim s_n = s."
  },
  {
    "objectID": "qmd/realanal/sequences/mono-cauchy.html#practice",
    "href": "qmd/realanal/sequences/mono-cauchy.html#practice",
    "title": "Monotone sequences and Cauchy sequences",
    "section": "Practice",
    "text": "Practice"
  },
  {
    "objectID": "qmd/realanal/sequences/mono-cauchy.html#recap",
    "href": "qmd/realanal/sequences/mono-cauchy.html#recap",
    "title": "Monotone sequences and Cauchy sequences",
    "section": "Recap",
    "text": "Recap\nIn this section we proved the following theorems and results.\n\n\n\n\n\n\nTheorem 1.3.1 (Monotone Convergence Theorem)\n\n\n\nA monotone sequence is convergent if and only if it is bounded.\n\n\n\n\n\n\n\n\nTheorem 1.3.2\n\n\n\n(a) If (s_n) is an unbounded increasing sequence, then \\lim s_n = + \\infty\n(b) If (s_n) is an unbounded decreasing sequence, then \\lim s_n = - \\infty\n\n\n\n\n\n\n\n\nLemma 1.3.3\n\n\n\nEvery convergent sequence is a Cauchy sequence.\n\n\n\n\n\n\n\n\nLemma 1.3.4\n\n\n\nEvery Cauchy sequence is bounded.\n\n\n\n\n\n\n\n\nTheorem 1.3.5 (Cauchy Convergence Criterion)\n\n\n\nA sequence (s_n) is convergent if and only if it is a Cauchy sequence."
  },
  {
    "objectID": "qmd/realanal/sequences/subsequences.html",
    "href": "qmd/realanal/sequences/subsequences.html",
    "title": "Subsequences",
    "section": "",
    "text": "Definition\n\n\n\nLet (s_n)^\\infty_{n=1} be a sequence and let (n_k)^\\infty_{k=1} be any increasing sequence of natural numbers. The sequence (s_{n_k})^\\infty_{k=1} is called a subsequence of (s_n).\nA subsequence is any sequence formed by deleting and renumbering terms of some original sequence. A subsequence must preserve the order of the terms of the original sequence, and consist of an infinite amount of terms.\nAnd for unbounded sequences"
  },
  {
    "objectID": "qmd/realanal/sequences/subsequences.html#cauchy-sequences",
    "href": "qmd/realanal/sequences/subsequences.html#cauchy-sequences",
    "title": "Subsequences",
    "section": "Cauchy sequences",
    "text": "Cauchy sequences\nWhen a sequence converges, not only do the terms get closer to the limit, they get closer to each other for sufficient large n. It turns out that if the terms in a sequence get continually closer to each other, the sequence itself converges.\n\n\n\n\n\n\nDefinition\n\n\n\nA sequence (s_n) is said to be a Cauchy sequence if for all \\varepsilon &gt; 0, there exists a natural number N such that m,n \\geq N implies that |s_n - s_m| &lt; \\varepsilon.\n\n\nEssentially, a sequence is Cauchy if the terms get arbitrarily close to each other.\n\n\n\n\n\n\nLemma 1.3.3\n\n\n\nEvery convergent sequence is a Cauchy sequence.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nSuppose that (s_n) converges to s. To show that s_n is close to s_m for sufficiently large n,m, we use the fact that they are both close to s. The triangle inequality gives\n\n|s_n - s_m| = |s_n - s + s - s_m| \\leq |s_n - s| + |s - s_m|.\n\nFor any \\varepsilon &gt; 0, choose some natural number N such that k \\geq N implies |s_k - s| &lt; \\varepsilon/2. This k exists, because \\lim s_n = s. Then for m,n \\geq N we have\n\n|s_n - s_m| \\leq |s_n - s| + |s - s_m| &lt; \\frac{\\varepsilon}{2} + \\frac{\\varepsilon}{2} = \\varepsilon\n\nTherefore (s_n) is a Cauchy sequence.\n\n\n\n\n\n\n\n\n\nLemma 1.3.4\n\n\n\nEvery Cauchy sequence is bounded.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLet (s_n) be a Cauchy sequence. Then there exists a natural number N such that for all n,m \\geq N, |s_n - s_m| &lt; \\varepsilon. Let \\varepsilon = 1. Let m = N. Through the triangle inequality we have\n\n|s_n| - |s_N| \\leq |s_n - s_N| &lt; 1 \\implies |s_n| &lt; 1 + |s_N|\n\nLet M = \\max\\{|s_1|,\\dots,|s_N|,1 + |s_N|\\}. Then for all n \\in \\mathbb{N}, |s_n| \\leq M. Thus (s_n) is bounded.\n\n\n\nThe above lemma is very similar to Theorem 1.1.3.\n\n\n\n\n\n\nTheorem 1.3.5 (Cauchy Convergence Criterion)\n\n\n\nA sequence (s_n) is convergent if and only if it is a Cauchy sequence.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nWe have already proved in Lemma 1.3.3 that every convergent sequence is a Cauchy sequence, so we only need to prove the reverse direction. Suppose (s_n) is a Cauchy sequence and let S = \\{s_n \\colon n \\in \\mathbb{N}\\} be the range of the sequence. We consider two cases, when S is finite, and when S is infinite.\nIf S is finite, then the minimum distant \\varepsilon between any two points is positive. Since (s_n) is Cauchy, there exists a natural number N such that m,n \\geq N implies |s_n - s_m| &lt; \\varepsilon. Given any m \\geq N, s_m and s_N are both in S. If the distant between them is less than \\varepsilon, then it must be zero. Thus s_m = s_N for all m \\geq N. Therefore \\lim s_n = s_N.\nNext, suppose that S is infinite. From Lemma 1.3.4 we know S is bounded. From the Bolzano-Weierstrass theorem there exists a point s in \\mathbb{R} that is an accumulation point of S. We claim (s_n) converges to s. Given any \\varepsilon &gt; 0, there exists a natural number N such that |s_n - s_m| &lt; \\varepsilon/2 for any n,m \\geq N. Since s is an accumulation point of S, the neighborhood N(s;\\varepsilon/2) contains an infinite amount of points in S. Thus there exists some integer m \\geq N such that s_m \\in N(s;\\varepsilon/2). Hence for any n \\geq N we have\n\n|s_n - s| = |s_n - s_m + s_m - s| \\leq |s_n - s_m| + |s_m - s| &lt; \\frac{\\varepsilon}{2} + \\frac{\\varepsilon}{2} = \\varepsilon\n\nThus \\lim s_n = s."
  },
  {
    "objectID": "qmd/realanal/sequences/subsequences.html#practice",
    "href": "qmd/realanal/sequences/subsequences.html#practice",
    "title": "Subsequences",
    "section": "Practice",
    "text": "Practice"
  },
  {
    "objectID": "qmd/realanal/sequences/subsequences.html#recap",
    "href": "qmd/realanal/sequences/subsequences.html#recap",
    "title": "Subsequences",
    "section": "Recap",
    "text": "Recap\n\n\n\n\n\n\nTheorem 1.4.1\n\n\n\nIf a sequence (s_n) converges to a real number s, then every subsequence of (s_n) also converges to s.\n\n\n\n\n\n\n\n\nTheorem 1.4.2\n\n\n\nEvery bounded sequence has a convergent subsequence.\n\n\n\n\n\n\n\n\nTheorem 1.4.3\n\n\n\nEvery unbounded sequence contains a monotone subsequence that diverges to \\pm \\infty.\n\n\n\n\n\n\n\n\nTheorem 1.4.4\n\n\n\nLet (s_n) be a bounded sequence and let m = \\lim \\sup s_n. Then the following properties hold:\n(a) For every \\varepsilon &gt; 0, there exists a natural number N such that n \\geq N implies s_n &lt; m + \\varepsilon.\n(b) For every \\varepsilon &gt; 0, and for every i \\in \\mathbb{N} there exists an integer k &gt; i such that s_k &gt; m - \\varepsilon.\nFurthermore, if m is a real number satisfying these properties, m = \\lim \\sup s_n.\n\n\n\n\n\n\n\n\nCorollary 1.4.5\n\n\n\nLet (s_n) be a bounded sequence and let m = \\lim \\sup s_n. Then m \\in S, where S is the set of subsequential limits of (s_n). That is, there exists a subsequence of (s_n) that converges to m.\n\n\n\n\n\n\n\n\nTheorem 1.4.6\n\n\n\nSuppose that (r_n) converges to a positive number r and (s_n) is a bounded sequence. Then\n\n\\lim \\sup r_n s_n = r\\lim \\sup s_n"
  },
  {
    "objectID": "qmd/realanal/sequences/subsequences.html#limit-superior-and-limit-inferior",
    "href": "qmd/realanal/sequences/subsequences.html#limit-superior-and-limit-inferior",
    "title": "Subsequences",
    "section": "Limit Superior and Limit Inferior",
    "text": "Limit Superior and Limit Inferior\n\n\n\n\n\n\nDefinition\n\n\n\nLet (s_n) be a bounded sequence. A subsequential limit of (s_n) is any real number that is the limit of some subsequence of (s_n). If S is the set of all subsequential limits of (s_n), then we define the limit superior of (s_n) to be\n\n\\lim \\sup s_n = \\sup S\n\nAnd the limit inferior of (s_n) to be\n\n\\lim \\inf s_n = \\inf S\n\n\n\nThis defintion requires (s_n) to be bounded. When (s_n) is a convergent sequence, \\lim \\inf s_n = \\lim \\sup s_n = \\lim s_n. If it happens that \\lim \\inf s_n &lt; \\lim \\sup s_n, we say that (s_n) oscillates.\n\n\n\n\n\n\nTheorem 1.4.4\n\n\n\nLet (s_n) be a bounded sequence and let m = \\lim \\sup s_n. Then the following properties hold:\n(a) For every \\varepsilon &gt; 0, there exists a natural number N such that n \\geq N implies s_n &lt; m + \\varepsilon.\n(b) For every \\varepsilon &gt; 0, and for every i \\in \\mathbb{N} there exists an integer k &gt; i such that s_k &gt; m - \\varepsilon.\nFurthermore, if m is a real number satisfying these properties, m = \\lim \\sup s_n.\n\n\n\n\n\n\n\n\nProof (TO-DO)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCorollary 1.4.5\n\n\n\nLet (s_n) be a bounded sequence and let m = \\lim \\sup s_n. Then m \\in S, where S is the set of subsequential limits of (s_n). That is, there exists a subsequence of (s_n) that converges to m.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nCombining both parts of Theorem 1.3.4, we have the existence of some subsequence (s_{n_k}) of (s_n) such that\n\nm - \\frac{1}{k} &lt; s_{n_k} &lt; m + \\frac{1}{k}\n\nClearly then (s_{n_k}) converges to m.\n\n\n\nFor a bounded sequence (s_n), Corollary 1.3.5 says the set S of subsequential limits of (s_n) contains its supremum m. That means m is actually the maximum of S. Likewise, \\lim \\inf s_n = \\min S. While this defintion is more correct, it is not readily generalized to unbounded sequences.\n\n\n\n\n\n\nTheorem 1.4.6\n\n\n\nSuppose that (r_n) converges to a positive number r and (s_n) is a bounded sequence. Then\n\n\\lim \\sup r_n s_n = r\\lim \\sup s_n\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLes s = \\lim \\sup s_n and t = \\lim \\sup r_ns_n. By the Corollary 1.3.5, there exists a subsequence (s_{n_k}) of (s_n) such that \\lim s_{n_k} = s. We know \\lim r_{n_k} = r by Theorem 1.4.1. Thus \\lim r_{n_k}s_{n_k} = rs. Thus rs \\leq \\lim \\sup r_n s_n = t (Why).\nSimilarly, let (r_{n_k}s_{n_k}) be a subsequence of (r_ns_n) that converges to t. Then since r &gt; 0,\n\n\\lim s_{n_k} = \\lim \\frac{r_{n_k}s_{n_k}}{r_{n_k}} = \\frac{t}{r},\n\nso that t/r \\leq s. Thus t \\leq rs. Since rs \\leq t and t \\leq rs, we have t = rs."
  },
  {
    "objectID": "qmd/realanal/limits-cont/funclim.html#sequential-criterion-for-limits",
    "href": "qmd/realanal/limits-cont/funclim.html#sequential-criterion-for-limits",
    "title": "Limits of Functions",
    "section": "Sequential Criterion for Limits",
    "text": "Sequential Criterion for Limits\nLimits of seqeunces and functions are closely related.\n\n\n\n\n\n\nTheorem 2.1.2\n\n\n\nLet f \\colon D \\to \\mathbb{R}, and c be an accumulation point of D. Then, \\lim_{x\\to c} f(x) = L if and only if for every sequence (s_n) in D that converges to c with s_n \\not = c for all n, the sequence (f(s_n)) converges to L.\n\n\n\n\n\n\n\n\nProof (TO-DO Reverse Direction)\n\n\n\n\n\nLet (s_n) be a sequence in D that converges to c and s_n \\not = c for all n, and \\lim_{x\\to c} f(x) = L.\nWe start with the forward direction. We want to show that \\lim_{n\\to \\infty} f(s_n) = L. By assumption \\lim_{x\\to c} f(x) = L, so given any \\varepsilon &gt; 0, there exists \\delta &gt; 0 such that 0 &lt; |x-c| &lt; \\delta \\implies |f(x) - L| &lt; \\varepsilon. Since (s_n) converges to c, there exists a natural number N such that n \\geq N implies |s_n - c| &lt; \\delta. Thus for n \\geq N we have 0 &lt; |s_n - c| &lt; \\delta and s_n \\in D such that |f(s_n) - L| &lt; \\varepsilon. Thus \\lim_{n \\to\\infty} = L.\n\n\n\n\n\n\n\n\n\nCorollary 2.1.3\n\n\n\nIf f \\colon D \\to \\mathbb{R} and if c is an accumulation point of D, then f can have only one limit at c.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nSuppose that \\lim_{x \\to c}f(x) = L_1 and \\lim_{x \\to c} f(x) = L_2. By Theorem 2.1.2, every sequence (f(s_n)) converges to L (Granted that s_n \\not = c and s_n converges to c). By Theorem 1.1.3, If (f(s_n)) converges, then it’s limit is unique. Therefore if (f(s_n)) converges to both L_1 and L_2, then L_1 = L_2.\n\n\n\n\n\n\n\n\n\nTheorem 2.1.4\n\n\n\nLet f \\colon D \\to \\mathbb{R}, and c be an accumulation point of D. Then the following are equivalent\n(a) f does not have a limit at c\n(b) There exists a sequence (s_n) in D with each s_n \\not = c such that (s_n) converges to c, but (f(s_n)) is not convergent in \\mathbb{R}.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nIf (a) was false (If f did have a limit at c), (b) would neccessarily be false by Theorem 2.1.2, and vice versa.\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet f(x) = \\sin(1/x) for x &gt; 0.\nClaim: \\lim_{x\\to 0} \\sin(1/x) does not exists.\nWe prove this by considering the sequence, s_n = \\frac{2}{\\pi n}. It is clear \\lim s_n = 0. But the sequence (f(s_n)) is constantly oscillating between 1,0,-1,0,1,\\dots, and does not converge to any real number L. Therefore by Theorem 2.1.4, \\sin(1/x) does not have a limit at 0.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nLet f \\colon D \\to \\mathbb{R} and g \\colon D \\to \\mathbb{R}. We define the sum f + g and the product fg to be the functions from D to \\mathbb{R} given By\n\n(f+g)(x) = f(x) + g(x) \\quad \\text{ and } \\quad (fg)(x) = f(x)\\cdot g(x)\n\nfor all x \\in D. If k \\in \\mathbb{R}, then the multiple kf \\colon D \\to \\mathbb{R} is the function defined by\n\n(kf)(x) = k \\cdot f(x), \\quad \\forall x \\in D.\n\nIf g(x) \\not = 0 for all x \\in D, then the quotient f/g \\colon D \\to \\mathbb{R} is the function defined by\n\n\\left(\\frac{f}{g}\\right)(x) = \\frac{f(x)}{g(x)}, \\quad \\forall x \\in D.\n\n\n\nThe above ‘definitions’ are mostly just clarity on notation.\n\n\n\n\n\n\nTheorem 2.1.5 (Algebraic Relations for functions)\n\n\n\nLet f \\colon D \\to \\mathbb{R} and g \\colon D \\to \\mathbb{R}, and let c be an accumulation point of D. If \\lim_{x\\ to c} f(x) = L and \\lim_{x\\to c}g(x) = M, and k \\in \\mathbb{R} then\n(a) \\lim_{x\\to c}(f + g)(x) = L + M,\n(b) \\lim_{x \\to c}(fg)(x) = LM,\n(c) \\lim_{x\\to c}(kf)(x) = kL,\n(d) If g(x) \\not = 0 for all x \\in D and M \\not = 0, \\lim_{x\\to c}(f/g)(x) = L/M.\n\n\n\n\n\n\n\n\nProof (TO-DO)\n\n\n\n\n\nTedious proof\n\n\n\n\n\n\n\n\n\nCorollary 2.1.6\n\n\n\nFor any polynomial P(x), we have that \\lim_{x \\to c} P(x) = P(c).\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nApply previous theorem repeatadly\n\n\n\n\n\n\n\n\n\nLemma 2.1.7\n\n\n\nLet f \\colon D \\to \\mathbb{R} where c is an accumulation point of D.\nSuppose \\lim_{x\\to c} f(x) &gt; 0. There exists a deleted neighborhood U of c, s.t. f(x) &gt; 0, \\forall x \\in U \\cap D.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLet L = \\lim_{x\\to c} f(x) &gt; 0. Consider the neighborhood N(L,L/2). By the first theorem today, \\exists a deleted neighborhood U of c such that f(x) is contained in this neighborhood for all x \\in U \\cap D. Therefore if L is positive, theres always a neighborhood of positive numbers."
  },
  {
    "objectID": "qmd/realanal/limits-cont/funclim.html#one-sided-limits",
    "href": "qmd/realanal/limits-cont/funclim.html#one-sided-limits",
    "title": "Limits of Functions",
    "section": "One-Sided Limits",
    "text": "One-Sided Limits\nTO-DO"
  },
  {
    "objectID": "qmd/realanal/limits-cont/funclim.html#practice",
    "href": "qmd/realanal/limits-cont/funclim.html#practice",
    "title": "Limits of Functions",
    "section": "Practice",
    "text": "Practice"
  },
  {
    "objectID": "qmd/realanal/limits-cont/funclim.html#recap",
    "href": "qmd/realanal/limits-cont/funclim.html#recap",
    "title": "Limits of Functions",
    "section": "Recap",
    "text": "Recap\nIn this section we proved the following theorems and results.\n\n\n\n\n\n\nTheorem 2.1.1\n\n\n\nLet f \\colon D \\to \\mathbb{R} and c be an accumulation point of D. Then \\lim_{x\\to c}f(x) = L if and only if for each neighborhood of V of L there exists a deleted neighborhood U of c such that f(U \\cap D) \\subseteq V.\n\n\n\n\n\n\n\n\nTheorem 2.1.2\n\n\n\nLet f \\colon D \\to \\mathbb{R}, and c be an accumulation point of D. Then, \\lim_{x\\to c} f(x) = L if and only if for every sequence (s_n) in D that converges to c with s_n \\not = c for all n, the sequence (f(s_n)) converges to L.\n\n\n\n\n\n\n\n\nCorollary 2.1.3\n\n\n\nIf f \\colon D \\to \\mathbb{R} and if c is an accumulation point of D, then f can have only one limit at c.\n\n\n\n\n\n\n\n\nTheorem 2.1.4\n\n\n\nLet f \\colon D \\to \\mathbb{R}, and c be an accumulation point of D. Then the following are equivalent\n(a) f does not have a limit at c\n(b) There exists a sequence (s_n) in D with each s_n \\not = c such that (s_n) converges to c, but (f(s_n)) is not convergent in \\mathbb{R}.\n\n\n\n\n\n\n\n\nTheorem 2.1.5 (Algebraic Relations for functions)\n\n\n\nLet f \\colon D \\to \\mathbb{R} and g \\colon D \\to \\mathbb{R}, and let c be an accumulation point of D. If \\lim_{x\\ to c} f(x) = L and \\lim_{x\\to c}g(x) = M, and k \\in \\mathbb{R} then\n(a) \\lim_{x\\to c}(f + g)(x) = L + M,\n(b) \\lim_{x \\to c}(fg)(x) = LM,\n(c) \\lim_{x\\to c}(kf)(x) = kL,\n(d) If g(x) \\not = 0 for all x \\in D and M \\not = 0, \\lim_{x\\to c}(f/g)(x) = L/M.\n\n\n\n\n\n\n\n\nCorollary 2.1.6\n\n\n\nFor any polynomial P(x), we have that \\lim_{x \\to c} P(x) = P(c).\n\n\n\n\n\n\n\n\nLemma 2.1.7\n\n\n\nLet f \\colon D \\to \\mathbb{R} where c is an accumulation point of D.\nSuppose \\lim_{x\\to c} f(x) &gt; 0. There exists a deleted neighborhood U of c, s.t. f(x) &gt; 0, \\forall x \\in U \\cap D."
  },
  {
    "objectID": "qmd/realanal/limits-cont/cont-func.html#practice",
    "href": "qmd/realanal/limits-cont/cont-func.html#practice",
    "title": "Continuous Functions",
    "section": "Practice",
    "text": "Practice"
  },
  {
    "objectID": "qmd/realanal/limits-cont/cont-func.html#recap",
    "href": "qmd/realanal/limits-cont/cont-func.html#recap",
    "title": "Continuous Functions",
    "section": "Recap",
    "text": "Recap\nIn this section we proved\n\n\n\n\n\n\nTheorem 2.2.1\n\n\n\nLet f \\colon D \\to \\mathbb{R} and let c \\in D. Then the following three conditions are equivalent\n(a) f is continuous at c.\n(b) If (x_n) is any sequence in D such that (x_n) converges to c, then \\lim f(x_n) = f(c).\n(c) For every neighborhood V of f(c) there exists a neighborhood U of c such that f(U \\cap D) \\subseteq V.\nFuthermore if c is an accumulation point of D, then the above are all equivalent to\n(d) f has a limit at c and \\lim_{x \\to c} f(x) = f(c).\n\n\n\n\n\n\n\n\nCorollary 2.2.2\n\n\n\nLet f \\colon D \\to \\mathbb{R} and c \\in D. Then f is discontinous at c if and only if there exists a sequence (x_n) in D such that (x_n) converges to c but the sequence (f(x_n)) does not converge to f(c).\n\n\n\n\n\n\n\n\nTheorem 2.2.3 (Algebraic Relations of Continuity)\n\n\n\nLet f,g\\; \\colon D \\to \\mathbb{R} and c \\in D. If f,g are both continous at the point c, then\n(a) f + g and fg are continous at c, and\n(b) f/g is continous at c if g(c) \\not = 0.\n\n\n\n\n\n\n\n\nTheorem 2.2.4\n\n\n\nLet f \\colon D \\to \\mathbb{R} and g \\colon E \\to \\mathbb{R} such that f(D) \\subseteq E.\nIf f is continuous at c \\in D and g is continuous at f(c), then g \\circ f \\colon D \\to \\mathbb{R} is continuous at c.\n\n\n\n\n\n\n\n\nTheorem 2.2.5\n\n\n\nA function f\\colon D \\to \\mathbb{R} is continous on D if and only if for every open set U of \\mathbb{R}, there exists an open subset V of \\mathbb{R} such that V \\cap D = f^{-1}(U).\n\n\n\n\n\n\n\n\nCorollary 2.2.6\n\n\n\nA function f \\colon \\mathbb{R} \\to \\mathbb{R} is continuous if and only if f^{-1}(G) is open in \\mathbb{R}"
  },
  {
    "objectID": "qmd/realanal/limits-cont/cont-func-prop.html",
    "href": "qmd/realanal/limits-cont/cont-func-prop.html",
    "title": "Properties of Continuous Functions",
    "section": "",
    "text": "Definition\n\n\n\nA function f \\colon D \\to \\mathbb{R} is called bounded if its range f(D) is a subset of \\mathbb{R} where there exists some M \\in \\mathbb{R} such that |f(x)| \\leq M for all x \\in D.\nA functions domain being bounded has no correlation\nOn the real number line, a set is compact if and only if it is closed and bounded. We use the definition of open subcovers as it applies to more generalized spaces."
  },
  {
    "objectID": "qmd/realanal/differentiation/derivatives.html",
    "href": "qmd/realanal/differentiation/derivatives.html",
    "title": "The Derivative",
    "section": "",
    "text": "Next we talk about differentialbility\n\n\n\n\n\n\nDefinition\n\n\n\nLet I be any interval on \\mathbb{R}, and let c \\in I. We say that f \\colon I \\to \\mathbb{R} is differentiable at c if\n\n\\lim_{x \\to c} \\frac{f(x)-f(c)}{x-c}\n\nexists and is finite.\n\n\nIf f is differentiable at every point in a subset S \\subseteq I, we say that f is differentiable on S. If f has a derivative at c, we notate f^\\prime(c).\n\n\n\n\n\n\nExample\n\n\n\nLet f \\colon \\mathbb{R} \\to \\mathbb{R} be a constant function. That is f(x) = d for some d \\in \\mathbb{R}.\nClaim: The derivative of f is zero at every point c \\in \\mathbb{R}.\nWe use out formula for differentiability\n\nf^\\prime(c) = \\lim_{x \\to c} \\frac{f(x) - f(c)}{x - c} = \\lim_{x \\to c} \\frac{d - d}{x - c} = 0\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet f \\colon \\mathbb{R} \\to \\mathbb{R} be the identity function. That is f(x) = x for all x \\in \\mathbb{R}.\nClaim: The derivative of f is one at every point c \\in \\mathbb{R}.\nWe use out formula for differentiability\n\nf^\\prime(c) = \\lim_{x \\to c} \\frac{f(x) - f(c)}{x - c} = \\lim_{x \\to c} \\frac{x - c}{x - c} = 1\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet f \\colon \\mathbb{R} \\to \\mathbb{R} where f(x) = x^2.\nClaim: The derivative of f is 2c at every point c \\in \\mathbb{R}.\nWe use our formula for differentiability\n\nf^\\prime(c) = \\lim_{x \\to c} \\frac{f(x) - f(c)}{x - c} = \\lim_{x \\to c} \\frac{x^2 - c^2}{x - c}\n\nUsing the formula x^2 - y^2 = (x-y)(x+y), we get\n\nf^\\prime(c) = \\lim_{x \\to c} \\frac{(x-c)(x+c)}{x - c} = \\lim_{x \\to c} x + c = 2c\n\n\n\nWe introduce another theorem\n\n\n\n\n\n\nTheorem 3.1.1 (Sequential criterion for differentiability)\n\n\n\nLet I be an interval containing c and f\\colon I \\to \\mathbb{R}. Then f is differentiable at c if and only if for all sequences (x_n) in I such that \\lim (x_n) = c we have\n\n\\left(\\frac{f(x_n)-f(c)}{x_n - c}\\right)\n\nconverges, given x_n \\not = c for all n. Furthermore, if f is differentiable at c, then the above sequence of quotients will converge to f^\\prime(c).\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet f \\colon \\mathbb{R} \\to \\mathbb{R} where f(x) = |x|.\nClaim: The function f is non-differentiable at x = 0.\nWe claim there exists some c \\in \\mathbb{R} such that f is not differentiabile at c. Using our sequence criterion, we consider the sequence (x_n) = (-1)^n/n.\nWe have that x_n \\to 0 and \\forall n,x_n \\not = 0. If we assume that this sequence converges, then any subsequence must also converge and converge to the same value. However, when n is even\n\n\\frac{f(x_n) - f(0)}{x_n - 0} = \\frac{1/n - 0}{1/n -0} = 1\n\nand when n is odd,\n\n\\frac{f(x_n) - f(0)}{x_n - 0} = \\frac{1/n - 0}{-1/n -0} = -1.\n\nOur subsequences converge to different values, so the original sequence does not converge. Thus f is not differentiable at 0.\n\n\nThe above is an example of a function that is continuous everywhere, but not differentiable everywhere. Below is another example of this phenomonea\n\n\n\n\n\n\nExample\n\n\n\nLet f \\colon \\mathbb{R} \\to \\mathbb{R} where\n\nf(x)=\\begin{cases}\n            x\\sin(1/x), & x \\not = 0\\\\\n            0, & x = 0\n         \\end{cases}\n\nClaim: The function f is non-differentiable at x = 0.\nFor x \\not = 0, we have that\n\n\\frac{f(x) - f(0)}{x - 0} = \\frac{x\\sin(1/x) - 0}{x -0} = \\sin(1/x)\n\nBut \\lim_{x\\to 0}\\sin(1/x) does not exists. Thus \n\\lim_{x\\to 0}\\frac{f(x) - f(0)}{x - 0}\n\ndoes not exists, and f is not differentiable at x = 0.\n\n\nIn the above example, we have a function that is continuous at x = 0, but not differentiable. We can conclude continuity does not imply differentiability.\n\n\n\n\n\n\nTheorem 3.1.2\n\n\n\nIf f \\colon I \\to \\mathbb{R} is differentiable at c, then f is continuous at c.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nWe want to show that \\lim_{x\\to c} f(x) = f(c). We do this by adding zero in a clever way. Note that\n\nf(x) =\\left(\\frac{f(x)-f(c)}{x-c}\\right)(x-c) + f(c)\n\nWhen x \\not = c. Since the derivative f^\\prime(c) exists and is finite, we know that the \\lim_{x\\to c} (f(x)-f(c))/x-c exists and is a real number. Taking the limit of the above equation\n\n\\lim_{x \\to c}f(x) = \\lim_{x\\to c}\\left(\\frac{f(x)-f(c)}{x-c}\\right)\\lim_{x\\to c}(x-c) + \\lim_{x \\to c}f(c)\n\nWhich gives\n\n\\lim_{x \\to c}f(x) = 0 + f(c) = f(c).\n\nHence f is continuous at c.\n\n\n\n\n\n\n\n\n\nTheorem 3.1.3 (Algebraic Properties of Derivatives)\n\n\n\nLet f,g \\colon I \\to \\mathbb{R} be differentiable at c \\in I. Then\n(a) (kf)^\\prime(c) = kf^\\prime(c), for all k \\in \\mathbb{R}\n(b) (f + g)^\\prime(c) = f^\\prime(c) + g^\\prime(c).\n(c) (fg)^\\prime(c) = f(c)g^\\prime(c) + f^\\prime(c)g(c).\n(d) (f/g)^\\prime(c) = (f(c)g^\\prime(c) - f^\\prime(c)g(c))/g^2(c), provided g(c) \\not = 0\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(c) For x \\in I, x \\not = c, we have \n\\frac{f(x)g(x) - f(c)g(c)}{x-c} = f(x)\\left(\\frac{g(x) - g(c)}{x-c}\\right) + g(c)\\left(\\frac{f(x)-f(c)}{x-c}\\right)\n\nWe want to evaluate the limit of the right hand side as x approaches c. Using our limit rules we have\n\n\\lim_{x\\to c} (fg)^\\prime(x) = \\lim_{x \\to c}f(x)\\left(\\frac{g(x) - g(c)}{x-c}\\right) + \\lim_{x \\to c} g(c)\\left(\\frac{f(x)-f(c)}{x-c}\\right)\n\nBecause f is differentiable at c, f is continuous at c, thus\n\n\\lim_{x \\to c}f(x)\\left(\\frac{g(x) - g(c)}{x-c}\\right) = f(c)g^\\prime(c)\n\nAnd similarly,\n\n\\lim_{x \\to c} g(c)\\left(\\frac{f(x)-f(c)}{x-c}\\right) = f^\\prime(c)g(c)\n\nThus\n\n\\lim_{x\\to c} (fg)^\\prime(x) = f(c)g^\\prime(c) + f^\\prime(c)g(c).\n\n\n(d)\n\n\n\n\n\n\n\n\n\nTheorem 3.1.4 (Chain Rule)\n\n\n\nLet I,J be intervals in \\mathbb{R} and f \\colon I \\to \\mathbb{R}, g \\colon J \\to \\mathbb{R}, where f(I)\\subseteq J and c \\in I. If f is differentiable at c and g is differentiable at f(c), then the composite function g \\circ f is differentiable at c and\n\n(g \\circ f)^\\prime(c) = g^\\prime(f(c))f^\\prime(c).\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nSince g is differentiable at f(c), we have\n\n\\lim_{y \\to f(c)} \\frac{g(y)-g(f(c))}{y - f(c)} = g^\\prime(f(c)).\n\nDefine h \\colon J \\to \\mathbb{R}, where\n\nh(y) = \\begin{cases}\n\\frac{g(y)-g(f(c))}{y-f(c)} & \\text{if } y \\not =  f(c)\\\\\ng^\\prime(f(c)) & \\text{if } y = f(c)\n\\end{cases}\n\nBy the first statement, we know that h is continuous at f(c). Since f is differentiable at c, f is continuous at c, and thus\n\n\\lim_{x\\to c} (h \\circ f)(x) = h(f(c)) = g^\\prime(f(c)).\n\nSkipped some steps\n\ng(f(c)) - g(f(c)) = h(f(x))(f(x)-f(c))"
  },
  {
    "objectID": "qmd/realanal/limits-cont/uniform-continuity.html#practice",
    "href": "qmd/realanal/limits-cont/uniform-continuity.html#practice",
    "title": "Uniform Continuity",
    "section": "Practice",
    "text": "Practice\n\n\n\n\n\n\nProblem\n\n\n\nA function f \\colon \\mathbb{R} \\to \\mathbb{R} is said to be periodic if there exists a number k &gt; 0 such that f(x + k) = f(x) for all x \\in \\mathbb{R}. Suppose that f \\colon \\mathbb{R} \\to \\mathbb{R} is continuous and periodic. Prove that f is bounded and uniformly continuous on \\mathbb{R}.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet f be a continuous function with period k. Take f \\colon [0,k] \\to \\mathbb{R}. Since [0,k] is compact, f([0,k]) is compact, and therefore bounded (since it obtains a minimum and maximum). For every x \\in \\mathbb{R}, we have some y \\in [0,k] such that x-y = nk for some integer n, thus f(x) = f(y + nk) = f(y), and f(\\mathbb{R}) = f([0,k]). Since f([0,k]) is bounded, so is f(\\mathbb{R}).\nSince [0,2k] is compact, and f is continuous, f([0,2k]) is uniformly continuous. That is, for every \\varepsilon &gt; 0, there exists some \\delta_k &gt; 0 such that\n\n|x_k - y_k| &lt; \\delta \\implies |f(x_k) - f(y_k)| &lt; \\varepsilon, \\forall x_k,y_k \\in [0,2k].\n\nChose some \\varepsilon &gt; 0. Let \\delta = \\delta_k. For all x,y \\in \\mathbb{R}, if |x-y| &lt; \\delta there exists x_k,y_k, \\in [0,2k] and such that x = x_k + nk and y = y_k + nk for some integer n. Then for all x,y\\in \\mathbb{R},\n\n|x - y| = |(x_k - n) - (y_k - n)| = |x_k - y_k| &lt; \\delta \\implies\\\\ |f(x) - f(y)| = |f(x_k + nk) - f(y_k + nk)| = |f(x_k) - f(y_k)| &lt; \\varepsilon\n\nThus f \\colon \\mathbb{R} \\to \\mathbb{R} is uniformly continuous. Note we choose the interval [0,2k] instead of [0,k], so there arise no complications when x &lt; nk and y &gt; nk."
  },
  {
    "objectID": "qmd/realanal/limits-cont/uniform-continuity.html#recap",
    "href": "qmd/realanal/limits-cont/uniform-continuity.html#recap",
    "title": "Uniform Continuity",
    "section": "Recap",
    "text": "Recap\nIn this section we proved.\n\n\n\n\n\n\nTheorem 2.4.1\n\n\n\nIf D is compact, and f \\colon D \\to \\mathbb{R} is continuous, then f is uniformly continuous.\n\n\n\n\n\n\n\n\nTheorem 2.4.2\n\n\n\nLet f \\colon D \\to \\mathbb{R} be uniformly continuous on D and suppose (x_n) is a Cauchy sequence in D. Then (f(x_n)) is Cauchy.\n\n\n\n\n\n\n\n\nTheorem 2.4.3\n\n\n\nA function f \\colon (a,b) \\to \\mathbb{R} is uniformly continuous on (a,b) if and only if it can be extended to a function \\tilde{f} that is continuous on [a,b].\n\n\n\n\n\n\n\n\nTheorem 2.4.4\n\n\n\nLet f\\colon D \\to \\mathbb{R} be a uniformly continuous function on the bounded set D. Prove that f is bounded on D."
  },
  {
    "objectID": "qmd/realanal/limits-cont/uniform-continuity.html#motivation",
    "href": "qmd/realanal/limits-cont/uniform-continuity.html#motivation",
    "title": "Uniform Continuity",
    "section": "Motivation",
    "text": "Motivation\nA uniformly continuous function has a single \\delta that works on the whole domain, whereas a continuous function has a separate \\delta for each point c \\in D.\nIn other words, continuity is a local condition on a function. It is defined at each point c \\in D, and cares only about an infinitesimally small neighborhood about said point. Uniform continuity is a stronger notion, defined over the entirety of the domain D of a function.\nRoughly speaking, a function is uniformly continuous if there exists no rapid changes in the function. Verticle asymptotes on a function are rapid changes, where as linear changes aren’t. Another piece of intuition is that a function is uniformly continuous if an infinitesimally small change in x does not create an appreciable change in f(x).1\nWe use the following definition to formalize our intuition on rapid changes.\n\n\n\n\n\n\nDefinition\n\n\n\nA function f \\colon D \\to \\mathbb{R} is uniformly continuous on D if for all \\varepsilon &gt; 0, there exists \\delta &gt; 0 such that for all x,y \\in D, |x-y| &lt; \\delta \\implies |f(x) - f(y)| &lt; \\varepsilon. Symbolically\n\n\\forall \\varepsilon &gt; 0, \\exists \\delta &gt; 0 | \\forall x,y \\in D |x-y| &lt; \\delta \\implies |f(x) - f(y)| &lt; \\varepsilon\n\n\n\n\n\n\n\n\n\nExample (A uniformly continuous function)\n\n\n\nClaim: The function f(x) = 2x is uniformly continuous on \\mathbb{R}.\nGiven \\varepsilon &gt; 0, we want to find some \\delta &gt; 0 such that\n\n\\forall x,y \\in D, |x-y| &lt; \\delta \\implies |f(x) - f(y)| = |2x - 2y| = 2|x - y| &lt; \\varepsilon.\n\nSeeing this its clear we should choose \\delta = \\varepsilon/2, as that gives us the relation\n\n\\forall x,y \\in D, |x-y| &lt; \\frac{\\varepsilon}{2} \\implies 2|x-y| &lt; 2\\frac{\\varepsilon}{2} = \\varepsilon.\n\nThus we have f(x) = 2x is uniformly continuous.\n\n\n\n\n\n\n\n\nExample (A non uniformly continuous function)\n\n\n\nClaim: The function f(x) = x^2 is not uniformly continuous on \\mathbb{R}.\nTo prove a function is not uniformly continuous is equivalent to saying there exists some \\varepsilon &gt; 0 such that for all \\delta &gt; 0, there exist some pair x,y \\in D such that |x-y| &lt; \\delta \\implies |f(x) - f(y)| \\geq \\varepsilon.\nWe first notice that\n\n|f(x) - f(y)| = |x^2 - y^2| = |x + y| \\cdot |x - y|.\n\nLet \\varepsilon = 1. We need to show that given any \\delta &gt; 0, there exists some pair x,y \\in D such that\n\n|x-y| &lt; \\delta \\implies |x + y| \\cdot |x - y| \\geq 1.\n\nBecause we only need to find one pair x,y for each \\delta, it makes sense to have our pair depend on \\delta. For any x, let y = x + \\delta/2. This gives us |x - y| = \\delta/2, and |x + y| \\cdot |x - y| = |x + y| \\cdot \\delta/2.\nIn order for |x + y| \\cdot \\delta/2 to be greater than 1, we need |x + y| \\geq 2/\\delta. We choose x = 1/\\delta, as this gives y = 1/\\delta + \\delta/2. We now have enough information to construct our proof.\n\nLet \\varepsilon = 1. Given any \\delta &gt; 0, let x = 1/\\delta, y = 1/\\delta + \\delta/2. Then |x-y| = \\delta/2 &lt; \\delta, and |f(x) - f(y)| = |x+y| \\cdot |x-y| = |2/\\delta + \\delta/2| \\cdot |\\delta/2| \\geq 1. Thus our function f is not continuous on \\mathbb{R}.\n\n\nThose two examples provide the usual process we use to prove a function is or is not continuous. However, a function being uniformly continuous depends on the domain used.\n\n\n\n\n\n\nExample (A bounded uniformly continuous function)\n\n\n\nClaim: The function f(x) = x^2 is uniformly continuous on D = [-5,5].\nNote that for any x,y \\in D, we have |x + y| \\leq 10. For any \\varepsilon &gt; 0, let \\delta = \\varepsilon/10. Then\n\n|x-y| &lt; \\delta \\implies |x + y|\\cdot|x - y| &lt; 10 \\cdot \\delta = 10\\frac{\\varepsilon}{10} = \\varepsilon\n\n\n\nBy bounding our domain, we were able to show the function is uniformly continuous on said domain. This leads us to the following theorem.\n\n\n\n\n\n\nTheorem 2.4.1\n\n\n\nIf D is compact, and f \\colon D \\to \\mathbb{R} is continuous, then f is uniformly continuous.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLet \\varepsilon &gt; 0. Since f is continuous on D, it is continuous at each x \\in D. For each x \\in D, there exists some \\delta_x &gt; 0 such that\n\n|x-y| &lt; \\delta_x \\implies |f(x) - f(y)| &lt; \\frac{\\varepsilon}{2}.\n\nThe collection\n\nF = \\left\\{ N\\left(x,\\frac{\\delta_x}{2}\\right) \\mid x \\in D \\right\\}\n\nis an open cover of D. Since D is compact, F contains a finite subcover. Thus there exists x_1,\\dots,x_n \\in D such that D \\subset N(x_1,\\delta_{x_1}/2) \\cup \\cdots \\cup N(x_n,\\delta_{x_n}/2).\nLet \\delta = \\min\\left\\{\\frac{\\delta_{x_1}}{2},\\cdots,\\frac{\\delta_{x_n}}{2}\\right\\}. We want to show that this \\delta fufills the conditions for uniform continuity. Suppose x,y \\in D and |x - y| &lt; \\delta. Since \\bigcup_{i=1}^nN(x_i,\\delta_{x_i}/2) covers D, there exists some i such that x \\in N(x_i,\\delta_{x_i}/2).\nSince |x-y| &lt; \\delta \\leq \\delta_{x_i}/2, we have\n\n|y - x_i| = |y-x + x - x_i| \\leq |y-x| + |x - x_i| &lt; \\frac{\\delta_{x_i}}{2} + \\frac{\\delta_{x_i}}{2} = \\delta_{x_i}.\n\nThus |f(y) - f(x_i)| &lt; \\varepsilon/2. We also have |x - x_i| &lt; \\delta_{x_i}, so |f(x) - f(x_i)| &lt; \\varepsilon/2. Through the triangle inequality\n\n|f(x) - f(y)| \\leq |f(x) - f(x_i)|+|f(x_i) - f(y)| &lt; \\frac{\\varepsilon}{2} + \\frac{\\varepsilon}{2} = \\varepsilon.\n\nTherefore our function is uniformly continuous.\n\n\n\nHistorically, Cauchy believed the following theorem was true of any continuous function, which was later found to be inaccurate.\n\n\n\n\n\n\nTheorem 2.4.2\n\n\n\nLet f \\colon D \\to \\mathbb{R} be uniformly continuous on D and suppose (x_n) is a Cauchy sequence in D. Then (f(x_n)) is Cauchy.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nGiven any \\varepsilon &gt; 0, since f is uniformly continuous on D, there exists some \\delta &gt; 0 such that for all x,y \\in D\n\n|x-y| &lt; \\delta \\implies |f(x) - f(y)| &lt; \\varepsilon.\n\nSince (x_n) is Cauchy, there exists an integer N such that, when n,m \\geq N\n\n|x_n - x_m| &lt; \\delta.\n\nTherefore, for m,n \\geq N, we also have |f(x_n) - f(x_m)| &lt; \\varepsilon, so (f(x_n)) is a Cauchy sequence."
  },
  {
    "objectID": "qmd/realanal/limits-cont/uniform-continuity.html#footnotes",
    "href": "qmd/realanal/limits-cont/uniform-continuity.html#footnotes",
    "title": "Uniform Continuity",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe following Mathexchange thread provides very useful intuition.↩︎"
  },
  {
    "objectID": "qmd/realanal/limits-cont/uniform-continuity.html#properties",
    "href": "qmd/realanal/limits-cont/uniform-continuity.html#properties",
    "title": "Uniform Continuity",
    "section": "Properties",
    "text": "Properties\n\n\n\n\n\n\nDefinition\n\n\n\nWe say that a function \\tilde{f} \\colon E \\to \\mathbb{R} is an extension of a function f \\colon D \\to \\mathbb{R} if D \\subseteq E and f(x) = \\tilde{f}(x) for all x \\in D.\n\n\nThis definition allows us to take a function f, and create a new function \\tilde{f} such that f(x) = \\tilde{f}(x). If we extend f to a domain, and prove \\tilde{f} is uniformly continuous on said domain, then clearly f is uniformly continuous on it’s sub-domain.\n\n\n\n\n\n\nTheorem 2.4.3\n\n\n\nA function f \\colon (a,b) \\to \\mathbb{R} is uniformly continuous on (a,b) if and only if it can be extended to a function \\tilde{f} that is continuous on [a,b].\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nWe start by proving the reverse direction. By Theorem 2.4.1 if \\tilde{f} is continuous on [a,b], it is uniformly continuous. It follws then that \\tilde{f}, and hence f, is also uniformly continuous on the subset (a,b).\nConversly, suppose that f is uniformly continuous on (a,b). Let (s_n) be a sequence in (a,b) such that \\lim s_n = a (We know this sequence exists, because a is an accumulation point). By Theorem 1.3.5, (s_n) is Cauchy. Then by Theorem 2.4.2, (f(s_n)) is Cauchy, and thus converges. By Theorem 2.1.4, \\lim_{x\\to a}f(x) = p for some p \\in \\mathbb{R}. Similarly, \\lim_{x \\to b}f(x) = q for some q \\in \\mathbb{R}.\nWe define \\tilde{f} \\colon [a,b] \\to \\mathbb{R} by\n\n\\tilde{f}(x) = \\begin{cases}\nf(x), & a &lt; x &lt; b\\\\\np, & x = a\\\\\nq, & x = b\n\\end{cases}\n\nThen \\tilde{f} is an extension of f. Since f is continuous on (a.b), so is \\tilde{f}. Since \\tilde{f} is continuous on a,b it follws that \\tilde{f} is continuous on [a,b].\n\n\n\nUnrelated.\n\n\n\n\n\n\nTheorem 2.4.4\n\n\n\nLet f\\colon D \\to \\mathbb{R} be a uniformly continuous function on the bounded set D. Prove that f is bounded on D.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nSuppose that f(D) is not bounded. Then, for any M \\in \\mathbb{R} there exists a sequence (x_n) \\in D such that for some natural number n, |f(x_n)| \\geq M.\nSince D is bounded, there exists a convergent sub-sequence (x^\\prime_n) of (x_n) by Theorem 1.4.2, which is additionally a Cauchy sequence by Lemma 1.3.3. Since f is uniformly continuous, we would have that (f(x^\\prime_n)) is a Cauchy sequence. But by Lemma 1.3.4, every cauchy sequence must be bounded. Thus our assumption that f(D) is unbounded is false, and f(D) must be bounded."
  },
  {
    "objectID": "qmd/realanal/limits-cont/cont-func-prop.html#review",
    "href": "qmd/realanal/limits-cont/cont-func-prop.html#review",
    "title": "Properties of Continuous Functions",
    "section": "Review",
    "text": "Review\nIn this section we proved\n\n\n\n\n\n\nTheorem 2.3.1\n\n\n\nIf D is a compact subset of \\mathbb{R} and f \\colon D \\to \\mathbb{R} is continuous, then f(D) is compact.\n\n\n\n\n\n\n\n\nCorollary 2.3.2\n\n\n\nLet D a compact subset of \\mathbb{R} and f \\colon D \\to \\mathbb{R} be continuous. Then, f attains a minimum and maximum on D.\n\n\n\n\n\n\n\n\nLemma 2.3.3\n\n\n\nLet f \\colon [a,b] \\to \\mathbb{R} be continuous, and suppose f(a) &lt; 0 &lt; f(b). Then there exists c \\in (a,b) such that f(c) = 0.\n\n\n\n\n\n\n\n\nTheorem 2.3.4 (Intermediate Value Theorem)\n\n\n\nLet f \\colon [a,b] \\to \\mathbb{R} be continuous. For any value k between f(a) and f(b), there exists c \\in (a,b) such that f(c) = k.\n\n\n\n\n\n\n\n\nTheorem 2.3.5\n\n\n\nLet I be a compact interval and suppose f \\colon I \\to \\mathbb{R} is a continuous function. Then the set f(I) is a compact interval"
  },
  {
    "objectID": "qmd/pde/fourier/fourier.html",
    "href": "qmd/pde/fourier/fourier.html",
    "title": "Fourier Series",
    "section": "",
    "text": "The fourier series of a function f(x) on the interval [-L,L] is\n\n\\text{Fourier series} = a_0 + \\sum^\\infty_{n=1}a_n\\cos\\frac{n\\pi x}{L} + \\sum^\\infty_{n=1}b_n\\sin\\frac{n\\pi x}{L}\n\nWhere the coeffiencts are given by\n\na_0 = \\frac{1}{2L}\\int^L_{-L}f(x)dx\\\\\na_n = \\frac{1}{L}\\int^L_{-L}f(x)\\cos\\frac{n\\pi x}{L}dx\\\\\nb_n = \\frac{1}{L}\\int^{L}_{-L}f(x)\\sin\\frac{n\\pi x}{L}dx\n\nFor odd functions, a_n = a_0 = 0. This gives us a fourier sine series."
  },
  {
    "objectID": "qmd/realanal/differentiation/taylor.html",
    "href": "qmd/realanal/differentiation/taylor.html",
    "title": "Taylor’s Theorem",
    "section": "",
    "text": "Theorem 3.4.1 (Taylor’s Theorem)\n\n\n\nLet f and its n-derivative be continuous on [a,b] and differentiable on (a,b). Let x_0 \\in [a,b]. For each x \\in [a,b] such that x \\not = x_0. Then there exists c between x,x_0 such that\n\\begin{align*}\nf(x) &= f(x_0) + f^\\prime(x_0)(x-x_0) + \\frac{f^{\\prime\\prime}(x_0)}{2!}(x-x_0)^2 + \\cdots \\\\\n&+ \\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n + \\frac{f^{(n+1)}(c)}{(n+1)!}(x-x_0)^{n+1}.\n\\end{align*}\n\n\nWe can think of the final term as measuring the failure of approximation given by the first n+1 terms.\n\n\n\n\n\n\nProof\n\n\n\n\n\nFix x \\in [a,b] such that x_0 \\not = x. Let M be the unique solution to\n\nf(x) = f(x_0) + \\cdots + \\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n + M(x-x_0)^{n+1}.\n\nDefine\n\nF(t) = f(t) + f^\\prime(t)(x-t) + \\cdots + \\frac{f^{(n)}(x_0)}{n!}(x-t)^n + M(x-t)^{n+1}.\n\nOur assumuptions imply F(t) and its n-derivatives are continuous on [a,b] and differentiable on (a,b). Note that F(x) = f(x). Our choice of M implies that F(x_0) = f(x). By the MVT, there exists c between x,x_0 such that\n\nF^\\prime(c) = \\frac{F(x)-F(x_0)}{x-x_0} = 0\n\nsince F(x) = F(x_0) = f(x). We can calculate F^\\prime(t), and find that all terms except the last two will cancel out. Thus\n\nF^\\prime(t) =\\frac{f^{(n+1)}(t)}{n!}(x-t)^n - M(n+1)(x-t)^n.\n\nThus, F^\\prime(c) = 0 implies\n\nF^\\prime(c) = \\frac{f^{(n+1)}(c)}{n!}(x-t)^n - M(n+1)(x-c)^n = 0\n\n\nM = \\frac{f^{(n+1)}(c)}{(n+1)!}.\n\nTherefore we have proved the Taylor series is an accurate representation."
  },
  {
    "objectID": "qmd/realanal/integration/riemann.html",
    "href": "qmd/realanal/integration/riemann.html",
    "title": "Riemann Integral",
    "section": "",
    "text": "The Riemann Integral was the first formal definition of an integral, defined by Bernhard Riemann in 1854. Gaston Darboux developed a simpler approach to the Riemann Integral in 1875 (source needed), that I’ll be using in this section."
  },
  {
    "objectID": "qmd/realanal/integration/riemann.html#definitions",
    "href": "qmd/realanal/integration/riemann.html#definitions",
    "title": "Riemann Integral",
    "section": "Definitions",
    "text": "Definitions\n\nPartitions\n\n\n\n\n\n\nDefinition\n\n\n\nLet [a,b] be an interval in \\mathbb{R}. A partition P of [a,b] is a finite set of points \\{x_0,x_1,\\ldots,x_n\\} in [a,b] such that\n\na = x_0 &lt; x_1 &lt; \\cdots &lt; x_n = b.\n\n\n\nA partition serves to chop up our interval [a,b] into fintely many subintervals [x_0,x_1],[x_1,x_2],\\ldots,[x_{n-1},x_{n}].\nWe notate the length of the i^{th} sub-interval in our partition with \n\\Delta x_i = x_i - x_{i-1}.\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf P and Q are two partitions of [a,b] with P \\subseteq Q, then Q is called a refinement of P.\n\n\n\n\nDarboux sums\n\n\n\n\n\n\nDefinition\n\n\n\nLet f be a bounded function on [a,b] and P = \\{x_1,\\ldots,x_n\\} be any partition on [a,b]. Let\n\nM_i(f) = \\sup\\{f(x) \\colon x \\in [x_{i-1},x_i]\\}\n and \nm_i(f) = \\inf\\{f(x) \\colon x \\in [x_{i-1},x_i]\\}\n\nfor each i \\in \\{1,\\ldots,n\\}. We define \nU(f,P) = \\sum^n_{i=1}M_i\\Delta x_i \\qquad L(f,P) = \\sum^n_{i=1}m_i\\Delta x_i\n\nas the Upper sum and Lower sum respectively.\n\n\nBecause we assume f to be bounded function, there exists a lower and upper bound on the interval [a,b]. Call these bounds m,M respectively (No relation to m_i,M_i). For any partition P of [a,b] we have \nm(b-a) \\leq L(f,p) \\leq U(f,p) \\leq M(b-a).\n\nThus we know the upper and lower sums for f exist, and form a bounded set.\n\n\nRiemann Integral\n\n\n\n\n\n\nDefinition\n\n\n\nLet f be a bounded function defined on [a,b] and P be a partition on [a,b]. Then\n\nU(f) = \\inf \\{U(f,P)\\} \\qquad L(f) = \\sup \\{L(f,P)\\}\n\nare called the upper integral and lower integral of f on [a,b], respectively.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf L(f) = U(f), we say that f is Riemann integrable on [a,b], and notate the value with\n\n\\int^a_b f \\quad \\text{ or } \\quad \\int^a_b f(x) \\, dx\n\nThis is known as the Riemann integral of f on [a,b]."
  },
  {
    "objectID": "qmd/realanal/integration/riemann.html#properties",
    "href": "qmd/realanal/integration/riemann.html#properties",
    "title": "Riemann Integral",
    "section": "Properties",
    "text": "Properties\n\n\n\n\n\n\nTheorem 4.1.3\n\n\n\nLet f be a bounded function on [a,b]. Then L(f) \\leq U(f).\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\nIf P and Q are partitions of [a,b], we have that L(f,P) \\leq U(f,Q) by Theorem 4.1.2. Then it follows that U(f,Q) is an upper bound of the set defined by\n\nS = \\{L(f,P) \\colon P \\text{ partitions } [a,b]\\}.\n\nThus U(f,Q) \\geq \\sup S. That is, L(f) \\leq U(f,Q) for all partitions Q of [a,b]. Hence\n\nL(f) \\leq \\inf \\{U(f,Q) \\colon Q \\text{ partitions } [a,b]\\} = U(f).\n\n\n\n\n\n\n\n\n\n\nExample (Non-integrable functions)\n\n\n\nLet f \\colon [0,1] \\to \\mathbb{R} be defined\n\ng(x) = \\begin{cases}\n1, & \\text{if $x$ is rational}\\\\\n0, & \\text{if $x$ is irrational.}\n\\end{cases}\n\nLet P = \\{x_1,\\ldots,x_n\\} be any partition of [0,1]. Since each subinterval [x_{i-1},x_i] contains both rational and irrational points, we have M_i = 1 and m_i = 0 for all i \\in \\{1,\\dots,n\\}. Therefore\n\nU(f,P) = \\sum^n_{i=1}(1)\\Delta x_i = 1 \\qquad L(f,P) = \\sum^n_{i=1}(0)\\Delta x_i = 0.\n\nSince the lower and upper integrals are different for every partition P, f is non-integrable on [0,1]. This special function f is known as the Dirichlet function.\n\n\n\n\n\n\n\n\nTheorem 4.1.4 (Riemann integrablility Criterion)\n\n\n\nLet f be a bounded function on [a,b]. Then f is integrable if and only if for each \\varepsilon &gt; 0 there exists a partition P of [a,b] such that\n\nU(f,P) - L(f,P) &lt; \\varepsilon.\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\n\nForward direction\nSuppose f is integrable, meaning L(f) = U(f). Given any \\varepsilon &gt; 0, there exists a partition P_1 of [a,b] such that\n\nL(f,P_1) &gt; L(f) - \\frac{\\varepsilon}{2}.\n\nThis follows since L(f) is a supremum. Similarly, there exists a partition P_2 of [a,b] such that\n\nU(f,P_2) &lt; U(f) + \\frac{\\varepsilon}{2}.\n\nLet P = P_1 \\cup P_2. Then by Theorem 4.1.1 we have\n\\begin{align*}\nU(f,P) - L(f,P) &\\leq U(f,P_2) - L(f,P_1)\\\\\n&&lt; \\left[U(f) + \\frac{\\varepsilon}{2}\\right] - \\left[L(f) - \\frac{\\varepsilon}{2}\\right]\\\\\n&= U(f) - L(f) + \\varepsilon = \\varepsilon.\n\\end{align*}\nTherefore f being integrable implies there exists P such that U(f,P) - L(f,P) &lt; \\varepsilon.\nReverse direction\nNow, suppose we have P such that U(f,P) - L(f,P) &lt; \\varepsilon. Then\n\nU(f) \\leq U(f,P) &lt; L(f,P) + \\varepsilon \\leq L(f) + \\varepsilon.\n\nSince \\varepsilon &gt; 0 is arbitrary, we have U(f) \\leq L(f). By Theorem 4.1.3 we have that L(f) \\leq U(f). Thus L(f) = U(f), and f is Riemann integrable."
  },
  {
    "objectID": "qmd/realanal/integration/riemannprop.html",
    "href": "qmd/realanal/integration/riemannprop.html",
    "title": "Properties of the Riemann Integral",
    "section": "",
    "text": "Theorem 4.2.1\n\n\n\nLet f be a monotone function on [a,b]. Then f is Riemann integrable.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\nSuppose f is increasing on [a,b]. Since f(a) \\leq f(x) \\leq f(b) for all x \\in [a,b], f is bounded on [a,b]. Now given \\varepsilon &gt; 0 there exists k &gt; 0 such that\n\nk[f(b)-f(a)] &lt; \\varepsilon\n\nBy the Arichimeadian property. Let P = \\{x_0,\\ldots,x_n\\} be a partition of [a,b] such that \\Delta x_i \\leq k for all i (Recall \\Delta x_i = x_i - x_{i-1}). Since f is increasing, we have\n\nm_i = f(x_{i-1}) \\qquad \\text{and} \\qquad M_i = f(x_i)\n\nfor i \\in \\{1,\\ldots,n\\}. Then\n\\begin{align*}\nU(f,P) - L(f,P) &= \\sum_{i=1}^n[f(x_i)-f(x_{i-1})](\\Delta x_i)\\\\\n&\\leq k\\sum_{i=1}^n[f(x_i)-f(x_{i-1})] = k[f(b)-f(a)] &lt; \\varepsilon\n\\end{align*}\nSince for all \\varepsilon &gt; 0, U(f,P) - L(f,P) &lt; \\varepsilon, f is Riemann integrable by Theorem 4.1.4. The proof is similar for decreasing monotone functions.\n\n\n\n\n\n\n\n\n\nTheorem 4.2.2\n\n\n\nLet f be a continuous function on [a,b]. Then f is integrable on [a,b].\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\nSince f is continuous on [a,b], a compact set, it is uniformly continuous on [a,b]. Thus for any \\varepsilon &gt; 0, there exists \\delta &gt; 0 such that\n\n|f(x)-f(y)| &lt; \\frac{\\varepsilon}{b-a}\n\nWhen x,y \\in [a,b] and |x-y| &lt; \\delta. Let P = \\{x_0,\\ldots,x_n\\} be a partition of [a,b] such that \\Delta x_i &lt; \\delta for all i \\in \\{i,\\ldots,n\\}. Since f assumes its minimum and maximum on [a,b], there exists points s_i,t_i \\in [a,b] such that m_i = f(s_i), and M_i = f(t_i). Since x_i - x_{i-1} &lt; \\delta, we have that |s_i - t_i| &lt; \\delta, and\n\n0 \\leq M_i - m_i = f(t_i) - f(s_i) &lt; \\frac{\\varepsilon}{b-a}\n\nfor all i. It follows that\n\nU(f,P) - L(f,P) = \\sum_{i=1}^n(M_i - m_i)(\\Delta x_i) &lt; \\frac{\\varepsilon}{b-a}\\sum_{i=1}^n\\Delta x_i = \\varepsilon\n\nThus by Theorem 4.1.4, f is Riemann integrable on [a,b].\n\n\n\nWe have now proved that two large classes of functions, monotone functions and continuous functions are Riemann integrable. There of course exists other functions that are neither continuous or monotone, but are still Riemann integrable.\n\n\n\n\n\n\nExample\n\n\n\nLet f be the Thomae’s function defined on the interval [0,1] as\n\nf(x) = \\begin{cases}\n\\frac{1}{n} & \\text{ if $x = \\frac{m}{n}$ in rational in lowest terms,}\\\\\n0, & \\text{ if $x$ is irrational.}\n\\end{cases}\n\nLet \\varepsilon &gt; 0, choose N such that N &gt; 2/\\varepsilon. Let Y_N be the set of all rational numbers in [0,1] that have a denominator less than N when expressed in lowest terms, for example\n\nY_5 = \\left\\{0,\\frac{1}{4},\\frac{1}{3},\\frac{1}{2},\\frac{2}{3},\\frac{3}{4},1\\right\\}.\n\nLet n &gt; 4m/\\varepsilon be an integer, and let P = \\{x_0,\\ldots,x_n\\} such that \\Delta x = 1/n for all n.\nWe want to split our indices into two disjoint subsets based on whether or not the indice contains a point in Y_N. Let\n\nA = \\{i \\colon [x_{i-1},x_i] \\cap Y = \\varnothing\\} \\text{ and } B = \\{i \\colon [x_{i-1},x_i] \\cap Y \\not = \\varnothing\\}.\n\nIf i \\in A, then every rational in [x_{i-1},x_i] has a denominator greater or equal to N. This means M_i \\leq 1/N &lt; \\varepsilon/2. It follows that\n\n\\sum_{i \\in A} M_i \\Delta x_i \\leq \\frac{\\varepsilon}{2}\\sum_{i \\in A} \\Delta x_i &lt; \\frac{\\varepsilon}{2}.\n\n\n\n\n\n\n\n\n\nTheorem 4.2.3 (Linearity of the Riemann integral)\n\n\n\nLet f and g be Riemann integerable functions on [a,b] and let k \\in \\mathbb{R}. Then\n(a) kf is Riemann integrable and\n\n\\int^b_a kf = k \\int^b_a f\n\n(b) f + g is Riemann integrable and\n\n\\int^b_a (f+g) = \\int^b_a f + \\int^b_a g\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\n(a) If k = 0, then the result is trivial. Suppose k &gt; 0 and let P = \\{x_0,\\ldots,x_n\\} be a partition of [a,b]. For all i we have\n\nM_i(kf) = kM_i(f).\n\nThus we have U(kf,P) = kU(f,P), and U(kf) = kU(f). Similarly we have L(kf) = kL(f). Since U(f) = L(f),\n\nL(kf) = k L(f) = k U(f) = U(kf).\n\nThus kf is Riemann integrable and furthermore\n\n\\int^b_a kf = U(kf) = kU(f) = k\\int^b_a f.\n\nThe case where k &lt; 0 is similar.\n(b) We know\n\n\\sup [(f+g)(D)] \\leq \\sup f(D) + \\sup g(D).\n\nSo for any partition P, we have M_i(f+g) \\leq M_i(f) + M_i(g) for each i, so\n\nU(f + g,P) \\leq U(f,P) + U(g,P).\n\nSimilarly\n\nL(f + g, P) \\geq L(f,P) + L(g,P).\n\nWe want to show U(f+g,P) - L(f+g,P) &lt; \\varepsilon. Given any \\varepsilon &gt; 0, there exists partitions P_1,P_2 of [a,b] such that\n\nU(f,P_1) &lt; L(f,P_1) + \\frac{\\varepsilon}{2} \\quad \\text{and} \\quad U(g,P_2) &lt; L(g,P_2) - \\frac{\\varepsilon}{2}.\n\nLet P = P_1 \\cup P_2. Then by Theorem 4.1.2 we have\n\nU(f,P) &lt; L(f,P) + \\frac{\\varepsilon}{2} \\quad \\text{and} \\quad U(g,P) &lt; L(g,P) - \\frac{\\varepsilon}{2}.\n\nCombining inequalities we obtain\n\n\\begin{align*}\nU(f+g,P) &\\leq U(f,P) + U(g,P)\\\\\n&&lt; L(f,P) + L(g,P) + \\varepsilon \\leq L(f+g,P) + \\varepsilon.\n\\end{align*}\n\nThus by Theorem 4.1.4 we have that f+g in Riemann integrable. Furthermore since\n\n\\begin{align*}\n\\int^b_a(f+g) &= U(f + g) \\leq U(f+g,P)\\\\\n&&lt; L(f,P) + L(g,P) + \\varepsilon\\\\\n&\\leq L(f) + L(g) + \\varepsilon = \\int^b_a f + \\int^b_a g + \\varepsilon\n\\end{align*}\n\nand\n\n\\begin{align*}\n\\int^b_a(f+g) &= L(f + g) \\geq L(f+g,P)\\\\\n&&gt; U(f,P) + U(g,P) - \\varepsilon\\\\\n&\\leq U(f) + U(g) - \\varepsilon = \\int^b_a f + \\int^b_a g - \\varepsilon\n\\end{align*}\n\nwe must have\n\n\\int^b_a (f+g) = \\int^b_a f + \\int^b_a g.\n\n\n\n\n\n\n\n\n\n\nTheorem 4.2.4\n\n\n\nIf f is Riemann integrable on both [a,c] and [c,b], then f is Riemann integrable on [a,b]. Furthermore\n\n\\int^b_a f = \\int^c_a f + \\int^b_c f.\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\nGiven \\varepsilon &gt; 0, there exists partitions P_1 of [a,c] and P_2 of [c,b] such that\n\nU(f,P_1) - L(f,P_1) &lt; \\frac{\\varepsilon}{2} \\quad \\text{and} \\quad U(f,P_2) - L(f,P_2) &lt; \\frac{\\varepsilon}{2}.\n\nLet P = P_1 \\cup P_2. Then P is a partition of [a,b] and we have\n\n\\begin{align*}\nU(f,P) - L(f,P) &= U(f,P_1) + U(f,P_2) - L(f,P_1) - L(f,P_2)\\\\\n&= [U(f,P_1)-L(f,P_1)] + [U(f,P_2) - L(f,P_2)]\\\\\n&&lt; \\frac{\\varepsilon}{2} + \\frac{\\varepsilon}{2} = \\varepsilon\n\\end{align*}\n\nThus f is Riemann integrable on [a,b] by Theorem 4.1.4. Furthermore,\n\n\\begin{align*}\n\\int^b_a f \\leq U(f,P) &= U(f,P_1)+U(f,P_2)\\\\\n&&lt; L(f,P_1) + L(f,P_2) + \\varepsilon \\leq \\int^c_a f + \\int^b_c f + \\varepsilon,\n\\end{align*}\n\nand\n\n\\begin{align*}\n\\int^b_a f \\geq L(f,P) &= L(f,P_1)+L(f,P_2)\\\\\n&&gt; U(f,P_1) + U(f,P_2) - \\varepsilon \\geq \\int^c_a f + \\int^b_c f - \\varepsilon,\n\\end{align*}\n\nThus\n\n\\int^b_a f = \\int^c_a f + \\int^b_c f.\n\n\n\n\n\n\n\n\n\n\nTheorem 4.2.5\n\n\n\nFor any functions f,g which are Riemann integerable on [a,b], such that f(x) \\leq g(x) for all x \\in [a,b], then\n\n\\int^b_a f \\leq \\int^b_a g\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\nLater.\n\n\n\n\n\n\n\n\n\nTheorem 4.2.6\n\n\n\nLet f be Riemann integerable on [a,b] and g be continuous on [c,d] where f([a,b]) \\subseteq [c,d]. Then g \\circ f is Riemann integrable on [a,b].\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\nGiven \\varepsilon &gt; 0, let K = \\sup\\{|g(t)| \\colon t \\in [c,d]\\} and choose \\varepsilon^\\prime &gt; 0 such that \\varepsilon^\\prime(b-a+2K) &lt; \\varepsilon. Since g is continuous on [c,d], it is uniformly continuous on [c,d]. Thus there exists some \\delta &gt; 0 such that \\delta &lt; \\varepsilon^\\prime and such that |g(s) - g(t)| &lt; \\varepsilon^\\prime whenever |s-t| &lt; \\delta and s,t \\in [c,d]. Since f is integrable on [a,b], there exists some partition P = \\{x_0,\\ldots,x_n\\} of [a,b] such that\n\nU(f,P) - L(f,P) &lt; \\delta^2.\n\nWe claim that for this partition P we also have\n\nU(g \\circ f,P) - L(g \\circ f,P) = \\sum_{i=1}^n[M_i(g\\circ f) - m_i(g \\circ f)]\\Delta x &lt; \\varepsilon.\n\nTo show this we seperate our partition P into two disjoint sets. Let\n\nA = \\{i \\colon M_i(f) - m_i(f) &lt; \\delta\\} \\text{ and } B = \\{i\\colon M_i(f) - m(i) \\geq \\delta\\}.\n\nThen if i \\in A, and x,y \\in [x_{i-1},x_i], we have\n\n|f(x) - f(y) | \\leq M_i(f) - m_i(f) &lt; \\delta\n\nso that |(g \\circ f)(x) - (g \\circ f)(y) | &lt; \\varepsilon^\\prime and therefore M_i(g \\circ f) - m_i(g \\circ f) \\leq \\varepsilon^\\prime. It follows that\n\n\\sum_{i \\in A}\\left[  M_i(g\\circ f) - m_i(g \\circ f) \\right]\\Delta x_i \\leq \\varepsilon^\\prime\\sum_{i\\in A} \\Delta x_i \\leq \\varepsilon^\\prime(b-a)\n\nOtherwise, if i \\in B, then [M_i(f) - m_i(f)]/\\delta \\geq 1 so\n\\begin{align*}\n\\sum_{i \\in B} \\Delta x_i &\\leq \\frac{1}{\\delta}\\sum_{i \\in B}[M_i(f) - m_i(f)]\\Delta x_i\\\\\n&\\leq \\frac{1}{\\delta}[U(f,P) - L(f,P)] &lt; \\delta &lt; \\varepsilon^\\prime.\n\\end{align*}\nThus since M_i(g \\circ f) - m_i(g \\circ f) \\leq 2K for all i we have\n\n\\sum_{i \\in B}[M_i(g \\circ f) - m_i(g \\circ f)]\\Delta x \\leq 2K\\sum_{i \\in B}\\Delta x &lt; 2K\\varepsilon^\\prime\n\nCombining our indices we have\n\\begin{align*}\nU(g \\circ f, P) - L(g \\circ f,P) &= \\sum_{i \\in A}\\left[  M_i(g\\circ f) - m_i(g \\circ f) \\right]\\Delta x_i\\\\\n&+ \\sum_{i \\in B}[M_i(g \\circ f) - m_i(g \\circ f)]\\Delta x\\\\\n&\\leq \\varepsilon^\\prime(b-a) + 2K\\varepsilon^\\prime = \\varepsilon^\\prime(b-a+2K) &lt; \\varepsilon\n\\end{align*}\nHence g \\circ f is Riemann integrable on [a,b].\n\n\n\n\n\n\n\n\n\nCorollary 4.2.6\n\n\n\nIf f is Riemann integrable on both [a,b] and |f| is Riemann integrable on [a,b], then\n\n\\left|\\int^b_a f \\right| \\leq \\int^b_a |f|\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\nSince f is Riemann integerable, the function is bounded on [a,b]. Let B \\geq |f(x)| for all x \\in [a,b]. Define g \\colon [-B,B] \\to \\mathbb{R} such that it maps t \\to |t|. Since g is continuous and g \\circ f = |f|, we have that |f| is integerable.\nSince we have that -|f(x)| \\leq f(x) \\leq |f(x)| for all x, by Lemma 4.2.5, we have that\n\n- \\int^b_a |f| \\leq \\int^b_a f  \\leq \\int^b_a |f|\n\nwhich we can then rewrite using the definition of absolute value to obtain\n\n\\left| \\int^b_a f \\right| \\leq \\int^b_a |f|"
  },
  {
    "objectID": "qmd/realanal/intro/sets.html",
    "href": "qmd/realanal/intro/sets.html",
    "title": "Convergence",
    "section": "",
    "text": "Definition\n\n\n\nA sequence S is a function whose domain is the set of natural numbers, \\mathbb{N}.\nA sequence S is usually notated (s_n) or as a list of elements\n(s_1,s_2,s_3,\\ldots)\nNormally we will consider sequences where the codomain is \\mathbb{R}."
  },
  {
    "objectID": "qmd/realanal/intro/sets.html#definition-and-properties",
    "href": "qmd/realanal/intro/sets.html#definition-and-properties",
    "title": "Convergence",
    "section": "Definition and properties",
    "text": "Definition and properties\n\n\n\n\n\n\nDefinition\n\n\n\nA sequence (s_n) of real numbers converges to a real number s if\n\n\\forall \\varepsilon &gt; 0, \\exists N \\in \\mathbb{N} \\;s.t.\\; \\forall n \\geq N, |s_n - s| &lt; \\varepsilon\n\n\n\nWhere |s_n - s| is the distance between the points s_n and s. Essentially, a sequence is convergent if the elements of (s_n) get arbitrarily close to a point s as the sequence progresses.\nIf a sequence does not converge, than we say it is divergent.\n\n\n\n\n\n\nDefinition\n\n\n\nIf (s_n) converges to s, then we say that s is the limit of (s_n) and we write\n\n\\lim_{n \\to \\infty} s_n = s\n\n\n\nWe use (s_n) to denote the sequence as a whole, where as s_n refers to an indivual element of the sequence. We also typically abbreviate \\lim_{n\\to\\infty}s_n = s as \\lim s_n = s\nSuppose we have a sequence (s_n) which appears to converge to a number s. How would we go about proving the sequence fufills the definition of convergence?\n\n\n\n\n\n\n\nExample\n\n\n\nClaim: Given the sequence s_n = 1/n, we have\n\n\\lim_{n \\to \\infty} \\frac{1}{n} = 0.\n\nIn order to show this sequence converges, we need to prove that for all \\varepsilon &gt; 0 there exists some N \\in \\mathbb{N} such that for all n \\geq N, we have\n\n|s_n - s| = \\left|\\frac{1}{n} - 0\\right| = \\left|\\frac{1}{n}\\right| = \\frac{1}{n} &lt; \\varepsilon.\n\nBy the Archimedean property, we know there always exists some n \\in \\mathbb{N} such that xn &gt; y for any positive x,y \\in \\mathbb{R}. It is then clear there exists some n such that 1/n &lt; y/x.\nTherefore for any \\varepsilon &gt; 0, we simply choose N such that 0 &lt; \\frac{1}{N} &lt; \\varepsilon. Then for any n \\geq N, we have |1/n - 0| = 1/n \\leq 1/N &lt; \\varepsilon. Thus our sequence converges, and \\lim s_n = 0.\n\n\n\nSee Practice for more examples.\n\n\n\n\n\n\nTheorem 1.1.1\n\n\n\nLet (s_n) and (a_n) be sequences of real numbers and let s \\in \\mathbb{R}. If for some k &gt; 0 and some m \\in \\mathbb{N} we have\n\n|s_n - s| \\leq k|a_n|, \\forall n \\geq m\n\nand if \\lim a_n = 0, then it follows that \\lim s_n = s.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nGiven any \\varepsilon &gt; 0, since \\lim a_n = 0 there exists N_1 \\in \\mathbb{N} such that n \\geq N_1 implies |a_n| &lt; \\varepsilon/k. Let N = \\max\\{m,N_1\\}. Then for n \\geq \\mathbb{N} we have n \\geq m and n \\geq N_1, so\n\n|s_n - s| \\leq k|a_n| &lt; k\\left(\\frac{\\varepsilon}{k}\\right) = \\varepsilon.\n\nThus \\lim s_n = s.\n\n\n\nThis Theorem can be applied quite liberally to help with a great variety of limit problems.\n\n\n\n\n\n\nExample\n\n\n\nClaim: The \\lim(4n^2 - 3)/(5^2 -2n) = 4/5.\nWe start with some algebraic manipulation\n\n\\left|\\frac{4n^2 - 3}{5n^2 - 2n} - \\frac{4}{5}\\right| = \\left| \\frac{8n-15}{5(5n^2-2n)}\\right|\n\nWe aim to find an upper bound to simplify the fraction. For the numerator, |8n - 15| &lt; 8n for all n \\in \\mathbb{N} (Note 0 \\not \\in \\mathbb{N}). For the denominator, we want some relation in the form 5n^2 - 2n \\geq kn^2 for some k &gt; 0. We use k = 4 to obtain\n\n5n^2 - 2n \\geq 4n^2 \\implies n^2 \\geq 2n \\implies n \\geq 2.\n\nWhen n \\geq 2, we now have the relation\n\n\\left| \\frac{8n-15}{5(5n^2-2n)}\\right| &lt; \\frac{8n}{5(4n^2)} = \\frac{2}{5}\\left(\\frac{1}{n}\\right).\n\nWe can turn this into a formal proof. If n \\geq 2, then n^2 \\geq 2n and 5n^2 -2n\\geq 4n^2 such that\n\n\\left|\\frac{4n^2 - 3}{5n^2 - 2n} - \\frac{4}{5}\\right| = \\left| \\frac{8n-15}{5(5n^2-2n)}\\right| &lt; \\frac{8n}{5(4n^2)} = \\frac{2}{5}\\left(\\frac{1}{n}\\right)\n\nSince \\lim (1/n) = 0 as shown in our last example, Theorem 1.1.1 states that\n\n\\lim \\frac{4n^2-3}{5n^2 - 2n} = \\frac{4}{5}.\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA sequence (s_n) is bounded if there exists M \\geq 0 such that |s_n| \\leq M.\n\n\n\n\n\n\n\n\nTheorem 1.1.2\n\n\n\nEvery convergent sequence is bounded.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLet (s_n) be a convergent sequence and let \\lim s_n = s. Choose \\varepsilon = 1. Because (s_n) is convergent, there exists some N \\in \\mathbb{N} such that for all n \\geq N, |s_n - s| &lt; 1.\nThrough the triangle inequality, we have that, for all n \\geq N\n\n|s_n| - |s| \\leq |s_n - s| &lt; 1 \\iff |s_n| &lt; |s| + 1.\n\nLet M = \\max\\{|s_1|,|s_2|,\\ldots,|s_N|,|s| + 1\\}. Thus for all n \\in \\mathbb{N}, |s_n| \\leq M and (s_n) is bounded.\n\n\n\nThe contrapositive is of course also true, any unbounded sequence is divergent. However, not all divergent sequences are unbounded.\n\n\n\n\n\n\nExample\n\n\n\nLet (s_n) = (-1)^n. This sequence is clearly bounded by M = 1, but not convergent.\n\n\n\n\n\n\n\n\nTheorem 1.1.3\n\n\n\nIf a sequence converges, its limit is unique.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLet (s_n) be a convergent sequence and suppose \\lim s_n = s and \\lim s_n = t. We want to show that s and t are arbitrarily close and therefore s = t.\nBy the definition of convergence we have\n\n\\exists N_1 \\in \\mathbb{N} \\text{ such that }\\forall n \\geq N_1, |s_n - s| &lt; \\frac{\\varepsilon}{2}.\n\nand\n\n\\exists N_2 \\in \\mathbb{N} \\text{ such that }\\forall n \\geq N_2, |s_n - t| &lt; \\frac{\\varepsilon}{2}.\n\nLet N = \\max\\{N_1,N_2\\}. From the triangle inequality we have\n\\begin{align*}\n|s-t| &= |s - s_n + s_n - t|\\\\\n&\\leq |s-s_n|+|s_n-t|\\\\\n&&lt; \\frac{\\varepsilon}{2} + \\frac{\\varepsilon}{2} = \\varepsilon\n\\end{align*}\nSince this holds for all \\varepsilon &gt; 0, we have s = t."
  },
  {
    "objectID": "qmd/realanal/intro/sets.html#sec-practice",
    "href": "qmd/realanal/intro/sets.html#sec-practice",
    "title": "Convergence",
    "section": "Practice",
    "text": "Practice\n\n\n\n\n\n\nProblem \\star\n\n\n\nProve if |x| &lt; 1, then \\lim_{n\\to\\infty} x^n = 0 using Bernoulii’s inequality,\n\n(1 + y)^n \\geq 1 + ny.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf x = 0, the proof is trivial, so we need to prove the case where 0 &lt; |x| &lt; 1. Bernoulii’s inequality states\n\n(1 + y)^n \\geq 1 + ny.\n\nIf we let x = 1/(1+y) for some y &gt; 0, we get\n\n(1 + \\frac{1}{x} - 1)^n \\geq 1 + n\\left(\\frac{1}{x} - 1\\right) \\implies \\frac{1}{x^n} \\geq 1 + \\frac{n}{x} - n\n\nFlipping both sides of the inequality gets us\n\nx^n \\leq \\frac{1}{1 + \\frac{n}{x} - n}.\n\nTaking the right hand side of the equation, and using our substitution for y, we obtain\n\n\\frac{1}{1 + \\frac{n}{x} + n} = \\frac{1}{1 + yn + 2n}.\n\nLet 1 + yn + 2n = k For any \\varepsilon &gt; 0, there exists N \\in \\mathbb{N} such that for all n \\geq N,\n\n\\left|\\frac{1}{1 + yn + 2n} - 0\\right| = \\left|\\frac{1}{k} - 0 \\right| \\leq \\frac{1}{k} \\leq \\varepsilon\n\nWe know by the Archimedian property there exists some n giving us a suffienct value of k. Thus \\lim 1/(1 + n/x - n) = 0. We have\n\n|x^n - 0| = x^n \\leq \\frac{1}{1 + \\frac{n}{x} - n}\n\nWhich by Theorem 1.1.1, gives us \\lim x^n = 0."
  },
  {
    "objectID": "qmd/realanal/intro/sets.html#recap",
    "href": "qmd/realanal/intro/sets.html#recap",
    "title": "Convergence",
    "section": "Recap",
    "text": "Recap\nIn this section we proved the following theorems and results.\n\n\n\n\n\n\nTheorem 1.1.1\n\n\n\nLet (s_n) and (a_n) be sequences of real numbers and let s \\in \\mathbb{R}. If for some k &gt; 0 and some m \\in \\mathbb{N} we have\n\n|s_n - s| \\leq k|a_n|, \\forall n \\geq m\n\nand if a_n = 0, then it follows that \\lim s_n = s.\n\n\n\n\n\n\n\n\nTheorem 1.1.2\n\n\n\nEvery convergent sequence is bounded.\n\n\n\n\n\n\n\n\nTheorem 1.1.3\n\n\n\nIf a sequence converges, its limit is unique.\n\n\n\n\n\n\n\n\nResult\n\n\n\nIf |x| &lt; 1, then \\lim_{n\\to\\infty} x^n = 0."
  },
  {
    "objectID": "qmd/layout.html",
    "href": "qmd/layout.html",
    "title": "Standard layout",
    "section": "",
    "text": "Add home page, intro to self, contact\nCustom ink-scape svg\nAdd images, dark mode priority, light mode later\nContent"
  },
  {
    "objectID": "qmd/layout.html#callouts",
    "href": "qmd/layout.html#callouts",
    "title": "Standard layout",
    "section": "Callouts",
    "text": "Callouts\nCallouts are used to section parts of the content together.\n\n\n\n\n\n\nDefinition\n\n\n\nDefinitions use .callout-note and explain a mathematical concept or term to be referenced. The definition callout should not be used for notation, but may include notation of the concept. The key term being discussed will be highlighted by applying {.definition} to the key term.\nThe key term will appear bold, and be colored blue in light mode, and cyan in dark mode."
  },
  {
    "objectID": "qmd/layout.html#latex",
    "href": "qmd/layout.html#latex",
    "title": "Standard layout",
    "section": "LaTeX",
    "text": "LaTeX\n\n\n\n\n\nSupply and Demand Model"
  },
  {
    "objectID": "qmd/layout.html#colors",
    "href": "qmd/layout.html#colors",
    "title": "Standard layout",
    "section": "Colors",
    "text": "Colors\nDark Mode: BG: #222222"
  },
  {
    "objectID": "qmd/layout.html#tikz",
    "href": "qmd/layout.html#tikz",
    "title": "Standard layout",
    "section": "Tikz",
    "text": "Tikz\nI use ‘knitr’, the engine for ‘R’ in order to render tikz images. Use fig-ext: svg for transparent backgrounds and svg outputs.\nTO-DO: Add light mode support (Wait for 1.5-1.6?)\n\n\n\n\n\nTest lines/text\n\n\n\n\n\n\n\n\n\nTest graph\n\n\n\n\n\nReal analysis exam 2\nIf \\(f^\\prime\\) is bounded on \\((a,b)\\), prove \\(f\\) is uniformly continuous on \\((a,b)\\).\nShow that any function with finite disconiutities is integerable.\nShow that if \\(f\\) is integerable \\(1/f\\) is integerable\nTaylor series nonsense\nNovemebr 17"
  },
  {
    "objectID": "qmd/layout.html#plot1",
    "href": "qmd/layout.html#plot1",
    "title": "Standard layout",
    "section": "Plot1",
    "text": "Plot1"
  },
  {
    "objectID": "qmd/layout.html#plot2",
    "href": "qmd/layout.html#plot2",
    "title": "Standard layout",
    "section": "Plot2",
    "text": "Plot2"
  },
  {
    "objectID": "qmd/realanal/integration/fundcalc.html",
    "href": "qmd/realanal/integration/fundcalc.html",
    "title": "Fundamental Theorem of Calculus",
    "section": "",
    "text": "Our main goal in this section will be to prove the Fundamental theorem of Calculus, which states that integration and derivation are inverse operations.\n\n\n\n\n\n\nTheorem 4.3.1 (Fundamental Theorem of Calculus I)\n\n\n\nIf f be integrable on [a,b], and for each x \\in [a,b], we set\n\nF(x) = \\int^x_a f(t)\\,dt,\n\nthen F is uniformly continuous on [a,b]. Furthermore if f is continuous at c \\in [a,b], then F is differentiable at c and\n\nF^\\prime(c) = f(c)\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\nSince f is Riemann integrable on [a,b], it is bounded by some B. We know f is uniformly continuous on [a,b], therefore given any x,y \\in [a,b] such that x &lt; y and |x-y| &lt; \\delta = \\varepsilon/B, then\n\\begin{align*}\n|F(x) - F(y)| &= \\left| \\int^y_a f - \\int^x_a f \\right|\\\\\n&= \\left| \\int^y_a f + \\int^a_x f \\right| \\text{ (Theorem $4.2.4$)}\\\\\n&= \\left| \\int^y_x f \\right| \\leq \\int^y_x |f| \\leq \\int^y_x B\\\\\n&\\leq \\frac{\\varepsilon}{B}B = \\varepsilon\n\\end{align*}\nThus F is uniformly continuous on [a,b].\n\nFurthermore, suppose f is continuous at some point c \\in [a,b]. Given any \\varepsilon &gt; 0, there exists \\delta &gt; 0 such that |f(t) - f(c)| &lt; \\varepsilon whenever t \\in [a,b] and |t-c| &lt; \\delta. Since f(c) is a constant, we write\n\nf(c) = \\frac{1}{x-c}\\int^x_c f(c) \\,dt, \\quad \\text{for } x \\not = c.\n\nSince f(c) is just a number, the integral evaluates to (x-c)f(c). Then for any x \\in [a,b] such that 0 &lt; |x-c| &lt; \\delta, we have\n\\begin{align*}\n\\left|\\frac{F(x) - F(c)}{x-c} - f(c)\\right| &= \\left| \\frac{1}{x-c} \\left[ \\int^x_a f - \\int^c_a f\\right] - f(c) \\right|\\\\\n&= \\left| \\frac{1}{x-c} \\int^x_c f - \\frac{1}{x-c} \\int^x_c f(c) \\right| \\text{ (Theorem $4.2.4$)}\\\\\n&= \\left| \\frac{1}{x-c} \\right| \\left| \\int^x_c [f - f(c)] \\right| \\\\\n&\\leq \\left| \\frac{1}{x-c} \\right| \\int^x_c \\left| f - f(c) \\right|\\\\\n&&lt;\\left| \\frac{1}{x-c} \\right| \\varepsilon |x-c| = \\varepsilon\n\\end{align*}\nIn the last step, because t is inbetween x and c, we know that |t - c| &lt; \\delta, and thus |f(t) - f(c)| &lt; \\varepsilon. Since \\varepsilon &gt; 0 was arbitrary, we conclude that\n\nF^\\prime(c) = \\lim_{x \\to c} \\frac{F(x) - F(c)}{x - c} = f(c)\n\n\n\n\n\n\n\n\n\n\nCorollary 4.3.2\n\n\n\nLet f be continuous on [a,b] and g be differentiable on [c,d], where g([c,d]) \\subseteq [a,b]. Define\n\nF(x) = \\int^{g(x)}_a f, \\quad \\text{for all $x \\in [c,d]$.}\n\nThen F is differentiable on [c,d] and F^\\prime(x) = g(f(x))g^\\prime(x).\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\nLet G(x) = \\int^x_a f for x \\in [a,b] so that F = G \\circ g on [c,d].\n\n\n\n\n\n\n\n\n\nTheorem 4.3.3 (Fundamental Theorem of Calculus II)\n\n\n\nLet f be differentiable on [a,b] and f^\\prime is Riemann integerable on [a,b]. Then\n\n\\int^b_a f^\\prime = f(b) - f(a).\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\nLet P = \\{x_0,\\dots,x_n\\} be a partition of [a,b]. On every subinterval [x_{i-1},x_i], apply Mean Value Theorem to obtain t_i \\in (x_{i-1},x_i) such that\n\nf(x_i) - f(x_{i-1}) = f^\\prime(t_i)(x_i - x_{i-1}).\n\nThus\n\nf(b) - f(a) = \\sum^n_{i=1} f(x_i) - f(x_{i-1}) = \\sum^n_{i=1} f^\\prime(t_i)\\Delta x_i.\n\nThen for all i, we have that m_i(f^\\prime) \\leq f^\\prime(t_i) \\leq M_i(f^\\prime). It follows that\n\nL(f^\\prime,P) \\leq f(b) - f(a) \\leq U(f^\\prime,P).\n\nSince this holds for every partition P, we also have\n\nL(f^\\prime) \\leq f(b) - f(a) \\leq U(f^\\prime).\n\nAnd since f^\\prime is assumed to be Riemann integrable on [a,b], we have\n\n\\int^b_a f^\\prime = f(b) - f(a)."
  },
  {
    "objectID": "qmd/layout.html#todo",
    "href": "qmd/layout.html#todo",
    "title": "Standard layout",
    "section": "",
    "text": "Add home page, intro to self, contact\nCustom ink-scape svg\nAdd images, dark mode priority, light mode later\nContent"
  },
  {
    "objectID": "qmd/realanal/integration/riemann.html#partitions",
    "href": "qmd/realanal/integration/riemann.html#partitions",
    "title": "Riemann Integral",
    "section": "Partitions",
    "text": "Partitions\n\n\n\n\n\n\nDefinition\n\n\n\nLet [a,b] be an interval in \\mathbb{R}. A partition P of [a,b] is a finite set of points \\{x_0,\\ldots,x_n\\} in [a,b] such that\n\na = x_0 &lt; x_1 &lt; \\cdots &lt; x_n = b.\n\n\n\nA partition serves to chop up our interval [a,b] into fintely many subintervals [x_{i-1},x_{i}]. We notate the length of the i^{th} sub-interval in our partition with \n\\Delta x_i = x_i - x_{i-1}.\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf P and Q are two partitions of [a,b] with P \\subseteq Q, then Q is called a refinement of P."
  },
  {
    "objectID": "qmd/realanal/integration/riemann.html#darboux-sums",
    "href": "qmd/realanal/integration/riemann.html#darboux-sums",
    "title": "Riemann Integral",
    "section": "Darboux sums",
    "text": "Darboux sums\n\n\n\n\n\n\nDefinition\n\n\n\nLet f be a bounded function on [a,b] and P = \\{x_0,\\ldots,x_n\\} be any partition on [a,b]. Let\n\nM_i(f) = \\sup\\{f(x) \\colon x \\in [x_{i-1},x_i]\\}\n and \nm_i(f) = \\inf\\{f(x) \\colon x \\in [x_{i-1},x_i]\\}\n\nfor each i \\in \\{1,\\ldots,n\\}. We define \nU(f,P) = \\sum^n_{i=1}M_i\\Delta x_i \\qquad L(f,P) = \\sum^n_{i=1}m_i\\Delta x_i\n\nas the Upper sum and Lower sum respectively.\n\n\nBecause we assume f to be bounded function, there exists a lower and upper bound on the interval [a,b]. Call these bounds m,M respectively (No relation to m_i,M_i). For any partition P of [a,b] we have \nm(b-a) \\leq L(f,p) \\leq U(f,p) \\leq M(b-a).\n\nThus we know the upper and lower sums for f exist, and form a bounded set.\n\n\n\n\n\n\nTheorem 4.1.1\n\n\n\nLet f be a bounded function on [a,b]. If P and Q are partitions of [a,b], and Q is a refinement of P, then\n\nL(f,P) \\leq L(f,Q) \\leq U(f,Q) \\leq U(f,P).\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\nThe middle inequality L(f,Q) \\leq U(f,Q) above follows from our definitions. To prove L(f,P) \\leq L(f,Q), suppose P = \\{x_0,\\ldots,x_k\\}, and consider the partition P* formed by adding x* to P, where x_{k-1} &lt; x* &lt; x_k for some k \\in \\{1,\\ldots,n\\}. Let\n\\begin{align*}\nt_1 &= \\inf \\{f(x) \\colon x \\in [x_{k-1},x*]\\}\\\\\nt_2 &= \\inf \\{f(x) \\colon x \\in [x*, x_k]\\}\n\\end{align*}\nThen t_1 \\geq m_k and t_2 \\geq m_k, where m_k = \\inf \\{f(x) \\colon x \\in [x_{k-1},x_k]\\} as defined previously. All of the terms in L(f,P*) and L(f,P) are the same except for those over the interval [x_{k-1},x_k]. Thus we have\n\\begin{align*}\nL(f,P*) - L(f,P) &= [t_1(x* - x_{k-1}) + t_2(x_k - x*)] - [m_k(x_k - x_{k-1})]\\\\\n&= (t_1 - m_k)(x* - x_{k-1}) + (t_2 - m_k)(x_k - x*).\n\\end{align*}\nThis final sum is positive since all of the terms are positive. Thus L(f,P) \\leq L(f,P*). If our partition Q contains r more points than P, we apply this argument r times to obtain L(f,P) \\leq L(f,Q).\nThe proof of U(f,Q) \\leq U(f,P) is similar.\n\n\n\n\n\n\n\n\n\nTheorem 4.1.2\n\n\n\nLet f be a bounded function on [a,b]. If P and Q are partitions of [a,b], then L(f,P) \\leq U(f,Q).\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\nIf P and Q are equal the proof is trivial, so we need only consider the case where P and Q are seperate partitions. Let R be the partition given by P \\cup Q. R is a refinement of both P and Q. By Theorem 4.1.1 we have\n\\begin{align*}\nL(f,P) \\leq L(f,R) &\\leq U(f,R) \\leq U(f,P)\\\\\nL(f,Q) \\leq L(f,R) &\\leq U(f,R) \\leq U(f,Q)\\\\\n\\end{align*}\nThus L(f,P) \\leq U(f,Q) for all partitions P and Q."
  },
  {
    "objectID": "qmd/realanal/integration/riemann.html#riemann-integral",
    "href": "qmd/realanal/integration/riemann.html#riemann-integral",
    "title": "Riemann Integral",
    "section": "Riemann Integral",
    "text": "Riemann Integral\n\n\n\n\n\n\nDefinition\n\n\n\nLet f be a bounded function defined on [a,b] and P be a partition on [a,b]. Then\n\nU(f) = \\inf \\{U(f,P)\\} \\qquad L(f) = \\sup \\{L(f,P)\\}\n\nare called the upper integral and lower integral of f on [a,b], respectively.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf L(f) = U(f), we say that f is Riemann integrable on [a,b], and notate the value with\n\n\\int^a_b f \\quad \\text{ or } \\quad \\int^a_b f(x) \\, dx.\n\nThis is known as the Riemann integral of f on [a,b].\n\n\nIf a function is Riemann integrable, then the value of the integral on [a,b] will be equal to the signed area between the function and the x-axis.\n\n\n\n\n\n\nCorollary 4.1.3\n\n\n\nLet f be a bounded function on [a,b]. Then L(f) \\leq U(f).\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\nIf P and Q are partitions of [a,b], we have that L(f,P) \\leq U(f,Q) by Theorem 4.1.2. Then it follows that U(f,Q) is an upper bound of the set defined by\n\nS = \\{L(f,P) \\colon P \\text{ partitions } [a,b]\\}.\n\nThus U(f,Q) \\geq \\sup S. That is, L(f) \\leq U(f,Q) for all partitions Q of [a,b]. Hence\n\nL(f) \\leq \\inf \\{U(f,Q) \\colon Q \\text{ partitions } [a,b]\\} = U(f).\n\n\n\n\nEssentially this Corollary states that every lower sum will be less than any upper sum.\nNot every function is going to be Riemann integrable.\n\n\n\n\n\n\nExample (Non-integrable functions)\n\n\n\nLet f \\colon [0,1] \\to \\mathbb{R} be defined\n\ng(x) = \\begin{cases}\n1, & \\text{if $x$ is rational}\\\\\n0, & \\text{if $x$ is irrational.}\n\\end{cases}\n\nLet P = \\{x_0,\\ldots,x_n\\} be any partition of [0,1]. Since each subinterval [x_{i-1},x_i] contains both rational and irrational points, we have M_i = 1 and m_i = 0 for all i \\in \\{1,\\dots,n\\}. Therefore\n\nU(f,P) = \\sum^n_{i=1}(1)\\Delta x_i = 1 \\qquad L(f,P) = \\sum^n_{i=1}(0)\\Delta x_i = 0.\n\nSince the lower and upper integrals are different for every partition P, f is non-integrable on [0,1]. This special function f is known as the Dirichlet function.\n\n\n\n\n\n\n\n\nTheorem 4.1.4 (Riemann integrablility Criterion)\n\n\n\nLet f be a bounded function on [a,b]. Then f is integrable if and only if for each \\varepsilon &gt; 0 there exists a partition P of [a,b] such that\n\nU(f,P) - L(f,P) &lt; \\varepsilon.\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\n\nForward direction\nSuppose f is integrable, meaning L(f) = U(f). Given any \\varepsilon &gt; 0, there exists a partition P_1 of [a,b] such that\n\nL(f,P_1) &gt; L(f) - \\frac{\\varepsilon}{2}.\n\nThis follows since L(f) is a supremum. Similarly, there exists a partition P_2 of [a,b] such that\n\nU(f,P_2) &lt; U(f) + \\frac{\\varepsilon}{2}.\n\nLet P = P_1 \\cup P_2. Then by Theorem 4.1.1 we have\n\\begin{align*}\nU(f,P) - L(f,P) &\\leq U(f,P_2) - L(f,P_1)\\\\\n&&lt; \\left[U(f) + \\frac{\\varepsilon}{2}\\right] - \\left[L(f) - \\frac{\\varepsilon}{2}\\right]\\\\\n&= U(f) - L(f) + \\varepsilon = \\varepsilon.\n\\end{align*}\nTherefore f being integrable implies there exists P such that U(f,P) - L(f,P) &lt; \\varepsilon.\nReverse direction\nNow, suppose we have P such that U(f,P) - L(f,P) &lt; \\varepsilon. Then\n\nU(f) \\leq U(f,P) &lt; L(f,P) + \\varepsilon \\leq L(f) + \\varepsilon.\n\nSince \\varepsilon &gt; 0 is arbitrary, we have U(f) \\leq L(f). By Theorem 4.1.3 we have that L(f) \\leq U(f). Thus L(f) = U(f), and f is Riemann integrable."
  },
  {
    "objectID": "qmd/realanal/differentiation/mvt.html",
    "href": "qmd/realanal/differentiation/mvt.html",
    "title": "Mean Value Theorem",
    "section": "",
    "text": "Theorem 3.2.1\n\n\n\nIf f is differentiable on an open interval (a,b) and f assumes its maximum or minimum at a point c \\in (a,b), then f^\\prime(c) = 0.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nSuppose that f assumes its maximum at c. That is, f(x) \\leq f(c) for all x \\in (a,b). Let (x_n) be a sequence converging to c such that a &lt; x_n &lt; c for all n. Since f is differentiable at c, the sequence\n\n\\left( \\frac{f(x_n) - f(c)}{x_n - c} \\right)\n\nconverges to f^\\prime(c). Since f(x_n) \\leq f(c) and x_n \\leq c, each term in our above sequence is nonnegative. Thus f^\\prime(c) \\geq 0.\nWe repeat this argument with a sequence (y_n), such that c &lt; y_n &lt; b for all n. Each term in the sequence\n\n\\left( \\frac{f(y_n) - f(c)}{y_n - c} \\right)\n\nwill be nonpositive, so f^\\prime(c) \\leq 0. We therefore conclude that f^\\prime(c) = 0. If f has a minimum at c, we apply the baove results to the function -f.\n\n\n\n\n\n\n\n\n\nTheorem 3.2.2 (Rolle’s Theorem)\n\n\n\nLet f be a continuous function on [a,b] that is differentiable on (a,b) and such that f(a) = f(b). Then there exists at least one point c in (a,b) such that f^\\prime(c) = 0.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nSince f is continuous on a compact interval [a,b], f obtains a minumum x_1 and maximum x_2 by the Extreme Value Theorem.\nIf x_1,x_2 are both endpoints of [a,b], then the function is a constant, and f^\\prime(x) = 0 for all x \\in [a,b].\nOtherwise, f assumes either a minimum or maximum at some point c \\in (a,b), and by Theorem 3.2.1, f^\\prime(c) = 0.\n\n\n\n\n\n\n\n\n\nTheorem 3.2.3 (Mean Value Theorem)\n\n\n\nLet f be a continuous function on [a,b] that is differentiable on (a,b). Then there exists at least one point c \\in (a,b) such that\n\nf^\\prime(c) = \\frac{f(b) - f(a)}{b-a}.\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLet g(x) be a function whose graph is the chord between f(a) and f(b). More formally\n\ng(x) = \\frac{f(b)-f(a)}{b-a}(x-a) + f(a), \\quad \\text{for all $x \\in [a,b]$}.\n\nThen the function h = f - g is continuous on [a,b] and differentiable on (a,b). Since f(a) = g(a) and f(b) = g(b), we have that h(a) = h(b) = 0. Applying Rolle’s Theorem we see that for some c \\in (a,b),\n\n0 = h^\\prime(c) = f^\\prime(c) - g^\\prime(c) = f^\\prime(c) - \\frac{f(b) - f(a)}{b-a}.\n\nThus\n\nf^\\prime(c) = \\frac{f(b)-f(a)}{b-a}.\n\n\n\n\n\n\n\n\n\n\nTheorem 3.2.4\n\n\n\nLet f be a continuous function on [a,b] that is differentiable on (a,b). If f^\\prime(x) = 0 for all x \\in (a,b), then f is constant on [a,b].\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nProof by Contradiction\nSuppose f were not constant on [a,b]. Then there exists two points a \\leq x_1 &lt; x_2 \\leq b such that f(x_1) \\not = f(x_2). But then by MVT, for some c \\in (x_1,x_2) there exists\n\nf^\\prime(c) = \\frac{f(x_2) - f(x_1)}{x_2 - x_1} \\not = 0\n\nThus a contradiction.\n\n\n\n\n\n\n\n\n\nCorollary 3.2.5\n\n\n\nLet f,g be continuous on [a,b] and differentiable on (a,b). Suppose that f^\\prime(x) = g^\\prime(x) for all x \\in (a,b). Then there exists a constant C such that\n\nf(x) = g(x) + C \\quad \\text{ for all $x \\in [a,b]$}\n\n\n\n\n\n\n\n\n\nProof (to-do)\n\n\n\n\n\nDirect Proof\nApply Theorem 3.2.4 to -g.\n\n\n\n\n\n\n\n\n\nTheorem 3.2.6\n\n\n\nLet f be differentiable on I. Then\n(a) if f^\\prime(x) &gt; 0 for all x \\in I, then f is strictly increasing on I, and\n(b) if f^\\prime(x) &lt; 0 for all x \\in I, then f is strictly decreasing on I.\n\n\n\n\n\n\n\n\nProof (to-do)\n\n\n\n\n\nDirect Proof\n\n\n\n\n\n\n\n\n\nTheorem 3.2.7 (Intermediate Value Theorem for Derivatives)\n\n\n\nLet f be differentiable on [a,b] and suppose there exists a number k between f^\\prime(a) and f^\\prime(b). Then there exists a point c \\in (a,b) such that f^\\prime(c) = k.\n(a) if f^\\prime(x) &gt; 0 for all x \\in I, then f is strictly increasing on I, and\n(b) if f^\\prime(x) &lt; 0 for all x \\in I, then f is strictly decreasing on I.\n\n\n\n\n\n\n\n\nProof (to-do)\n\n\n\n\n\nDirect Proof"
  },
  {
    "objectID": "qmd/realanal/differentiation/lhospital.html",
    "href": "qmd/realanal/differentiation/lhospital.html",
    "title": "L’Hospitals Rule",
    "section": "",
    "text": "Theorem 3.3.1 (Cauchy Mean Value Theorem)\n\n\n\nIf f and g be functions that are continuous on [a,b] and differentiable on (a,b). Then there exists at least one point c \\in (a,b) such that\n\n[f(b) - f(a)]g^\\prime(c) = [g(b)-g(a)]f^\\prime(c).\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLet\n\nh(x) = [f(b) - f(a)]g(x) = [g(b)-g(a)]f(x) \\quad \\text{for all $x \\in [a,b]$}.\n\nThen h is continuous on [a,b] and differentiable on (a,b). Furthermore\n\nh(a) = f(b)g(a) - g(b)f(a) = h(b)\n\nThus by the Mean Value Theorem there exists c \\in (a,b) such that h^\\prime(c) = 0. That is,\n\nh^\\prime(c) = [f(b)-f(a)]g^\\prime(c) - [g(b)-g(a)]f^\\prime(c) = 0.\n\n\n\n\n\n\n\n\n\n\nTheorem 3.3.2 (L’Hospitals Rule)\n\n\n\nLet f and g be differentiable on (a,\\infty). Suppose that \\lim_{x \\to \\infty}f(x) = \\lim_{x \\to \\infty}g(x) = \\infty and that g^\\prime(x) \\not = 0 for x \\in (a,\\infty). If\n\n\\lim_{x \\to \\infty} \\frac{f^\\prime(x)}{g^\\prime(x)} = L, \\quad\n\\text{where $L \\in \\mathbb{R}$},\n\nthen\n\n\\lim_{x\\to\\infty} \\frac{f(x)}{g(x)} = L.\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nGiven \\varepsilon &gt; 0, there exists an N_1 &gt; a such that x &gt; N_1 implies that\n\n\\left|  \\frac{f^\\prime(x)}{g^\\prime(x)} - L \\right| &lt; \\frac{\\varepsilon}{2}.\n\nSince \\lim_{x\\to\\infty} f(x) = \\lim_{x\\to\\infty} g(x) = \\infty, there exists an N_2 &gt; N_1 such that x &gt; N_2 implies that f(x) &gt; 0, and g(x) &gt; 0.\nFurthermore, there exists N_3 &gt; N_2 such that x &gt; N_3 implies that f(x) &gt; f(N_2) and g(x) &gt; g(N_2). For any point x &gt; N_3, the Cauchy mean value theorem implies that there exists some point c in (N_2,x) such that\n\n\\frac{f^\\prime(c)}{g^\\prime(c)} = \\frac{f(x) - f(N_2)}{g(x) - g(N_2)} = \\frac{f(x)}{g(x)} \\frac{1 - f(N_2)/f(x)}{1 - g(N_2)/g(x)}.\n\nBut then for x &gt; N_3 we have\n\n\\frac{f(x)}{g(x)} = \\frac{f^\\prime(c)}{g^\\prime(c)} F(x) \\quad \\text{where } F(x) = \\frac{1 - g(N_2)/g(x)}{1-f(N_2)/f(x)}."
  },
  {
    "objectID": "qmd/realanal/integration.html#citations",
    "href": "qmd/realanal/integration.html#citations",
    "title": "Integration",
    "section": "Citations",
    "text": "Citations\n[Ha01] Hammarström, O. (2016). Origins of Integration (Dissertation)."
  },
  {
    "objectID": "qmd/realanal/integration.html#origins",
    "href": "qmd/realanal/integration.html#origins",
    "title": "Integration",
    "section": "Origins",
    "text": "Origins\n\nPre-calculus\nThe concept of integration has been used since antiquity, due to its connections with geometry. Democritus of Thrace (c. 460BC - 370BC) considered the use of infinitely small slices of a cone in order to calculate it’s volume, and Eudoxus of Cnidus (c. 390BC - 340BC) proved his formulas through his method of exhaustion. This method was used to calculate the area and volume of numerous shapes and solids, but “there was no general procedure that could be applied with minimal modifications to any problem”1\nSimilar and independent methods for calculating volume were discovered by Liu Hui (c. 225 - 295) and used to calculate the volume of a sphere by Zu Chongzhi (c. 429 - 500) and Zu Geng (c. 480 - 525).\nAlhazen of Buyid (c. 965 - 1040), known as the “father of modern optics” developed an approach to calculate the area of the curve given by y = x^k, for any positive k; which is equivalant to calculating\n\n\\int x^k \\, dx.\n\nIt was not until the 17th century however that advancements in integration and infinity were discovered. Bonaventura Cavalieri (1598-1647) developed the method of indivisibles, which allowed for relating the volume of a 3-dimensional shape to the area of its 2-dimensional slices.\nCavalieri published his work in two texts, Geometria, which consisted of seven books and 700 pages, and Exercitationes, consisting of six books. These books however, being very long and difficult to follow (as Cavalieri did not use standard notation), were not well disseminated to the mathematical community. Cavalieri wrote these texts explicitly avoiding infinite sums, as the concept was not well founded and we wanted to maintain rigour in his writing, however due to the nature of his writing many mathematicians interpreted the method of indivisibles as one relating to infinitesimals.\n\n…while Cavalieri’s method of indivisibles, as he constructed it, did not directly give rise to modern calculus, it, and the interpretations other mathematicians made of it, helped stimulate research in the area, and was no doubt a significant development in the history of integration.2\n\n\n\nLeibniz and Newton\nIn the 17th century it was discovered by Isaac Newton (1643 - 1727) and Gottfried Leibnitz (1646 - 1716) that the area under a curve given by a function f(x), is directly related to the rate of change of the curve, known as the Fundemental Theorem of Calculus. Their work eventually led to the discovery of calculus, and enacted a major controversy as to who had first invented the discipline.3\nBecause of Fundemental Theorem of Calculus, the integral was generally seen as simply the ‘anti-derivative’ of a function, which simply happened to be related to an infinite summation. Additionally, their definitions of integration involved infinitely small numbers called infinitesimals, which did not obey the Archimedean property. This was also the subject of controversy for many years."
  },
  {
    "objectID": "qmd/realanal/integration.html#footnotes",
    "href": "qmd/realanal/integration.html#footnotes",
    "title": "Integration",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHammarström, O. (2016). Origins of Integration (Dissertation) p.5↩︎\nHammarström, O. (2016). Origins of Integration (Dissertation) p.44↩︎\nWikipedia has an article discussing the controversy.↩︎"
  },
  {
    "objectID": "qmd/realanal/integration.html#citations-change-to-bibtex",
    "href": "qmd/realanal/integration.html#citations-change-to-bibtex",
    "title": "Integration",
    "section": "Citations (Change to bibtex)",
    "text": "Citations (Change to bibtex)\n[Ha01] Hammarström, O. (2016). Origins of Integration (Dissertation)."
  },
  {
    "objectID": "qmd/realanal/infinite-series/converge.html",
    "href": "qmd/realanal/infinite-series/converge.html",
    "title": "Convergence of Infinite Series",
    "section": "",
    "text": "Infinite series are essentially sequences formed by summing the terms of another sequence. In this section we define what infinite series are, and what it means for them to converge."
  },
  {
    "objectID": "qmd/pde/introduction.html#exam-3-review",
    "href": "qmd/pde/introduction.html#exam-3-review",
    "title": "Partial differential equations",
    "section": "Exam 3 review",
    "text": "Exam 3 review\n\nFourier Series\n\n– Derivatives of fourier\n– Sin and cosine\n– Integrals of fourier series\n\nWave equation\n\n– Find solutions using sep of var\n– Boundary conditions\n– Initial conditions from solution\n– Solutions from int. con\n\nu(x,t) = \\sum^\\infty_{n=1} \\sin\\left(\\frac{n\\pi x}{L}\\right) \\left(  A_n\\cos\\left( \\frac{n\\pi ct}{L} \\right)  + B_n \\sin \\left( \\frac{n\\pi ct}{L} \\right)\\right)\n\nWe convert\n\n_n\\cos\\left( \\frac{n\\pi ct}{L} \\right)  + B_n \\sin \\left( \\frac{n\\pi ct}{L} \\right)\n\nTo\n\nR\\sin \\left( \\frac{n\\pi ct}{L} + \\theta \\right)\n\nWhere R = \\sqrt{A^2_N + B^2_n} and \\theta = \\arctan(A_n/B_n).\nNote that\n\n\\sin\\left( \\frac{n\\pi x}{L} \\right)\\left( R\\sin \\left( \\frac{n\\pi ct}{L} + \\theta \\right)\n\\right) = n^{th} \\text{ node}\n\n\nWhere a node\n\n= A_n\\sin \\left( \\frac{n\\pi x}{L} \\right)\\cos \\left( \\frac{n\\pi ct}{L} \\right) + B_n \\sin \\left( \\frac{n\\pi x}{L} \\right)\\sin \\left( \\frac{n\\pi ct}{L} \\right)\n\nUsing the formula\n\n\\cos \\alpha - \\cos \\beta = -2\\sin\\left( \\frac{\\alpha + \\beta}{2} \\right)\\sin\\left( \\frac{\\alpha - \\beta}{2}\\right)\n\n\n\\frac{1}{2}\\cos \\beta - \\frac{1}{2} \\cos \\alpha = \\sin\\left( \\frac{\\alpha + \\beta}{2} \\right)\\sin\\left( \\frac{\\alpha - \\beta}{2}\\right)\n\nSo we set\n\n\\frac{\\alpha + \\beta}{2} = \\frac{n\\pi x}{L} \\quad \\text{and} \\quad \\frac{\\alpha - \\beta}{2} = \\frac{n\\pi ct}{L}\n\nAdding them together we get\n\n\\frac{\\alpha + \\beta}{2} + \\frac{\\alpha - \\beta}{2} = \\alpha = \\frac{n\\pi}{L}(x + ct)\n\nSubtracting gives used\n\n\\frac{\\alpha + \\beta}{2} - \\frac{\\alpha - \\beta}{2} = \\beta = \\frac{n\\pi}{L}(x - ct)\n\nThus we get\n\n\\sin \\left( \\frac{n\\pi x}{L} \\right)\\sin \\left( \\frac{n\\pi ct}{L} \\right)  = \\frac{1}{2}\\cos \\left( \\frac{n\\pi}{L}(x-ct) \\right) - \\frac{1}{2} \\cos \\left( \\frac{n\\pi}{L} (x+ct) \\right)\n\nWhen t = 0, we get\n\n\\frac{1}{2}\\cos \\left( \\frac{n\\pi}{L}(x-ct) \\right) - \\frac{1}{2} \\cos \\left( \\frac{n\\pi}{L} (x+ct) \\right) = 0\n\nThe solution of the wave equation is the sum of two traveling waves, one to the left and one to the right.\n\nBy conservation of energy we have\n\n\\frac{d^2u}{dt^2} = c^2\\frac{d^2u}{dx^2}\n\nWe have\n\n\\int^L_0 \\frac{\\partial^2u}{\\partial t^2} \\cdot \\frac{\\partial u}{\\partial t} \\, dx = \\int^L_0 c^2\\frac{\\partial^2u}{\\partial x^2} \\cdot \\frac{\\partial u}{\\partial t} \\, dx\n\nNote that\n\n\\frac{\\partial^2u}{\\partial t^2} \\cdot \\frac{\\partial u}{\\partial t} = \\frac{\\partial}{\\partial t}\\left( \\frac{1}{2} \\left(\\frac{\\partial u}{\\partial t}\\right)^2\\right)\n\nThus\n\n\\int^L_0 \\frac{\\partial^2u}{\\partial t^2} \\cdot \\frac{\\partial u}{\\partial t} \\, dx = \\int^L_0 \\frac{\\partial}{\\partial t}\\left( \\frac{1}{2} \\left(\\frac{\\partial u}{\\partial t}\\right)^2\\right) \\, dx\n\nAnd\n\n\\int^L_0 c^2\\frac{\\partial^2u}{\\partial x^2} \\cdot \\frac{\\partial u}{\\partial t} \\, dx = \\frac{\\partial u}{\\partial x} \\frac{\\partial u}{\\partial t}\n\nThe solution is also the infinite sum of some\n\n\\text{Solution } = \\sum^\\infty_{n=1} \\text{ Nodes}"
  },
  {
    "objectID": "qmd/realanal/infinite-series/infser.html",
    "href": "qmd/realanal/infinite-series/infser.html",
    "title": "Infinite Series",
    "section": "",
    "text": "Definition\n\n\n\nLet (a_n) be a sequence of real numbers. A partial sum of (a_n) is given by\n\na_1 + a_2 + \\cdots a_k\n\nfor some k \\leq n.\n\n\n\n\n\n\n\n\nNotation\n\n\n\nA partial sum\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nLet (a_n) be a sequence of real numbers. Let the sequence (s_n)\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf (s_n) converges to a real number s, we say the series \\sum^\\infty_{n=1}a_n is convergent and write\n\n\\sum^\\infty_{n=1}a_n = s.\n\nIf (s_n) does not converge, the series \\sum^\\infty_{n=1}a_n is divergent. If\n\\begin{align*}\n\\lim_{n \\to \\infty} s_n &= +\\infty \\quad \\text{then} \\quad \\sum^\\infty_{n=1}a_n = +\\infty \\quad \\text{ and}\\\\\n\\lim_{n \\to \\infty} s_n &= -\\infty \\quad \\text{then} \\quad \\sum^\\infty_{n=1}a_n = -\\infty.\n\\end{align*}\n\n\n\n\n\n\n\n\nExample (Harmonic Series)\n\n\n\nThe harmonic series is defined\n\n\\sum^\\infty_{n=1} \\frac{1}{n}\n\nand has the partial sums s_n = 1 + 1/2 + \\cdots + 1/n. The sequence (s_n) is divergent, and thus the harmonic series is divergent.\n\n\n\n\n\n\n\n\nExample (Telescoping Series)\n\n\n\nThe series\n\n\\sum^\\infty_{n=1} \\frac{1}{n(n+1)}\n\nhas the partial sum\n\ns_n = \\frac{1}{2} + \\frac{1}{6} + \\frac{1}{12} + \\cdots + \\frac{1}{n(n+1)}\n\n\n\n\n\n\n\n\n\nTheorem 5.1.1\n\n\n\nLet \\sum a_n = s and \\sum b_n = t. Then\n(a) \\sum (a_n + b_n) = s + t and\n(b) \\sum (ka_n) = ks for every k \\in \\mathbb{R}.\n\n\n\n\n\n\n\n\nTheorem 5.1.2\n\n\n\nIf \\sum a_n is a convergent series, then \\lim_{n \\to \\infty} a_n = 0.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nIf \\sum a_n is a convergent series, then the sequence of partial sums (s_n) must have a finite limit. Since a_n = s_n - s_{n-1}, we have \\lim a_n = \\lim s_n - \\lim s_{n-1} = 0.\n\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nThe infinite series \\sum a_n converges if and only if for each \\varepsilon &gt; 0, there exists a natural number N such that if n \\leq m \\leq N, then\n\n|a_m + a_{m+1} + \\cdots + a+{n}| = |s_n - s_{m-1}| &lt; \\varepsilon.\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLater.\n\n\n\n\n\n\n\n\n\nTheorem (Comparison Test)\n\n\n\nLet \\sum a_n and \\sum b_n be infinite series such that a_n,b_n \\leq 0 for all n. Then\n(a) If \\sum a_n converges and 0 \\leq b_n \\leq a_n for all n, then \\sum b_n converges.\n(b) If \\sum a_n = +and 0 \\leq a_n \\leq b_n for all n, then \\sum b_n = + \\infty.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(a) Because s_{a_n} is monotone and bounded, s_{b_n} converges.\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nIf \\sum |a_n| converges, then \\sum a_n is absolutly convergent, or that the sum converges absolutly.\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nIf a series converges absolutly, then it converges.\n\n\n\n\n\n\n\n\nTheorem (Ratio Test)\n\n\n\nIf \\sum a_n, a_n \\not = 0\n(a) If \\limsup |a_{n+1}/a_n| &lt; 1, the the series is absolutly convergent.\n(b) If \\liminf |a_{n+1}/a_n| &gt; 1 then the series diverges.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTheorem (Integral test)\n\n\n\nLet f be a continuous function defined on [0,\\infty) and suppose that f is positive and decreasing. Then the series \\sum f(n) converges if and only if\n\n\\lim_{n \\to \\infty} \\left( \\int^n_1 f(x) \\,dx \\right)\n\n\n\n\n\n\n\n\n\nTheorem (Alternating series test)\n\n\n\nIf (a_n) is a decreasing sequence of positive numbers and \\lim a_n = 0, then the series \\sum (-1)^{n}a_n converges."
  },
  {
    "objectID": "qmd/realanal/infinite-series/converge.html#definition",
    "href": "qmd/realanal/infinite-series/converge.html#definition",
    "title": "Convergence of Infinite Series",
    "section": "Definition",
    "text": "Definition\n\n\n\n\n\n\nDefinition\n\n\n\nLet (a_n) be a sequence of real numbers. A partial sum of (a_n) is given by\n\na_{m} + a_{m+1} + \\cdots a_{n}\n\nwhere m \\leq n.\n\n\nPartial sums are a partial collection of terms of the sequence added together.\n\n\n\n\n\n\nNotation\n\n\n\nLet (a_n) be a sequence of real numbers. We notate the partial sum from m to n by\n\n\\sum^n_{k=m} a_k\n\nWe may also save time by letting\n\n\\sum a_n := \\sum^{\\infty}_{n=0} a_n \\text{ or } \\sum^{\\infty}_{n=1} a_n\n\nwhere are index starts at 0 or 1, whichever makes sense in context.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nLet (a_n) be a sequence of real numbers. We define a sequence (s_n) of partial sums by\n\ns_n = \\sum^n_{k=1} a_k = a_1 + a_2 + \\cdots + a_n.\n\nWe refer to the sequence (s_n) as an infinite series.\n\n\nWe define (s_n) as a sequence of partial sums in order to formalize the series into a sequence, which we’ve already studied. All of our previous theorems will apply to (s_n), and therefore we can prove many theorems essentially for free!"
  },
  {
    "objectID": "qmd/realanal/infinite-series/converge.html#convergence",
    "href": "qmd/realanal/infinite-series/converge.html#convergence",
    "title": "Convergence of Infinite Series",
    "section": "Convergence",
    "text": "Convergence\n\n\n\n\n\n\nDefinition\n\n\n\nIf (s_n) converges to a real number s, we say the series \\sum a_n is convergent and write\n\n\\sum^\\infty_{n=1}a_n = s.\n\nIf (s_n) does not converge, the series \\sum^\\infty_{n=1}a_n is divergent. If\n\\begin{align*}\n\\lim_{n \\to \\infty} s_n &= +\\infty \\quad \\text{then} \\quad \\sum^\\infty_{n=1}a_n = +\\infty \\quad \\text{ and}\\\\\n\\lim_{n \\to \\infty} s_n &= -\\infty \\quad \\text{then} \\quad \\sum^\\infty_{n=1}a_n = -\\infty.\n\\end{align*}\n\n\nThe question of whether or not a series converges is of great interest to mathematicians.\n\n\n\n\n\n\nExample (Harmonic Series)\n\n\n\nThe harmonic series is defined\n\n\\sum^\\infty_{n=1} \\frac{1}{n}\n\nThe sequence (s_n) is divergent, and thus the harmonic series is divergent. This is\n\n\n\n\n\n\n\n\nExample (Telescoping Series)\n\n\n\nThe series\n\n\\sum^\\infty_{n=1} \\frac{1}{n(n+1)}\n\nhas the partial sum\n\ns_n = \\frac{1}{2} + \\frac{1}{6} + \\frac{1}{12} + \\cdots + \\frac{1}{n(n+1)}\n\n\n\n\n\n\n\n\n\nTheorem 5.1.1 (Algebraic properties of Series)\n\n\n\nLet \\sum a_n = s and \\sum b_n = t. Then\n(a) \\sum (a_n + b_n) = s + t and\n(b) \\sum (ka_n) = ks for every k \\in \\mathbb{R}.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n(a) By converting our series to limits, we obtain \n\\sum (a_n + b_n) = \\lim (s_{a_n} + s_{b_n}) = s + t.\n\n\n(b) Similarly, we obtain\n\n\\sum (ka_n) = \\lim ks_{a_n} = k\\lim s_{a_n} = ks.\n\n\n\n\n\n\n\n\n\n\nTheorem 5.1.2\n\n\n\nIf \\sum a_n is a convergent series, then \\lim_{n \\to \\infty} a_n = 0.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nIf \\sum a_n is a convergent series, then the sequence of partial sums (s_n) must have a finite limit.\nSince a_n = s_n - s_{n-1}, we have \\lim a_n = \\lim s_n - \\lim s_{n-1} = 0.\n\n\n\n\n\n\n\n\n\nTheorem 5.1.3 (Cauchy Criterion for Series)\n\n\n\nThe infinite series \\sum a_n converges if and only if for each \\varepsilon &gt; 0, there exists a natural number N such that if n \\geq m \\geq N, then\n\n|a_m + a_{m+1} + \\cdots + a_{n}| = |s_n - s_{m-1}| &lt; \\varepsilon.\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLet \\sum a_n be a convergent series. Then the sequence (s_n) of partial sums converges. By the Cauchy Convergent Criterion, (s_n) is Cauchy. Thus, for any \\varepsilon &gt; 0, there exists N \\in \\mathbb{N} such that m,n \\geq N implies |s_n - s_m| &lt; \\varepsilon. Hence, if n \\geq m \\geq N + 1, then m - 1 \\geq N, and |s_n - s_{m-1}| &lt; \\varepsilon as desired.\nConversly, for all \\varepsilon &gt; 0 let N exists such that n \\geq m \\geq N implies |s_n - s_{m-1}| &lt; \\varepsilon. Then for n &gt; m \\geq N we have m + 1 &gt; N, so that |s_n - s_m| &lt; \\varepsilon. This implies (s_n) is Cauchy, and therefore convergent."
  },
  {
    "objectID": "qmd/realanal/infinite-series/power.html",
    "href": "qmd/realanal/infinite-series/power.html",
    "title": "Power Series",
    "section": "",
    "text": "Definition\n\n\n\nLet (a_n) be a sequence of real numbers. The series\n\n\\sum^\\infty_{n=0} a_n x^n = a_0 + a_1x + a_2x^2 + \\cdots\n\nIs called the power series of a_n.\n\n\nPower series can be thought of as a generalization of polynomials, because given any polynomial\n\nP = a_0 + a_1 x + a_2 x^2 + \\cdots + a_n x^n\n\nWe can define a sequence\n\n(a_n) = (a_0,a_1,a_2,\\cdots,a_n,0,0,0,\\cdots)\n\nAnd then the power series of (a_n) will be equal to the polynomial P.\n\n\n\n\n\n\nNotation\n\n\n\nWe let \\mathbb{R}[x] denote a polynomial with real coeffients, and \\mathbb{R}[|x|] denote a power series with real coeffients.\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nLet (a_n) be a sequence of real numbers. Let \\alpha = \\limsup |a_n|^{1/n}. We define a function R such that\n\nR = \\begin{cases}\n\\frac{1}{\\alpha} & \\text{if } 0 &lt; \\alpha &lt; \\infty\\\\\n\\infty & \\text{if } \\alpha = 0\\\\\n0& \\text{if } \\alpha = \\infty\n\\end{cases}\n\nThe power series of (a_n)\n(a) Converges absolutly whenever |x| &lt; R, and\n(b) Diverges when |x| &gt; R."
  },
  {
    "objectID": "qmd/realanal/infinite-series/power.html#definition",
    "href": "qmd/realanal/infinite-series/power.html#definition",
    "title": "Power Series",
    "section": "",
    "text": "Definition\n\n\n\nLet (a_n) be a sequence of real numbers. The series\n\n\\sum^\\infty_{n=0} a_n x^n = a_0 + a_1x + a_2x^2 + \\cdots\n\nIs called the power series of a_n.\n\n\nPower series can be thought of as a generalization of polynomials, because given any polynomial\n\nP = a_0 + a_1 x + a_2 x^2 + \\cdots + a_n x^n\n\nWe can define a sequence\n\n(a_n) = (a_0,a_1,a_2,\\cdots,a_n,0,0,0,\\cdots)\n\nAnd then the power series of (a_n) will be equal to the polynomial P.\n\n\n\n\n\n\nNotation\n\n\n\nWe let \\mathbb{R}[x] denote a polynomial with real coeffients, and \\mathbb{R}[|x|] denote a power series with real coeffients.\n\n\n\n\n\n\n\n\nTheorem\n\n\n\nLet (a_n) be a sequence of real numbers. Let \\alpha = \\limsup |a_n|^{1/n}. We define a function R such that\n\nR = \\begin{cases}\n\\frac{1}{\\alpha} & \\text{if } 0 &lt; \\alpha &lt; \\infty\\\\\n\\infty & \\text{if } \\alpha = 0\\\\\n0& \\text{if } \\alpha = \\infty\n\\end{cases}\n\nThe power series of (a_n)\n(a) Converges absolutly whenever |x| &lt; R, and\n(b) Diverges when |x| &gt; R."
  },
  {
    "objectID": "qmd/foundations/intro.html",
    "href": "qmd/foundations/intro.html",
    "title": "Foundations",
    "section": "",
    "text": "For the purposes of this website, I will, unless explictily stated, be using \\textbf{ZFC} as the assumed set of axioms."
  },
  {
    "objectID": "qmd/foundations/intro.html#table-of-contents",
    "href": "qmd/foundations/intro.html#table-of-contents",
    "title": "Foundations",
    "section": "Table of Contents",
    "text": "Table of Contents"
  },
  {
    "objectID": "qmd/foundations/fundcalc.html",
    "href": "qmd/foundations/fundcalc.html",
    "title": "Axioms of ZFC",
    "section": "",
    "text": "Our main goal in this section will be to prove the Fundamental theorem of Calculus, which states that integration and derivation are inverse operations.\n\n\n\n\n\n\nTheorem 4.3.1 (Fundamental Theorem of Calculus I)\n\n\n\nIf f be integrable on [a,b], and for each x \\in [a,b], we set\n\nF(x) = \\int^x_a f(t)\\,dt,\n\nthen F is uniformly continuous on [a,b]. Furthermore if f is continuous at c \\in [a,b], then F is differentiable at c and\n\nF^\\prime(c) = f(c)\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\nSince f is Riemann integrable on [a,b], it is bounded by some B. We know f is uniformly continuous on [a,b], therefore given any x,y \\in [a,b] such that x &lt; y and |x-y| &lt; \\delta = \\varepsilon/B, then\n\\begin{align*}\n|F(x) - F(y)| &= \\left| \\int^y_a f - \\int^x_a f \\right|\\\\\n&= \\left| \\int^y_a f + \\int^a_x f \\right| \\text{ (Theorem $4.2.4$)}\\\\\n&= \\left| \\int^y_x f \\right| \\leq \\int^y_x |f| \\leq \\int^y_x B\\\\\n&\\leq \\frac{\\varepsilon}{B}B = \\varepsilon\n\\end{align*}\nThus F is uniformly continuous on [a,b].\n\nFurthermore, suppose f is continuous at some point c \\in [a,b]. Given any \\varepsilon &gt; 0, there exists \\delta &gt; 0 such that |f(t) - f(c)| &lt; \\varepsilon whenever t \\in [a,b] and |t-c| &lt; \\delta. Since f(c) is a constant, we write\n\nf(c) = \\frac{1}{x-c}\\int^x_c f(c) \\,dt, \\quad \\text{for } x \\not = c.\n\nSince f(c) is just a number, the integral evaluates to (x-c)f(c). Then for any x \\in [a,b] such that 0 &lt; |x-c| &lt; \\delta, we have\n\\begin{align*}\n\\left|\\frac{F(x) - F(c)}{x-c} - f(c)\\right| &= \\left| \\frac{1}{x-c} \\left[ \\int^x_a f - \\int^c_a f\\right] - f(c) \\right|\\\\\n&= \\left| \\frac{1}{x-c} \\int^x_c f - \\frac{1}{x-c} \\int^x_c f(c) \\right| \\text{ (Theorem $4.2.4$)}\\\\\n&= \\left| \\frac{1}{x-c} \\right| \\left| \\int^x_c [f - f(c)] \\right| \\\\\n&\\leq \\left| \\frac{1}{x-c} \\right| \\int^x_c \\left| f - f(c) \\right|\\\\\n&&lt;\\left| \\frac{1}{x-c} \\right| \\varepsilon |x-c| = \\varepsilon\n\\end{align*}\nIn the last step, because t is inbetween x and c, we know that |t - c| &lt; \\delta, and thus |f(t) - f(c)| &lt; \\varepsilon. Since \\varepsilon &gt; 0 was arbitrary, we conclude that\n\nF^\\prime(c) = \\lim_{x \\to c} \\frac{F(x) - F(c)}{x - c} = f(c)\n\n\n\n\n\n\n\n\n\n\nCorollary 4.3.2\n\n\n\nLet f be continuous on [a,b] and g be differentiable on [c,d], where g([c,d]) \\subseteq [a,b]. Define\n\nF(x) = \\int^{g(x)}_a f, \\quad \\text{for all $x \\in [c,d]$.}\n\nThen F is differentiable on [c,d] and F^\\prime(x) = g(f(x))g^\\prime(x).\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\nLet G(x) = \\int^x_a f for x \\in [a,b] so that F = G \\circ g on [c,d].\n\n\n\n\n\n\n\n\n\nTheorem 4.3.3 (Fundamental Theorem of Calculus II)\n\n\n\nLet f be differentiable on [a,b] and f^\\prime is Riemann integerable on [a,b]. Then\n\n\\int^b_a f^\\prime = f(b) - f(a).\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nDirect Proof\nLet P = \\{x_0,\\dots,x_n\\} be a partition of [a,b]. On every subinterval [x_{i-1},x_i], apply Mean Value Theorem to obtain t_i \\in (x_{i-1},x_i) such that\n\nf(x_i) - f(x_{i-1}) = f^\\prime(t_i)(x_i - x_{i-1}).\n\nThus\n\nf(b) - f(a) = \\sum^n_{i=1} f(x_i) - f(x_{i-1}) = \\sum^n_{i=1} f^\\prime(t_i)\\Delta x_i.\n\nThen for all i, we have that m_i(f^\\prime) \\leq f^\\prime(t_i) \\leq M_i(f^\\prime). It follows that\n\nL(f^\\prime,P) \\leq f(b) - f(a) \\leq U(f^\\prime,P).\n\nSince this holds for every partition P, we also have\n\nL(f^\\prime) \\leq f(b) - f(a) \\leq U(f^\\prime).\n\nAnd since f^\\prime is assumed to be Riemann integrable on [a,b], we have\n\n\\int^b_a f^\\prime = f(b) - f(a)."
  },
  {
    "objectID": "qmd/realanal/sequences/construction.html",
    "href": "qmd/realanal/sequences/construction.html",
    "title": "Construction",
    "section": "",
    "text": "In order to work with seqeunces, we must first have an understanding of what they are and how to construct them.\n\n\n\n\n\n\nDefinition\n\n\n\nA sequence is a function S whose domain is the set of natural numbers, \\mathbb{N}.\n\n\nInformally a sequence is simply a collection of numbers, such that the order matters. If you swap the positions of two values in a sequence, the result will not be equivalant to the original sequence.\n\n\n\n\n\n\nNotation\n\n\n\nA sequence S is notated (s_n) or as a list of elements\n\n(s_1,s_2,s_3,\\ldots)\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nThe function S \\colon \\mathbb{N} \\to \\mathbb{Q} such that n \\rightarrowtail \\frac{1}{n} is a sequence. We use the notation (1/n) as an abbreviation for\n\n\\left(1,\\frac{1}{2},\\frac{1}{3},\\ldots\\right)\n\nSimilarly, the sequence S \\colon \\mathbb{N} \\to \\mathbb{N} where n \\rightarrowtail 2n is denoted (2n), abbreviating\n\n(2,4,6,\\ldots)\n\n\n\nNormally we will consider sequences where the codomain is \\mathbb{R}."
  },
  {
    "objectID": "qmd/realanal/sequences/definition.html",
    "href": "qmd/realanal/sequences/definition.html",
    "title": "Definition",
    "section": "",
    "text": "Definition\n\n\n\nA sequence is a, possibly infinite, collection of numbers such that each number is indexed by a natural number.\n\n\nFor example, the following is a sequence\n\n(F_n) = \\left(1,1,2,3,5,8,13,\\dots\\right)\n\nknown as a the Fibbonachi sequence. We can denote each term by its placement, such that F_3 = 2, and F_7 = 13.\nFor the purposes of real analysis, we will formalize sequences as functions from subsets of the natural numbers to the reals.\n\n\n\n\n\n\nNotation\n\n\n\nLet f \\colon A \\to S be a function such that A \\subseteq \\mathbb{N}. We call this function a sequence. We choose some symbol, for example a, to represent the elements of the sequence.\nFor each n \\in A, let a_n denote f(n), and (a_n) denote f We may also denote a sequence (a_n) by listing all of its terms,\n\n(a_1,a_2,\\dots,a_n)."
  },
  {
    "objectID": "qmd/realanal/sequences.html#contents",
    "href": "qmd/realanal/sequences.html#contents",
    "title": "Sequences",
    "section": "Contents",
    "text": "Contents\n\nDefinition\nConvergence\n\n\n\n\n\n\n\nDefinition\n\n\n\nA sequence is a, possibly infinite, collection of numbers such that each number is indexed by a natural number.\n\n\nFor example, the following is a sequence\n\n(F_n) = \\left(1,1,2,3,5,8,13,\\dots\\right)\n\nknown as a the Fibbonachi sequence. We can denote each term by its placement, such that F_3 = 2, and F_7 = 13.\nFor the purposes of real analysis, we will formalize sequences as functions from subsets of the natural numbers to the reals.\n\n\n\n\n\n\nNotation\n\n\n\nLet f \\colon A \\to S be a function such that A \\subseteq \\mathbb{N}. We call this function a sequence. We choose some symbol, for example a, to represent the elements of the sequence.\nFor each n \\in A, let a_n denote f(n), and (a_n) denote f We may also denote a sequence (a_n) by listing all of its terms,\n\n(a_1,a_2,\\dots,a_n)."
  },
  {
    "objectID": "qmd/realanal/infinite-series/converge.html#recap",
    "href": "qmd/realanal/infinite-series/converge.html#recap",
    "title": "Convergence of Infinite Series",
    "section": "Recap",
    "text": "Recap\n\n\n\n\n\n\nTheorem 5.1.1 (Algebraic properties of Series)\n\n\n\nLet \\sum a_n = s and \\sum b_n = t. Then\n(a) \\sum (a_n + b_n) = s + t and\n(b) \\sum (ka_n) = ks for every k \\in \\mathbb{R}.\n\n\n\n\n\n\n\n\nTheorem 5.1.2\n\n\n\nIf \\sum a_n is a convergent series, then \\lim_{n \\to \\infty} a_n = 0.\n\n\n\n\n\n\n\n\nTheorem 5.1.3 (Cauchy Criterion for Series)\n\n\n\nThe infinite series \\sum a_n converges if and only if for each \\varepsilon &gt; 0, there exists a natural number N such that if n \\geq m \\geq N, then\n\n|a_m + a_{m+1} + \\cdots + a_{n}| = |s_n - s_{m-1}| &lt; \\varepsilon."
  }
]